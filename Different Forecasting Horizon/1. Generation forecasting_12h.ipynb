{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "60c4cdbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "import pandas as pd\n",
    "import codecs\n",
    "import numpy as np\n",
    "import math\n",
    "import csv\n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.metrics import recall_score, precision_score # New\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn import preprocessing\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow.keras.preprocessing\n",
    "#from tensorflow.keras.callbacks import ModelCheckpoint, CSVLogger, EarlyStopping, LearningRateScheduler, ReduceLROnPlateau\n",
    "from tensorflow.keras.models import Sequential, Model\n",
    "from tensorflow.keras.layers import Dense, Input, Flatten, Add, Multiply, Subtract\n",
    "from tensorflow.keras import backend as K\n",
    "from tensorflow.keras.layers import Activation, BatchNormalization\n",
    "# regularizers\n",
    "from tensorflow.keras.layers import Conv1D, Conv2D\n",
    "from tensorflow.keras.layers import MaxPooling1D\n",
    "from tensorflow.keras.layers import concatenate\n",
    "from tensorflow.keras.layers import LSTM, Bidirectional\n",
    "from tensorflow.keras.utils import plot_model\n",
    "from tensorflow.keras.layers import Dropout, SpatialDropout1D\n",
    "from scipy import signal\n",
    "import openpyxl\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "from matplotlib import pylab as plt\n",
    "import matplotlib.dates as mdates\n",
    "import seaborn as sns\n",
    "import sklearn\n",
    "from sklearn.model_selection import train_test_split\n",
    "from numpy.linalg import svd\n",
    "import gc\n",
    "from keijzer import *\n",
    "from tensorflow import keras\n",
    "from keras.models import Model\n",
    "from keras.layers import *\n",
    "from tensorflow.keras.optimizers import Adam,SGD\n",
    "from keras.layers import Dense, Input, Flatten, Add, concatenate, Dropout, Activation, Multiply, Embedding, Layer, Reshape\n",
    "from keras.layers import LSTM, Bidirectional, GlobalMaxPooling1D, GlobalAveragePooling1D  \n",
    "from keras.layers import Conv1D, AveragePooling1D, MaxPooling1D\n",
    "#from keras.ops import convert_to_tensor, convert_to_numpy\n",
    "#from keras.utils import plot_model\n",
    "from keras import activations\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from keras.callbacks import ModelCheckpoint, CSVLogger, EarlyStopping, LearningRateScheduler, ReduceLROnPlateau\n",
    "import math\n",
    "\n",
    "class LossHistory(tensorflow.keras.callbacks.Callback):  # history = LossHistory()\n",
    "    def init(self):  # history.init()\n",
    "        self.losses = []\n",
    "        # self.accs = []\n",
    "        self.val_losses = []\n",
    "        # self.val_accs = []\n",
    "        self.rmses = []\n",
    "        self.mses = []\n",
    "        self.maes = []\n",
    "        self.mapes = []\n",
    "        self.val_rmses = []\n",
    "        self.val_mses = []\n",
    "        self.val_maes = []\n",
    "        self.val_mapes = []\n",
    "\n",
    "    def on_epoch_end(self, batch, logs={}):\n",
    "        self.losses.append(logs.get('loss'))\n",
    "        # self.accs.append(logs.get('acc'))\n",
    "        self.val_losses.append(logs.get('val_loss'))\n",
    "        # self.val_accs.append(logs.get('val_accuracy\n",
    "        self.rmses.append(logs.get('root_mean_squared_error'))\n",
    "        self.mses.append(logs.get('mean_squared_error'))\n",
    "        self.maes.append(logs.get('mean_absolute_error'))\n",
    "        self.mapes.append(logs.get('mean_absolute_percentage_error'))\n",
    "        self.val_rmses.append(logs.get('val_root_mean_squared_error'))\n",
    "        self.val_mses.append(logs.get('val_mean_squared_error'))\n",
    "        self.val_maes.append(logs.get('val_mean_absolute_error'))\n",
    "        self.val_mapes.append(logs.get('val_mean_absolute_percentage_error'))\n",
    "\n",
    "\n",
    "\n",
    "def root_squared_mean_error(y_true, y_pred):\n",
    "    return K.mean((K.abs(y_pred - y_true))*K.square(y_true-K.mean(y_true)))*100\n",
    "\n",
    "def mse_mae(y_true, y_pred):\n",
    "    return K.mean(K.square(y_pred - y_true))+K.mean(K.abs(y_pred - y_true))\n",
    "\n",
    "from keras.layers.advanced_activations import PReLU\n",
    "\n",
    "def mean_absolute_percentage_error(y_true, y_pred):\n",
    "    y_true, y_pred = np.array(y_true), np.array(y_pred)\n",
    "    return np.mean(np.abs((y_true - y_pred) / y_true)) * 100\n",
    "\n",
    "def root_mean_squared_error(y_true, y_pred):\n",
    "        return K.sqrt(K.mean(K.square(y_pred - y_true))) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0bc74014",
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy as sc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c33c483a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = '0' # 여러개 사용시 '0,1,2' 식으로 하나의 문자열에 입력\n",
    "gpus = tf.config.experimental.list_physical_devices('GPU') # 호스트 러나임에 표시되는 GPU 장치 목록 반환\n",
    "\n",
    "if gpus: # 반환된 GPU 장치 목록이 있다면\n",
    "    try: # 해당 장치에 대한 메모리 증가 활성화 여부 설정\n",
    "        tf.config.experimental.set_memory_growth(gpus[0], True)\n",
    "    except RuntimeError as e: # try문 실패시에 에러문구 출력\n",
    "        print(e)\n",
    "\n",
    "print(tf.config.list_physical_devices('GPU'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddcf8ae9",
   "metadata": {},
   "source": [
    "## Import Data & Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "28bf3a2b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Time-Date stamp</th>\n",
       "      <th>Date</th>\n",
       "      <th>ERCOT Load</th>\n",
       "      <th>Total Wind Output</th>\n",
       "      <th>Total Wind Installed</th>\n",
       "      <th>Wind Output, % of Load</th>\n",
       "      <th>Wind Output, % of Installed</th>\n",
       "      <th>1-hr MW change</th>\n",
       "      <th>1-hr % change</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>01-01-2020 00:00:00</td>\n",
       "      <td>Jan-01</td>\n",
       "      <td>36823</td>\n",
       "      <td>12335</td>\n",
       "      <td>27040</td>\n",
       "      <td>33.5</td>\n",
       "      <td>45.617</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>01-01-2020 01:00:00</td>\n",
       "      <td>Jan-01</td>\n",
       "      <td>36511</td>\n",
       "      <td>13300</td>\n",
       "      <td>27040</td>\n",
       "      <td>36.4</td>\n",
       "      <td>49.187</td>\n",
       "      <td>965.4</td>\n",
       "      <td>7.826</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>01-01-2020 02:00:00</td>\n",
       "      <td>Jan-01</td>\n",
       "      <td>36022</td>\n",
       "      <td>13586</td>\n",
       "      <td>27040</td>\n",
       "      <td>37.7</td>\n",
       "      <td>50.245</td>\n",
       "      <td>286.2</td>\n",
       "      <td>2.152</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>01-01-2020 03:00:00</td>\n",
       "      <td>Jan-01</td>\n",
       "      <td>35790</td>\n",
       "      <td>14107</td>\n",
       "      <td>27040</td>\n",
       "      <td>39.4</td>\n",
       "      <td>52.171</td>\n",
       "      <td>520.9</td>\n",
       "      <td>3.834</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>01-01-2020 04:00:00</td>\n",
       "      <td>Jan-01</td>\n",
       "      <td>35642</td>\n",
       "      <td>14887</td>\n",
       "      <td>27040</td>\n",
       "      <td>41.8</td>\n",
       "      <td>55.055</td>\n",
       "      <td>779.6</td>\n",
       "      <td>5.527</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35060</th>\n",
       "      <td>12-31-2023 20:00:00</td>\n",
       "      <td>Dec-31</td>\n",
       "      <td>44887</td>\n",
       "      <td>17161</td>\n",
       "      <td>38631</td>\n",
       "      <td>38.23</td>\n",
       "      <td>44.42</td>\n",
       "      <td>2858</td>\n",
       "      <td>19.99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35061</th>\n",
       "      <td>12-31-2023 21:00:00</td>\n",
       "      <td>Dec-31</td>\n",
       "      <td>44013</td>\n",
       "      <td>18301</td>\n",
       "      <td>38631</td>\n",
       "      <td>41.58</td>\n",
       "      <td>47.37</td>\n",
       "      <td>1139</td>\n",
       "      <td>6.64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35062</th>\n",
       "      <td>12-31-2023 22:00:00</td>\n",
       "      <td>Dec-31</td>\n",
       "      <td>43280</td>\n",
       "      <td>18607</td>\n",
       "      <td>38631</td>\n",
       "      <td>42.99</td>\n",
       "      <td>48.17</td>\n",
       "      <td>307</td>\n",
       "      <td>1.67</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35063</th>\n",
       "      <td>12-31-2023 23:00:00</td>\n",
       "      <td>Dec-31</td>\n",
       "      <td>42319</td>\n",
       "      <td>17866</td>\n",
       "      <td>38631</td>\n",
       "      <td>42.22</td>\n",
       "      <td>46.25</td>\n",
       "      <td>-741</td>\n",
       "      <td>-3.98</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35064</th>\n",
       "      <td>01-01-2024 00:00:00</td>\n",
       "      <td>Jan-01</td>\n",
       "      <td>41682</td>\n",
       "      <td>15869</td>\n",
       "      <td>38631</td>\n",
       "      <td>38.07</td>\n",
       "      <td>41.08</td>\n",
       "      <td>-1996</td>\n",
       "      <td>-11.17</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>35065 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           Time-Date stamp    Date ERCOT Load Total Wind Output  \\\n",
       "0      01-01-2020 00:00:00  Jan-01      36823             12335   \n",
       "1      01-01-2020 01:00:00  Jan-01      36511             13300   \n",
       "2      01-01-2020 02:00:00  Jan-01      36022             13586   \n",
       "3      01-01-2020 03:00:00  Jan-01      35790             14107   \n",
       "4      01-01-2020 04:00:00  Jan-01      35642             14887   \n",
       "...                    ...     ...        ...               ...   \n",
       "35060  12-31-2023 20:00:00  Dec-31      44887             17161   \n",
       "35061  12-31-2023 21:00:00  Dec-31      44013             18301   \n",
       "35062  12-31-2023 22:00:00  Dec-31      43280             18607   \n",
       "35063  12-31-2023 23:00:00  Dec-31      42319             17866   \n",
       "35064  01-01-2024 00:00:00  Jan-01      41682             15869   \n",
       "\n",
       "      Total Wind Installed Wind Output, % of Load Wind Output, % of Installed  \\\n",
       "0                    27040                   33.5                      45.617   \n",
       "1                    27040                   36.4                      49.187   \n",
       "2                    27040                   37.7                      50.245   \n",
       "3                    27040                   39.4                      52.171   \n",
       "4                    27040                   41.8                      55.055   \n",
       "...                    ...                    ...                         ...   \n",
       "35060                38631                  38.23                       44.42   \n",
       "35061                38631                  41.58                       47.37   \n",
       "35062                38631                  42.99                       48.17   \n",
       "35063                38631                  42.22                       46.25   \n",
       "35064                38631                  38.07                       41.08   \n",
       "\n",
       "      1-hr MW change 1-hr % change  \n",
       "0                NaN           NaN  \n",
       "1              965.4         7.826  \n",
       "2              286.2         2.152  \n",
       "3              520.9         3.834  \n",
       "4              779.6         5.527  \n",
       "...              ...           ...  \n",
       "35060           2858         19.99  \n",
       "35061           1139          6.64  \n",
       "35062            307          1.67  \n",
       "35063           -741         -3.98  \n",
       "35064          -1996        -11.17  \n",
       "\n",
       "[35065 rows x 9 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_path = 'C:/Users/smartgrid_AI/Desktop/windpower_ramprate/ercot_2020.csv'\n",
    "data_source1 = pd.read_csv(data_path)\n",
    "dat_source1 = pd.DataFrame(data_source1)\n",
    "#dat_source1 = dat_source1.iloc[:-3,:]\n",
    "\n",
    "data_path = 'C:/Users/smartgrid_AI/Desktop/windpower_ramprate/ercot_2021.csv'\n",
    "data_source2 = pd.read_csv(data_path)\n",
    "dat_source2 = pd.DataFrame(data_source2)\n",
    "dat_source2 = dat_source2.iloc[:8761,:9]\n",
    "\n",
    "data_path = 'C:/Users/smartgrid_AI/Desktop/windpower_ramprate/ercot_2022.csv'\n",
    "data_source3 = pd.read_csv(data_path)\n",
    "dat_source3 = pd.DataFrame(data_source3)\n",
    "dat_source3 = dat_source3.iloc[:8760,:9]\n",
    "\n",
    "data_path = 'C:/Users/smartgrid_AI/Desktop/windpower_ramprate/ercot_2023.csv'\n",
    "data_source4 = pd.read_csv(data_path)\n",
    "dat_source4 = pd.DataFrame(data_source4)\n",
    "dat_source4 = dat_source4.iloc[:8760,:9]\n",
    "\n",
    "dat_arr1 = np.array(dat_source1)\n",
    "dat_arr2 = np.array(dat_source2)\n",
    "dat_arr3 = np.array(dat_source3)\n",
    "dat_arr4 = np.array(dat_source4)\n",
    "\n",
    "dat_arr = np.concatenate([dat_arr1, dat_arr2, dat_arr3, dat_arr4],axis=0)\n",
    "dat_arr.shape # 8784, 8761, 8760, 8760\n",
    "\n",
    "dat_source = pd.DataFrame(dat_arr, columns=['Time-Date stamp','Date','ERCOT Load','Total Wind Output','Total Wind Installed','Wind Output, % of Load','Wind Output, % of Installed','1-hr MW change','1-hr % change'])\n",
    "dat_source"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fab239ad",
   "metadata": {},
   "source": [
    "### Dividing by Installed Capacity & Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4c0b5194",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MW % change</th>\n",
       "      <th>Total Wind Output</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3.56879</td>\n",
       "      <td>0.491864</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.05769</td>\n",
       "      <td>0.502441</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.92678</td>\n",
       "      <td>0.521709</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2.88462</td>\n",
       "      <td>0.550555</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.580621</td>\n",
       "      <td>0.544749</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35059</th>\n",
       "      <td>7.3982</td>\n",
       "      <td>0.444229</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35060</th>\n",
       "      <td>2.951</td>\n",
       "      <td>0.473739</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35061</th>\n",
       "      <td>0.79211</td>\n",
       "      <td>0.48166</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35062</th>\n",
       "      <td>-1.91815</td>\n",
       "      <td>0.462478</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35063</th>\n",
       "      <td>-5.16942</td>\n",
       "      <td>0.410784</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>35064 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      MW % change Total Wind Output\n",
       "0         3.56879          0.491864\n",
       "1         1.05769          0.502441\n",
       "2         1.92678          0.521709\n",
       "3         2.88462          0.550555\n",
       "4       -0.580621          0.544749\n",
       "...           ...               ...\n",
       "35059      7.3982          0.444229\n",
       "35060       2.951          0.473739\n",
       "35061     0.79211           0.48166\n",
       "35062    -1.91815          0.462478\n",
       "35063    -5.16942          0.410784\n",
       "\n",
       "[35064 rows x 2 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dat = pd.DataFrame()\n",
    "dat['MW % change'] = np.array(dat_source.iloc[1:,3], dtype=float)-np.array(dat_source.iloc[0:-1,3], dtype=float)\n",
    "dat['MW % change'] = np.divide(np.array(dat['MW % change']),np.array(dat_source.iloc[1:,4]))*100\n",
    "dat['Total Wind Output'] = np.divide(np.array(dat_source.iloc[1:,3]), np.array(dat_source.iloc[1:,4]))\n",
    "\n",
    "dat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8aa1edfa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Year</th>\n",
       "      <th>MW % change</th>\n",
       "      <th>Total Wind Output</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2020</td>\n",
       "      <td>3.56879</td>\n",
       "      <td>0.491864</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2020</td>\n",
       "      <td>1.05769</td>\n",
       "      <td>0.502441</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2020</td>\n",
       "      <td>1.92678</td>\n",
       "      <td>0.521709</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2020</td>\n",
       "      <td>2.88462</td>\n",
       "      <td>0.550555</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2020</td>\n",
       "      <td>-0.580621</td>\n",
       "      <td>0.544749</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35059</th>\n",
       "      <td>2023</td>\n",
       "      <td>7.3982</td>\n",
       "      <td>0.444229</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35060</th>\n",
       "      <td>2023</td>\n",
       "      <td>2.951</td>\n",
       "      <td>0.473739</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35061</th>\n",
       "      <td>2023</td>\n",
       "      <td>0.79211</td>\n",
       "      <td>0.48166</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35062</th>\n",
       "      <td>2023</td>\n",
       "      <td>-1.91815</td>\n",
       "      <td>0.462478</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35063</th>\n",
       "      <td>2023</td>\n",
       "      <td>-5.16942</td>\n",
       "      <td>0.410784</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>35064 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Year MW % change Total Wind Output\n",
       "0      2020     3.56879          0.491864\n",
       "1      2020     1.05769          0.502441\n",
       "2      2020     1.92678          0.521709\n",
       "3      2020     2.88462          0.550555\n",
       "4      2020   -0.580621          0.544749\n",
       "...     ...         ...               ...\n",
       "35059  2023      7.3982          0.444229\n",
       "35060  2023       2.951          0.473739\n",
       "35061  2023     0.79211           0.48166\n",
       "35062  2023    -1.91815          0.462478\n",
       "35063  2023    -5.16942          0.410784\n",
       "\n",
       "[35064 rows x 3 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ramp_ratio = 20\n",
    "load_ratio = 10\n",
    "year_arr = np.concatenate([np.ones(8784)*2020, np.ones(8760)*2021, np.ones(8760)*2022, np.ones(8760)*2023])\n",
    "year_df = pd.DataFrame(year_arr, columns=['Year'], dtype=int)\n",
    "wind_df = pd.concat([year_df, dat], axis=1)\n",
    "wind_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e5f4103f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Year</th>\n",
       "      <th>MW % change</th>\n",
       "      <th>Total Wind Output</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2020</td>\n",
       "      <td>0.620197</td>\n",
       "      <td>0.644724</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2020</td>\n",
       "      <td>0.544580</td>\n",
       "      <td>0.658617</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2020</td>\n",
       "      <td>0.570751</td>\n",
       "      <td>0.683924</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2020</td>\n",
       "      <td>0.599594</td>\n",
       "      <td>0.721813</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2020</td>\n",
       "      <td>0.495246</td>\n",
       "      <td>0.714187</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35058</th>\n",
       "      <td>2023</td>\n",
       "      <td>0.774643</td>\n",
       "      <td>0.484984</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35059</th>\n",
       "      <td>2023</td>\n",
       "      <td>0.735512</td>\n",
       "      <td>0.582157</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35060</th>\n",
       "      <td>2023</td>\n",
       "      <td>0.601593</td>\n",
       "      <td>0.620917</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35061</th>\n",
       "      <td>2023</td>\n",
       "      <td>0.536583</td>\n",
       "      <td>0.631322</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35062</th>\n",
       "      <td>2023</td>\n",
       "      <td>0.454969</td>\n",
       "      <td>0.606127</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>35063 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Year  MW % change  Total Wind Output\n",
       "0      2020     0.620197           0.644724\n",
       "1      2020     0.544580           0.658617\n",
       "2      2020     0.570751           0.683924\n",
       "3      2020     0.599594           0.721813\n",
       "4      2020     0.495246           0.714187\n",
       "...     ...          ...                ...\n",
       "35058  2023     0.774643           0.484984\n",
       "35059  2023     0.735512           0.582157\n",
       "35060  2023     0.601593           0.620917\n",
       "35061  2023     0.536583           0.631322\n",
       "35062  2023     0.454969           0.606127\n",
       "\n",
       "[35063 rows x 3 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wind_df = wind_df.reset_index(drop=True)\n",
    "\n",
    "std_scaler = sklearn.preprocessing.MinMaxScaler()\n",
    "std_scaler_load = sklearn.preprocessing.MinMaxScaler()\n",
    "std_scaler_ramp = sklearn.preprocessing.MinMaxScaler()\n",
    "\n",
    "wind_df[['Total Wind Output']] = std_scaler.fit_transform(wind_df[['Total Wind Output']])\n",
    "wind_df[['MW % change']] = std_scaler_ramp.fit_transform(wind_df[['MW % change']])\n",
    "wind_df = wind_df.iloc[:-1,:]\n",
    "wind_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6a74497e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Year</th>\n",
       "      <th>Wind Change</th>\n",
       "      <th>Wind Output</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2020</td>\n",
       "      <td>0.620197</td>\n",
       "      <td>0.644724</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2020</td>\n",
       "      <td>0.544580</td>\n",
       "      <td>0.658617</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2020</td>\n",
       "      <td>0.570751</td>\n",
       "      <td>0.683924</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2020</td>\n",
       "      <td>0.599594</td>\n",
       "      <td>0.721813</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2020</td>\n",
       "      <td>0.495246</td>\n",
       "      <td>0.714187</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35058</th>\n",
       "      <td>2023</td>\n",
       "      <td>0.774643</td>\n",
       "      <td>0.484984</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35059</th>\n",
       "      <td>2023</td>\n",
       "      <td>0.735512</td>\n",
       "      <td>0.582157</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35060</th>\n",
       "      <td>2023</td>\n",
       "      <td>0.601593</td>\n",
       "      <td>0.620917</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35061</th>\n",
       "      <td>2023</td>\n",
       "      <td>0.536583</td>\n",
       "      <td>0.631322</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35062</th>\n",
       "      <td>2023</td>\n",
       "      <td>0.454969</td>\n",
       "      <td>0.606127</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>35063 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Year  Wind Change  Wind Output\n",
       "0      2020     0.620197     0.644724\n",
       "1      2020     0.544580     0.658617\n",
       "2      2020     0.570751     0.683924\n",
       "3      2020     0.599594     0.721813\n",
       "4      2020     0.495246     0.714187\n",
       "...     ...          ...          ...\n",
       "35058  2023     0.774643     0.484984\n",
       "35059  2023     0.735512     0.582157\n",
       "35060  2023     0.601593     0.620917\n",
       "35061  2023     0.536583     0.631322\n",
       "35062  2023     0.454969     0.606127\n",
       "\n",
       "[35063 rows x 3 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ramp_df = pd.DataFrame(wind_df)\n",
    "ramp_df.columns=['Year', 'Wind Change', 'Wind Output']\n",
    "ramp_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33e1990e",
   "metadata": {},
   "source": [
    "## Wind Generation Forecasting"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0551ddb",
   "metadata": {},
   "source": [
    "### SVD-based Feature Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "77e59bbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_dataset(dataset, timesteps, output_timesteps, leadtime):\n",
    "    dataX, dataY = [], []\n",
    "    for i in range(len(dataset) - timesteps -output_timesteps - leadtime - 1):\n",
    "        a = dataset[i:(i + timesteps), :]\n",
    "        dataX.append(a)\n",
    "        dataY.append(dataset[(i + timesteps + leadtime):(i+timesteps+output_timesteps+leadtime), :])\n",
    "    return np.array(dataX), np.array(dataY)\n",
    "\n",
    "def svdadd(X, start, end, b_size):\n",
    "    dec_x = X[start:end, :, :]\n",
    "    U, S, Vh = svd(dec_x.reshape(b_size, -1), full_matrices=True)\n",
    "\n",
    "    high_sig = np.matmul(np.matmul(U[:,:high_ind], np.diag(S[0:high_ind])), Vh[:high_ind,:])\n",
    "    low_sig = X[:dec_num, :, :].reshape(b_size,-1)-high_sig\n",
    "\n",
    "    rec_x = np.zeros((b_size, b_size, high_ind))\n",
    "    \n",
    "    for i in range(high_ind):\n",
    "        rec_x[:,:,i] = np.matmul((U[:,i]*S[i]).reshape(-1,1), Vh[i,:].reshape(1,-1))    \n",
    "    return rec_x, low_sig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0f9269f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "norm_df = np.array(wind_df.iloc[:,2]).reshape(-1,1)\n",
    "timesteps = 24*6\n",
    "output_timesteps = 12\n",
    "leadtime = 4\n",
    "num_features = 1\n",
    "X, Y = create_dataset(norm_df, timesteps, output_timesteps, leadtime)\n",
    "b_size = timesteps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a81aa6dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "dec_num = timesteps\n",
    "high_ind = 35\n",
    "\n",
    "addX = np.zeros((X.shape[0], dec_num, high_ind+1))\n",
    "\n",
    "for k in range(X.shape[0]//dec_num):\n",
    "    rec_x, low_sig = svdadd(X, k*dec_num, (k+1)*dec_num, b_size)\n",
    "    addX[k*dec_num:k*dec_num+dec_num,:, :-1] = rec_x\n",
    "    addX[k*dec_num:k*dec_num+dec_num,:, -1] = low_sig\n",
    "    \n",
    "rec_x, low_sig = svdadd(X, X.shape[0]-dec_num, X.shape[0], b_size)\n",
    "addX[X.shape[0]-dec_num:X.shape[0], :, :-1] = rec_x\n",
    "addX[X.shape[0]-dec_num:X.shape[0],:, -1] = low_sig\n",
    "\n",
    "addX_det = addX[:, :, :-1]\n",
    "addX_det = np.sum(addX_det, axis=2)\n",
    "X = np.concatenate([X, addX], axis=2)\n",
    "num_features = X.shape[2]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef14307d",
   "metadata": {},
   "source": [
    "### Training/Test Set Division & Shuffled Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "56d9d8ab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((31411, 144, 37), (31411, 12), (3491, 144, 37), (3491, 12))"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trvaX, teX, trvaY, teY = train_test_split(X, Y, test_size=0.1, shuffle=False)\n",
    "\n",
    "idx = np.arange(trvaX.shape[0])\n",
    "np.random.shuffle(idx)\n",
    "strvaX = trvaX[idx]\n",
    "strvaY = trvaY[idx]\n",
    "strvaY = strvaY.reshape(-1, output_timesteps)\n",
    "\n",
    "trvaY = trvaY.reshape(-1, output_timesteps)\n",
    "teY = teY.reshape(-1, output_timesteps)\n",
    "\n",
    "strX, svaX, strY, svaY = train_test_split(strvaX, strvaY, test_size=0.3, shuffle=False)\n",
    "trX, vaX, trY, vaY = train_test_split(trvaX, trvaY, test_size=0.3, shuffle=False)\n",
    "\n",
    "trvaX.shape, trvaY.shape, teX.shape, teY.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0ad55af",
   "metadata": {},
   "source": [
    "## Wind Generation Forecasting Basic Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b8fac15b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def MAEMS(y_true, y_pred):\n",
    "    return K.mean((K.abs(y_pred - y_true))*K.square(y_true))*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a2181f7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers.advanced_activations import PReLU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3fdb95da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            [(None, 144, 37)]    0                                            \n",
      "__________________________________________________________________________________________________\n",
      "permute (Permute)               (None, 37, 144)      0           input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, 37, 144)      20880       permute[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 37, 144)      20880       permute[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "multiply (Multiply)             (None, 37, 144)      0           dense[0][0]                      \n",
      "                                                                 dense_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "attention_vec (Permute)         (None, 144, 37)      0           multiply[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "multiply_1 (Multiply)           (None, 144, 37)      0           input_1[0][0]                    \n",
      "                                                                 attention_vec[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv1d (Conv1D)                 (None, 144, 256)     9728        multiply_1[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation (Activation)         (None, 144, 256)     0           conv1d[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "activation_1 (Activation)       (None, 144, 256)     0           conv1d[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "multiply_2 (Multiply)           (None, 144, 256)     0           activation[0][0]                 \n",
      "                                                                 activation_1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_1 (Conv1D)               (None, 144, 37)      18981       multiply_2[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_2 (Activation)       (None, 144, 37)      0           conv1d_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_3 (Activation)       (None, 144, 37)      0           conv1d_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "multiply_3 (Multiply)           (None, 144, 37)      0           activation_2[0][0]               \n",
      "                                                                 activation_3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "add (Add)                       (None, 144, 37)      0           input_1[0][0]                    \n",
      "                                                                 multiply_3[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "subtract (Subtract)             (None, 144, 37)      0           input_1[0][0]                    \n",
      "                                                                 multiply_3[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_2 (Conv1D)               (None, 144, 256)     9728        add[0][0]                        \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_4 (Conv1D)               (None, 144, 256)     9728        subtract[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_4 (Activation)       (None, 144, 256)     0           conv1d_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_5 (Activation)       (None, 144, 256)     0           conv1d_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_8 (Activation)       (None, 144, 256)     0           conv1d_4[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_9 (Activation)       (None, 144, 256)     0           conv1d_4[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "multiply_4 (Multiply)           (None, 144, 256)     0           activation_4[0][0]               \n",
      "                                                                 activation_5[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "multiply_6 (Multiply)           (None, 144, 256)     0           activation_8[0][0]               \n",
      "                                                                 activation_9[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_3 (Conv1D)               (None, 144, 37)      18981       multiply_4[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_5 (Conv1D)               (None, 144, 37)      18981       multiply_6[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_6 (Activation)       (None, 144, 37)      0           conv1d_3[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_7 (Activation)       (None, 144, 37)      0           conv1d_3[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_10 (Activation)      (None, 144, 37)      0           conv1d_5[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_11 (Activation)      (None, 144, 37)      0           conv1d_5[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "multiply_5 (Multiply)           (None, 144, 37)      0           activation_6[0][0]               \n",
      "                                                                 activation_7[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "multiply_7 (Multiply)           (None, 144, 37)      0           activation_10[0][0]              \n",
      "                                                                 activation_11[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "add_1 (Add)                     (None, 144, 37)      0           add[0][0]                        \n",
      "                                                                 multiply_5[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "subtract_1 (Subtract)           (None, 144, 37)      0           subtract[0][0]                   \n",
      "                                                                 multiply_7[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "concatenate (Concatenate)       (None, 144, 148)     0           add_1[0][0]                      \n",
      "                                                                 subtract_1[0][0]                 \n",
      "                                                                 add[0][0]                        \n",
      "                                                                 subtract[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_6 (Conv1D)               (None, 144, 256)     38144       concatenate[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_8 (Conv1D)               (None, 144, 256)     38144       concatenate[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "activation_12 (Activation)      (None, 144, 256)     0           conv1d_6[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_13 (Activation)      (None, 144, 256)     0           conv1d_6[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_16 (Activation)      (None, 144, 256)     0           conv1d_8[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_17 (Activation)      (None, 144, 256)     0           conv1d_8[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "multiply_8 (Multiply)           (None, 144, 256)     0           activation_12[0][0]              \n",
      "                                                                 activation_13[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "multiply_10 (Multiply)          (None, 144, 256)     0           activation_16[0][0]              \n",
      "                                                                 activation_17[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_7 (Conv1D)               (None, 144, 37)      18981       multiply_8[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_9 (Conv1D)               (None, 144, 37)      18981       multiply_10[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "activation_14 (Activation)      (None, 144, 37)      0           conv1d_7[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_15 (Activation)      (None, 144, 37)      0           conv1d_7[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_18 (Activation)      (None, 144, 37)      0           conv1d_9[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_19 (Activation)      (None, 144, 37)      0           conv1d_9[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "multiply_9 (Multiply)           (None, 144, 37)      0           activation_14[0][0]              \n",
      "                                                                 activation_15[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "multiply_11 (Multiply)          (None, 144, 37)      0           activation_18[0][0]              \n",
      "                                                                 activation_19[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "add_2 (Add)                     (None, 144, 37)      0           add_1[0][0]                      \n",
      "                                                                 multiply_9[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "subtract_2 (Subtract)           (None, 144, 37)      0           subtract_1[0][0]                 \n",
      "                                                                 multiply_11[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, 144, 222)     0           add_2[0][0]                      \n",
      "                                                                 subtract_2[0][0]                 \n",
      "                                                                 concatenate[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_10 (Conv1D)              (None, 144, 256)     57088       concatenate_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_12 (Conv1D)              (None, 144, 256)     57088       concatenate_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_20 (Activation)      (None, 144, 256)     0           conv1d_10[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_21 (Activation)      (None, 144, 256)     0           conv1d_10[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_24 (Activation)      (None, 144, 256)     0           conv1d_12[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_25 (Activation)      (None, 144, 256)     0           conv1d_12[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "multiply_12 (Multiply)          (None, 144, 256)     0           activation_20[0][0]              \n",
      "                                                                 activation_21[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "multiply_14 (Multiply)          (None, 144, 256)     0           activation_24[0][0]              \n",
      "                                                                 activation_25[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_11 (Conv1D)              (None, 144, 37)      18981       multiply_12[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_13 (Conv1D)              (None, 144, 37)      18981       multiply_14[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "activation_22 (Activation)      (None, 144, 37)      0           conv1d_11[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_23 (Activation)      (None, 144, 37)      0           conv1d_11[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_26 (Activation)      (None, 144, 37)      0           conv1d_13[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_27 (Activation)      (None, 144, 37)      0           conv1d_13[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "multiply_13 (Multiply)          (None, 144, 37)      0           activation_22[0][0]              \n",
      "                                                                 activation_23[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "multiply_15 (Multiply)          (None, 144, 37)      0           activation_26[0][0]              \n",
      "                                                                 activation_27[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "add_3 (Add)                     (None, 144, 37)      0           add_2[0][0]                      \n",
      "                                                                 multiply_13[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "subtract_3 (Subtract)           (None, 144, 37)      0           subtract_1[0][0]                 \n",
      "                                                                 multiply_15[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_2 (Concatenate)     (None, 144, 296)     0           add_3[0][0]                      \n",
      "                                                                 subtract_3[0][0]                 \n",
      "                                                                 concatenate_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_14 (Conv1D)              (None, 144, 256)     76032       concatenate_2[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_16 (Conv1D)              (None, 144, 256)     76032       concatenate_2[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_28 (Activation)      (None, 144, 256)     0           conv1d_14[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_29 (Activation)      (None, 144, 256)     0           conv1d_14[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_32 (Activation)      (None, 144, 256)     0           conv1d_16[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_33 (Activation)      (None, 144, 256)     0           conv1d_16[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "multiply_16 (Multiply)          (None, 144, 256)     0           activation_28[0][0]              \n",
      "                                                                 activation_29[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "multiply_18 (Multiply)          (None, 144, 256)     0           activation_32[0][0]              \n",
      "                                                                 activation_33[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_15 (Conv1D)              (None, 144, 37)      18981       multiply_16[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_17 (Conv1D)              (None, 144, 37)      18981       multiply_18[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "activation_30 (Activation)      (None, 144, 37)      0           conv1d_15[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_31 (Activation)      (None, 144, 37)      0           conv1d_15[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_34 (Activation)      (None, 144, 37)      0           conv1d_17[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_35 (Activation)      (None, 144, 37)      0           conv1d_17[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "multiply_17 (Multiply)          (None, 144, 37)      0           activation_30[0][0]              \n",
      "                                                                 activation_31[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "multiply_19 (Multiply)          (None, 144, 37)      0           activation_34[0][0]              \n",
      "                                                                 activation_35[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "add_4 (Add)                     (None, 144, 37)      0           add_3[0][0]                      \n",
      "                                                                 multiply_17[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "subtract_4 (Subtract)           (None, 144, 37)      0           subtract_3[0][0]                 \n",
      "                                                                 multiply_19[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_3 (Concatenate)     (None, 144, 370)     0           add_4[0][0]                      \n",
      "                                                                 subtract_4[0][0]                 \n",
      "                                                                 concatenate_2[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_4 (Concatenate)     (None, 144, 74)      0           add_4[0][0]                      \n",
      "                                                                 subtract_4[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_5 (Concatenate)     (None, 144, 1110)    0           concatenate[0][0]                \n",
      "                                                                 concatenate_1[0][0]              \n",
      "                                                                 concatenate_2[0][0]              \n",
      "                                                                 concatenate_3[0][0]              \n",
      "                                                                 concatenate_4[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_22 (Conv1D)              (None, 144, 720)     903600      concatenate_5[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout (Dropout)               (None, 144, 720)     0           conv1d_22[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_23 (Conv1D)              (None, 144, 432)     373680      dropout[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)             (None, 144, 432)     0           conv1d_23[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling1d (Globa (None, 432)          0           dropout_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_2 (Dense)                 (None, 12)           5196        global_average_pooling1d[0][0]   \n",
      "==================================================================================================\n",
      "Total params: 1,866,777\n",
      "Trainable params: 1,866,777\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "num_features = trvaX.shape[2]\n",
    "output_timesteps = trvaY.shape[1]\n",
    "\n",
    "with tf.device('/gpu:0'):\n",
    "    alpha=1.0\n",
    "    gamma=1.2\n",
    "    beta = 1\n",
    "    hfilters = 256\n",
    "    hkernel_size1 = 1\n",
    "    hkernel_size2 = 2\n",
    "    \n",
    "    visible1 = Input(shape=(timesteps, num_features))\n",
    "   \n",
    "    ## Attention Block\n",
    "    per1 = Permute((2,1))(visible1)\n",
    "    den1a = Dense(timesteps, activation='tanh')(per1)\n",
    "    den1b = Dense(timesteps, activation='sigmoid')(per1)\n",
    "    den1 = Multiply()([den1a, den1b])\n",
    "    per2 = Permute((2,1), name='attention_vec')(den1)\n",
    "    mul1 = Multiply()([visible1, per2])\n",
    "    \n",
    "    ## Series PN DCCNN Blocks 1 ~ 6\n",
    "    d1 = Conv1D(filters=round(hfilters*alpha), kernel_size=round(hkernel_size1*beta), padding='causal', dilation_rate=1)(mul1)\n",
    "    d1a = Activation(activations.tanh)(d1)\n",
    "    d1b = Activation(activations.sigmoid)(d1)\n",
    "    d1 = Multiply()([d1a, d1b])\n",
    "    \n",
    "    d1 = Conv1D(filters=num_features, kernel_size=round(hkernel_size2*beta), padding='causal', dilation_rate=2)(d1)\n",
    "    d1a = Activation(activations.tanh)(d1)\n",
    "    d1b = Activation(activations.sigmoid)(d1)\n",
    "    d1 = Multiply()([d1a, d1b])\n",
    "    \n",
    "    res01a = Add()([visible1, d1])   # (100, 25) (100, 25)\n",
    "    res01b = Subtract()([visible1, d1])\n",
    "\n",
    "    d1 = Conv1D(filters=round(hfilters*alpha), kernel_size=round(hkernel_size1*beta), padding='causal', dilation_rate=2)(res01a)\n",
    "    d1a = Activation(activations.tanh)(d1)\n",
    "    d1b = Activation(activations.sigmoid)(d1)\n",
    "    d1 = Multiply()([d1a, d1b])\n",
    "    \n",
    "    d1 = Conv1D(filters=num_features, kernel_size=round(hkernel_size2*beta), padding='causal', dilation_rate=4)(d1)    \n",
    "    d1a = Activation(activations.tanh)(d1)\n",
    "    d1b = Activation(activations.sigmoid)(d1)\n",
    "    \n",
    "    d1 = Multiply()([d1a, d1b])\n",
    "    res02a = Add()([res01a, d1])   # (100, 25) (100, 25)\n",
    "    \n",
    "    d2 = Conv1D(filters=round(hfilters*alpha), kernel_size=round(hkernel_size1*beta), padding='causal', dilation_rate=2)(res01b) \n",
    "    d2a = Activation(activations.tanh)(d2)\n",
    "    d2b = Activation(activations.sigmoid)(d2)\n",
    "    d2 = Multiply()([d2a, d2b])\n",
    "    \n",
    "    d2 = Conv1D(filters=num_features, kernel_size=round(hkernel_size2*beta), padding='causal', dilation_rate=4)(d2) \n",
    "    d2a = Activation(activations.tanh)(d2)\n",
    "    d2b = Activation(activations.sigmoid)(d2)\n",
    "    d2 = Multiply()([d2a, d2b])\n",
    "    \n",
    "    res02b = Subtract()([res01b, d2])   # (100, 25) (100, 25) \n",
    "    res02 = Concatenate()([res02a, res02b, res01a, res01b])\n",
    "    \n",
    "    d1 = Conv1D(filters=round(hfilters*alpha), kernel_size=round(hkernel_size1*beta), padding='causal', dilation_rate=4)(res02)\n",
    "    d1a = Activation(activations.tanh)(d1)\n",
    "    d1b = Activation(activations.sigmoid)(d1)\n",
    "    d1 = Multiply()([d1a, d1b])\n",
    "    \n",
    "    d1 = Conv1D(filters=num_features, kernel_size=round(hkernel_size2*beta), padding='causal', dilation_rate=8)(d1)    \n",
    "    d1a = Activation(activations.tanh)(d1)\n",
    "    d1b = Activation(activations.sigmoid)(d1)\n",
    "    d1 = Multiply()([d1a, d1b])\n",
    "    \n",
    "    res03a = Add()([res02a, d1])   # (100, 25) (100, 25)\n",
    "    \n",
    "    d2 = Conv1D(filters=round(hfilters*alpha), kernel_size=round(hkernel_size1*beta), padding='causal', dilation_rate=4)(res02) \n",
    "    d2a = Activation(activations.tanh)(d2)\n",
    "    d2b = Activation(activations.sigmoid)(d2)\n",
    "    d2 = Multiply()([d2a, d2b])\n",
    "    \n",
    "    d2 = Conv1D(filters=num_features, kernel_size=round(hkernel_size2*beta), padding='causal', dilation_rate=8)(d2) \n",
    "    d2a = Activation(activations.tanh)(d2)\n",
    "    d2b = Activation(activations.sigmoid)(d2)\n",
    "    d2 = Multiply()([d2a, d2b])\n",
    "    \n",
    "    res03b = Subtract()([res02b, d2])   # (100, 25) (100, 25)\n",
    "    res03 = Concatenate()([res03a, res03b, res02])\n",
    "    \n",
    "    d1 = Conv1D(filters=round(hfilters*alpha), kernel_size=round(hkernel_size1*beta), padding='causal', dilation_rate=8)(res03)\n",
    "    d1a = Activation(activations.tanh)(d1)\n",
    "    d1b = Activation(activations.sigmoid)(d1)\n",
    "    d1 = Multiply()([d1a, d1b])\n",
    "    d1 = Conv1D(filters=num_features, kernel_size=round(hkernel_size2*beta), padding='causal', dilation_rate=4)(d1)    \n",
    "    d1a = Activation(activations.tanh)(d1)\n",
    "    d1b = Activation(activations.sigmoid)(d1)\n",
    "    d1 = Multiply()([d1a, d1b])\n",
    "    res04a = Add()([res03a, d1])   # (100, 25) (100, 25)\n",
    "    \n",
    "    d2 = Conv1D(filters=round(hfilters*alpha), kernel_size=round(hkernel_size1*beta), padding='causal', dilation_rate=8)(res03) \n",
    "    d2a = Activation(activations.tanh)(d2)\n",
    "    d2b = Activation(activations.sigmoid)(d2)\n",
    "    d2 = Multiply()([d2a, d2b])\n",
    "    \n",
    "    d2 = Conv1D(filters=num_features, kernel_size=round(hkernel_size2*beta), padding='causal', dilation_rate=4)(d2) \n",
    "    d2a = Activation(activations.tanh)(d2)\n",
    "    d2b = Activation(activations.sigmoid)(d2)\n",
    "    d2 = Multiply()([d2a, d2b])\n",
    "    \n",
    "    res04b = Subtract()([res02b, d2])   # (100, 25) (100, 25)\n",
    "    res04 = Concatenate()([res04a, res04b, res03])\n",
    "    \n",
    "    d1 = Conv1D(filters=round(hfilters*alpha), kernel_size=round(hkernel_size1*beta), padding='causal', dilation_rate=4)(res04)\n",
    "    d1a = Activation(activations.tanh)(d1)\n",
    "    d1b = Activation(activations.sigmoid)(d1)\n",
    "    d1 = Multiply()([d1a, d1b])\n",
    "    \n",
    "    d1 = Conv1D(filters=num_features, kernel_size=round(hkernel_size2*beta), padding='causal', dilation_rate=2)(d1)    \n",
    "    d1a = Activation(activations.tanh)(d1)\n",
    "    d1b = Activation(activations.sigmoid)(d1)\n",
    "    d1 = Multiply()([d1a, d1b])\n",
    "    \n",
    "    res05a = Add()([res04a, d1])   # (100, 25) (100, 25)\n",
    "    \n",
    "    d2 = Conv1D(filters=round(hfilters*alpha), kernel_size=round(hkernel_size1*beta), padding='causal', dilation_rate=4)(res04) \n",
    "    d2a = Activation(activations.tanh)(d2)\n",
    "    d2b = Activation(activations.sigmoid)(d2)\n",
    "    d2 = Multiply()([d2a, d2b])\n",
    "    \n",
    "    d2 = Conv1D(filters=num_features, kernel_size=round(hkernel_size2*beta), padding='causal', dilation_rate=2)(d2) \n",
    "    d2a = Activation(activations.tanh)(d2)\n",
    "    d2b = Activation(activations.sigmoid)(d2)\n",
    "    d2 = Multiply()([d2a, d2b])\n",
    "    \n",
    "    res05b = Subtract()([res04b, d2])   # (100, 25) (100, 25)\n",
    "    res05 = Concatenate()([res05a, res05b, res04])\n",
    "    \n",
    "    d1 = Conv1D(filters=round(hfilters*alpha), kernel_size=round(hkernel_size1*beta), padding='causal', dilation_rate=2)(res05)\n",
    "    d1a = Activation(activations.tanh)(d1)\n",
    "    d1b = Activation(activations.sigmoid)(d1)\n",
    "    d1 = Multiply()([d1a, d1b])\n",
    "    \n",
    "    d1 = Conv1D(filters=num_features, kernel_size=round(hkernel_size2*beta), padding='causal', dilation_rate=1)(d1)    \n",
    "    d1a = Activation(activations.tanh)(d1)\n",
    "    d1b = Activation(activations.sigmoid)(d1)\n",
    "    d1 = Multiply()([d1a, d1b])\n",
    "\n",
    "    res06a = Add()([res05a, d1])   # (100, 25) (100, 25)\n",
    "    \n",
    "    d2 = Conv1D(filters=round(hfilters*alpha), kernel_size=round(hkernel_size1*beta), padding='causal', dilation_rate=2)(res05) \n",
    "    d2a = Activation(activations.tanh)(d2)\n",
    "    d2b = Activation(activations.sigmoid)(d2)\n",
    "    d2 = Multiply()([d2a, d2b])\n",
    "    d2 = Conv1D(filters=num_features, kernel_size=round(hkernel_size2*beta), padding='causal', dilation_rate=1)(d2) \n",
    "    d2a = Activation(activations.tanh)(d2)\n",
    "    d2b = Activation(activations.sigmoid)(d2)\n",
    "    d2 = Multiply()([d2a, d2b])\n",
    "\n",
    "    res06b = Subtract()([res05b, d2])   # (100, 25) (100, 25)\n",
    "    res06 = Concatenate()([res05a, res05b])\n",
    "    \n",
    "    res10 = Concatenate()([res02, res03, res04, res05, res06])   # \n",
    "    \n",
    "    #print('res10 :', res10.shap)  # (None, 24, 11) \n",
    "    \n",
    "    ## Output Block\n",
    "    out = Conv1D(timesteps*5, 1, padding='same', activation=PReLU())(res10)   # 256, 11X10=110\n",
    "    out = Dropout(0.2)(out)   #SpatialDropout1D\n",
    "    \n",
    "    out = Conv1D(timesteps*3, 1, padding='same', activation=PReLU())(out) # 512,  110X5=550\n",
    "    out = Dropout(0.2)(out)\n",
    "    \n",
    "    out = GlobalAveragePooling1D()(out) # pool_size=2, strides=1\n",
    "    \n",
    "    out = Dense(output_timesteps)(out) \n",
    "    model = Model(inputs=[visible1], outputs=[out])\n",
    "    \n",
    "    print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6feb9c30",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1371"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "8d17ff7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "    model.compile(loss=MAEMS, optimizer='adam', metrics=['mse','mae', MAEMS])\n",
    "    early_stopping =EarlyStopping(monitor='val_loss', patience=50)\n",
    "    epochs = 1000\n",
    "    #root_squared_mean_error\n",
    "    history = LossHistory()\n",
    "    history.init()\n",
    "    \n",
    "    #hist = model.fit(trX, trY, epochs=epochs, batch_size=batch_size, shuffle=False, validation_data=(vaX, vaY), callbacks=[history, early_stopping])  # , checkpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "52917202",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "1833/1833 [==============================] - 56s 28ms/step - loss: 3.1731 - mse: 0.0654 - mae: 0.2062 - MAEMS: 3.1747 - val_loss: 2.6814 - val_mse: 0.0475 - val_mae: 0.1722 - val_MAEMS: 2.6810\n",
      "Epoch 2/1000\n",
      "1833/1833 [==============================] - 51s 28ms/step - loss: 2.6857 - mse: 0.0461 - mae: 0.1693 - MAEMS: 2.6871 - val_loss: 2.4292 - val_mse: 0.0401 - val_mae: 0.1555 - val_MAEMS: 2.4291\n",
      "Epoch 3/1000\n",
      "1833/1833 [==============================] - 50s 27ms/step - loss: 2.4253 - mse: 0.0385 - mae: 0.1517 - MAEMS: 2.4263 - val_loss: 2.2859 - val_mse: 0.0378 - val_mae: 0.1477 - val_MAEMS: 2.2860\n",
      "Epoch 4/1000\n",
      "1833/1833 [==============================] - 51s 28ms/step - loss: 2.2410 - mse: 0.0339 - mae: 0.1401 - MAEMS: 2.2417 - val_loss: 2.1179 - val_mse: 0.0311 - val_mae: 0.1324 - val_MAEMS: 2.1180\n",
      "Epoch 5/1000\n",
      "1833/1833 [==============================] - 50s 27ms/step - loss: 2.0909 - mse: 0.0306 - mae: 0.1313 - MAEMS: 2.0914 - val_loss: 2.0829 - val_mse: 0.0272 - val_mae: 0.1237 - val_MAEMS: 2.0826\n",
      "Epoch 6/1000\n",
      "1833/1833 [==============================] - 50s 27ms/step - loss: 1.9767 - mse: 0.0285 - mae: 0.1253 - MAEMS: 1.9771 - val_loss: 2.0188 - val_mse: 0.0313 - val_mae: 0.1319 - val_MAEMS: 2.0192\n",
      "Epoch 7/1000\n",
      "1833/1833 [==============================] - 50s 27ms/step - loss: 1.8810 - mse: 0.0266 - mae: 0.1201 - MAEMS: 1.8811 - val_loss: 1.9011 - val_mse: 0.0255 - val_mae: 0.1177 - val_MAEMS: 1.9013\n",
      "Epoch 8/1000\n",
      "1833/1833 [==============================] - 49s 27ms/step - loss: 1.8108 - mse: 0.0251 - mae: 0.1160 - MAEMS: 1.8109 - val_loss: 1.8504 - val_mse: 0.0265 - val_mae: 0.1191 - val_MAEMS: 1.8508\n",
      "Epoch 9/1000\n",
      "1833/1833 [==============================] - 50s 27ms/step - loss: 1.7484 - mse: 0.0237 - mae: 0.1122 - MAEMS: 1.7483 - val_loss: 1.7303 - val_mse: 0.0215 - val_mae: 0.1067 - val_MAEMS: 1.7303\n",
      "Epoch 10/1000\n",
      "1833/1833 [==============================] - 50s 27ms/step - loss: 1.6908 - mse: 0.0226 - mae: 0.1087 - MAEMS: 1.6910 - val_loss: 1.7552 - val_mse: 0.0257 - val_mae: 0.1167 - val_MAEMS: 1.7553\n",
      "Epoch 11/1000\n",
      "1833/1833 [==============================] - 50s 27ms/step - loss: 1.6630 - mse: 0.0216 - mae: 0.1062 - MAEMS: 1.6630 - val_loss: 1.6714 - val_mse: 0.0219 - val_mae: 0.1072 - val_MAEMS: 1.6716\n",
      "Epoch 12/1000\n",
      "1833/1833 [==============================] - 50s 28ms/step - loss: 1.6375 - mse: 0.0210 - mae: 0.1044 - MAEMS: 1.6377 - val_loss: 1.6603 - val_mse: 0.0229 - val_mae: 0.1093 - val_MAEMS: 1.6605\n",
      "Epoch 13/1000\n",
      "1833/1833 [==============================] - 51s 28ms/step - loss: 1.5924 - mse: 0.0203 - mae: 0.1021 - MAEMS: 1.5925 - val_loss: 1.6859 - val_mse: 0.0232 - val_mae: 0.1120 - val_MAEMS: 1.6862\n",
      "Epoch 14/1000\n",
      "1833/1833 [==============================] - 51s 28ms/step - loss: 1.5525 - mse: 0.0196 - mae: 0.1000 - MAEMS: 1.5524 - val_loss: 1.6842 - val_mse: 0.0230 - val_mae: 0.1100 - val_MAEMS: 1.6842\n",
      "Epoch 15/1000\n",
      "1833/1833 [==============================] - 50s 27ms/step - loss: 1.5304 - mse: 0.0190 - mae: 0.0982 - MAEMS: 1.5307 - val_loss: 1.5819 - val_mse: 0.0199 - val_mae: 0.1004 - val_MAEMS: 1.5822\n",
      "Epoch 16/1000\n",
      "1833/1833 [==============================] - 51s 28ms/step - loss: 1.5049 - mse: 0.0185 - mae: 0.0967 - MAEMS: 1.5053 - val_loss: 1.5365 - val_mse: 0.0212 - val_mae: 0.1048 - val_MAEMS: 1.5367\n",
      "Epoch 17/1000\n",
      "1833/1833 [==============================] - 51s 28ms/step - loss: 1.4694 - mse: 0.0180 - mae: 0.0949 - MAEMS: 1.4697 - val_loss: 1.5265 - val_mse: 0.0191 - val_mae: 0.0995 - val_MAEMS: 1.5266\n",
      "Epoch 18/1000\n",
      "1833/1833 [==============================] - 51s 28ms/step - loss: 1.4470 - mse: 0.0173 - mae: 0.0931 - MAEMS: 1.4472 - val_loss: 1.4601 - val_mse: 0.0188 - val_mae: 0.0970 - val_MAEMS: 1.4603\n",
      "Epoch 19/1000\n",
      "1833/1833 [==============================] - 51s 28ms/step - loss: 1.4349 - mse: 0.0170 - mae: 0.0919 - MAEMS: 1.4350 - val_loss: 1.5277 - val_mse: 0.0195 - val_mae: 0.0998 - val_MAEMS: 1.5280\n",
      "Epoch 20/1000\n",
      "1833/1833 [==============================] - 50s 27ms/step - loss: 1.4117 - mse: 0.0166 - mae: 0.0908 - MAEMS: 1.4118 - val_loss: 1.4643 - val_mse: 0.0183 - val_mae: 0.0956 - val_MAEMS: 1.4642\n",
      "Epoch 21/1000\n",
      "1833/1833 [==============================] - 51s 28ms/step - loss: 1.4046 - mse: 0.0163 - mae: 0.0897 - MAEMS: 1.4046 - val_loss: 1.4919 - val_mse: 0.0196 - val_mae: 0.1000 - val_MAEMS: 1.4922\n",
      "Epoch 22/1000\n",
      "1833/1833 [==============================] - 50s 27ms/step - loss: 1.3737 - mse: 0.0157 - mae: 0.0879 - MAEMS: 1.3740 - val_loss: 1.5166 - val_mse: 0.0199 - val_mae: 0.1009 - val_MAEMS: 1.5169\n",
      "Epoch 23/1000\n",
      "1833/1833 [==============================] - 51s 28ms/step - loss: 1.3808 - mse: 0.0156 - mae: 0.0878 - MAEMS: 1.3812 - val_loss: 1.4510 - val_mse: 0.0170 - val_mae: 0.0927 - val_MAEMS: 1.4513\n",
      "Epoch 24/1000\n",
      "1833/1833 [==============================] - 51s 28ms/step - loss: 1.3425 - mse: 0.0151 - mae: 0.0859 - MAEMS: 1.3426 - val_loss: 1.3561 - val_mse: 0.0163 - val_mae: 0.0891 - val_MAEMS: 1.3561\n",
      "Epoch 25/1000\n",
      "1833/1833 [==============================] - 51s 28ms/step - loss: 1.3220 - mse: 0.0148 - mae: 0.0848 - MAEMS: 1.3220 - val_loss: 1.3795 - val_mse: 0.0154 - val_mae: 0.0868 - val_MAEMS: 1.3797\n",
      "Epoch 26/1000\n",
      "1833/1833 [==============================] - 50s 28ms/step - loss: 1.3099 - mse: 0.0144 - mae: 0.0836 - MAEMS: 1.3100 - val_loss: 1.3491 - val_mse: 0.0150 - val_mae: 0.0854 - val_MAEMS: 1.3495\n",
      "Epoch 27/1000\n",
      "1833/1833 [==============================] - 51s 28ms/step - loss: 1.2977 - mse: 0.0141 - mae: 0.0828 - MAEMS: 1.2982 - val_loss: 1.3850 - val_mse: 0.0180 - val_mae: 0.0954 - val_MAEMS: 1.3852\n",
      "Epoch 28/1000\n",
      "1833/1833 [==============================] - 50s 27ms/step - loss: 1.2815 - mse: 0.0138 - mae: 0.0816 - MAEMS: 1.2817 - val_loss: 1.3633 - val_mse: 0.0173 - val_mae: 0.0930 - val_MAEMS: 1.3633\n",
      "Epoch 29/1000\n",
      "1833/1833 [==============================] - 50s 27ms/step - loss: 1.2690 - mse: 0.0136 - mae: 0.0809 - MAEMS: 1.2689 - val_loss: 1.3124 - val_mse: 0.0143 - val_mae: 0.0828 - val_MAEMS: 1.3123\n",
      "Epoch 30/1000\n",
      "1833/1833 [==============================] - 50s 27ms/step - loss: 1.2532 - mse: 0.0134 - mae: 0.0801 - MAEMS: 1.2537 - val_loss: 1.4554 - val_mse: 0.0167 - val_mae: 0.0920 - val_MAEMS: 1.4560\n",
      "Epoch 31/1000\n",
      "1833/1833 [==============================] - 50s 27ms/step - loss: 1.2429 - mse: 0.0130 - mae: 0.0790 - MAEMS: 1.2432 - val_loss: 1.2894 - val_mse: 0.0135 - val_mae: 0.0802 - val_MAEMS: 1.2893\n",
      "Epoch 32/1000\n",
      "1833/1833 [==============================] - 49s 27ms/step - loss: 1.2303 - mse: 0.0126 - mae: 0.0777 - MAEMS: 1.2306 - val_loss: 1.3352 - val_mse: 0.0164 - val_mae: 0.0895 - val_MAEMS: 1.3353\n",
      "Epoch 33/1000\n",
      "1833/1833 [==============================] - 49s 27ms/step - loss: 1.2237 - mse: 0.0128 - mae: 0.0781 - MAEMS: 1.2240 - val_loss: 1.2743 - val_mse: 0.0146 - val_mae: 0.0841 - val_MAEMS: 1.2744\n",
      "Epoch 34/1000\n",
      "1833/1833 [==============================] - 51s 28ms/step - loss: 1.2147 - mse: 0.0124 - mae: 0.0769 - MAEMS: 1.2152 - val_loss: 1.2865 - val_mse: 0.0159 - val_mae: 0.0883 - val_MAEMS: 1.2864\n",
      "Epoch 35/1000\n",
      "1833/1833 [==============================] - 50s 28ms/step - loss: 1.2004 - mse: 0.0122 - mae: 0.0762 - MAEMS: 1.2005 - val_loss: 1.2617 - val_mse: 0.0131 - val_mae: 0.0800 - val_MAEMS: 1.2620\n",
      "Epoch 36/1000\n",
      "1833/1833 [==============================] - 50s 27ms/step - loss: 1.1924 - mse: 0.0119 - mae: 0.0754 - MAEMS: 1.1926 - val_loss: 1.2515 - val_mse: 0.0132 - val_mae: 0.0797 - val_MAEMS: 1.2516\n",
      "Epoch 37/1000\n",
      "1833/1833 [==============================] - 50s 27ms/step - loss: 1.1721 - mse: 0.0116 - mae: 0.0743 - MAEMS: 1.1726 - val_loss: 1.2713 - val_mse: 0.0123 - val_mae: 0.0772 - val_MAEMS: 1.2713\n",
      "Epoch 38/1000\n",
      "1833/1833 [==============================] - 50s 27ms/step - loss: 1.1649 - mse: 0.0115 - mae: 0.0738 - MAEMS: 1.1648 - val_loss: 1.2546 - val_mse: 0.0146 - val_mae: 0.0836 - val_MAEMS: 1.2549\n",
      "Epoch 39/1000\n",
      "1833/1833 [==============================] - 50s 27ms/step - loss: 1.1547 - mse: 0.0114 - mae: 0.0731 - MAEMS: 1.1548 - val_loss: 1.2099 - val_mse: 0.0121 - val_mae: 0.0756 - val_MAEMS: 1.2100\n",
      "Epoch 40/1000\n",
      "1833/1833 [==============================] - 50s 27ms/step - loss: 1.1507 - mse: 0.0113 - mae: 0.0729 - MAEMS: 1.1507 - val_loss: 1.1714 - val_mse: 0.0120 - val_mae: 0.0747 - val_MAEMS: 1.1715\n",
      "Epoch 41/1000\n",
      "1833/1833 [==============================] - 49s 27ms/step - loss: 1.1476 - mse: 0.0110 - mae: 0.0721 - MAEMS: 1.1477 - val_loss: 1.1764 - val_mse: 0.0110 - val_mae: 0.0719 - val_MAEMS: 1.1764\n",
      "Epoch 42/1000\n",
      "1833/1833 [==============================] - 50s 27ms/step - loss: 1.1388 - mse: 0.0108 - mae: 0.0714 - MAEMS: 1.1389 - val_loss: 1.1820 - val_mse: 0.0112 - val_mae: 0.0723 - val_MAEMS: 1.1820\n",
      "Epoch 43/1000\n",
      "1833/1833 [==============================] - 50s 27ms/step - loss: 1.1224 - mse: 0.0107 - mae: 0.0708 - MAEMS: 1.1224 - val_loss: 1.1696 - val_mse: 0.0123 - val_mae: 0.0759 - val_MAEMS: 1.1696\n",
      "Epoch 44/1000\n",
      "1833/1833 [==============================] - 51s 28ms/step - loss: 1.1126 - mse: 0.0105 - mae: 0.0700 - MAEMS: 1.1127 - val_loss: 1.2136 - val_mse: 0.0113 - val_mae: 0.0731 - val_MAEMS: 1.2137\n",
      "Epoch 45/1000\n",
      "1833/1833 [==============================] - 50s 27ms/step - loss: 1.1059 - mse: 0.0103 - mae: 0.0695 - MAEMS: 1.1060 - val_loss: 1.1975 - val_mse: 0.0114 - val_mae: 0.0739 - val_MAEMS: 1.1976\n",
      "Epoch 46/1000\n",
      "1833/1833 [==============================] - 50s 27ms/step - loss: 1.1036 - mse: 0.0102 - mae: 0.0690 - MAEMS: 1.1039 - val_loss: 1.2203 - val_mse: 0.0125 - val_mae: 0.0774 - val_MAEMS: 1.2205\n",
      "Epoch 47/1000\n",
      "1833/1833 [==============================] - 50s 27ms/step - loss: 1.0974 - mse: 0.0100 - mae: 0.0686 - MAEMS: 1.0974 - val_loss: 1.2030 - val_mse: 0.0111 - val_mae: 0.0731 - val_MAEMS: 1.2031\n",
      "Epoch 48/1000\n",
      "1833/1833 [==============================] - 50s 27ms/step - loss: 1.0765 - mse: 0.0098 - mae: 0.0677 - MAEMS: 1.0769 - val_loss: 1.1280 - val_mse: 0.0104 - val_mae: 0.0692 - val_MAEMS: 1.1282\n",
      "Epoch 49/1000\n",
      "1833/1833 [==============================] - 50s 27ms/step - loss: 1.0654 - mse: 0.0096 - mae: 0.0670 - MAEMS: 1.0657 - val_loss: 1.1382 - val_mse: 0.0116 - val_mae: 0.0735 - val_MAEMS: 1.1383\n",
      "Epoch 50/1000\n",
      "1833/1833 [==============================] - 50s 27ms/step - loss: 1.0661 - mse: 0.0095 - mae: 0.0665 - MAEMS: 1.0666 - val_loss: 1.1037 - val_mse: 0.0101 - val_mae: 0.0681 - val_MAEMS: 1.1041\n",
      "Epoch 51/1000\n",
      "1833/1833 [==============================] - 50s 27ms/step - loss: 1.0619 - mse: 0.0094 - mae: 0.0662 - MAEMS: 1.0621 - val_loss: 1.1764 - val_mse: 0.0114 - val_mae: 0.0738 - val_MAEMS: 1.1767\n",
      "Epoch 52/1000\n",
      "1833/1833 [==============================] - 49s 27ms/step - loss: 1.0520 - mse: 0.0092 - mae: 0.0655 - MAEMS: 1.0519 - val_loss: 1.1232 - val_mse: 0.0100 - val_mae: 0.0682 - val_MAEMS: 1.1233\n",
      "Epoch 53/1000\n",
      "1833/1833 [==============================] - 50s 28ms/step - loss: 1.0479 - mse: 0.0092 - mae: 0.0654 - MAEMS: 1.0480 - val_loss: 1.1098 - val_mse: 0.0099 - val_mae: 0.0684 - val_MAEMS: 1.1100\n",
      "Epoch 54/1000\n",
      "1833/1833 [==============================] - 51s 28ms/step - loss: 1.0413 - mse: 0.0090 - mae: 0.0648 - MAEMS: 1.0415 - val_loss: 1.1412 - val_mse: 0.0091 - val_mae: 0.0653 - val_MAEMS: 1.1413\n",
      "Epoch 55/1000\n",
      "1833/1833 [==============================] - 51s 28ms/step - loss: 1.0366 - mse: 0.0089 - mae: 0.0644 - MAEMS: 1.0369 - val_loss: 1.0915 - val_mse: 0.0096 - val_mae: 0.0664 - val_MAEMS: 1.0917\n",
      "Epoch 56/1000\n",
      "1833/1833 [==============================] - 50s 27ms/step - loss: 1.0246 - mse: 0.0088 - mae: 0.0640 - MAEMS: 1.0247 - val_loss: 1.1069 - val_mse: 0.0086 - val_mae: 0.0634 - val_MAEMS: 1.1069\n",
      "Epoch 57/1000\n",
      "1833/1833 [==============================] - 51s 28ms/step - loss: 1.0213 - mse: 0.0087 - mae: 0.0634 - MAEMS: 1.0215 - val_loss: 1.1123 - val_mse: 0.0098 - val_mae: 0.0675 - val_MAEMS: 1.1124\n",
      "Epoch 58/1000\n",
      "1833/1833 [==============================] - 50s 27ms/step - loss: 1.0130 - mse: 0.0085 - mae: 0.0629 - MAEMS: 1.0134 - val_loss: 1.0915 - val_mse: 0.0108 - val_mae: 0.0718 - val_MAEMS: 1.0917\n",
      "Epoch 59/1000\n",
      "1833/1833 [==============================] - 51s 28ms/step - loss: 1.0078 - mse: 0.0084 - mae: 0.0625 - MAEMS: 1.0082 - val_loss: 1.0880 - val_mse: 0.0109 - val_mae: 0.0723 - val_MAEMS: 1.0880\n",
      "Epoch 60/1000\n",
      "1833/1833 [==============================] - 51s 28ms/step - loss: 1.0046 - mse: 0.0084 - mae: 0.0623 - MAEMS: 1.0048 - val_loss: 1.0567 - val_mse: 0.0103 - val_mae: 0.0690 - val_MAEMS: 1.0568\n",
      "Epoch 61/1000\n",
      "1833/1833 [==============================] - 50s 27ms/step - loss: 0.9987 - mse: 0.0082 - mae: 0.0619 - MAEMS: 0.9987 - val_loss: 1.1354 - val_mse: 0.0086 - val_mae: 0.0637 - val_MAEMS: 1.1356\n",
      "Epoch 62/1000\n",
      "1833/1833 [==============================] - 50s 27ms/step - loss: 0.9974 - mse: 0.0082 - mae: 0.0618 - MAEMS: 0.9978 - val_loss: 1.1179 - val_mse: 0.0118 - val_mae: 0.0751 - val_MAEMS: 1.1178\n",
      "Epoch 63/1000\n",
      "1833/1833 [==============================] - 50s 27ms/step - loss: 0.9866 - mse: 0.0080 - mae: 0.0611 - MAEMS: 0.9867 - val_loss: 1.0597 - val_mse: 0.0098 - val_mae: 0.0670 - val_MAEMS: 1.0597\n",
      "Epoch 64/1000\n",
      "1833/1833 [==============================] - 50s 27ms/step - loss: 0.9793 - mse: 0.0079 - mae: 0.0607 - MAEMS: 0.9795 - val_loss: 1.1278 - val_mse: 0.0115 - val_mae: 0.0742 - val_MAEMS: 1.1278\n",
      "Epoch 65/1000\n",
      "1833/1833 [==============================] - 50s 27ms/step - loss: 0.9795 - mse: 0.0079 - mae: 0.0607 - MAEMS: 0.9796 - val_loss: 1.0642 - val_mse: 0.0083 - val_mae: 0.0617 - val_MAEMS: 1.0642\n",
      "Epoch 66/1000\n",
      "1833/1833 [==============================] - 50s 28ms/step - loss: 0.9697 - mse: 0.0078 - mae: 0.0601 - MAEMS: 0.9698 - val_loss: 1.1312 - val_mse: 0.0119 - val_mae: 0.0752 - val_MAEMS: 1.1311\n",
      "Epoch 67/1000\n",
      "1833/1833 [==============================] - 51s 28ms/step - loss: 0.9667 - mse: 0.0077 - mae: 0.0599 - MAEMS: 0.9671 - val_loss: 1.0802 - val_mse: 0.0113 - val_mae: 0.0736 - val_MAEMS: 1.0802\n",
      "Epoch 68/1000\n",
      "1833/1833 [==============================] - 51s 28ms/step - loss: 0.9747 - mse: 0.0077 - mae: 0.0599 - MAEMS: 0.9750 - val_loss: 1.1090 - val_mse: 0.0078 - val_mae: 0.0608 - val_MAEMS: 1.1091\n",
      "Epoch 69/1000\n",
      "1833/1833 [==============================] - 51s 28ms/step - loss: 0.9623 - mse: 0.0076 - mae: 0.0594 - MAEMS: 0.9624 - val_loss: 0.9986 - val_mse: 0.0094 - val_mae: 0.0656 - val_MAEMS: 0.9989\n",
      "Epoch 70/1000\n",
      "1833/1833 [==============================] - 51s 28ms/step - loss: 0.9424 - mse: 0.0073 - mae: 0.0582 - MAEMS: 0.9428 - val_loss: 1.0407 - val_mse: 0.0107 - val_mae: 0.0705 - val_MAEMS: 1.0407\n",
      "Epoch 71/1000\n",
      "1833/1833 [==============================] - 51s 28ms/step - loss: 0.9449 - mse: 0.0073 - mae: 0.0582 - MAEMS: 0.9451 - val_loss: 1.0203 - val_mse: 0.0096 - val_mae: 0.0661 - val_MAEMS: 1.0204\n",
      "Epoch 72/1000\n",
      "1833/1833 [==============================] - 50s 27ms/step - loss: 0.9464 - mse: 0.0072 - mae: 0.0581 - MAEMS: 0.9467 - val_loss: 1.0679 - val_mse: 0.0096 - val_mae: 0.0671 - val_MAEMS: 1.0679\n",
      "Epoch 73/1000\n",
      "1833/1833 [==============================] - 50s 27ms/step - loss: 0.9403 - mse: 0.0072 - mae: 0.0578 - MAEMS: 0.9407 - val_loss: 1.0911 - val_mse: 0.0117 - val_mae: 0.0750 - val_MAEMS: 1.0913\n",
      "Epoch 74/1000\n",
      "1833/1833 [==============================] - 50s 27ms/step - loss: 0.9320 - mse: 0.0072 - mae: 0.0576 - MAEMS: 0.9323 - val_loss: 0.9930 - val_mse: 0.0080 - val_mae: 0.0604 - val_MAEMS: 0.9931\n",
      "Epoch 75/1000\n",
      "1833/1833 [==============================] - 50s 27ms/step - loss: 0.9284 - mse: 0.0071 - mae: 0.0573 - MAEMS: 0.9287 - val_loss: 1.0231 - val_mse: 0.0107 - val_mae: 0.0710 - val_MAEMS: 1.0233\n",
      "Epoch 76/1000\n",
      "1833/1833 [==============================] - 50s 27ms/step - loss: 0.9207 - mse: 0.0069 - mae: 0.0567 - MAEMS: 0.9208 - val_loss: 1.0044 - val_mse: 0.0086 - val_mae: 0.0632 - val_MAEMS: 1.0047\n",
      "Epoch 77/1000\n",
      "1833/1833 [==============================] - 50s 28ms/step - loss: 0.9220 - mse: 0.0069 - mae: 0.0565 - MAEMS: 0.9223 - val_loss: 1.0455 - val_mse: 0.0081 - val_mae: 0.0611 - val_MAEMS: 1.0455\n",
      "Epoch 78/1000\n",
      "1833/1833 [==============================] - 51s 28ms/step - loss: 0.9194 - mse: 0.0068 - mae: 0.0562 - MAEMS: 0.9198 - val_loss: 0.9881 - val_mse: 0.0077 - val_mae: 0.0593 - val_MAEMS: 0.9883\n",
      "Epoch 79/1000\n",
      "1833/1833 [==============================] - 50s 27ms/step - loss: 0.9097 - mse: 0.0067 - mae: 0.0558 - MAEMS: 0.9097 - val_loss: 0.9821 - val_mse: 0.0083 - val_mae: 0.0611 - val_MAEMS: 0.9822\n",
      "Epoch 80/1000\n",
      "1833/1833 [==============================] - 49s 27ms/step - loss: 0.9103 - mse: 0.0068 - mae: 0.0558 - MAEMS: 0.9106 - val_loss: 1.0009 - val_mse: 0.0094 - val_mae: 0.0658 - val_MAEMS: 1.0012\n",
      "Epoch 81/1000\n",
      "1833/1833 [==============================] - 50s 27ms/step - loss: 0.9040 - mse: 0.0066 - mae: 0.0554 - MAEMS: 0.9041 - val_loss: 1.0600 - val_mse: 0.0110 - val_mae: 0.0730 - val_MAEMS: 1.0600\n",
      "Epoch 82/1000\n",
      "1833/1833 [==============================] - 50s 27ms/step - loss: 0.9051 - mse: 0.0066 - mae: 0.0553 - MAEMS: 0.9052 - val_loss: 1.0031 - val_mse: 0.0082 - val_mae: 0.0613 - val_MAEMS: 1.0036\n",
      "Epoch 83/1000\n",
      "1833/1833 [==============================] - 49s 27ms/step - loss: 0.9012 - mse: 0.0066 - mae: 0.0551 - MAEMS: 0.9014 - val_loss: 1.0286 - val_mse: 0.0106 - val_mae: 0.0706 - val_MAEMS: 1.0287\n",
      "Epoch 84/1000\n",
      "1833/1833 [==============================] - 49s 27ms/step - loss: 0.8973 - mse: 0.0065 - mae: 0.0550 - MAEMS: 0.8975 - val_loss: 1.0125 - val_mse: 0.0088 - val_mae: 0.0636 - val_MAEMS: 1.0127\n",
      "Epoch 85/1000\n",
      "1833/1833 [==============================] - 50s 27ms/step - loss: 0.9000 - mse: 0.0065 - mae: 0.0548 - MAEMS: 0.9001 - val_loss: 0.9819 - val_mse: 0.0089 - val_mae: 0.0635 - val_MAEMS: 0.9821\n",
      "Epoch 86/1000\n",
      "1833/1833 [==============================] - 50s 27ms/step - loss: 0.8927 - mse: 0.0065 - mae: 0.0547 - MAEMS: 0.8928 - val_loss: 0.9953 - val_mse: 0.0085 - val_mae: 0.0630 - val_MAEMS: 0.9955\n",
      "Epoch 87/1000\n",
      "1833/1833 [==============================] - 49s 27ms/step - loss: 0.8777 - mse: 0.0063 - mae: 0.0537 - MAEMS: 0.8779 - val_loss: 0.9780 - val_mse: 0.0081 - val_mae: 0.0606 - val_MAEMS: 0.9781\n",
      "Epoch 88/1000\n",
      "1833/1833 [==============================] - 50s 28ms/step - loss: 0.8803 - mse: 0.0062 - mae: 0.0536 - MAEMS: 0.8804 - val_loss: 1.0075 - val_mse: 0.0091 - val_mae: 0.0654 - val_MAEMS: 1.0074\n",
      "Epoch 89/1000\n",
      "1833/1833 [==============================] - 50s 27ms/step - loss: 0.8841 - mse: 0.0062 - mae: 0.0538 - MAEMS: 0.8841 - val_loss: 0.9564 - val_mse: 0.0077 - val_mae: 0.0589 - val_MAEMS: 0.9565\n",
      "Epoch 90/1000\n",
      "1833/1833 [==============================] - 50s 27ms/step - loss: 0.8821 - mse: 0.0062 - mae: 0.0537 - MAEMS: 0.8821 - val_loss: 0.9639 - val_mse: 0.0070 - val_mae: 0.0564 - val_MAEMS: 0.9643\n",
      "Epoch 91/1000\n",
      "1833/1833 [==============================] - 50s 27ms/step - loss: 0.8689 - mse: 0.0061 - mae: 0.0532 - MAEMS: 0.8689 - val_loss: 0.9585 - val_mse: 0.0076 - val_mae: 0.0585 - val_MAEMS: 0.9586\n",
      "Epoch 92/1000\n",
      "1833/1833 [==============================] - 50s 27ms/step - loss: 0.8692 - mse: 0.0061 - mae: 0.0530 - MAEMS: 0.8693 - val_loss: 0.9737 - val_mse: 0.0079 - val_mae: 0.0602 - val_MAEMS: 0.9737\n",
      "Epoch 93/1000\n",
      "1833/1833 [==============================] - 49s 27ms/step - loss: 0.8678 - mse: 0.0061 - mae: 0.0533 - MAEMS: 0.8679 - val_loss: 0.9428 - val_mse: 0.0078 - val_mae: 0.0591 - val_MAEMS: 0.9426\n",
      "Epoch 94/1000\n",
      "1833/1833 [==============================] - 49s 27ms/step - loss: 0.8706 - mse: 0.0061 - mae: 0.0531 - MAEMS: 0.8707 - val_loss: 0.9962 - val_mse: 0.0085 - val_mae: 0.0627 - val_MAEMS: 0.9964\n",
      "Epoch 95/1000\n",
      "1833/1833 [==============================] - 49s 27ms/step - loss: 0.8593 - mse: 0.0059 - mae: 0.0523 - MAEMS: 0.8597 - val_loss: 0.9531 - val_mse: 0.0088 - val_mae: 0.0630 - val_MAEMS: 0.9531\n",
      "Epoch 96/1000\n",
      "1833/1833 [==============================] - 49s 27ms/step - loss: 0.8588 - mse: 0.0060 - mae: 0.0525 - MAEMS: 0.8589 - val_loss: 0.9484 - val_mse: 0.0084 - val_mae: 0.0613 - val_MAEMS: 0.9486\n",
      "Epoch 97/1000\n",
      "1833/1833 [==============================] - 49s 27ms/step - loss: 0.8558 - mse: 0.0059 - mae: 0.0523 - MAEMS: 0.8559 - val_loss: 1.0344 - val_mse: 0.0088 - val_mae: 0.0639 - val_MAEMS: 1.0345\n",
      "Epoch 98/1000\n",
      "1833/1833 [==============================] - 50s 27ms/step - loss: 0.8580 - mse: 0.0058 - mae: 0.0520 - MAEMS: 0.8581 - val_loss: 0.9508 - val_mse: 0.0064 - val_mae: 0.0547 - val_MAEMS: 0.9511\n",
      "Epoch 99/1000\n",
      "1833/1833 [==============================] - 49s 27ms/step - loss: 0.8410 - mse: 0.0057 - mae: 0.0514 - MAEMS: 0.8414 - val_loss: 0.9186 - val_mse: 0.0077 - val_mae: 0.0586 - val_MAEMS: 0.9186\n",
      "Epoch 100/1000\n",
      "1833/1833 [==============================] - 49s 27ms/step - loss: 0.8475 - mse: 0.0057 - mae: 0.0514 - MAEMS: 0.8476 - val_loss: 1.0405 - val_mse: 0.0105 - val_mae: 0.0721 - val_MAEMS: 1.0406\n",
      "Epoch 101/1000\n",
      "1833/1833 [==============================] - 49s 27ms/step - loss: 0.8389 - mse: 0.0056 - mae: 0.0510 - MAEMS: 0.8389 - val_loss: 1.0478 - val_mse: 0.0082 - val_mae: 0.0630 - val_MAEMS: 1.0480\n",
      "Epoch 102/1000\n",
      "1833/1833 [==============================] - 50s 27ms/step - loss: 0.8441 - mse: 0.0057 - mae: 0.0514 - MAEMS: 0.8442 - val_loss: 0.9511 - val_mse: 0.0089 - val_mae: 0.0633 - val_MAEMS: 0.9515\n",
      "Epoch 103/1000\n",
      "1833/1833 [==============================] - 49s 27ms/step - loss: 0.8482 - mse: 0.0057 - mae: 0.0514 - MAEMS: 0.8483 - val_loss: 0.9470 - val_mse: 0.0076 - val_mae: 0.0587 - val_MAEMS: 0.9470\n",
      "Epoch 104/1000\n",
      "1833/1833 [==============================] - 50s 27ms/step - loss: 0.8329 - mse: 0.0055 - mae: 0.0507 - MAEMS: 0.8331 - val_loss: 1.0215 - val_mse: 0.0100 - val_mae: 0.0704 - val_MAEMS: 1.0218\n",
      "Epoch 105/1000\n",
      "1833/1833 [==============================] - 49s 27ms/step - loss: 0.8327 - mse: 0.0055 - mae: 0.0506 - MAEMS: 0.8329 - val_loss: 1.1639 - val_mse: 0.0123 - val_mae: 0.0806 - val_MAEMS: 1.1640\n",
      "Epoch 106/1000\n",
      "1833/1833 [==============================] - 49s 27ms/step - loss: 0.8376 - mse: 0.0055 - mae: 0.0507 - MAEMS: 0.8376 - val_loss: 0.9411 - val_mse: 0.0068 - val_mae: 0.0559 - val_MAEMS: 0.9411\n",
      "Epoch 107/1000\n",
      "1833/1833 [==============================] - 50s 27ms/step - loss: 0.8313 - mse: 0.0055 - mae: 0.0504 - MAEMS: 0.8314 - val_loss: 0.9962 - val_mse: 0.0100 - val_mae: 0.0680 - val_MAEMS: 0.9962\n",
      "Epoch 108/1000\n",
      "1833/1833 [==============================] - 50s 27ms/step - loss: 0.8295 - mse: 0.0055 - mae: 0.0504 - MAEMS: 0.8295 - val_loss: 0.9047 - val_mse: 0.0076 - val_mae: 0.0582 - val_MAEMS: 0.9048\n",
      "Epoch 109/1000\n",
      "1833/1833 [==============================] - 50s 27ms/step - loss: 0.8215 - mse: 0.0053 - mae: 0.0498 - MAEMS: 0.8218 - val_loss: 0.9540 - val_mse: 0.0077 - val_mae: 0.0595 - val_MAEMS: 0.9540\n",
      "Epoch 110/1000\n",
      "1833/1833 [==============================] - 50s 27ms/step - loss: 0.8223 - mse: 0.0054 - mae: 0.0499 - MAEMS: 0.8225 - val_loss: 0.9239 - val_mse: 0.0078 - val_mae: 0.0596 - val_MAEMS: 0.9240\n",
      "Epoch 111/1000\n",
      "1833/1833 [==============================] - 49s 27ms/step - loss: 0.8205 - mse: 0.0053 - mae: 0.0498 - MAEMS: 0.8206 - val_loss: 0.9306 - val_mse: 0.0083 - val_mae: 0.0617 - val_MAEMS: 0.9306\n",
      "Epoch 112/1000\n",
      "1833/1833 [==============================] - 47s 26ms/step - loss: 0.8179 - mse: 0.0053 - mae: 0.0495 - MAEMS: 0.8180 - val_loss: 0.9329 - val_mse: 0.0076 - val_mae: 0.0590 - val_MAEMS: 0.9331\n",
      "Epoch 113/1000\n",
      "1833/1833 [==============================] - 48s 26ms/step - loss: 0.8168 - mse: 0.0052 - mae: 0.0494 - MAEMS: 0.8170 - val_loss: 0.9613 - val_mse: 0.0088 - val_mae: 0.0640 - val_MAEMS: 0.9614\n",
      "Epoch 114/1000\n",
      "1833/1833 [==============================] - 50s 27ms/step - loss: 0.8207 - mse: 0.0052 - mae: 0.0495 - MAEMS: 0.8210 - val_loss: 0.9298 - val_mse: 0.0077 - val_mae: 0.0596 - val_MAEMS: 0.9300\n",
      "Epoch 115/1000\n",
      "1833/1833 [==============================] - 50s 27ms/step - loss: 0.8097 - mse: 0.0052 - mae: 0.0491 - MAEMS: 0.8099 - val_loss: 0.9578 - val_mse: 0.0078 - val_mae: 0.0607 - val_MAEMS: 0.9580\n",
      "Epoch 116/1000\n",
      "1833/1833 [==============================] - 50s 27ms/step - loss: 0.8145 - mse: 0.0052 - mae: 0.0494 - MAEMS: 0.8145 - val_loss: 0.8845 - val_mse: 0.0065 - val_mae: 0.0541 - val_MAEMS: 0.8847\n",
      "Epoch 117/1000\n",
      "1833/1833 [==============================] - 50s 27ms/step - loss: 0.8112 - mse: 0.0052 - mae: 0.0491 - MAEMS: 0.8113 - val_loss: 0.9825 - val_mse: 0.0088 - val_mae: 0.0648 - val_MAEMS: 0.9826\n",
      "Epoch 118/1000\n",
      "1833/1833 [==============================] - 50s 27ms/step - loss: 0.8107 - mse: 0.0051 - mae: 0.0490 - MAEMS: 0.8110 - val_loss: 0.9027 - val_mse: 0.0077 - val_mae: 0.0598 - val_MAEMS: 0.9029\n",
      "Epoch 119/1000\n",
      "1833/1833 [==============================] - 50s 27ms/step - loss: 0.8124 - mse: 0.0051 - mae: 0.0490 - MAEMS: 0.8124 - val_loss: 0.9047 - val_mse: 0.0073 - val_mae: 0.0581 - val_MAEMS: 0.9050\n",
      "Epoch 120/1000\n",
      "1833/1833 [==============================] - 49s 27ms/step - loss: 0.8106 - mse: 0.0051 - mae: 0.0490 - MAEMS: 0.8109 - val_loss: 0.9379 - val_mse: 0.0079 - val_mae: 0.0608 - val_MAEMS: 0.9380\n",
      "Epoch 121/1000\n",
      "1833/1833 [==============================] - 49s 27ms/step - loss: 0.8072 - mse: 0.0051 - mae: 0.0488 - MAEMS: 0.8072 - val_loss: 0.9304 - val_mse: 0.0086 - val_mae: 0.0624 - val_MAEMS: 0.9307\n",
      "Epoch 122/1000\n",
      "1833/1833 [==============================] - 49s 27ms/step - loss: 0.8063 - mse: 0.0051 - mae: 0.0488 - MAEMS: 0.8064 - val_loss: 0.9229 - val_mse: 0.0074 - val_mae: 0.0578 - val_MAEMS: 0.9232\n",
      "Epoch 123/1000\n",
      "1833/1833 [==============================] - 51s 28ms/step - loss: 0.7956 - mse: 0.0050 - mae: 0.0483 - MAEMS: 0.7957 - val_loss: 0.9149 - val_mse: 0.0075 - val_mae: 0.0590 - val_MAEMS: 0.9150\n",
      "Epoch 124/1000\n",
      "1833/1833 [==============================] - 50s 27ms/step - loss: 0.7987 - mse: 0.0050 - mae: 0.0483 - MAEMS: 0.7989 - val_loss: 0.8863 - val_mse: 0.0068 - val_mae: 0.0552 - val_MAEMS: 0.8866\n",
      "Epoch 125/1000\n",
      "1833/1833 [==============================] - 50s 27ms/step - loss: 0.7985 - mse: 0.0050 - mae: 0.0482 - MAEMS: 0.7986 - val_loss: 0.9084 - val_mse: 0.0077 - val_mae: 0.0594 - val_MAEMS: 0.9084\n",
      "Epoch 126/1000\n",
      "1833/1833 [==============================] - 50s 27ms/step - loss: 0.7900 - mse: 0.0049 - mae: 0.0477 - MAEMS: 0.7902 - val_loss: 0.9424 - val_mse: 0.0080 - val_mae: 0.0604 - val_MAEMS: 0.9426\n",
      "Epoch 127/1000\n",
      "1833/1833 [==============================] - 51s 28ms/step - loss: 0.7941 - mse: 0.0049 - mae: 0.0478 - MAEMS: 0.7942 - val_loss: 0.9207 - val_mse: 0.0072 - val_mae: 0.0575 - val_MAEMS: 0.9213\n",
      "Epoch 128/1000\n",
      "1833/1833 [==============================] - 51s 28ms/step - loss: 0.7886 - mse: 0.0049 - mae: 0.0476 - MAEMS: 0.7887 - val_loss: 0.9393 - val_mse: 0.0057 - val_mae: 0.0517 - val_MAEMS: 0.9395\n",
      "Epoch 129/1000\n",
      "1833/1833 [==============================] - 50s 27ms/step - loss: 0.7943 - mse: 0.0049 - mae: 0.0478 - MAEMS: 0.7944 - val_loss: 0.9136 - val_mse: 0.0072 - val_mae: 0.0574 - val_MAEMS: 0.9137\n",
      "Epoch 130/1000\n",
      "1833/1833 [==============================] - 50s 27ms/step - loss: 0.7915 - mse: 0.0048 - mae: 0.0477 - MAEMS: 0.7916 - val_loss: 0.9027 - val_mse: 0.0075 - val_mae: 0.0590 - val_MAEMS: 0.9029\n",
      "Epoch 131/1000\n",
      "1833/1833 [==============================] - 51s 28ms/step - loss: 0.7876 - mse: 0.0049 - mae: 0.0477 - MAEMS: 0.7879 - val_loss: 0.9197 - val_mse: 0.0083 - val_mae: 0.0627 - val_MAEMS: 0.9197\n",
      "Epoch 132/1000\n",
      "1833/1833 [==============================] - 51s 28ms/step - loss: 0.7843 - mse: 0.0048 - mae: 0.0475 - MAEMS: 0.7843 - val_loss: 0.9127 - val_mse: 0.0065 - val_mae: 0.0546 - val_MAEMS: 0.9127\n",
      "Epoch 133/1000\n",
      "1833/1833 [==============================] - 50s 27ms/step - loss: 0.7896 - mse: 0.0049 - mae: 0.0478 - MAEMS: 0.7897 - val_loss: 0.9631 - val_mse: 0.0075 - val_mae: 0.0597 - val_MAEMS: 0.9631\n",
      "Epoch 134/1000\n",
      "1833/1833 [==============================] - 49s 27ms/step - loss: 0.7818 - mse: 0.0048 - mae: 0.0472 - MAEMS: 0.7819 - val_loss: 0.9015 - val_mse: 0.0087 - val_mae: 0.0641 - val_MAEMS: 0.9015\n",
      "Epoch 135/1000\n",
      "1833/1833 [==============================] - 50s 27ms/step - loss: 0.7806 - mse: 0.0048 - mae: 0.0472 - MAEMS: 0.7808 - val_loss: 0.8765 - val_mse: 0.0075 - val_mae: 0.0581 - val_MAEMS: 0.8766\n",
      "Epoch 136/1000\n",
      "1833/1833 [==============================] - 50s 27ms/step - loss: 0.7842 - mse: 0.0048 - mae: 0.0474 - MAEMS: 0.7844 - val_loss: 0.8652 - val_mse: 0.0070 - val_mae: 0.0561 - val_MAEMS: 0.8652\n",
      "Epoch 137/1000\n",
      "1833/1833 [==============================] - 50s 27ms/step - loss: 0.7768 - mse: 0.0047 - mae: 0.0471 - MAEMS: 0.7770 - val_loss: 0.8808 - val_mse: 0.0061 - val_mae: 0.0526 - val_MAEMS: 0.8810\n",
      "Epoch 138/1000\n",
      "1833/1833 [==============================] - 49s 27ms/step - loss: 0.7693 - mse: 0.0047 - mae: 0.0468 - MAEMS: 0.7694 - val_loss: 0.8798 - val_mse: 0.0067 - val_mae: 0.0549 - val_MAEMS: 0.8800\n",
      "Epoch 139/1000\n",
      "1833/1833 [==============================] - 50s 27ms/step - loss: 0.7726 - mse: 0.0047 - mae: 0.0469 - MAEMS: 0.7728 - val_loss: 0.9147 - val_mse: 0.0074 - val_mae: 0.0580 - val_MAEMS: 0.9150\n",
      "Epoch 140/1000\n",
      "1833/1833 [==============================] - 49s 27ms/step - loss: 0.7684 - mse: 0.0047 - mae: 0.0466 - MAEMS: 0.7685 - val_loss: 0.9155 - val_mse: 0.0071 - val_mae: 0.0576 - val_MAEMS: 0.9157\n",
      "Epoch 141/1000\n",
      "1833/1833 [==============================] - 49s 27ms/step - loss: 0.7822 - mse: 0.0047 - mae: 0.0469 - MAEMS: 0.7823 - val_loss: 0.9124 - val_mse: 0.0082 - val_mae: 0.0613 - val_MAEMS: 0.9126\n",
      "Epoch 142/1000\n",
      "1833/1833 [==============================] - 50s 27ms/step - loss: 0.7698 - mse: 0.0046 - mae: 0.0465 - MAEMS: 0.7701 - val_loss: 0.8974 - val_mse: 0.0078 - val_mae: 0.0603 - val_MAEMS: 0.8977\n",
      "Epoch 143/1000\n",
      "1833/1833 [==============================] - 49s 27ms/step - loss: 0.7670 - mse: 0.0046 - mae: 0.0462 - MAEMS: 0.7673 - val_loss: 0.9622 - val_mse: 0.0102 - val_mae: 0.0702 - val_MAEMS: 0.9623\n",
      "Epoch 144/1000\n",
      "1833/1833 [==============================] - 50s 27ms/step - loss: 0.7661 - mse: 0.0045 - mae: 0.0460 - MAEMS: 0.7664 - val_loss: 0.9073 - val_mse: 0.0071 - val_mae: 0.0574 - val_MAEMS: 0.9074\n",
      "Epoch 145/1000\n",
      "1833/1833 [==============================] - 49s 27ms/step - loss: 0.7642 - mse: 0.0045 - mae: 0.0461 - MAEMS: 0.7643 - val_loss: 0.9011 - val_mse: 0.0080 - val_mae: 0.0606 - val_MAEMS: 0.9013\n",
      "Epoch 146/1000\n",
      "1833/1833 [==============================] - 51s 28ms/step - loss: 0.7665 - mse: 0.0045 - mae: 0.0461 - MAEMS: 0.7667 - val_loss: 0.8811 - val_mse: 0.0064 - val_mae: 0.0541 - val_MAEMS: 0.8815\n",
      "Epoch 147/1000\n",
      "1833/1833 [==============================] - 50s 27ms/step - loss: 0.7673 - mse: 0.0046 - mae: 0.0462 - MAEMS: 0.7675 - val_loss: 0.8796 - val_mse: 0.0078 - val_mae: 0.0606 - val_MAEMS: 0.8797\n",
      "Epoch 148/1000\n",
      "1833/1833 [==============================] - 50s 27ms/step - loss: 0.7642 - mse: 0.0045 - mae: 0.0461 - MAEMS: 0.7642 - val_loss: 0.8627 - val_mse: 0.0064 - val_mae: 0.0539 - val_MAEMS: 0.8627\n",
      "Epoch 149/1000\n",
      "1833/1833 [==============================] - 50s 27ms/step - loss: 0.7728 - mse: 0.0046 - mae: 0.0464 - MAEMS: 0.7733 - val_loss: 0.8936 - val_mse: 0.0071 - val_mae: 0.0569 - val_MAEMS: 0.8936\n",
      "Epoch 150/1000\n",
      "1833/1833 [==============================] - 50s 27ms/step - loss: 0.7626 - mse: 0.0046 - mae: 0.0462 - MAEMS: 0.7627 - val_loss: 0.8710 - val_mse: 0.0071 - val_mae: 0.0565 - val_MAEMS: 0.8713\n",
      "Epoch 151/1000\n",
      "1833/1833 [==============================] - 50s 27ms/step - loss: 0.7559 - mse: 0.0045 - mae: 0.0458 - MAEMS: 0.7561 - val_loss: 0.8808 - val_mse: 0.0076 - val_mae: 0.0591 - val_MAEMS: 0.8810\n",
      "Epoch 152/1000\n",
      "1833/1833 [==============================] - 50s 27ms/step - loss: 0.7565 - mse: 0.0046 - mae: 0.0461 - MAEMS: 0.7565 - val_loss: 0.8866 - val_mse: 0.0073 - val_mae: 0.0581 - val_MAEMS: 0.8867\n",
      "Epoch 153/1000\n",
      "1833/1833 [==============================] - 49s 27ms/step - loss: 0.7516 - mse: 0.0045 - mae: 0.0456 - MAEMS: 0.7516 - val_loss: 0.8617 - val_mse: 0.0065 - val_mae: 0.0546 - val_MAEMS: 0.8617\n",
      "Epoch 154/1000\n",
      "1833/1833 [==============================] - 50s 27ms/step - loss: 0.7584 - mse: 0.0045 - mae: 0.0458 - MAEMS: 0.7587 - val_loss: 0.9254 - val_mse: 0.0084 - val_mae: 0.0636 - val_MAEMS: 0.9255\n",
      "Epoch 155/1000\n",
      "1833/1833 [==============================] - 49s 27ms/step - loss: 0.7545 - mse: 0.0044 - mae: 0.0454 - MAEMS: 0.7546 - val_loss: 0.8866 - val_mse: 0.0065 - val_mae: 0.0545 - val_MAEMS: 0.8868\n",
      "Epoch 156/1000\n",
      "1833/1833 [==============================] - 49s 27ms/step - loss: 0.7584 - mse: 0.0044 - mae: 0.0456 - MAEMS: 0.7585 - val_loss: 0.8693 - val_mse: 0.0062 - val_mae: 0.0532 - val_MAEMS: 0.8695\n",
      "Epoch 157/1000\n",
      "1833/1833 [==============================] - 50s 27ms/step - loss: 0.7556 - mse: 0.0045 - mae: 0.0457 - MAEMS: 0.7559 - val_loss: 0.8623 - val_mse: 0.0071 - val_mae: 0.0567 - val_MAEMS: 0.8626\n",
      "Epoch 158/1000\n",
      "1833/1833 [==============================] - 49s 27ms/step - loss: 0.7456 - mse: 0.0044 - mae: 0.0452 - MAEMS: 0.7457 - val_loss: 0.8991 - val_mse: 0.0079 - val_mae: 0.0611 - val_MAEMS: 0.8992\n",
      "Epoch 159/1000\n",
      "1833/1833 [==============================] - 49s 27ms/step - loss: 0.7539 - mse: 0.0044 - mae: 0.0454 - MAEMS: 0.7540 - val_loss: 0.8618 - val_mse: 0.0064 - val_mae: 0.0544 - val_MAEMS: 0.8620\n",
      "Epoch 160/1000\n",
      "1833/1833 [==============================] - 50s 27ms/step - loss: 0.7494 - mse: 0.0044 - mae: 0.0452 - MAEMS: 0.7496 - val_loss: 0.8546 - val_mse: 0.0064 - val_mae: 0.0538 - val_MAEMS: 0.8545\n",
      "Epoch 161/1000\n",
      "1833/1833 [==============================] - 50s 27ms/step - loss: 0.7531 - mse: 0.0044 - mae: 0.0455 - MAEMS: 0.7531 - val_loss: 0.8855 - val_mse: 0.0066 - val_mae: 0.0551 - val_MAEMS: 0.8858\n",
      "Epoch 162/1000\n",
      "1833/1833 [==============================] - 50s 27ms/step - loss: 0.7507 - mse: 0.0044 - mae: 0.0453 - MAEMS: 0.7510 - val_loss: 0.8750 - val_mse: 0.0057 - val_mae: 0.0507 - val_MAEMS: 0.8750\n",
      "Epoch 163/1000\n",
      "1833/1833 [==============================] - 50s 27ms/step - loss: 0.7462 - mse: 0.0043 - mae: 0.0450 - MAEMS: 0.7463 - val_loss: 0.9174 - val_mse: 0.0076 - val_mae: 0.0600 - val_MAEMS: 0.9176\n",
      "Epoch 164/1000\n",
      "1833/1833 [==============================] - 49s 27ms/step - loss: 0.7378 - mse: 0.0042 - mae: 0.0445 - MAEMS: 0.7379 - val_loss: 0.8621 - val_mse: 0.0062 - val_mae: 0.0526 - val_MAEMS: 0.8624\n",
      "Epoch 165/1000\n",
      "1833/1833 [==============================] - 49s 27ms/step - loss: 0.7407 - mse: 0.0043 - mae: 0.0448 - MAEMS: 0.7409 - val_loss: 0.9009 - val_mse: 0.0075 - val_mae: 0.0592 - val_MAEMS: 0.9011\n",
      "Epoch 166/1000\n",
      "1833/1833 [==============================] - 50s 27ms/step - loss: 0.7405 - mse: 0.0042 - mae: 0.0446 - MAEMS: 0.7406 - val_loss: 0.8797 - val_mse: 0.0074 - val_mae: 0.0585 - val_MAEMS: 0.8799\n",
      "Epoch 167/1000\n",
      "1833/1833 [==============================] - 50s 27ms/step - loss: 0.7444 - mse: 0.0043 - mae: 0.0449 - MAEMS: 0.7445 - val_loss: 0.8361 - val_mse: 0.0058 - val_mae: 0.0512 - val_MAEMS: 0.8362\n",
      "Epoch 168/1000\n",
      "1833/1833 [==============================] - 50s 27ms/step - loss: 0.7457 - mse: 0.0042 - mae: 0.0447 - MAEMS: 0.7457 - val_loss: 0.8459 - val_mse: 0.0065 - val_mae: 0.0546 - val_MAEMS: 0.8462\n",
      "Epoch 169/1000\n",
      "1833/1833 [==============================] - 49s 27ms/step - loss: 0.7370 - mse: 0.0042 - mae: 0.0446 - MAEMS: 0.7372 - val_loss: 0.8603 - val_mse: 0.0059 - val_mae: 0.0510 - val_MAEMS: 0.8605\n",
      "Epoch 170/1000\n",
      "1833/1833 [==============================] - 48s 26ms/step - loss: 0.7390 - mse: 0.0043 - mae: 0.0447 - MAEMS: 0.7392 - val_loss: 0.8506 - val_mse: 0.0066 - val_mae: 0.0546 - val_MAEMS: 0.8507\n",
      "Epoch 171/1000\n",
      "1833/1833 [==============================] - 50s 27ms/step - loss: 0.7386 - mse: 0.0043 - mae: 0.0446 - MAEMS: 0.7387 - val_loss: 0.8748 - val_mse: 0.0069 - val_mae: 0.0561 - val_MAEMS: 0.8749\n",
      "Epoch 172/1000\n",
      "1833/1833 [==============================] - 50s 27ms/step - loss: 0.7396 - mse: 0.0042 - mae: 0.0445 - MAEMS: 0.7396 - val_loss: 0.8529 - val_mse: 0.0066 - val_mae: 0.0549 - val_MAEMS: 0.8530\n",
      "Epoch 173/1000\n",
      "1833/1833 [==============================] - 50s 27ms/step - loss: 0.7392 - mse: 0.0042 - mae: 0.0445 - MAEMS: 0.7392 - val_loss: 0.8531 - val_mse: 0.0063 - val_mae: 0.0535 - val_MAEMS: 0.8531\n",
      "Epoch 174/1000\n",
      "1833/1833 [==============================] - 50s 27ms/step - loss: 0.7353 - mse: 0.0042 - mae: 0.0444 - MAEMS: 0.7354 - val_loss: 0.8570 - val_mse: 0.0064 - val_mae: 0.0540 - val_MAEMS: 0.8572\n",
      "Epoch 175/1000\n",
      "1833/1833 [==============================] - 50s 27ms/step - loss: 0.7280 - mse: 0.0042 - mae: 0.0441 - MAEMS: 0.7280 - val_loss: 0.8724 - val_mse: 0.0056 - val_mae: 0.0508 - val_MAEMS: 0.8726\n",
      "Epoch 176/1000\n",
      "1833/1833 [==============================] - 50s 27ms/step - loss: 0.7322 - mse: 0.0042 - mae: 0.0441 - MAEMS: 0.7323 - val_loss: 0.8964 - val_mse: 0.0072 - val_mae: 0.0583 - val_MAEMS: 0.8965\n",
      "Epoch 177/1000\n",
      "1833/1833 [==============================] - 49s 27ms/step - loss: 0.7352 - mse: 0.0042 - mae: 0.0444 - MAEMS: 0.7352 - val_loss: 0.8612 - val_mse: 0.0062 - val_mae: 0.0539 - val_MAEMS: 0.8615\n",
      "Epoch 178/1000\n",
      "1833/1833 [==============================] - 48s 26ms/step - loss: 0.7284 - mse: 0.0041 - mae: 0.0439 - MAEMS: 0.7287 - val_loss: 0.8703 - val_mse: 0.0073 - val_mae: 0.0582 - val_MAEMS: 0.8703\n",
      "Epoch 179/1000\n",
      "1833/1833 [==============================] - 48s 26ms/step - loss: 0.7316 - mse: 0.0042 - mae: 0.0442 - MAEMS: 0.7318 - val_loss: 0.9119 - val_mse: 0.0059 - val_mae: 0.0524 - val_MAEMS: 0.9123\n",
      "Epoch 180/1000\n",
      "1833/1833 [==============================] - 50s 27ms/step - loss: 0.7266 - mse: 0.0041 - mae: 0.0438 - MAEMS: 0.7268 - val_loss: 0.8512 - val_mse: 0.0062 - val_mae: 0.0535 - val_MAEMS: 0.8512\n",
      "Epoch 181/1000\n",
      "1833/1833 [==============================] - 50s 27ms/step - loss: 0.7230 - mse: 0.0040 - mae: 0.0435 - MAEMS: 0.7231 - val_loss: 0.8383 - val_mse: 0.0063 - val_mae: 0.0535 - val_MAEMS: 0.8384\n",
      "Epoch 182/1000\n",
      "1833/1833 [==============================] - 50s 27ms/step - loss: 0.7195 - mse: 0.0040 - mae: 0.0434 - MAEMS: 0.7196 - val_loss: 0.8556 - val_mse: 0.0059 - val_mae: 0.0518 - val_MAEMS: 0.8555\n",
      "Epoch 183/1000\n",
      "1833/1833 [==============================] - 51s 28ms/step - loss: 0.7294 - mse: 0.0041 - mae: 0.0438 - MAEMS: 0.7294 - val_loss: 0.8364 - val_mse: 0.0063 - val_mae: 0.0535 - val_MAEMS: 0.8364\n",
      "Epoch 184/1000\n",
      "1833/1833 [==============================] - 50s 27ms/step - loss: 0.7292 - mse: 0.0040 - mae: 0.0436 - MAEMS: 0.7293 - val_loss: 0.9267 - val_mse: 0.0050 - val_mae: 0.0493 - val_MAEMS: 0.9269\n",
      "Epoch 185/1000\n",
      "1833/1833 [==============================] - 50s 27ms/step - loss: 0.7283 - mse: 0.0041 - mae: 0.0438 - MAEMS: 0.7283 - val_loss: 0.8553 - val_mse: 0.0067 - val_mae: 0.0558 - val_MAEMS: 0.8556\n",
      "Epoch 186/1000\n",
      "1833/1833 [==============================] - 50s 27ms/step - loss: 0.7335 - mse: 0.0041 - mae: 0.0439 - MAEMS: 0.7338 - val_loss: 0.9243 - val_mse: 0.0081 - val_mae: 0.0630 - val_MAEMS: 0.9244\n",
      "Epoch 187/1000\n",
      "1833/1833 [==============================] - 50s 27ms/step - loss: 0.7317 - mse: 0.0041 - mae: 0.0439 - MAEMS: 0.7319 - val_loss: 0.9058 - val_mse: 0.0073 - val_mae: 0.0596 - val_MAEMS: 0.9061\n",
      "Epoch 188/1000\n",
      "1833/1833 [==============================] - 50s 27ms/step - loss: 0.7246 - mse: 0.0040 - mae: 0.0436 - MAEMS: 0.7247 - val_loss: 0.8437 - val_mse: 0.0061 - val_mae: 0.0527 - val_MAEMS: 0.8438\n",
      "Epoch 189/1000\n",
      "1833/1833 [==============================] - 48s 26ms/step - loss: 0.7253 - mse: 0.0041 - mae: 0.0438 - MAEMS: 0.7255 - val_loss: 0.8949 - val_mse: 0.0075 - val_mae: 0.0591 - val_MAEMS: 0.8949\n",
      "Epoch 190/1000\n",
      "1833/1833 [==============================] - 48s 26ms/step - loss: 0.7234 - mse: 0.0041 - mae: 0.0436 - MAEMS: 0.7235 - val_loss: 0.8890 - val_mse: 0.0071 - val_mae: 0.0577 - val_MAEMS: 0.8892\n",
      "Epoch 191/1000\n",
      "1833/1833 [==============================] - 48s 26ms/step - loss: 0.7204 - mse: 0.0040 - mae: 0.0435 - MAEMS: 0.7204 - val_loss: 0.8549 - val_mse: 0.0068 - val_mae: 0.0566 - val_MAEMS: 0.8550\n",
      "Epoch 192/1000\n",
      "1833/1833 [==============================] - 48s 26ms/step - loss: 0.7222 - mse: 0.0040 - mae: 0.0436 - MAEMS: 0.7223 - val_loss: 0.8442 - val_mse: 0.0061 - val_mae: 0.0531 - val_MAEMS: 0.8443\n",
      "Epoch 193/1000\n",
      "1833/1833 [==============================] - 48s 26ms/step - loss: 0.7165 - mse: 0.0040 - mae: 0.0433 - MAEMS: 0.7165 - val_loss: 0.8754 - val_mse: 0.0074 - val_mae: 0.0593 - val_MAEMS: 0.8755\n",
      "Epoch 194/1000\n",
      "1833/1833 [==============================] - 49s 27ms/step - loss: 0.7234 - mse: 0.0040 - mae: 0.0435 - MAEMS: 0.7235 - val_loss: 0.9290 - val_mse: 0.0083 - val_mae: 0.0637 - val_MAEMS: 0.9291\n",
      "Epoch 195/1000\n",
      "1833/1833 [==============================] - 50s 27ms/step - loss: 0.7249 - mse: 0.0041 - mae: 0.0437 - MAEMS: 0.7250 - val_loss: 0.8798 - val_mse: 0.0075 - val_mae: 0.0603 - val_MAEMS: 0.8799\n",
      "Epoch 196/1000\n",
      "1833/1833 [==============================] - 50s 27ms/step - loss: 0.7159 - mse: 0.0040 - mae: 0.0431 - MAEMS: 0.7161 - val_loss: 0.8820 - val_mse: 0.0070 - val_mae: 0.0577 - val_MAEMS: 0.8820\n",
      "Epoch 197/1000\n",
      "1833/1833 [==============================] - 49s 27ms/step - loss: 0.7175 - mse: 0.0039 - mae: 0.0431 - MAEMS: 0.7176 - val_loss: 0.8456 - val_mse: 0.0062 - val_mae: 0.0531 - val_MAEMS: 0.8457\n",
      "Epoch 198/1000\n",
      "1833/1833 [==============================] - 50s 27ms/step - loss: 0.7173 - mse: 0.0040 - mae: 0.0432 - MAEMS: 0.7174 - val_loss: 0.8564 - val_mse: 0.0062 - val_mae: 0.0534 - val_MAEMS: 0.8564\n",
      "Epoch 199/1000\n",
      "1833/1833 [==============================] - 50s 27ms/step - loss: 0.7158 - mse: 0.0039 - mae: 0.0431 - MAEMS: 0.7159 - val_loss: 0.8690 - val_mse: 0.0059 - val_mae: 0.0518 - val_MAEMS: 0.8690\n",
      "Epoch 200/1000\n",
      "1833/1833 [==============================] - 50s 27ms/step - loss: 0.7165 - mse: 0.0040 - mae: 0.0432 - MAEMS: 0.7168 - val_loss: 0.9053 - val_mse: 0.0073 - val_mae: 0.0587 - val_MAEMS: 0.9052\n",
      "Epoch 201/1000\n",
      "1833/1833 [==============================] - 50s 27ms/step - loss: 0.7067 - mse: 0.0039 - mae: 0.0428 - MAEMS: 0.7067 - val_loss: 0.8665 - val_mse: 0.0077 - val_mae: 0.0606 - val_MAEMS: 0.8664\n",
      "Epoch 202/1000\n",
      "1833/1833 [==============================] - 50s 27ms/step - loss: 0.7107 - mse: 0.0039 - mae: 0.0428 - MAEMS: 0.7108 - val_loss: 0.8700 - val_mse: 0.0063 - val_mae: 0.0535 - val_MAEMS: 0.8701\n",
      "Epoch 203/1000\n",
      "1833/1833 [==============================] - 50s 27ms/step - loss: 0.7137 - mse: 0.0040 - mae: 0.0430 - MAEMS: 0.7137 - val_loss: 0.8371 - val_mse: 0.0064 - val_mae: 0.0543 - val_MAEMS: 0.8372\n",
      "Epoch 204/1000\n",
      "1833/1833 [==============================] - 50s 27ms/step - loss: 0.7157 - mse: 0.0039 - mae: 0.0431 - MAEMS: 0.7158 - val_loss: 0.8613 - val_mse: 0.0064 - val_mae: 0.0544 - val_MAEMS: 0.8615\n",
      "Epoch 205/1000\n",
      "1833/1833 [==============================] - 50s 27ms/step - loss: 0.7102 - mse: 0.0039 - mae: 0.0427 - MAEMS: 0.7104 - val_loss: 0.8904 - val_mse: 0.0069 - val_mae: 0.0569 - val_MAEMS: 0.8905\n",
      "Epoch 206/1000\n",
      "1833/1833 [==============================] - 50s 27ms/step - loss: 0.7117 - mse: 0.0039 - mae: 0.0429 - MAEMS: 0.7118 - val_loss: 0.8509 - val_mse: 0.0059 - val_mae: 0.0520 - val_MAEMS: 0.8508\n",
      "Epoch 207/1000\n",
      "1833/1833 [==============================] - 50s 27ms/step - loss: 0.7103 - mse: 0.0039 - mae: 0.0428 - MAEMS: 0.7104 - val_loss: 0.8316 - val_mse: 0.0062 - val_mae: 0.0530 - val_MAEMS: 0.8315\n",
      "Epoch 208/1000\n",
      "1833/1833 [==============================] - 49s 27ms/step - loss: 0.7155 - mse: 0.0039 - mae: 0.0430 - MAEMS: 0.7157 - val_loss: 0.8256 - val_mse: 0.0062 - val_mae: 0.0528 - val_MAEMS: 0.8258\n",
      "Epoch 209/1000\n",
      "1833/1833 [==============================] - 48s 26ms/step - loss: 0.7062 - mse: 0.0039 - mae: 0.0425 - MAEMS: 0.7063 - val_loss: 0.8533 - val_mse: 0.0068 - val_mae: 0.0563 - val_MAEMS: 0.8533\n",
      "Epoch 210/1000\n",
      "1833/1833 [==============================] - 49s 27ms/step - loss: 0.7130 - mse: 0.0039 - mae: 0.0428 - MAEMS: 0.7129 - val_loss: 0.8423 - val_mse: 0.0062 - val_mae: 0.0532 - val_MAEMS: 0.8422\n",
      "Epoch 211/1000\n",
      "1833/1833 [==============================] - 49s 27ms/step - loss: 0.7060 - mse: 0.0039 - mae: 0.0427 - MAEMS: 0.7062 - val_loss: 0.8717 - val_mse: 0.0060 - val_mae: 0.0521 - val_MAEMS: 0.8716\n",
      "Epoch 212/1000\n",
      "1833/1833 [==============================] - 48s 26ms/step - loss: 0.7042 - mse: 0.0038 - mae: 0.0424 - MAEMS: 0.7045 - val_loss: 0.9052 - val_mse: 0.0068 - val_mae: 0.0570 - val_MAEMS: 0.9054\n",
      "Epoch 213/1000\n",
      "1833/1833 [==============================] - 49s 27ms/step - loss: 0.7103 - mse: 0.0039 - mae: 0.0427 - MAEMS: 0.7104 - val_loss: 0.8587 - val_mse: 0.0056 - val_mae: 0.0513 - val_MAEMS: 0.8588\n",
      "Epoch 214/1000\n",
      "1833/1833 [==============================] - 50s 27ms/step - loss: 0.6972 - mse: 0.0038 - mae: 0.0423 - MAEMS: 0.6973 - val_loss: 0.8284 - val_mse: 0.0061 - val_mae: 0.0523 - val_MAEMS: 0.8286\n",
      "Epoch 215/1000\n",
      "1833/1833 [==============================] - 50s 27ms/step - loss: 0.6997 - mse: 0.0039 - mae: 0.0424 - MAEMS: 0.6997 - val_loss: 0.8271 - val_mse: 0.0060 - val_mae: 0.0528 - val_MAEMS: 0.8273\n",
      "Epoch 216/1000\n",
      "1833/1833 [==============================] - 50s 27ms/step - loss: 0.7035 - mse: 0.0039 - mae: 0.0425 - MAEMS: 0.7037 - val_loss: 0.8868 - val_mse: 0.0060 - val_mae: 0.0530 - val_MAEMS: 0.8869\n",
      "Epoch 217/1000\n",
      "1833/1833 [==============================] - 50s 27ms/step - loss: 0.7077 - mse: 0.0039 - mae: 0.0427 - MAEMS: 0.7079 - val_loss: 0.8220 - val_mse: 0.0057 - val_mae: 0.0510 - val_MAEMS: 0.8219\n",
      "Epoch 218/1000\n",
      "1833/1833 [==============================] - 50s 27ms/step - loss: 0.7021 - mse: 0.0038 - mae: 0.0424 - MAEMS: 0.7021 - val_loss: 0.8410 - val_mse: 0.0062 - val_mae: 0.0534 - val_MAEMS: 0.8411\n",
      "Epoch 219/1000\n",
      "1833/1833 [==============================] - 50s 27ms/step - loss: 0.6998 - mse: 0.0038 - mae: 0.0422 - MAEMS: 0.7000 - val_loss: 0.8958 - val_mse: 0.0077 - val_mae: 0.0602 - val_MAEMS: 0.8961\n",
      "Epoch 220/1000\n",
      "1833/1833 [==============================] - 50s 27ms/step - loss: 0.7061 - mse: 0.0038 - mae: 0.0423 - MAEMS: 0.7062 - val_loss: 0.8383 - val_mse: 0.0060 - val_mae: 0.0529 - val_MAEMS: 0.8383\n",
      "Epoch 221/1000\n",
      "1833/1833 [==============================] - 50s 27ms/step - loss: 0.7010 - mse: 0.0038 - mae: 0.0424 - MAEMS: 0.7011 - val_loss: 0.8815 - val_mse: 0.0069 - val_mae: 0.0573 - val_MAEMS: 0.8814\n",
      "Epoch 222/1000\n",
      "1833/1833 [==============================] - 51s 28ms/step - loss: 0.7047 - mse: 0.0038 - mae: 0.0424 - MAEMS: 0.7048 - val_loss: 0.8447 - val_mse: 0.0068 - val_mae: 0.0566 - val_MAEMS: 0.8448\n",
      "Epoch 223/1000\n",
      "1833/1833 [==============================] - 50s 27ms/step - loss: 0.7047 - mse: 0.0038 - mae: 0.0424 - MAEMS: 0.7048 - val_loss: 0.9485 - val_mse: 0.0082 - val_mae: 0.0643 - val_MAEMS: 0.9487\n",
      "Epoch 224/1000\n",
      "1833/1833 [==============================] - 49s 27ms/step - loss: 0.7040 - mse: 0.0038 - mae: 0.0422 - MAEMS: 0.7042 - val_loss: 0.8967 - val_mse: 0.0075 - val_mae: 0.0611 - val_MAEMS: 0.8969\n",
      "Epoch 225/1000\n",
      "1833/1833 [==============================] - 49s 27ms/step - loss: 0.7031 - mse: 0.0038 - mae: 0.0424 - MAEMS: 0.7031 - val_loss: 0.8431 - val_mse: 0.0070 - val_mae: 0.0573 - val_MAEMS: 0.8434\n",
      "Epoch 226/1000\n",
      "1833/1833 [==============================] - 50s 27ms/step - loss: 0.6976 - mse: 0.0037 - mae: 0.0417 - MAEMS: 0.6978 - val_loss: 0.8648 - val_mse: 0.0063 - val_mae: 0.0544 - val_MAEMS: 0.8647\n",
      "Epoch 227/1000\n",
      "1833/1833 [==============================] - 49s 27ms/step - loss: 0.7040 - mse: 0.0038 - mae: 0.0422 - MAEMS: 0.7040 - val_loss: 0.8328 - val_mse: 0.0055 - val_mae: 0.0506 - val_MAEMS: 0.8329\n",
      "Epoch 228/1000\n",
      "1833/1833 [==============================] - 50s 27ms/step - loss: 0.7009 - mse: 0.0038 - mae: 0.0424 - MAEMS: 0.7010 - val_loss: 0.8507 - val_mse: 0.0067 - val_mae: 0.0557 - val_MAEMS: 0.8507\n",
      "Epoch 229/1000\n",
      "1833/1833 [==============================] - 49s 27ms/step - loss: 0.6955 - mse: 0.0037 - mae: 0.0419 - MAEMS: 0.6956 - val_loss: 0.8620 - val_mse: 0.0068 - val_mae: 0.0568 - val_MAEMS: 0.8620\n",
      "Epoch 230/1000\n",
      "1833/1833 [==============================] - 48s 26ms/step - loss: 0.7021 - mse: 0.0038 - mae: 0.0423 - MAEMS: 0.7022 - val_loss: 0.8769 - val_mse: 0.0072 - val_mae: 0.0590 - val_MAEMS: 0.8771\n",
      "Epoch 231/1000\n",
      "1833/1833 [==============================] - 49s 27ms/step - loss: 0.6996 - mse: 0.0037 - mae: 0.0419 - MAEMS: 0.6997 - val_loss: 0.8123 - val_mse: 0.0060 - val_mae: 0.0525 - val_MAEMS: 0.8125\n",
      "Epoch 232/1000\n",
      "1833/1833 [==============================] - 50s 27ms/step - loss: 0.6958 - mse: 0.0037 - mae: 0.0419 - MAEMS: 0.6960 - val_loss: 0.8483 - val_mse: 0.0052 - val_mae: 0.0488 - val_MAEMS: 0.8484\n",
      "Epoch 233/1000\n",
      "1833/1833 [==============================] - 50s 27ms/step - loss: 0.6984 - mse: 0.0038 - mae: 0.0422 - MAEMS: 0.6985 - val_loss: 0.8693 - val_mse: 0.0073 - val_mae: 0.0585 - val_MAEMS: 0.8695\n",
      "Epoch 234/1000\n",
      "1833/1833 [==============================] - 50s 27ms/step - loss: 0.6969 - mse: 0.0038 - mae: 0.0419 - MAEMS: 0.6969 - val_loss: 0.8334 - val_mse: 0.0063 - val_mae: 0.0542 - val_MAEMS: 0.8336\n",
      "Epoch 235/1000\n",
      "1833/1833 [==============================] - 50s 27ms/step - loss: 0.6937 - mse: 0.0037 - mae: 0.0415 - MAEMS: 0.6939 - val_loss: 0.8385 - val_mse: 0.0052 - val_mae: 0.0488 - val_MAEMS: 0.8383\n",
      "Epoch 236/1000\n",
      "1833/1833 [==============================] - 50s 27ms/step - loss: 0.6998 - mse: 0.0038 - mae: 0.0422 - MAEMS: 0.6999 - val_loss: 0.8625 - val_mse: 0.0066 - val_mae: 0.0556 - val_MAEMS: 0.8624\n",
      "Epoch 237/1000\n",
      "1833/1833 [==============================] - 49s 27ms/step - loss: 0.7018 - mse: 0.0038 - mae: 0.0420 - MAEMS: 0.7020 - val_loss: 0.8099 - val_mse: 0.0062 - val_mae: 0.0532 - val_MAEMS: 0.8101\n",
      "Epoch 238/1000\n",
      "1833/1833 [==============================] - 50s 27ms/step - loss: 0.6932 - mse: 0.0037 - mae: 0.0418 - MAEMS: 0.6935 - val_loss: 0.8240 - val_mse: 0.0058 - val_mae: 0.0514 - val_MAEMS: 0.8239\n",
      "Epoch 239/1000\n",
      "1833/1833 [==============================] - 50s 27ms/step - loss: 0.6998 - mse: 0.0038 - mae: 0.0421 - MAEMS: 0.6998 - val_loss: 0.8681 - val_mse: 0.0058 - val_mae: 0.0521 - val_MAEMS: 0.8682\n",
      "Epoch 240/1000\n",
      "1833/1833 [==============================] - 50s 28ms/step - loss: 0.7018 - mse: 0.0038 - mae: 0.0422 - MAEMS: 0.7018 - val_loss: 0.8546 - val_mse: 0.0053 - val_mae: 0.0492 - val_MAEMS: 0.8544\n",
      "Epoch 241/1000\n",
      "1833/1833 [==============================] - 51s 28ms/step - loss: 0.6880 - mse: 0.0037 - mae: 0.0416 - MAEMS: 0.6880 - val_loss: 0.7999 - val_mse: 0.0055 - val_mae: 0.0496 - val_MAEMS: 0.7998\n",
      "Epoch 242/1000\n",
      "1833/1833 [==============================] - 49s 27ms/step - loss: 0.6863 - mse: 0.0036 - mae: 0.0412 - MAEMS: 0.6864 - val_loss: 0.8742 - val_mse: 0.0065 - val_mae: 0.0555 - val_MAEMS: 0.8744\n",
      "Epoch 243/1000\n",
      "1833/1833 [==============================] - 50s 27ms/step - loss: 0.6943 - mse: 0.0037 - mae: 0.0417 - MAEMS: 0.6944 - val_loss: 0.8445 - val_mse: 0.0062 - val_mae: 0.0540 - val_MAEMS: 0.8446\n",
      "Epoch 244/1000\n",
      "1833/1833 [==============================] - 50s 27ms/step - loss: 0.6835 - mse: 0.0036 - mae: 0.0412 - MAEMS: 0.6837 - val_loss: 0.8488 - val_mse: 0.0065 - val_mae: 0.0551 - val_MAEMS: 0.8490\n",
      "Epoch 245/1000\n",
      "1833/1833 [==============================] - 50s 27ms/step - loss: 0.6928 - mse: 0.0036 - mae: 0.0414 - MAEMS: 0.6929 - val_loss: 0.8435 - val_mse: 0.0048 - val_mae: 0.0473 - val_MAEMS: 0.8435\n",
      "Epoch 246/1000\n",
      "1833/1833 [==============================] - 50s 27ms/step - loss: 0.6923 - mse: 0.0036 - mae: 0.0414 - MAEMS: 0.6924 - val_loss: 0.8722 - val_mse: 0.0053 - val_mae: 0.0497 - val_MAEMS: 0.8722\n",
      "Epoch 247/1000\n",
      "1833/1833 [==============================] - 50s 27ms/step - loss: 0.6855 - mse: 0.0036 - mae: 0.0414 - MAEMS: 0.6856 - val_loss: 0.8206 - val_mse: 0.0061 - val_mae: 0.0532 - val_MAEMS: 0.8207\n",
      "Epoch 248/1000\n",
      "1833/1833 [==============================] - 50s 27ms/step - loss: 0.6909 - mse: 0.0036 - mae: 0.0415 - MAEMS: 0.6912 - val_loss: 0.8514 - val_mse: 0.0069 - val_mae: 0.0575 - val_MAEMS: 0.8515\n",
      "Epoch 249/1000\n",
      "1833/1833 [==============================] - 50s 27ms/step - loss: 0.6884 - mse: 0.0036 - mae: 0.0413 - MAEMS: 0.6885 - val_loss: 0.8979 - val_mse: 0.0082 - val_mae: 0.0627 - val_MAEMS: 0.8979\n",
      "Epoch 250/1000\n",
      "1833/1833 [==============================] - 50s 27ms/step - loss: 0.6865 - mse: 0.0036 - mae: 0.0413 - MAEMS: 0.6866 - val_loss: 0.9125 - val_mse: 0.0086 - val_mae: 0.0654 - val_MAEMS: 0.9127\n",
      "Epoch 251/1000\n",
      "1833/1833 [==============================] - 49s 27ms/step - loss: 0.6958 - mse: 0.0037 - mae: 0.0416 - MAEMS: 0.6960 - val_loss: 0.8722 - val_mse: 0.0075 - val_mae: 0.0602 - val_MAEMS: 0.8723\n",
      "Epoch 252/1000\n",
      "1833/1833 [==============================] - 49s 27ms/step - loss: 0.6883 - mse: 0.0036 - mae: 0.0413 - MAEMS: 0.6884 - val_loss: 0.8969 - val_mse: 0.0069 - val_mae: 0.0582 - val_MAEMS: 0.8972\n",
      "Epoch 253/1000\n",
      "1833/1833 [==============================] - 49s 27ms/step - loss: 0.6789 - mse: 0.0036 - mae: 0.0409 - MAEMS: 0.6791 - val_loss: 0.8590 - val_mse: 0.0063 - val_mae: 0.0546 - val_MAEMS: 0.8591\n",
      "Epoch 254/1000\n",
      "1833/1833 [==============================] - 49s 26ms/step - loss: 0.6798 - mse: 0.0036 - mae: 0.0410 - MAEMS: 0.6798 - val_loss: 0.7910 - val_mse: 0.0052 - val_mae: 0.0485 - val_MAEMS: 0.7913\n",
      "Epoch 255/1000\n",
      "1833/1833 [==============================] - 49s 27ms/step - loss: 0.6886 - mse: 0.0037 - mae: 0.0415 - MAEMS: 0.6887 - val_loss: 0.8323 - val_mse: 0.0059 - val_mae: 0.0524 - val_MAEMS: 0.8326\n",
      "Epoch 256/1000\n",
      "1833/1833 [==============================] - 50s 27ms/step - loss: 0.6809 - mse: 0.0036 - mae: 0.0409 - MAEMS: 0.6811 - val_loss: 0.8562 - val_mse: 0.0056 - val_mae: 0.0514 - val_MAEMS: 0.8562\n",
      "Epoch 257/1000\n",
      "1833/1833 [==============================] - 50s 27ms/step - loss: 0.6873 - mse: 0.0036 - mae: 0.0414 - MAEMS: 0.6874 - val_loss: 0.8222 - val_mse: 0.0062 - val_mae: 0.0537 - val_MAEMS: 0.8225\n",
      "Epoch 258/1000\n",
      "1833/1833 [==============================] - 49s 27ms/step - loss: 0.6821 - mse: 0.0036 - mae: 0.0411 - MAEMS: 0.6824 - val_loss: 0.8464 - val_mse: 0.0060 - val_mae: 0.0533 - val_MAEMS: 0.8466\n",
      "Epoch 259/1000\n",
      "1833/1833 [==============================] - 49s 27ms/step - loss: 0.6779 - mse: 0.0036 - mae: 0.0410 - MAEMS: 0.6780 - val_loss: 0.8108 - val_mse: 0.0056 - val_mae: 0.0506 - val_MAEMS: 0.8110\n",
      "Epoch 260/1000\n",
      "1833/1833 [==============================] - 50s 27ms/step - loss: 0.6835 - mse: 0.0037 - mae: 0.0414 - MAEMS: 0.6836 - val_loss: 0.8877 - val_mse: 0.0077 - val_mae: 0.0617 - val_MAEMS: 0.8880\n",
      "Epoch 261/1000\n",
      "1833/1833 [==============================] - 50s 27ms/step - loss: 0.6782 - mse: 0.0035 - mae: 0.0408 - MAEMS: 0.6783 - val_loss: 0.8518 - val_mse: 0.0062 - val_mae: 0.0539 - val_MAEMS: 0.8519\n",
      "Epoch 262/1000\n",
      "1833/1833 [==============================] - 48s 26ms/step - loss: 0.6872 - mse: 0.0036 - mae: 0.0412 - MAEMS: 0.6872 - val_loss: 0.8676 - val_mse: 0.0063 - val_mae: 0.0541 - val_MAEMS: 0.8679\n",
      "Epoch 263/1000\n",
      "1833/1833 [==============================] - 48s 26ms/step - loss: 0.6827 - mse: 0.0036 - mae: 0.0409 - MAEMS: 0.6828 - val_loss: 0.8088 - val_mse: 0.0063 - val_mae: 0.0540 - val_MAEMS: 0.8089\n",
      "Epoch 264/1000\n",
      "1833/1833 [==============================] - 51s 28ms/step - loss: 0.6883 - mse: 0.0036 - mae: 0.0412 - MAEMS: 0.6884 - val_loss: 0.8208 - val_mse: 0.0059 - val_mae: 0.0527 - val_MAEMS: 0.8208\n",
      "Epoch 265/1000\n",
      "1833/1833 [==============================] - 51s 28ms/step - loss: 0.6857 - mse: 0.0036 - mae: 0.0413 - MAEMS: 0.6860 - val_loss: 1.0201 - val_mse: 0.0097 - val_mae: 0.0729 - val_MAEMS: 1.0203\n",
      "Epoch 266/1000\n",
      "1833/1833 [==============================] - 50s 27ms/step - loss: 0.6859 - mse: 0.0036 - mae: 0.0413 - MAEMS: 0.6861 - val_loss: 0.9110 - val_mse: 0.0075 - val_mae: 0.0616 - val_MAEMS: 0.9112\n",
      "Epoch 267/1000\n",
      "1833/1833 [==============================] - 50s 27ms/step - loss: 0.6846 - mse: 0.0035 - mae: 0.0410 - MAEMS: 0.6847 - val_loss: 0.8678 - val_mse: 0.0062 - val_mae: 0.0544 - val_MAEMS: 0.8679\n",
      "Epoch 268/1000\n",
      "1833/1833 [==============================] - 49s 27ms/step - loss: 0.6841 - mse: 0.0036 - mae: 0.0411 - MAEMS: 0.6843 - val_loss: 0.8205 - val_mse: 0.0050 - val_mae: 0.0480 - val_MAEMS: 0.8205\n",
      "Epoch 269/1000\n",
      "1833/1833 [==============================] - 50s 27ms/step - loss: 0.6918 - mse: 0.0036 - mae: 0.0415 - MAEMS: 0.6920 - val_loss: 0.8360 - val_mse: 0.0061 - val_mae: 0.0538 - val_MAEMS: 0.8361\n",
      "Epoch 270/1000\n",
      "1833/1833 [==============================] - 49s 27ms/step - loss: 0.6837 - mse: 0.0036 - mae: 0.0411 - MAEMS: 0.6837 - val_loss: 0.8080 - val_mse: 0.0055 - val_mae: 0.0500 - val_MAEMS: 0.8083\n",
      "Epoch 271/1000\n",
      "1833/1833 [==============================] - 50s 27ms/step - loss: 0.6753 - mse: 0.0035 - mae: 0.0408 - MAEMS: 0.6754 - val_loss: 0.8208 - val_mse: 0.0058 - val_mae: 0.0516 - val_MAEMS: 0.8209\n",
      "Epoch 272/1000\n",
      "1833/1833 [==============================] - 50s 27ms/step - loss: 0.6840 - mse: 0.0035 - mae: 0.0409 - MAEMS: 0.6841 - val_loss: 0.8499 - val_mse: 0.0070 - val_mae: 0.0578 - val_MAEMS: 0.8499\n",
      "Epoch 273/1000\n",
      "1833/1833 [==============================] - 50s 27ms/step - loss: 0.6822 - mse: 0.0036 - mae: 0.0412 - MAEMS: 0.6823 - val_loss: 0.8207 - val_mse: 0.0066 - val_mae: 0.0554 - val_MAEMS: 0.8207\n",
      "Epoch 274/1000\n",
      "1833/1833 [==============================] - 49s 27ms/step - loss: 0.6779 - mse: 0.0035 - mae: 0.0409 - MAEMS: 0.6781 - val_loss: 0.8917 - val_mse: 0.0078 - val_mae: 0.0615 - val_MAEMS: 0.8917\n",
      "Epoch 275/1000\n",
      "1833/1833 [==============================] - 50s 27ms/step - loss: 0.6756 - mse: 0.0035 - mae: 0.0407 - MAEMS: 0.6756 - val_loss: 0.8567 - val_mse: 0.0065 - val_mae: 0.0552 - val_MAEMS: 0.8569\n",
      "Epoch 276/1000\n",
      "1833/1833 [==============================] - 50s 27ms/step - loss: 0.6786 - mse: 0.0035 - mae: 0.0408 - MAEMS: 0.6788 - val_loss: 0.9156 - val_mse: 0.0075 - val_mae: 0.0610 - val_MAEMS: 0.9158\n",
      "Epoch 277/1000\n",
      "1833/1833 [==============================] - 50s 27ms/step - loss: 0.6826 - mse: 0.0036 - mae: 0.0410 - MAEMS: 0.6828 - val_loss: 0.8503 - val_mse: 0.0072 - val_mae: 0.0590 - val_MAEMS: 0.8503\n",
      "Epoch 278/1000\n",
      "1833/1833 [==============================] - 50s 27ms/step - loss: 0.6705 - mse: 0.0035 - mae: 0.0406 - MAEMS: 0.6707 - val_loss: 0.8790 - val_mse: 0.0077 - val_mae: 0.0616 - val_MAEMS: 0.8791\n",
      "Epoch 279/1000\n",
      "1833/1833 [==============================] - 50s 27ms/step - loss: 0.6777 - mse: 0.0035 - mae: 0.0407 - MAEMS: 0.6779 - val_loss: 0.8589 - val_mse: 0.0070 - val_mae: 0.0578 - val_MAEMS: 0.8590\n",
      "Epoch 280/1000\n",
      "1833/1833 [==============================] - 50s 27ms/step - loss: 0.6818 - mse: 0.0035 - mae: 0.0409 - MAEMS: 0.6818 - val_loss: 0.8007 - val_mse: 0.0055 - val_mae: 0.0504 - val_MAEMS: 0.8009\n",
      "Epoch 281/1000\n",
      "1833/1833 [==============================] - 50s 27ms/step - loss: 0.6808 - mse: 0.0036 - mae: 0.0410 - MAEMS: 0.6811 - val_loss: 0.8546 - val_mse: 0.0068 - val_mae: 0.0574 - val_MAEMS: 0.8548\n",
      "Epoch 282/1000\n",
      "1833/1833 [==============================] - 50s 27ms/step - loss: 0.6694 - mse: 0.0035 - mae: 0.0405 - MAEMS: 0.6694 - val_loss: 0.8843 - val_mse: 0.0080 - val_mae: 0.0627 - val_MAEMS: 0.8845\n",
      "Epoch 283/1000\n",
      "1833/1833 [==============================] - 50s 27ms/step - loss: 0.6764 - mse: 0.0036 - mae: 0.0409 - MAEMS: 0.6765 - val_loss: 0.8465 - val_mse: 0.0069 - val_mae: 0.0578 - val_MAEMS: 0.8465\n",
      "Epoch 284/1000\n",
      "1833/1833 [==============================] - 49s 27ms/step - loss: 0.6780 - mse: 0.0035 - mae: 0.0408 - MAEMS: 0.6781 - val_loss: 0.9477 - val_mse: 0.0087 - val_mae: 0.0668 - val_MAEMS: 0.9479\n",
      "Epoch 285/1000\n",
      "1833/1833 [==============================] - 49s 27ms/step - loss: 0.6723 - mse: 0.0035 - mae: 0.0408 - MAEMS: 0.6725 - val_loss: 0.9744 - val_mse: 0.0081 - val_mae: 0.0646 - val_MAEMS: 0.9746\n",
      "Epoch 286/1000\n",
      "1833/1833 [==============================] - 48s 26ms/step - loss: 0.6842 - mse: 0.0036 - mae: 0.0412 - MAEMS: 0.6843 - val_loss: 0.8773 - val_mse: 0.0065 - val_mae: 0.0559 - val_MAEMS: 0.8774\n",
      "Epoch 287/1000\n",
      "1833/1833 [==============================] - 49s 27ms/step - loss: 0.6766 - mse: 0.0035 - mae: 0.0405 - MAEMS: 0.6766 - val_loss: 0.8351 - val_mse: 0.0057 - val_mae: 0.0520 - val_MAEMS: 0.8352\n",
      "Epoch 288/1000\n",
      "1833/1833 [==============================] - 51s 28ms/step - loss: 0.6762 - mse: 0.0035 - mae: 0.0406 - MAEMS: 0.6763 - val_loss: 0.8285 - val_mse: 0.0061 - val_mae: 0.0529 - val_MAEMS: 0.8286\n",
      "Epoch 289/1000\n",
      "1833/1833 [==============================] - 51s 28ms/step - loss: 0.6763 - mse: 0.0035 - mae: 0.0406 - MAEMS: 0.6766 - val_loss: 0.8628 - val_mse: 0.0074 - val_mae: 0.0599 - val_MAEMS: 0.8627\n",
      "Epoch 290/1000\n",
      "1833/1833 [==============================] - 50s 27ms/step - loss: 0.6770 - mse: 0.0035 - mae: 0.0408 - MAEMS: 0.6771 - val_loss: 0.9011 - val_mse: 0.0075 - val_mae: 0.0613 - val_MAEMS: 0.9013\n",
      "Epoch 291/1000\n",
      "1833/1833 [==============================] - 50s 27ms/step - loss: 0.6690 - mse: 0.0034 - mae: 0.0401 - MAEMS: 0.6690 - val_loss: 0.9127 - val_mse: 0.0078 - val_mae: 0.0623 - val_MAEMS: 0.9129\n",
      "Epoch 292/1000\n",
      "1833/1833 [==============================] - 49s 27ms/step - loss: 0.6669 - mse: 0.0034 - mae: 0.0402 - MAEMS: 0.6670 - val_loss: 0.7961 - val_mse: 0.0053 - val_mae: 0.0491 - val_MAEMS: 0.7962\n",
      "Epoch 293/1000\n",
      "1833/1833 [==============================] - 50s 27ms/step - loss: 0.6677 - mse: 0.0034 - mae: 0.0403 - MAEMS: 0.6678 - val_loss: 0.8020 - val_mse: 0.0051 - val_mae: 0.0482 - val_MAEMS: 0.8021\n",
      "Epoch 294/1000\n",
      "1833/1833 [==============================] - 50s 27ms/step - loss: 0.6699 - mse: 0.0034 - mae: 0.0402 - MAEMS: 0.6700 - val_loss: 0.7982 - val_mse: 0.0050 - val_mae: 0.0476 - val_MAEMS: 0.7984\n",
      "Epoch 295/1000\n",
      "1833/1833 [==============================] - 49s 27ms/step - loss: 0.6632 - mse: 0.0034 - mae: 0.0400 - MAEMS: 0.6633 - val_loss: 0.8605 - val_mse: 0.0067 - val_mae: 0.0570 - val_MAEMS: 0.8607\n",
      "Epoch 296/1000\n",
      "1833/1833 [==============================] - 50s 27ms/step - loss: 0.6727 - mse: 0.0034 - mae: 0.0404 - MAEMS: 0.6727 - val_loss: 0.8260 - val_mse: 0.0053 - val_mae: 0.0496 - val_MAEMS: 0.8263\n",
      "Epoch 297/1000\n",
      "1833/1833 [==============================] - 51s 28ms/step - loss: 0.6673 - mse: 0.0034 - mae: 0.0402 - MAEMS: 0.6675 - val_loss: 0.8092 - val_mse: 0.0061 - val_mae: 0.0533 - val_MAEMS: 0.8094\n",
      "Epoch 298/1000\n",
      "1833/1833 [==============================] - 49s 27ms/step - loss: 0.6705 - mse: 0.0034 - mae: 0.0402 - MAEMS: 0.6709 - val_loss: 0.8239 - val_mse: 0.0050 - val_mae: 0.0477 - val_MAEMS: 0.8239\n",
      "Epoch 299/1000\n",
      "1833/1833 [==============================] - 48s 26ms/step - loss: 0.6705 - mse: 0.0034 - mae: 0.0401 - MAEMS: 0.6705 - val_loss: 0.8633 - val_mse: 0.0057 - val_mae: 0.0521 - val_MAEMS: 0.8634\n",
      "Epoch 300/1000\n",
      "1833/1833 [==============================] - 49s 27ms/step - loss: 0.6694 - mse: 0.0034 - mae: 0.0403 - MAEMS: 0.6698 - val_loss: 0.8126 - val_mse: 0.0062 - val_mae: 0.0541 - val_MAEMS: 0.8128\n",
      "Epoch 301/1000\n",
      "1833/1833 [==============================] - 49s 27ms/step - loss: 0.6663 - mse: 0.0034 - mae: 0.0400 - MAEMS: 0.6665 - val_loss: 0.8469 - val_mse: 0.0065 - val_mae: 0.0558 - val_MAEMS: 0.8471\n",
      "Epoch 302/1000\n",
      "1833/1833 [==============================] - 50s 27ms/step - loss: 0.6672 - mse: 0.0034 - mae: 0.0400 - MAEMS: 0.6673 - val_loss: 0.8531 - val_mse: 0.0069 - val_mae: 0.0585 - val_MAEMS: 0.8534\n",
      "Epoch 303/1000\n",
      "1833/1833 [==============================] - 51s 28ms/step - loss: 0.6730 - mse: 0.0034 - mae: 0.0404 - MAEMS: 0.6730 - val_loss: 0.8511 - val_mse: 0.0061 - val_mae: 0.0543 - val_MAEMS: 0.8514\n",
      "Epoch 304/1000\n",
      "1833/1833 [==============================] - 50s 27ms/step - loss: 0.6617 - mse: 0.0034 - mae: 0.0399 - MAEMS: 0.6618 - val_loss: 0.8136 - val_mse: 0.0065 - val_mae: 0.0549 - val_MAEMS: 0.8139\n",
      "Wall time: 4h 12min 20s\n"
     ]
    }
   ],
   "source": [
    "    %%time\n",
    "    b_size = output_timesteps\n",
    "    hist = model.fit(strX, strY, epochs=epochs, batch_size=b_size, shuffle=False, validation_data=(svaX, svaY), callbacks=[history, early_stopping])  # , checkpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "3485316c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4594"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b019263a",
   "metadata": {},
   "source": [
    "## Saving Results & Figures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "23a47a78",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_history = hist.history['loss']\n",
    "valloss_history = hist.history['val_loss']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "575b49a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#np.savetxt('losshistory.txt',(loss_history,valloss_history))\n",
    "model.save('Basic Model Final_fh12.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08b3ae36",
   "metadata": {},
   "source": [
    "## Basic Model Test Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "d059185c",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = b_size\n",
    "testPredict = model.predict(teX, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "57e9a063",
   "metadata": {},
   "outputs": [],
   "source": [
    "def npMAEMS(y_true, y_pred):\n",
    "    return np.mean((abs(y_pred - y_true))*np.square(y_true))*100\n",
    "def npMAEMD(y_true, y_pred):\n",
    "    return np.mean((abs(y_pred - y_true))*np.square(y_true-np.mean(y_true)))*100\n",
    "def npMSE(y_true, y_pred):\n",
    "    return np.mean(np.square(-y_true+y_pred))\n",
    "def npMAE(y_true, y_pred):\n",
    "    return np.mean(abs(-y_true+y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "82754476",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error Test Score > MSE ==  0.027214180758768285  MAE ==  0.12977480031721506  MAEMD ==  0.5944849505025466\n"
     ]
    }
   ],
   "source": [
    "tePredict = testPredict.reshape(-1)\n",
    "testY = teY.reshape(-1)\n",
    "print('Error Test Score > MSE == ', npMSE(testY, tePredict), ' MAE == ', npMAE(testY, tePredict), ' MAEMD == ', npMAEMD(testY, tePredict))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e148628",
   "metadata": {},
   "source": [
    "## Wind Generation FFEL Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "df79cbb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "trX, vaX, trY, vaY = train_test_split(trvaX, trvaY, test_size=1/6, shuffle=False)\n",
    "trY = trY.reshape(-1,output_timesteps)\n",
    "vaY = vaY.reshape(-1,output_timesteps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "39ae6874",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainPredict = model.predict(trX, batch_size=batch_size)\n",
    "validPredict = model.predict(vaX, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "dc9d8834",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(31411, 12)\n",
      "(31411, 12)\n"
     ]
    }
   ],
   "source": [
    "e_tr = trainPredict - trY\n",
    "e_va = validPredict - vaY\n",
    "errors = np.vstack([e_tr, e_va])\n",
    "prediction = np.vstack([trainPredict, validPredict])\n",
    "print(errors.shape)\n",
    "print(prediction.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "f1392b36",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Normalized Wind</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.644724</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.658617</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.683924</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.721813</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.714187</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Normalized Wind\n",
       "0         0.644724\n",
       "1         0.658617\n",
       "2         0.683924\n",
       "3         0.721813\n",
       "4         0.714187"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "norm_df2 = pd.DataFrame(norm_df).iloc[:prediction.shape[0], :]\n",
    "norm_df2.columns = ['Normalized Wind']\n",
    "norm_df2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "cf70b0d5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Prediction1</th>\n",
       "      <th>Prediction2</th>\n",
       "      <th>Prediction3</th>\n",
       "      <th>Prediction4</th>\n",
       "      <th>Prediction5</th>\n",
       "      <th>Prediction6</th>\n",
       "      <th>Prediction7</th>\n",
       "      <th>Prediction8</th>\n",
       "      <th>Prediction9</th>\n",
       "      <th>Prediction10</th>\n",
       "      <th>Prediction11</th>\n",
       "      <th>Prediction12</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.399960</td>\n",
       "      <td>0.429434</td>\n",
       "      <td>0.481648</td>\n",
       "      <td>0.506049</td>\n",
       "      <td>0.511644</td>\n",
       "      <td>0.536437</td>\n",
       "      <td>0.559587</td>\n",
       "      <td>0.591610</td>\n",
       "      <td>0.606001</td>\n",
       "      <td>0.610144</td>\n",
       "      <td>0.601526</td>\n",
       "      <td>0.570662</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.352472</td>\n",
       "      <td>0.371040</td>\n",
       "      <td>0.411365</td>\n",
       "      <td>0.421782</td>\n",
       "      <td>0.430169</td>\n",
       "      <td>0.470344</td>\n",
       "      <td>0.501786</td>\n",
       "      <td>0.537461</td>\n",
       "      <td>0.559749</td>\n",
       "      <td>0.557520</td>\n",
       "      <td>0.540493</td>\n",
       "      <td>0.509934</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.407803</td>\n",
       "      <td>0.409733</td>\n",
       "      <td>0.429213</td>\n",
       "      <td>0.432311</td>\n",
       "      <td>0.450604</td>\n",
       "      <td>0.495748</td>\n",
       "      <td>0.518091</td>\n",
       "      <td>0.536294</td>\n",
       "      <td>0.527751</td>\n",
       "      <td>0.509399</td>\n",
       "      <td>0.483734</td>\n",
       "      <td>0.475756</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.441920</td>\n",
       "      <td>0.433120</td>\n",
       "      <td>0.450634</td>\n",
       "      <td>0.455771</td>\n",
       "      <td>0.483881</td>\n",
       "      <td>0.536041</td>\n",
       "      <td>0.559484</td>\n",
       "      <td>0.561809</td>\n",
       "      <td>0.509127</td>\n",
       "      <td>0.480476</td>\n",
       "      <td>0.493337</td>\n",
       "      <td>0.544904</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.447935</td>\n",
       "      <td>0.463115</td>\n",
       "      <td>0.499792</td>\n",
       "      <td>0.510718</td>\n",
       "      <td>0.532205</td>\n",
       "      <td>0.570618</td>\n",
       "      <td>0.559038</td>\n",
       "      <td>0.531497</td>\n",
       "      <td>0.481462</td>\n",
       "      <td>0.500781</td>\n",
       "      <td>0.559105</td>\n",
       "      <td>0.629110</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31406</th>\n",
       "      <td>0.518467</td>\n",
       "      <td>0.569279</td>\n",
       "      <td>0.619652</td>\n",
       "      <td>0.631811</td>\n",
       "      <td>0.605485</td>\n",
       "      <td>0.606846</td>\n",
       "      <td>0.582167</td>\n",
       "      <td>0.572136</td>\n",
       "      <td>0.550121</td>\n",
       "      <td>0.531675</td>\n",
       "      <td>0.508671</td>\n",
       "      <td>0.481982</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31407</th>\n",
       "      <td>0.577464</td>\n",
       "      <td>0.630980</td>\n",
       "      <td>0.632098</td>\n",
       "      <td>0.594880</td>\n",
       "      <td>0.545163</td>\n",
       "      <td>0.544239</td>\n",
       "      <td>0.518164</td>\n",
       "      <td>0.524765</td>\n",
       "      <td>0.517756</td>\n",
       "      <td>0.515137</td>\n",
       "      <td>0.501649</td>\n",
       "      <td>0.469528</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31408</th>\n",
       "      <td>0.612628</td>\n",
       "      <td>0.634992</td>\n",
       "      <td>0.605043</td>\n",
       "      <td>0.561689</td>\n",
       "      <td>0.532853</td>\n",
       "      <td>0.536198</td>\n",
       "      <td>0.509705</td>\n",
       "      <td>0.517685</td>\n",
       "      <td>0.499898</td>\n",
       "      <td>0.484949</td>\n",
       "      <td>0.482179</td>\n",
       "      <td>0.480296</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31409</th>\n",
       "      <td>0.653783</td>\n",
       "      <td>0.649182</td>\n",
       "      <td>0.596476</td>\n",
       "      <td>0.539113</td>\n",
       "      <td>0.517933</td>\n",
       "      <td>0.539815</td>\n",
       "      <td>0.538498</td>\n",
       "      <td>0.539775</td>\n",
       "      <td>0.502985</td>\n",
       "      <td>0.506353</td>\n",
       "      <td>0.531747</td>\n",
       "      <td>0.546151</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31410</th>\n",
       "      <td>0.677108</td>\n",
       "      <td>0.652687</td>\n",
       "      <td>0.609915</td>\n",
       "      <td>0.573427</td>\n",
       "      <td>0.562220</td>\n",
       "      <td>0.582300</td>\n",
       "      <td>0.552633</td>\n",
       "      <td>0.529187</td>\n",
       "      <td>0.516752</td>\n",
       "      <td>0.550881</td>\n",
       "      <td>0.559493</td>\n",
       "      <td>0.519544</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>31411 rows × 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Prediction1  Prediction2  Prediction3  Prediction4  Prediction5  \\\n",
       "0         0.399960     0.429434     0.481648     0.506049     0.511644   \n",
       "1         0.352472     0.371040     0.411365     0.421782     0.430169   \n",
       "2         0.407803     0.409733     0.429213     0.432311     0.450604   \n",
       "3         0.441920     0.433120     0.450634     0.455771     0.483881   \n",
       "4         0.447935     0.463115     0.499792     0.510718     0.532205   \n",
       "...            ...          ...          ...          ...          ...   \n",
       "31406     0.518467     0.569279     0.619652     0.631811     0.605485   \n",
       "31407     0.577464     0.630980     0.632098     0.594880     0.545163   \n",
       "31408     0.612628     0.634992     0.605043     0.561689     0.532853   \n",
       "31409     0.653783     0.649182     0.596476     0.539113     0.517933   \n",
       "31410     0.677108     0.652687     0.609915     0.573427     0.562220   \n",
       "\n",
       "       Prediction6  Prediction7  Prediction8  Prediction9  Prediction10  \\\n",
       "0         0.536437     0.559587     0.591610     0.606001      0.610144   \n",
       "1         0.470344     0.501786     0.537461     0.559749      0.557520   \n",
       "2         0.495748     0.518091     0.536294     0.527751      0.509399   \n",
       "3         0.536041     0.559484     0.561809     0.509127      0.480476   \n",
       "4         0.570618     0.559038     0.531497     0.481462      0.500781   \n",
       "...            ...          ...          ...          ...           ...   \n",
       "31406     0.606846     0.582167     0.572136     0.550121      0.531675   \n",
       "31407     0.544239     0.518164     0.524765     0.517756      0.515137   \n",
       "31408     0.536198     0.509705     0.517685     0.499898      0.484949   \n",
       "31409     0.539815     0.538498     0.539775     0.502985      0.506353   \n",
       "31410     0.582300     0.552633     0.529187     0.516752      0.550881   \n",
       "\n",
       "       Prediction11  Prediction12  \n",
       "0          0.601526      0.570662  \n",
       "1          0.540493      0.509934  \n",
       "2          0.483734      0.475756  \n",
       "3          0.493337      0.544904  \n",
       "4          0.559105      0.629110  \n",
       "...             ...           ...  \n",
       "31406      0.508671      0.481982  \n",
       "31407      0.501649      0.469528  \n",
       "31408      0.482179      0.480296  \n",
       "31409      0.531747      0.546151  \n",
       "31410      0.559493      0.519544  \n",
       "\n",
       "[31411 rows x 12 columns]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Prindex = ['Prediction1', 'Prediction2','Prediction3','Prediction4','Prediction5','Prediction6','Prediction7','Prediction8','Prediction9','Prediction10','Prediction11','Prediction12']\n",
    "Erindex = ['Error1', 'Error2','Error3','Error4','Error5','Error6','Error7','Error8','Error9','Error10','Error11','Error12']\n",
    "\n",
    "pr_df = pd.DataFrame(prediction, columns=Prindex)\n",
    "pr_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "6ffae559",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Error1</th>\n",
       "      <th>Error2</th>\n",
       "      <th>Error3</th>\n",
       "      <th>Error4</th>\n",
       "      <th>Error5</th>\n",
       "      <th>Error6</th>\n",
       "      <th>Error7</th>\n",
       "      <th>Error8</th>\n",
       "      <th>Error9</th>\n",
       "      <th>Error10</th>\n",
       "      <th>Error11</th>\n",
       "      <th>Error12</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.122027</td>\n",
       "      <td>0.108026</td>\n",
       "      <td>0.116619</td>\n",
       "      <td>0.105075</td>\n",
       "      <td>0.110718</td>\n",
       "      <td>0.180638</td>\n",
       "      <td>0.171145</td>\n",
       "      <td>0.115393</td>\n",
       "      <td>0.091944</td>\n",
       "      <td>0.096135</td>\n",
       "      <td>0.104033</td>\n",
       "      <td>0.092794</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.031064</td>\n",
       "      <td>0.006012</td>\n",
       "      <td>0.010391</td>\n",
       "      <td>0.020856</td>\n",
       "      <td>0.074369</td>\n",
       "      <td>0.081902</td>\n",
       "      <td>0.025568</td>\n",
       "      <td>0.023403</td>\n",
       "      <td>0.045740</td>\n",
       "      <td>0.060027</td>\n",
       "      <td>0.062624</td>\n",
       "      <td>0.084380</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.042774</td>\n",
       "      <td>0.008759</td>\n",
       "      <td>0.028287</td>\n",
       "      <td>0.076511</td>\n",
       "      <td>0.062162</td>\n",
       "      <td>0.019530</td>\n",
       "      <td>0.004034</td>\n",
       "      <td>0.022285</td>\n",
       "      <td>0.030258</td>\n",
       "      <td>0.031530</td>\n",
       "      <td>0.058181</td>\n",
       "      <td>0.057732</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.040946</td>\n",
       "      <td>0.032194</td>\n",
       "      <td>0.094834</td>\n",
       "      <td>0.067329</td>\n",
       "      <td>0.007663</td>\n",
       "      <td>0.021984</td>\n",
       "      <td>0.045475</td>\n",
       "      <td>0.064316</td>\n",
       "      <td>0.031258</td>\n",
       "      <td>0.054922</td>\n",
       "      <td>0.075313</td>\n",
       "      <td>-0.034730</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.047009</td>\n",
       "      <td>0.107315</td>\n",
       "      <td>0.111350</td>\n",
       "      <td>0.034501</td>\n",
       "      <td>0.018148</td>\n",
       "      <td>0.056609</td>\n",
       "      <td>0.061545</td>\n",
       "      <td>0.053629</td>\n",
       "      <td>0.055909</td>\n",
       "      <td>0.082757</td>\n",
       "      <td>-0.020529</td>\n",
       "      <td>-0.042525</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31406</th>\n",
       "      <td>0.072509</td>\n",
       "      <td>0.054711</td>\n",
       "      <td>0.031003</td>\n",
       "      <td>0.003244</td>\n",
       "      <td>-0.008893</td>\n",
       "      <td>0.067457</td>\n",
       "      <td>0.138510</td>\n",
       "      <td>0.162260</td>\n",
       "      <td>0.055181</td>\n",
       "      <td>0.004557</td>\n",
       "      <td>0.011151</td>\n",
       "      <td>-0.010587</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31407</th>\n",
       "      <td>0.062897</td>\n",
       "      <td>0.042331</td>\n",
       "      <td>0.003531</td>\n",
       "      <td>-0.019498</td>\n",
       "      <td>0.005774</td>\n",
       "      <td>0.100581</td>\n",
       "      <td>0.108288</td>\n",
       "      <td>0.029826</td>\n",
       "      <td>-0.009362</td>\n",
       "      <td>0.017617</td>\n",
       "      <td>0.009080</td>\n",
       "      <td>-0.039252</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31408</th>\n",
       "      <td>0.023978</td>\n",
       "      <td>0.006425</td>\n",
       "      <td>-0.009335</td>\n",
       "      <td>0.022300</td>\n",
       "      <td>0.089195</td>\n",
       "      <td>0.126322</td>\n",
       "      <td>0.014766</td>\n",
       "      <td>-0.009432</td>\n",
       "      <td>0.002379</td>\n",
       "      <td>-0.007621</td>\n",
       "      <td>-0.026601</td>\n",
       "      <td>0.004391</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31409</th>\n",
       "      <td>0.025216</td>\n",
       "      <td>0.034804</td>\n",
       "      <td>0.057087</td>\n",
       "      <td>0.095456</td>\n",
       "      <td>0.108057</td>\n",
       "      <td>0.044875</td>\n",
       "      <td>0.011381</td>\n",
       "      <td>0.042255</td>\n",
       "      <td>0.010415</td>\n",
       "      <td>-0.002427</td>\n",
       "      <td>0.055841</td>\n",
       "      <td>0.081402</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31410</th>\n",
       "      <td>0.062730</td>\n",
       "      <td>0.113298</td>\n",
       "      <td>0.166258</td>\n",
       "      <td>0.163551</td>\n",
       "      <td>0.067280</td>\n",
       "      <td>0.055182</td>\n",
       "      <td>0.055114</td>\n",
       "      <td>0.036618</td>\n",
       "      <td>0.007972</td>\n",
       "      <td>0.074976</td>\n",
       "      <td>0.094744</td>\n",
       "      <td>0.124449</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>31411 rows × 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         Error1    Error2    Error3    Error4    Error5    Error6    Error7  \\\n",
       "0      0.122027  0.108026  0.116619  0.105075  0.110718  0.180638  0.171145   \n",
       "1      0.031064  0.006012  0.010391  0.020856  0.074369  0.081902  0.025568   \n",
       "2      0.042774  0.008759  0.028287  0.076511  0.062162  0.019530  0.004034   \n",
       "3      0.040946  0.032194  0.094834  0.067329  0.007663  0.021984  0.045475   \n",
       "4      0.047009  0.107315  0.111350  0.034501  0.018148  0.056609  0.061545   \n",
       "...         ...       ...       ...       ...       ...       ...       ...   \n",
       "31406  0.072509  0.054711  0.031003  0.003244 -0.008893  0.067457  0.138510   \n",
       "31407  0.062897  0.042331  0.003531 -0.019498  0.005774  0.100581  0.108288   \n",
       "31408  0.023978  0.006425 -0.009335  0.022300  0.089195  0.126322  0.014766   \n",
       "31409  0.025216  0.034804  0.057087  0.095456  0.108057  0.044875  0.011381   \n",
       "31410  0.062730  0.113298  0.166258  0.163551  0.067280  0.055182  0.055114   \n",
       "\n",
       "         Error8    Error9   Error10   Error11   Error12  \n",
       "0      0.115393  0.091944  0.096135  0.104033  0.092794  \n",
       "1      0.023403  0.045740  0.060027  0.062624  0.084380  \n",
       "2      0.022285  0.030258  0.031530  0.058181  0.057732  \n",
       "3      0.064316  0.031258  0.054922  0.075313 -0.034730  \n",
       "4      0.053629  0.055909  0.082757 -0.020529 -0.042525  \n",
       "...         ...       ...       ...       ...       ...  \n",
       "31406  0.162260  0.055181  0.004557  0.011151 -0.010587  \n",
       "31407  0.029826 -0.009362  0.017617  0.009080 -0.039252  \n",
       "31408 -0.009432  0.002379 -0.007621 -0.026601  0.004391  \n",
       "31409  0.042255  0.010415 -0.002427  0.055841  0.081402  \n",
       "31410  0.036618  0.007972  0.074976  0.094744  0.124449  \n",
       "\n",
       "[31411 rows x 12 columns]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "er_df = pd.DataFrame(errors, columns=Erindex)\n",
    "er_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "e9f0159e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Normalized Wind</th>\n",
       "      <th>Prediction1</th>\n",
       "      <th>Prediction2</th>\n",
       "      <th>Prediction3</th>\n",
       "      <th>Prediction4</th>\n",
       "      <th>Prediction5</th>\n",
       "      <th>Prediction6</th>\n",
       "      <th>Prediction7</th>\n",
       "      <th>Prediction8</th>\n",
       "      <th>Prediction9</th>\n",
       "      <th>...</th>\n",
       "      <th>Error3</th>\n",
       "      <th>Error4</th>\n",
       "      <th>Error5</th>\n",
       "      <th>Error6</th>\n",
       "      <th>Error7</th>\n",
       "      <th>Error8</th>\n",
       "      <th>Error9</th>\n",
       "      <th>Error10</th>\n",
       "      <th>Error11</th>\n",
       "      <th>Error12</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.644724</td>\n",
       "      <td>0.399960</td>\n",
       "      <td>0.429434</td>\n",
       "      <td>0.481648</td>\n",
       "      <td>0.506049</td>\n",
       "      <td>0.511644</td>\n",
       "      <td>0.536437</td>\n",
       "      <td>0.559587</td>\n",
       "      <td>0.591610</td>\n",
       "      <td>0.606001</td>\n",
       "      <td>...</td>\n",
       "      <td>0.116619</td>\n",
       "      <td>0.105075</td>\n",
       "      <td>0.110718</td>\n",
       "      <td>0.180638</td>\n",
       "      <td>0.171145</td>\n",
       "      <td>0.115393</td>\n",
       "      <td>0.091944</td>\n",
       "      <td>0.096135</td>\n",
       "      <td>0.104033</td>\n",
       "      <td>0.092794</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.658617</td>\n",
       "      <td>0.352472</td>\n",
       "      <td>0.371040</td>\n",
       "      <td>0.411365</td>\n",
       "      <td>0.421782</td>\n",
       "      <td>0.430169</td>\n",
       "      <td>0.470344</td>\n",
       "      <td>0.501786</td>\n",
       "      <td>0.537461</td>\n",
       "      <td>0.559749</td>\n",
       "      <td>...</td>\n",
       "      <td>0.010391</td>\n",
       "      <td>0.020856</td>\n",
       "      <td>0.074369</td>\n",
       "      <td>0.081902</td>\n",
       "      <td>0.025568</td>\n",
       "      <td>0.023403</td>\n",
       "      <td>0.045740</td>\n",
       "      <td>0.060027</td>\n",
       "      <td>0.062624</td>\n",
       "      <td>0.084380</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.683924</td>\n",
       "      <td>0.407803</td>\n",
       "      <td>0.409733</td>\n",
       "      <td>0.429213</td>\n",
       "      <td>0.432311</td>\n",
       "      <td>0.450604</td>\n",
       "      <td>0.495748</td>\n",
       "      <td>0.518091</td>\n",
       "      <td>0.536294</td>\n",
       "      <td>0.527751</td>\n",
       "      <td>...</td>\n",
       "      <td>0.028287</td>\n",
       "      <td>0.076511</td>\n",
       "      <td>0.062162</td>\n",
       "      <td>0.019530</td>\n",
       "      <td>0.004034</td>\n",
       "      <td>0.022285</td>\n",
       "      <td>0.030258</td>\n",
       "      <td>0.031530</td>\n",
       "      <td>0.058181</td>\n",
       "      <td>0.057732</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.721813</td>\n",
       "      <td>0.441920</td>\n",
       "      <td>0.433120</td>\n",
       "      <td>0.450634</td>\n",
       "      <td>0.455771</td>\n",
       "      <td>0.483881</td>\n",
       "      <td>0.536041</td>\n",
       "      <td>0.559484</td>\n",
       "      <td>0.561809</td>\n",
       "      <td>0.509127</td>\n",
       "      <td>...</td>\n",
       "      <td>0.094834</td>\n",
       "      <td>0.067329</td>\n",
       "      <td>0.007663</td>\n",
       "      <td>0.021984</td>\n",
       "      <td>0.045475</td>\n",
       "      <td>0.064316</td>\n",
       "      <td>0.031258</td>\n",
       "      <td>0.054922</td>\n",
       "      <td>0.075313</td>\n",
       "      <td>-0.034730</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.714187</td>\n",
       "      <td>0.447935</td>\n",
       "      <td>0.463115</td>\n",
       "      <td>0.499792</td>\n",
       "      <td>0.510718</td>\n",
       "      <td>0.532205</td>\n",
       "      <td>0.570618</td>\n",
       "      <td>0.559038</td>\n",
       "      <td>0.531497</td>\n",
       "      <td>0.481462</td>\n",
       "      <td>...</td>\n",
       "      <td>0.111350</td>\n",
       "      <td>0.034501</td>\n",
       "      <td>0.018148</td>\n",
       "      <td>0.056609</td>\n",
       "      <td>0.061545</td>\n",
       "      <td>0.053629</td>\n",
       "      <td>0.055909</td>\n",
       "      <td>0.082757</td>\n",
       "      <td>-0.020529</td>\n",
       "      <td>-0.042525</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 25 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Normalized Wind  Prediction1  Prediction2  Prediction3  Prediction4  \\\n",
       "0         0.644724     0.399960     0.429434     0.481648     0.506049   \n",
       "1         0.658617     0.352472     0.371040     0.411365     0.421782   \n",
       "2         0.683924     0.407803     0.409733     0.429213     0.432311   \n",
       "3         0.721813     0.441920     0.433120     0.450634     0.455771   \n",
       "4         0.714187     0.447935     0.463115     0.499792     0.510718   \n",
       "\n",
       "   Prediction5  Prediction6  Prediction7  Prediction8  Prediction9  ...  \\\n",
       "0     0.511644     0.536437     0.559587     0.591610     0.606001  ...   \n",
       "1     0.430169     0.470344     0.501786     0.537461     0.559749  ...   \n",
       "2     0.450604     0.495748     0.518091     0.536294     0.527751  ...   \n",
       "3     0.483881     0.536041     0.559484     0.561809     0.509127  ...   \n",
       "4     0.532205     0.570618     0.559038     0.531497     0.481462  ...   \n",
       "\n",
       "     Error3    Error4    Error5    Error6    Error7    Error8    Error9  \\\n",
       "0  0.116619  0.105075  0.110718  0.180638  0.171145  0.115393  0.091944   \n",
       "1  0.010391  0.020856  0.074369  0.081902  0.025568  0.023403  0.045740   \n",
       "2  0.028287  0.076511  0.062162  0.019530  0.004034  0.022285  0.030258   \n",
       "3  0.094834  0.067329  0.007663  0.021984  0.045475  0.064316  0.031258   \n",
       "4  0.111350  0.034501  0.018148  0.056609  0.061545  0.053629  0.055909   \n",
       "\n",
       "    Error10   Error11   Error12  \n",
       "0  0.096135  0.104033  0.092794  \n",
       "1  0.060027  0.062624  0.084380  \n",
       "2  0.031530  0.058181  0.057732  \n",
       "3  0.054922  0.075313 -0.034730  \n",
       "4  0.082757 -0.020529 -0.042525  \n",
       "\n",
       "[5 rows x 25 columns]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "norm_df2 = pd.concat([norm_df2, pr_df, er_df],axis=1)\n",
    "norm_df2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "954fc938",
   "metadata": {},
   "outputs": [],
   "source": [
    "norm_df22 = pd.DataFrame(norm_df).iloc[prediction.shape[0]+timesteps:, :]\n",
    "norm_df22.columns = ['Normalized Wind']\n",
    "npnorm22 = np.array(norm_df22)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "175291cb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.647168</td>\n",
       "      <td>0.623515</td>\n",
       "      <td>0.597096</td>\n",
       "      <td>0.575948</td>\n",
       "      <td>0.573299</td>\n",
       "      <td>0.597353</td>\n",
       "      <td>0.552190</td>\n",
       "      <td>0.503197</td>\n",
       "      <td>0.492928</td>\n",
       "      <td>0.517591</td>\n",
       "      <td>0.474474</td>\n",
       "      <td>0.387376</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.643588</td>\n",
       "      <td>0.627118</td>\n",
       "      <td>0.612184</td>\n",
       "      <td>0.601875</td>\n",
       "      <td>0.577799</td>\n",
       "      <td>0.554303</td>\n",
       "      <td>0.493358</td>\n",
       "      <td>0.451701</td>\n",
       "      <td>0.450464</td>\n",
       "      <td>0.439559</td>\n",
       "      <td>0.372763</td>\n",
       "      <td>0.290452</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.654424</td>\n",
       "      <td>0.638656</td>\n",
       "      <td>0.634021</td>\n",
       "      <td>0.617097</td>\n",
       "      <td>0.574289</td>\n",
       "      <td>0.538726</td>\n",
       "      <td>0.505116</td>\n",
       "      <td>0.478562</td>\n",
       "      <td>0.460780</td>\n",
       "      <td>0.416367</td>\n",
       "      <td>0.359203</td>\n",
       "      <td>0.325772</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.638452</td>\n",
       "      <td>0.629698</td>\n",
       "      <td>0.623970</td>\n",
       "      <td>0.583469</td>\n",
       "      <td>0.517653</td>\n",
       "      <td>0.510108</td>\n",
       "      <td>0.492611</td>\n",
       "      <td>0.448254</td>\n",
       "      <td>0.399689</td>\n",
       "      <td>0.352527</td>\n",
       "      <td>0.324033</td>\n",
       "      <td>0.325392</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.601920</td>\n",
       "      <td>0.594024</td>\n",
       "      <td>0.555320</td>\n",
       "      <td>0.486235</td>\n",
       "      <td>0.429057</td>\n",
       "      <td>0.461331</td>\n",
       "      <td>0.437006</td>\n",
       "      <td>0.371605</td>\n",
       "      <td>0.324776</td>\n",
       "      <td>0.322958</td>\n",
       "      <td>0.315062</td>\n",
       "      <td>0.324037</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3486</th>\n",
       "      <td>0.651783</td>\n",
       "      <td>0.611293</td>\n",
       "      <td>0.567865</td>\n",
       "      <td>0.535929</td>\n",
       "      <td>0.506188</td>\n",
       "      <td>0.521192</td>\n",
       "      <td>0.529792</td>\n",
       "      <td>0.544198</td>\n",
       "      <td>0.555925</td>\n",
       "      <td>0.558441</td>\n",
       "      <td>0.543425</td>\n",
       "      <td>0.523845</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3487</th>\n",
       "      <td>0.628393</td>\n",
       "      <td>0.599270</td>\n",
       "      <td>0.560104</td>\n",
       "      <td>0.523728</td>\n",
       "      <td>0.499505</td>\n",
       "      <td>0.511799</td>\n",
       "      <td>0.514244</td>\n",
       "      <td>0.525624</td>\n",
       "      <td>0.529808</td>\n",
       "      <td>0.534559</td>\n",
       "      <td>0.536510</td>\n",
       "      <td>0.543618</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3488</th>\n",
       "      <td>0.597815</td>\n",
       "      <td>0.557033</td>\n",
       "      <td>0.516217</td>\n",
       "      <td>0.478600</td>\n",
       "      <td>0.451679</td>\n",
       "      <td>0.444117</td>\n",
       "      <td>0.445771</td>\n",
       "      <td>0.456053</td>\n",
       "      <td>0.440937</td>\n",
       "      <td>0.402120</td>\n",
       "      <td>0.396793</td>\n",
       "      <td>0.429057</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3489</th>\n",
       "      <td>0.569339</td>\n",
       "      <td>0.532265</td>\n",
       "      <td>0.486733</td>\n",
       "      <td>0.436686</td>\n",
       "      <td>0.405860</td>\n",
       "      <td>0.409523</td>\n",
       "      <td>0.401598</td>\n",
       "      <td>0.399661</td>\n",
       "      <td>0.376074</td>\n",
       "      <td>0.390039</td>\n",
       "      <td>0.441424</td>\n",
       "      <td>0.493606</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3490</th>\n",
       "      <td>0.585099</td>\n",
       "      <td>0.580723</td>\n",
       "      <td>0.543644</td>\n",
       "      <td>0.490107</td>\n",
       "      <td>0.447495</td>\n",
       "      <td>0.453772</td>\n",
       "      <td>0.409138</td>\n",
       "      <td>0.355545</td>\n",
       "      <td>0.320614</td>\n",
       "      <td>0.335177</td>\n",
       "      <td>0.347921</td>\n",
       "      <td>0.340653</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3491 rows × 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            0         1         2         3         4         5         6   \\\n",
       "0     0.647168  0.623515  0.597096  0.575948  0.573299  0.597353  0.552190   \n",
       "1     0.643588  0.627118  0.612184  0.601875  0.577799  0.554303  0.493358   \n",
       "2     0.654424  0.638656  0.634021  0.617097  0.574289  0.538726  0.505116   \n",
       "3     0.638452  0.629698  0.623970  0.583469  0.517653  0.510108  0.492611   \n",
       "4     0.601920  0.594024  0.555320  0.486235  0.429057  0.461331  0.437006   \n",
       "...        ...       ...       ...       ...       ...       ...       ...   \n",
       "3486  0.651783  0.611293  0.567865  0.535929  0.506188  0.521192  0.529792   \n",
       "3487  0.628393  0.599270  0.560104  0.523728  0.499505  0.511799  0.514244   \n",
       "3488  0.597815  0.557033  0.516217  0.478600  0.451679  0.444117  0.445771   \n",
       "3489  0.569339  0.532265  0.486733  0.436686  0.405860  0.409523  0.401598   \n",
       "3490  0.585099  0.580723  0.543644  0.490107  0.447495  0.453772  0.409138   \n",
       "\n",
       "            7         8         9         10        11  \n",
       "0     0.503197  0.492928  0.517591  0.474474  0.387376  \n",
       "1     0.451701  0.450464  0.439559  0.372763  0.290452  \n",
       "2     0.478562  0.460780  0.416367  0.359203  0.325772  \n",
       "3     0.448254  0.399689  0.352527  0.324033  0.325392  \n",
       "4     0.371605  0.324776  0.322958  0.315062  0.324037  \n",
       "...        ...       ...       ...       ...       ...  \n",
       "3486  0.544198  0.555925  0.558441  0.543425  0.523845  \n",
       "3487  0.525624  0.529808  0.534559  0.536510  0.543618  \n",
       "3488  0.456053  0.440937  0.402120  0.396793  0.429057  \n",
       "3489  0.399661  0.376074  0.390039  0.441424  0.493606  \n",
       "3490  0.355545  0.320614  0.335177  0.347921  0.340653  \n",
       "\n",
       "[3491 rows x 12 columns]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pr_df = pd.DataFrame(tePredict.reshape(-1,output_timesteps))\n",
    "pr_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "86adfa2d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Error1</th>\n",
       "      <th>Error2</th>\n",
       "      <th>Error3</th>\n",
       "      <th>Error4</th>\n",
       "      <th>Error5</th>\n",
       "      <th>Error6</th>\n",
       "      <th>Error7</th>\n",
       "      <th>Error8</th>\n",
       "      <th>Error9</th>\n",
       "      <th>Error10</th>\n",
       "      <th>Error11</th>\n",
       "      <th>Error12</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.107779</td>\n",
       "      <td>0.179858</td>\n",
       "      <td>0.187220</td>\n",
       "      <td>0.081008</td>\n",
       "      <td>0.046181</td>\n",
       "      <td>0.099833</td>\n",
       "      <td>0.059621</td>\n",
       "      <td>-0.005583</td>\n",
       "      <td>0.017023</td>\n",
       "      <td>0.052842</td>\n",
       "      <td>0.079379</td>\n",
       "      <td>0.071977</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.199931</td>\n",
       "      <td>0.217242</td>\n",
       "      <td>0.117244</td>\n",
       "      <td>0.074758</td>\n",
       "      <td>0.080280</td>\n",
       "      <td>0.061734</td>\n",
       "      <td>-0.015423</td>\n",
       "      <td>-0.024205</td>\n",
       "      <td>-0.014286</td>\n",
       "      <td>0.044464</td>\n",
       "      <td>0.057364</td>\n",
       "      <td>0.032157</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.244549</td>\n",
       "      <td>0.143716</td>\n",
       "      <td>0.106904</td>\n",
       "      <td>0.119577</td>\n",
       "      <td>0.081720</td>\n",
       "      <td>0.029945</td>\n",
       "      <td>0.029211</td>\n",
       "      <td>0.013813</td>\n",
       "      <td>0.065685</td>\n",
       "      <td>0.100968</td>\n",
       "      <td>0.100908</td>\n",
       "      <td>0.099794</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.143512</td>\n",
       "      <td>0.102580</td>\n",
       "      <td>0.126450</td>\n",
       "      <td>0.090900</td>\n",
       "      <td>0.008873</td>\n",
       "      <td>0.034203</td>\n",
       "      <td>0.027861</td>\n",
       "      <td>0.053160</td>\n",
       "      <td>0.084289</td>\n",
       "      <td>0.094233</td>\n",
       "      <td>0.098055</td>\n",
       "      <td>0.085993</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.074802</td>\n",
       "      <td>0.096505</td>\n",
       "      <td>0.062751</td>\n",
       "      <td>-0.022545</td>\n",
       "      <td>-0.046848</td>\n",
       "      <td>-0.003418</td>\n",
       "      <td>0.041911</td>\n",
       "      <td>0.056205</td>\n",
       "      <td>0.066481</td>\n",
       "      <td>0.096980</td>\n",
       "      <td>0.075663</td>\n",
       "      <td>0.071389</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3486</th>\n",
       "      <td>0.045656</td>\n",
       "      <td>0.071092</td>\n",
       "      <td>0.096210</td>\n",
       "      <td>0.102898</td>\n",
       "      <td>0.203004</td>\n",
       "      <td>0.242149</td>\n",
       "      <td>0.214810</td>\n",
       "      <td>0.246251</td>\n",
       "      <td>0.274229</td>\n",
       "      <td>0.264846</td>\n",
       "      <td>0.232252</td>\n",
       "      <td>0.182819</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3487</th>\n",
       "      <td>0.088192</td>\n",
       "      <td>0.127614</td>\n",
       "      <td>0.127073</td>\n",
       "      <td>0.220545</td>\n",
       "      <td>0.220462</td>\n",
       "      <td>0.196818</td>\n",
       "      <td>0.216296</td>\n",
       "      <td>0.243929</td>\n",
       "      <td>0.236213</td>\n",
       "      <td>0.223386</td>\n",
       "      <td>0.195484</td>\n",
       "      <td>0.172876</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3488</th>\n",
       "      <td>0.126160</td>\n",
       "      <td>0.124002</td>\n",
       "      <td>0.213034</td>\n",
       "      <td>0.199556</td>\n",
       "      <td>0.136697</td>\n",
       "      <td>0.146170</td>\n",
       "      <td>0.164076</td>\n",
       "      <td>0.162458</td>\n",
       "      <td>0.129763</td>\n",
       "      <td>0.061094</td>\n",
       "      <td>0.026051</td>\n",
       "      <td>-0.055927</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3489</th>\n",
       "      <td>0.136308</td>\n",
       "      <td>0.229082</td>\n",
       "      <td>0.207690</td>\n",
       "      <td>0.121704</td>\n",
       "      <td>0.107913</td>\n",
       "      <td>0.127828</td>\n",
       "      <td>0.108002</td>\n",
       "      <td>0.088488</td>\n",
       "      <td>0.035048</td>\n",
       "      <td>0.019296</td>\n",
       "      <td>-0.043559</td>\n",
       "      <td>-0.088551</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3490</th>\n",
       "      <td>0.281915</td>\n",
       "      <td>0.301679</td>\n",
       "      <td>0.228663</td>\n",
       "      <td>0.192159</td>\n",
       "      <td>0.165800</td>\n",
       "      <td>0.160176</td>\n",
       "      <td>0.097964</td>\n",
       "      <td>0.014519</td>\n",
       "      <td>-0.050129</td>\n",
       "      <td>-0.149807</td>\n",
       "      <td>-0.234236</td>\n",
       "      <td>-0.280264</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3491 rows × 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        Error1    Error2    Error3    Error4    Error5    Error6    Error7  \\\n",
       "0     0.107779  0.179858  0.187220  0.081008  0.046181  0.099833  0.059621   \n",
       "1     0.199931  0.217242  0.117244  0.074758  0.080280  0.061734 -0.015423   \n",
       "2     0.244549  0.143716  0.106904  0.119577  0.081720  0.029945  0.029211   \n",
       "3     0.143512  0.102580  0.126450  0.090900  0.008873  0.034203  0.027861   \n",
       "4     0.074802  0.096505  0.062751 -0.022545 -0.046848 -0.003418  0.041911   \n",
       "...        ...       ...       ...       ...       ...       ...       ...   \n",
       "3486  0.045656  0.071092  0.096210  0.102898  0.203004  0.242149  0.214810   \n",
       "3487  0.088192  0.127614  0.127073  0.220545  0.220462  0.196818  0.216296   \n",
       "3488  0.126160  0.124002  0.213034  0.199556  0.136697  0.146170  0.164076   \n",
       "3489  0.136308  0.229082  0.207690  0.121704  0.107913  0.127828  0.108002   \n",
       "3490  0.281915  0.301679  0.228663  0.192159  0.165800  0.160176  0.097964   \n",
       "\n",
       "        Error8    Error9   Error10   Error11   Error12  \n",
       "0    -0.005583  0.017023  0.052842  0.079379  0.071977  \n",
       "1    -0.024205 -0.014286  0.044464  0.057364  0.032157  \n",
       "2     0.013813  0.065685  0.100968  0.100908  0.099794  \n",
       "3     0.053160  0.084289  0.094233  0.098055  0.085993  \n",
       "4     0.056205  0.066481  0.096980  0.075663  0.071389  \n",
       "...        ...       ...       ...       ...       ...  \n",
       "3486  0.246251  0.274229  0.264846  0.232252  0.182819  \n",
       "3487  0.243929  0.236213  0.223386  0.195484  0.172876  \n",
       "3488  0.162458  0.129763  0.061094  0.026051 -0.055927  \n",
       "3489  0.088488  0.035048  0.019296 -0.043559 -0.088551  \n",
       "3490  0.014519 -0.050129 -0.149807 -0.234236 -0.280264  \n",
       "\n",
       "[3491 rows x 12 columns]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "teY = testY.reshape(-1,output_timesteps)\n",
    "e_te = testPredict-teY\n",
    "er_df = pd.DataFrame(e_te, columns=Erindex)\n",
    "er_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "f150f28b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3491, 12)\n"
     ]
    }
   ],
   "source": [
    "prnorm = np.array(pr_df)\n",
    "ernorm =np.array(er_df)\n",
    "print(ernorm.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "be7a0200",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.50905911, 0.66286355, 0.64435244, 0.6382727 , 0.63147575,\n",
       "        0.61518335, 0.61691707, 0.58595443, 0.54062736, 0.51851928,\n",
       "        0.48299387, 0.42328489, 0.38398591, 0.30451401, 0.32578074,\n",
       "        0.35658528, 0.39528358, 0.41280759, 0.44417423, 0.43604637,\n",
       "        0.43203109, 0.38422952, 0.35762885, 0.33902248, 0.32395277],\n",
       "       [0.47426657, 0.58089948, 0.56743556, 0.5533759 , 0.53227925,\n",
       "        0.50116456, 0.52452481, 0.5157842 , 0.46406293, 0.4016363 ,\n",
       "        0.34403944, 0.29891023, 0.28839415, 0.26232778, 0.28574814,\n",
       "        0.31718374, 0.32990349, 0.32842171, 0.37461675, 0.40718793,\n",
       "        0.32977317, 0.27627128, 0.25977703, 0.23887709, 0.23930777]])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "etedat = np.concatenate((npnorm22[:prnorm.shape[0],:], prnorm, ernorm), axis=1)\n",
    "etedat[169:171,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "c76540c6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3345, 1, 25)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#output_timesteps = 1\n",
    "eteX, eteY = create_dataset(etedat, timesteps, 1, 0)\n",
    "eteY.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "f2d40e0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "eteY = eteY[:,:,-output_timesteps:].reshape(-1,output_timesteps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "e56959e0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(31265, 1, 25)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "norm_df2 = np.array(norm_df2)\n",
    "Xe, Ye = create_dataset(norm_df2, timesteps, 1, 0)\n",
    "Ye.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "8ac9e574",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(31265, 144, 25)\n",
      "(31265, 12)\n"
     ]
    }
   ],
   "source": [
    "Ye = Ye[:,:,-output_timesteps:].reshape(-1,output_timesteps)\n",
    "print(Xe.shape)\n",
    "print(Ye.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "80bffea7",
   "metadata": {},
   "outputs": [],
   "source": [
    "trXe, vaXe, trYe, vaYe = train_test_split(Xe, Ye, test_size=0.3, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "3b8f4be0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6278"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "86f3456f",
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = np.arange(Xe.shape[0])\n",
    "np.random.shuffle(idx)\n",
    "Xe = Xe[idx]\n",
    "Ye = Ye[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "773d464b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((3345, 144, 25), (3345, 12), (31265, 144, 25), (31265, 12))"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eteX.shape, eteY.shape, Xe.shape, Ye.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "11495308",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mse_mae(y_true, y_pred):\n",
    "    return K.mean(K.square(y_pred - y_true))*10+K.mean(K.abs(y_pred - y_true))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "9d6cd09d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_2 (InputLayer)            [(None, 144, 25)]    0                                            \n",
      "__________________________________________________________________________________________________\n",
      "permute_1 (Permute)             (None, 25, 144)      0           input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_3 (Dense)                 (None, 25, 144)      20880       permute_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_4 (Dense)                 (None, 25, 144)      20880       permute_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "multiply_24 (Multiply)          (None, 25, 144)      0           dense_3[0][0]                    \n",
      "                                                                 dense_4[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "attention_vec (Permute)         (None, 144, 25)      0           multiply_24[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "multiply_25 (Multiply)          (None, 144, 25)      0           input_2[0][0]                    \n",
      "                                                                 attention_vec[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_24 (Conv1D)              (None, 144, 256)     6656        multiply_25[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "activation_44 (Activation)      (None, 144, 256)     0           conv1d_24[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_45 (Activation)      (None, 144, 256)     0           conv1d_24[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "multiply_26 (Multiply)          (None, 144, 256)     0           activation_44[0][0]              \n",
      "                                                                 activation_45[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_25 (Conv1D)              (None, 144, 25)      12825       multiply_26[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "activation_46 (Activation)      (None, 144, 25)      0           conv1d_25[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_47 (Activation)      (None, 144, 25)      0           conv1d_25[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "multiply_27 (Multiply)          (None, 144, 25)      0           activation_46[0][0]              \n",
      "                                                                 activation_47[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "add_6 (Add)                     (None, 144, 25)      0           input_2[0][0]                    \n",
      "                                                                 multiply_27[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "subtract_6 (Subtract)           (None, 144, 25)      0           input_2[0][0]                    \n",
      "                                                                 multiply_27[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_26 (Conv1D)              (None, 144, 256)     6656        add_6[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_28 (Conv1D)              (None, 144, 256)     6656        subtract_6[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_48 (Activation)      (None, 144, 256)     0           conv1d_26[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_49 (Activation)      (None, 144, 256)     0           conv1d_26[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_52 (Activation)      (None, 144, 256)     0           conv1d_28[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_53 (Activation)      (None, 144, 256)     0           conv1d_28[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "multiply_28 (Multiply)          (None, 144, 256)     0           activation_48[0][0]              \n",
      "                                                                 activation_49[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "multiply_30 (Multiply)          (None, 144, 256)     0           activation_52[0][0]              \n",
      "                                                                 activation_53[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_27 (Conv1D)              (None, 144, 25)      12825       multiply_28[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_29 (Conv1D)              (None, 144, 25)      12825       multiply_30[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "activation_50 (Activation)      (None, 144, 25)      0           conv1d_27[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_51 (Activation)      (None, 144, 25)      0           conv1d_27[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_54 (Activation)      (None, 144, 25)      0           conv1d_29[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_55 (Activation)      (None, 144, 25)      0           conv1d_29[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "multiply_29 (Multiply)          (None, 144, 25)      0           activation_50[0][0]              \n",
      "                                                                 activation_51[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "multiply_31 (Multiply)          (None, 144, 25)      0           activation_54[0][0]              \n",
      "                                                                 activation_55[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "add_7 (Add)                     (None, 144, 25)      0           add_6[0][0]                      \n",
      "                                                                 multiply_29[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "subtract_7 (Subtract)           (None, 144, 25)      0           subtract_6[0][0]                 \n",
      "                                                                 multiply_31[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_6 (Concatenate)     (None, 144, 100)     0           add_7[0][0]                      \n",
      "                                                                 subtract_7[0][0]                 \n",
      "                                                                 add_6[0][0]                      \n",
      "                                                                 subtract_6[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_30 (Conv1D)              (None, 144, 256)     25856       concatenate_6[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_32 (Conv1D)              (None, 144, 256)     25856       concatenate_6[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_56 (Activation)      (None, 144, 256)     0           conv1d_30[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_57 (Activation)      (None, 144, 256)     0           conv1d_30[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_60 (Activation)      (None, 144, 256)     0           conv1d_32[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_61 (Activation)      (None, 144, 256)     0           conv1d_32[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "multiply_32 (Multiply)          (None, 144, 256)     0           activation_56[0][0]              \n",
      "                                                                 activation_57[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "multiply_34 (Multiply)          (None, 144, 256)     0           activation_60[0][0]              \n",
      "                                                                 activation_61[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_31 (Conv1D)              (None, 144, 25)      12825       multiply_32[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_33 (Conv1D)              (None, 144, 25)      12825       multiply_34[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "activation_58 (Activation)      (None, 144, 25)      0           conv1d_31[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_59 (Activation)      (None, 144, 25)      0           conv1d_31[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_62 (Activation)      (None, 144, 25)      0           conv1d_33[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_63 (Activation)      (None, 144, 25)      0           conv1d_33[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "multiply_33 (Multiply)          (None, 144, 25)      0           activation_58[0][0]              \n",
      "                                                                 activation_59[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "multiply_35 (Multiply)          (None, 144, 25)      0           activation_62[0][0]              \n",
      "                                                                 activation_63[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "add_8 (Add)                     (None, 144, 25)      0           add_7[0][0]                      \n",
      "                                                                 multiply_33[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "subtract_8 (Subtract)           (None, 144, 25)      0           subtract_7[0][0]                 \n",
      "                                                                 multiply_35[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_7 (Concatenate)     (None, 144, 150)     0           add_8[0][0]                      \n",
      "                                                                 subtract_8[0][0]                 \n",
      "                                                                 concatenate_6[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_34 (Conv1D)              (None, 144, 256)     38656       concatenate_7[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_36 (Conv1D)              (None, 144, 256)     38656       concatenate_7[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_64 (Activation)      (None, 144, 256)     0           conv1d_34[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_65 (Activation)      (None, 144, 256)     0           conv1d_34[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_68 (Activation)      (None, 144, 256)     0           conv1d_36[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_69 (Activation)      (None, 144, 256)     0           conv1d_36[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "multiply_36 (Multiply)          (None, 144, 256)     0           activation_64[0][0]              \n",
      "                                                                 activation_65[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "multiply_38 (Multiply)          (None, 144, 256)     0           activation_68[0][0]              \n",
      "                                                                 activation_69[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_35 (Conv1D)              (None, 144, 25)      12825       multiply_36[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_37 (Conv1D)              (None, 144, 25)      12825       multiply_38[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "activation_66 (Activation)      (None, 144, 25)      0           conv1d_35[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_67 (Activation)      (None, 144, 25)      0           conv1d_35[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_70 (Activation)      (None, 144, 25)      0           conv1d_37[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_71 (Activation)      (None, 144, 25)      0           conv1d_37[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "multiply_37 (Multiply)          (None, 144, 25)      0           activation_66[0][0]              \n",
      "                                                                 activation_67[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "multiply_39 (Multiply)          (None, 144, 25)      0           activation_70[0][0]              \n",
      "                                                                 activation_71[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "add_9 (Add)                     (None, 144, 25)      0           add_8[0][0]                      \n",
      "                                                                 multiply_37[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "subtract_9 (Subtract)           (None, 144, 25)      0           subtract_7[0][0]                 \n",
      "                                                                 multiply_39[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_8 (Concatenate)     (None, 144, 200)     0           add_9[0][0]                      \n",
      "                                                                 subtract_9[0][0]                 \n",
      "                                                                 concatenate_7[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_38 (Conv1D)              (None, 144, 256)     51456       concatenate_8[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_40 (Conv1D)              (None, 144, 256)     51456       concatenate_8[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_72 (Activation)      (None, 144, 256)     0           conv1d_38[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_73 (Activation)      (None, 144, 256)     0           conv1d_38[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_76 (Activation)      (None, 144, 256)     0           conv1d_40[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_77 (Activation)      (None, 144, 256)     0           conv1d_40[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "multiply_40 (Multiply)          (None, 144, 256)     0           activation_72[0][0]              \n",
      "                                                                 activation_73[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "multiply_42 (Multiply)          (None, 144, 256)     0           activation_76[0][0]              \n",
      "                                                                 activation_77[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_39 (Conv1D)              (None, 144, 25)      12825       multiply_40[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_41 (Conv1D)              (None, 144, 25)      12825       multiply_42[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "activation_74 (Activation)      (None, 144, 25)      0           conv1d_39[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_75 (Activation)      (None, 144, 25)      0           conv1d_39[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_78 (Activation)      (None, 144, 25)      0           conv1d_41[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_79 (Activation)      (None, 144, 25)      0           conv1d_41[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "multiply_41 (Multiply)          (None, 144, 25)      0           activation_74[0][0]              \n",
      "                                                                 activation_75[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "multiply_43 (Multiply)          (None, 144, 25)      0           activation_78[0][0]              \n",
      "                                                                 activation_79[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "add_10 (Add)                    (None, 144, 25)      0           add_9[0][0]                      \n",
      "                                                                 multiply_41[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "subtract_10 (Subtract)          (None, 144, 25)      0           subtract_9[0][0]                 \n",
      "                                                                 multiply_43[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_9 (Concatenate)     (None, 144, 250)     0           add_10[0][0]                     \n",
      "                                                                 subtract_10[0][0]                \n",
      "                                                                 concatenate_8[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_10 (Concatenate)    (None, 144, 50)      0           add_10[0][0]                     \n",
      "                                                                 subtract_10[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_11 (Concatenate)    (None, 144, 750)     0           concatenate_6[0][0]              \n",
      "                                                                 concatenate_7[0][0]              \n",
      "                                                                 concatenate_8[0][0]              \n",
      "                                                                 concatenate_9[0][0]              \n",
      "                                                                 concatenate_10[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_46 (Conv1D)              (None, 144, 720)     644400      concatenate_11[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout_2 (Dropout)             (None, 144, 720)     0           conv1d_46[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_47 (Conv1D)              (None, 144, 432)     373680      dropout_2[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_3 (Dropout)             (None, 144, 432)     0           conv1d_47[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling1d_1 (Glo (None, 432)          0           dropout_3[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_5 (Dense)                 (None, 12)           5196        global_average_pooling1d_1[0][0] \n",
      "==================================================================================================\n",
      "Total params: 1,432,365\n",
      "Trainable params: 1,432,365\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "num_features = Xe.shape[2]\n",
    "\n",
    "with tf.device('/gpu:0'):\n",
    "    alpha=1.0\n",
    "    gamma=1.2\n",
    "    beta = 1\n",
    "    hfilters = 256\n",
    "    hkernel_size1 = 1\n",
    "    hkernel_size2 = 2\n",
    "    visible1e = Input(shape=(timesteps, num_features))\n",
    "   \n",
    "    per1e = Permute((2,1))(visible1e)\n",
    "    den1ae = Dense(timesteps, activation='tanh')(per1e)\n",
    "    den1be = Dense(timesteps, activation='sigmoid')(per1e)\n",
    "    den1e = Multiply()([den1ae, den1be])\n",
    "    per2e = Permute((2,1), name='attention_vec')(den1e)\n",
    "    mul1e = Multiply()([visible1e, per2e])\n",
    "    \n",
    "    d1e = Conv1D(filters=round(hfilters*alpha), kernel_size=round(hkernel_size1*beta), padding='causal', dilation_rate=1)(mul1e)\n",
    "    d1ae = Activation(activations.tanh)(d1e)\n",
    "    d1be = Activation(activations.sigmoid)(d1e)\n",
    "    d1e = Multiply()([d1ae, d1be])\n",
    "    \n",
    "    d1e = Conv1D(filters=num_features, kernel_size=round(hkernel_size2*beta), padding='causal', dilation_rate=2)(d1e)\n",
    "    d1ae = Activation(activations.tanh)(d1e)\n",
    "    d1be = Activation(activations.sigmoid)(d1e)\n",
    "    d1e = Multiply()([d1ae, d1be])\n",
    "    \n",
    "    res01ae = Add()([visible1e, d1e])   # (100, 25) (100, 25)\n",
    "    res01be = Subtract()([visible1e, d1e])\n",
    "\n",
    "    d1e = Conv1D(filters=round(hfilters*alpha), kernel_size=round(hkernel_size1*beta), padding='causal', dilation_rate=2)(res01ae)\n",
    "    d1ae = Activation(activations.tanh)(d1e)\n",
    "    d1be = Activation(activations.sigmoid)(d1e)\n",
    "    d1e = Multiply()([d1ae, d1be])\n",
    "    \n",
    "    d1e = Conv1D(filters=num_features, kernel_size=round(hkernel_size2*beta), padding='causal', dilation_rate=4)(d1e)    \n",
    "    d1ae = Activation(activations.tanh)(d1e)\n",
    "    d1be = Activation(activations.sigmoid)(d1e)\n",
    "    \n",
    "    d1e = Multiply()([d1ae, d1be])\n",
    "    res02ae = Add()([res01ae, d1e])   # (100, 25) (100, 25)\n",
    "    \n",
    "    d2e = Conv1D(filters=round(hfilters*alpha), kernel_size=round(hkernel_size1*beta), padding='causal', dilation_rate=2)(res01be) \n",
    "    d2ae = Activation(activations.tanh)(d2e)\n",
    "    d2be = Activation(activations.sigmoid)(d2e)\n",
    "    d2e = Multiply()([d2ae, d2be])\n",
    "    \n",
    "    d2e = Conv1D(filters=num_features, kernel_size=round(hkernel_size2*beta), padding='causal', dilation_rate=4)(d2e) \n",
    "    d2ae = Activation(activations.tanh)(d2e)\n",
    "    d2be = Activation(activations.sigmoid)(d2e)\n",
    "    d2e = Multiply()([d2ae, d2be])\n",
    "    \n",
    "    res02be = Subtract()([res01be, d2e])   # (100, 25) (100, 25) \n",
    "    res02e = Concatenate()([res02ae, res02be, res01ae, res01be])\n",
    "    \n",
    "    d1e = Conv1D(filters=round(hfilters*alpha), kernel_size=round(hkernel_size1*beta), padding='causal', dilation_rate=4)(res02e)\n",
    "    d1ae = Activation(activations.tanh)(d1e)\n",
    "    d1be = Activation(activations.sigmoid)(d1e)\n",
    "    d1e = Multiply()([d1ae, d1be])\n",
    "    \n",
    "    d1e = Conv1D(filters=num_features, kernel_size=round(hkernel_size2*beta), padding='causal', dilation_rate=8)(d1e)    \n",
    "    d1ae = Activation(activations.tanh)(d1e)\n",
    "    d1be = Activation(activations.sigmoid)(d1e)\n",
    "    d1e = Multiply()([d1ae, d1be])\n",
    "    \n",
    "    res03ae = Add()([res02ae, d1e])   # (100, 25) (100, 25)\n",
    "    \n",
    "    d2e = Conv1D(filters=round(hfilters*alpha), kernel_size=round(hkernel_size1*beta), padding='causal', dilation_rate=4)(res02e) \n",
    "    d2ae = Activation(activations.tanh)(d2e)\n",
    "    d2be = Activation(activations.sigmoid)(d2e)\n",
    "    d2e = Multiply()([d2ae, d2be])\n",
    "    \n",
    "    d2e = Conv1D(filters=num_features, kernel_size=round(hkernel_size2*beta), padding='causal', dilation_rate=8)(d2e) \n",
    "    d2ae = Activation(activations.tanh)(d2e)\n",
    "    d2be = Activation(activations.sigmoid)(d2e)\n",
    "    d2e = Multiply()([d2ae, d2be])\n",
    "    \n",
    "    res03be = Subtract()([res02be, d2e])   # (100, 25) (100, 25)\n",
    "    res03e = Concatenate()([res03ae, res03be, res02e])\n",
    "    \n",
    "    d1e = Conv1D(filters=round(hfilters*alpha), kernel_size=round(hkernel_size1*beta), padding='causal', dilation_rate=8)(res03e)\n",
    "    d1ae = Activation(activations.tanh)(d1e)\n",
    "    d1be = Activation(activations.sigmoid)(d1e)\n",
    "    d1e = Multiply()([d1ae, d1be])\n",
    "    d1e = Conv1D(filters=num_features, kernel_size=round(hkernel_size2*beta), padding='causal', dilation_rate=4)(d1e)    \n",
    "    d1ae = Activation(activations.tanh)(d1e)\n",
    "    d1be = Activation(activations.sigmoid)(d1e)\n",
    "    d1e = Multiply()([d1ae, d1be])\n",
    "    res04ae = Add()([res03ae, d1e])   # (100, 25) (100, 25)\n",
    "    \n",
    "    d2e = Conv1D(filters=round(hfilters*alpha), kernel_size=round(hkernel_size1*beta), padding='causal', dilation_rate=8)(res03e) \n",
    "    d2ae = Activation(activations.tanh)(d2e)\n",
    "    d2be = Activation(activations.sigmoid)(d2e)\n",
    "    d2e = Multiply()([d2ae, d2be])\n",
    "    \n",
    "    d2e = Conv1D(filters=num_features, kernel_size=round(hkernel_size2*beta), padding='causal', dilation_rate=4)(d2e) \n",
    "    d2ae = Activation(activations.tanh)(d2e)\n",
    "    d2be = Activation(activations.sigmoid)(d2e)\n",
    "    d2e = Multiply()([d2ae, d2be])\n",
    "    \n",
    "    res04be = Subtract()([res02be, d2e])   # (100, 25) (100, 25)\n",
    "    res04e = Concatenate()([res04ae, res04be, res03e])\n",
    "    \n",
    "    d1e = Conv1D(filters=round(hfilters*alpha), kernel_size=round(hkernel_size1*beta), padding='causal', dilation_rate=4)(res04e)\n",
    "    d1ae = Activation(activations.tanh)(d1e)\n",
    "    d1be = Activation(activations.sigmoid)(d1e)\n",
    "    d1e = Multiply()([d1ae, d1be])\n",
    "    \n",
    "    d1e = Conv1D(filters=num_features, kernel_size=round(hkernel_size2*beta), padding='causal', dilation_rate=2)(d1e)    \n",
    "    d1ae = Activation(activations.tanh)(d1e)\n",
    "    d1be = Activation(activations.sigmoid)(d1e)\n",
    "    d1e = Multiply()([d1ae, d1be])\n",
    "    \n",
    "    res05ae = Add()([res04ae, d1e])   # (100, 25) (100, 25)\n",
    "    \n",
    "    d2e = Conv1D(filters=round(hfilters*alpha), kernel_size=round(hkernel_size1*beta), padding='causal', dilation_rate=4)(res04e) \n",
    "    d2ae = Activation(activations.tanh)(d2e)\n",
    "    d2be = Activation(activations.sigmoid)(d2e)\n",
    "    d2e = Multiply()([d2ae, d2be])\n",
    "    \n",
    "    d2e = Conv1D(filters=num_features, kernel_size=round(hkernel_size2*beta), padding='causal', dilation_rate=2)(d2e) \n",
    "    d2ae = Activation(activations.tanh)(d2e)\n",
    "    d2be = Activation(activations.sigmoid)(d2e)\n",
    "    d2e = Multiply()([d2ae, d2be])\n",
    "    \n",
    "    res05be = Subtract()([res04be, d2e])   # (100, 25) (100, 25)\n",
    "    res05e = Concatenate()([res05ae, res05be, res04e])\n",
    "    \n",
    "    d1e = Conv1D(filters=round(hfilters*alpha), kernel_size=round(hkernel_size1*beta), padding='causal', dilation_rate=2)(res05e)\n",
    "    d1ae = Activation(activations.tanh)(d1e)\n",
    "    d1be = Activation(activations.sigmoid)(d1e)\n",
    "    d1e = Multiply()([d1ae, d1be])\n",
    "    \n",
    "    d1e = Conv1D(filters=num_features, kernel_size=round(hkernel_size2*beta), padding='causal', dilation_rate=1)(d1e)    \n",
    "    d1ae = Activation(activations.tanh)(d1e)\n",
    "    d1be = Activation(activations.sigmoid)(d1e)\n",
    "    d1e = Multiply()([d1ae, d1be])\n",
    "\n",
    "    res06ae = Add()([res05ae, d1e])   # (100, 25) (100, 25)\n",
    "    \n",
    "    d2e = Conv1D(filters=round(hfilters*alpha), kernel_size=round(hkernel_size1*beta), padding='causal', dilation_rate=2)(res05e) \n",
    "    d2ae = Activation(activations.tanh)(d2e)\n",
    "    d2be = Activation(activations.sigmoid)(d2e)\n",
    "    d2e = Multiply()([d2ae, d2be])\n",
    "    d2e = Conv1D(filters=num_features, kernel_size=round(hkernel_size2*beta), padding='causal', dilation_rate=1)(d2e) \n",
    "    d2ae = Activation(activations.tanh)(d2e)\n",
    "    d2be = Activation(activations.sigmoid)(d2e)\n",
    "    d2e = Multiply()([d2ae, d2be])\n",
    "\n",
    "    res06be = Subtract()([res05be, d2e])   # (100, 25) (100, 25)\n",
    "    res06e = Concatenate()([res05ae, res05be])\n",
    "    \n",
    "    res10e = Concatenate()([res02e, res03e, res04e, res05e, res06e])   # \n",
    "    \n",
    "    #print('res10 :', res10.shape)  # (None, 24, 11) \n",
    "    \n",
    "    oute = Conv1D(timesteps*5, 1, padding='same', activation=PReLU())(res10e)   # 256, 11X10=110\n",
    "    oute = Dropout(0.2)(oute)   #SpatialDropout1D\n",
    "    \n",
    "    oute = Conv1D(timesteps*3, 1, padding='same', activation=PReLU())(oute) # 512,  110X5=550\n",
    "    oute = Dropout(0.2)(oute)\n",
    "    \n",
    "    oute = GlobalAveragePooling1D()(oute) # pool_size=2, strides=1\n",
    "    \n",
    "    oute = Dense(output_timesteps)(oute) \n",
    "    modele = Model(inputs=[visible1e], outputs=[oute])\n",
    "    \n",
    "    print(modele.summary())\n",
    "    \n",
    "    modele.compile(loss=mse_mae, optimizer='adam', metrics=['mse','mae','mape'])\n",
    "    early_stopping =EarlyStopping(monitor='val_loss', patience=10)\n",
    "    batch_size = b_size\n",
    "    epochs = 1000\n",
    "\n",
    "    history_e = LossHistory()\n",
    "    history_e.init()\n",
    "    \n",
    "    #hist = model.fit(trX, trY, epochs=epochs, batch_size=batch_size, shuffle=False, validation_data=(vaX, vaY), callbacks=[history, early_stopping])  # , checkpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "b4885b1a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2538"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "4c79697a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "1824/1824 [==============================] - 55s 28ms/step - loss: 0.0622 - mse: 0.0029 - mae: 0.0330 - mape: 679.8691 - val_loss: 0.0363 - val_mse: 0.0011 - val_mae: 0.0250 - val_mape: 455.3880\n",
      "Epoch 2/1000\n",
      "1824/1824 [==============================] - 48s 26ms/step - loss: 0.0358 - mse: 0.0011 - mae: 0.0246 - mape: 536.4160 - val_loss: 0.0327 - val_mse: 9.6005e-04 - val_mae: 0.0231 - val_mape: 477.6962\n",
      "Epoch 3/1000\n",
      "1824/1824 [==============================] - 47s 26ms/step - loss: 0.0326 - mse: 9.7106e-04 - mae: 0.0229 - mape: 532.4348 - val_loss: 0.0326 - val_mse: 9.4491e-04 - val_mae: 0.0231 - val_mape: 529.5105\n",
      "Epoch 4/1000\n",
      "1824/1824 [==============================] - 47s 26ms/step - loss: 0.0314 - mse: 9.2052e-04 - mae: 0.0222 - mape: 539.1929 - val_loss: 0.0312 - val_mse: 8.9987e-04 - val_mae: 0.0222 - val_mape: 457.1164\n",
      "Epoch 5/1000\n",
      "1824/1824 [==============================] - 48s 26ms/step - loss: 0.0309 - mse: 9.0293e-04 - mae: 0.0219 - mape: 519.5220 - val_loss: 0.0302 - val_mse: 8.6491e-04 - val_mae: 0.0216 - val_mape: 414.4358\n",
      "Epoch 6/1000\n",
      "1824/1824 [==============================] - 47s 26ms/step - loss: 0.0304 - mse: 8.8206e-04 - mae: 0.0216 - mape: 515.0184 - val_loss: 0.0294 - val_mse: 8.3028e-04 - val_mae: 0.0211 - val_mape: 386.2183\n",
      "Epoch 7/1000\n",
      "1824/1824 [==============================] - 48s 26ms/step - loss: 0.0301 - mse: 8.6752e-04 - mae: 0.0215 - mape: 509.1142 - val_loss: 0.0300 - val_mse: 8.4855e-04 - val_mae: 0.0215 - val_mape: 466.2199\n",
      "Epoch 8/1000\n",
      "1824/1824 [==============================] - 50s 27ms/step - loss: 0.0299 - mse: 8.5781e-04 - mae: 0.0213 - mape: 541.8439 - val_loss: 0.0302 - val_mse: 8.5994e-04 - val_mae: 0.0216 - val_mape: 445.7414\n",
      "Epoch 9/1000\n",
      "1824/1824 [==============================] - 49s 27ms/step - loss: 0.0296 - mse: 8.4792e-04 - mae: 0.0212 - mape: 575.7422 - val_loss: 0.0307 - val_mse: 8.7201e-04 - val_mae: 0.0220 - val_mape: 496.5149\n",
      "Epoch 10/1000\n",
      "1824/1824 [==============================] - 50s 27ms/step - loss: 0.0296 - mse: 8.4427e-04 - mae: 0.0211 - mape: 506.1407 - val_loss: 0.0299 - val_mse: 8.5539e-04 - val_mae: 0.0214 - val_mape: 416.3697\n",
      "Epoch 11/1000\n",
      "1824/1824 [==============================] - 50s 27ms/step - loss: 0.0294 - mse: 8.3817e-04 - mae: 0.0211 - mape: 577.0338 - val_loss: 0.0296 - val_mse: 8.3294e-04 - val_mae: 0.0213 - val_mape: 452.6660\n",
      "Epoch 12/1000\n",
      "1824/1824 [==============================] - 50s 27ms/step - loss: 0.0292 - mse: 8.2724e-04 - mae: 0.0209 - mape: 543.2188 - val_loss: 0.0293 - val_mse: 8.2776e-04 - val_mae: 0.0210 - val_mape: 424.3808\n",
      "Epoch 13/1000\n",
      "1824/1824 [==============================] - 50s 27ms/step - loss: 0.0290 - mse: 8.2085e-04 - mae: 0.0208 - mape: 518.5638 - val_loss: 0.0302 - val_mse: 8.4547e-04 - val_mae: 0.0217 - val_mape: 471.3214\n",
      "Epoch 14/1000\n",
      "1824/1824 [==============================] - 49s 27ms/step - loss: 0.0290 - mse: 8.1615e-04 - mae: 0.0208 - mape: 553.1795 - val_loss: 0.0287 - val_mse: 7.9421e-04 - val_mae: 0.0207 - val_mape: 394.3535\n",
      "Epoch 15/1000\n",
      "1824/1824 [==============================] - 49s 27ms/step - loss: 0.0291 - mse: 8.2409e-04 - mae: 0.0209 - mape: 577.8618 - val_loss: 0.0298 - val_mse: 8.6458e-04 - val_mae: 0.0212 - val_mape: 364.9166\n",
      "Epoch 16/1000\n",
      "1824/1824 [==============================] - 51s 28ms/step - loss: 0.0285 - mse: 7.9556e-04 - mae: 0.0206 - mape: 607.4236 - val_loss: 0.0298 - val_mse: 8.4069e-04 - val_mae: 0.0214 - val_mape: 446.8688\n",
      "Epoch 17/1000\n",
      "1824/1824 [==============================] - 50s 27ms/step - loss: 0.0286 - mse: 7.9832e-04 - mae: 0.0206 - mape: 511.9744 - val_loss: 0.0300 - val_mse: 8.5169e-04 - val_mae: 0.0215 - val_mape: 476.5862\n",
      "Epoch 18/1000\n",
      "1824/1824 [==============================] - 49s 27ms/step - loss: 0.0284 - mse: 7.8751e-04 - mae: 0.0205 - mape: 487.8600 - val_loss: 0.0310 - val_mse: 8.9787e-04 - val_mae: 0.0220 - val_mape: 473.2468\n",
      "Epoch 19/1000\n",
      "1824/1824 [==============================] - 49s 27ms/step - loss: 0.0284 - mse: 7.8763e-04 - mae: 0.0206 - mape: 689.0886 - val_loss: 0.0297 - val_mse: 8.5088e-04 - val_mae: 0.0212 - val_mape: 401.9720\n",
      "Epoch 20/1000\n",
      "1824/1824 [==============================] - 47s 26ms/step - loss: 0.0283 - mse: 7.8268e-04 - mae: 0.0205 - mape: 527.2764 - val_loss: 0.0296 - val_mse: 8.3776e-04 - val_mae: 0.0212 - val_mape: 408.0779\n",
      "Epoch 21/1000\n",
      "1824/1824 [==============================] - 47s 26ms/step - loss: 0.0278 - mse: 7.5900e-04 - mae: 0.0202 - mape: 564.3731 - val_loss: 0.0301 - val_mse: 8.6409e-04 - val_mae: 0.0215 - val_mape: 434.2450\n",
      "Epoch 22/1000\n",
      "1824/1824 [==============================] - 49s 27ms/step - loss: 0.0282 - mse: 7.7734e-04 - mae: 0.0205 - mape: 515.9884 - val_loss: 0.0306 - val_mse: 8.7678e-04 - val_mae: 0.0218 - val_mape: 422.6503\n",
      "Epoch 23/1000\n",
      "1824/1824 [==============================] - 49s 27ms/step - loss: 0.0277 - mse: 7.5533e-04 - mae: 0.0202 - mape: 458.6296 - val_loss: 0.0310 - val_mse: 9.1810e-04 - val_mae: 0.0218 - val_mape: 372.6163\n",
      "Epoch 24/1000\n",
      "1824/1824 [==============================] - 50s 27ms/step - loss: 0.0277 - mse: 7.5486e-04 - mae: 0.0202 - mape: 392.4347 - val_loss: 0.0305 - val_mse: 8.7542e-04 - val_mae: 0.0217 - val_mape: 434.5084\n"
     ]
    }
   ],
   "source": [
    "# %%time\n",
    "    histe = modele.fit(trXe, trYe, epochs=epochs, batch_size=b_size, shuffle=False, validation_data=(vaXe, vaYe), callbacks=[history_e, early_stopping])  # , checkpoint"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3aed0382",
   "metadata": {},
   "source": [
    "### Saving FFEL Model Training Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "a8507129",
   "metadata": {},
   "outputs": [],
   "source": [
    "eloss_history = histe.history['loss']\n",
    "valeloss_history = histe.history['val_loss']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "b26f3d55",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4601"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "5bed470f",
   "metadata": {},
   "outputs": [],
   "source": [
    "modele.save('Error Learning Model_fh12.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6035c816",
   "metadata": {},
   "source": [
    "## FFEL Model Test Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "9efd2202",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainePredict = modele.predict(Xe, batch_size=batch_size)\n",
    "etePredict = modele.predict(eteX, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "55b56fe3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error Training Score > MSE ==  0.0007828482439679945  MAE ==  0.02059833721616899  RMSE ==  0.02797942536879545\n"
     ]
    }
   ],
   "source": [
    "trePredict = trainePredict.reshape([-1])\n",
    "trainYe = Ye.reshape([-1])\n",
    "\n",
    "print('Error Training Score > MSE == ', (np.mean(np.square(trainYe-trePredict))), ' MAE == ', mean_absolute_error(trainYe,trePredict), ' RMSE == ', np.sqrt(np.mean(np.square(trainYe-trePredict))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "19a26013",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error Training Score > MSE ==  0.017314227089429878  MAE ==  0.09909625429604708  RMSE ==  0.13158353654401403\n"
     ]
    }
   ],
   "source": [
    "etestPredict = etePredict.reshape([-1])\n",
    "testYe = eteY.reshape([-1])\n",
    "\n",
    "print('Error Training Score > MSE == ', (np.mean(np.square(testYe-etestPredict))), ' MAE == ', mean_absolute_error(testYe,etestPredict), ' RMSE == ', np.sqrt(np.mean(np.square(testYe-etestPredict))))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b477db4f",
   "metadata": {},
   "source": [
    "## Final Prediction Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "39090e4a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3345, 12)\n"
     ]
    }
   ],
   "source": [
    "testPredict = tePredict.reshape(-1,12)\n",
    "addtestPredict = -etePredict + testPredict[timesteps:-2,:]\n",
    "print(addtestPredict.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "1804b555",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error Test Score > MSE ==  0.02747686284489561  MAE ==  0.13036319878180488 MAPE ==  76.09992725038967\n",
      "Error Test Score > MSE ==  0.01731422709714043  MAE ==  0.09909625430676622 MAPE ==  39.93736930065974\n"
     ]
    }
   ],
   "source": [
    "print('Error Test Score > MSE == ', (np.mean(np.square(teY[timesteps:-2,:]-testPredict[timesteps:-2,:]))), ' MAE == ', mean_absolute_error(teY[timesteps:-2,:], testPredict[timesteps:-2,:]), 'MAPE == ', mean_absolute_percentage_error(teY[timesteps:-2,:], testPredict[timesteps:-2,:]))\n",
    "print('Error Test Score > MSE == ', (np.mean(np.square(teY[timesteps:-2,:]-addtestPredict))), ' MAE == ', mean_absolute_error(teY[timesteps:-2,:], addtestPredict), 'MAPE == ', mean_absolute_percentage_error(teY[timesteps:-2,:], addtestPredict))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
