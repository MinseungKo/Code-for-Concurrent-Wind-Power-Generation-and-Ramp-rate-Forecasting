{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0b08637d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "import pandas as pd\n",
    "import codecs\n",
    "import numpy as np\n",
    "import math\n",
    "import csv\n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.metrics import recall_score, precision_score # New\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn import preprocessing\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow.keras.preprocessing\n",
    "#from tensorflow.keras.callbacks import ModelCheckpoint, CSVLogger, EarlyStopping, LearningRateScheduler, ReduceLROnPlateau\n",
    "from tensorflow.keras.models import Sequential, Model\n",
    "from tensorflow.keras.layers import Dense, Input, Flatten, Add, Multiply, Subtract\n",
    "from tensorflow.keras import backend as K\n",
    "from tensorflow.keras.layers import Activation, BatchNormalization\n",
    "# regularizers\n",
    "from tensorflow.keras.layers import Conv1D, Conv2D\n",
    "from tensorflow.keras.layers import MaxPooling1D\n",
    "from tensorflow.keras.layers import concatenate\n",
    "from tensorflow.keras.layers import LSTM, Bidirectional\n",
    "from tensorflow.keras.utils import plot_model\n",
    "from tensorflow.keras.layers import Dropout, SpatialDropout1D\n",
    "from scipy import signal\n",
    "import openpyxl\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "from matplotlib import pylab as plt\n",
    "import matplotlib.dates as mdates\n",
    "import seaborn as sns\n",
    "import sklearn\n",
    "from sklearn.model_selection import train_test_split\n",
    "from numpy.linalg import svd\n",
    "import gc\n",
    "from keijzer import *\n",
    "from tensorflow import keras\n",
    "from keras.models import Model\n",
    "from keras.layers import *\n",
    "from tensorflow.keras.optimizers import Adam,SGD\n",
    "from keras.layers import Dense, Input, Flatten, Add, concatenate, Dropout, Activation, Multiply, Embedding, Layer, Reshape\n",
    "from keras.layers import LSTM, Bidirectional, GlobalMaxPooling1D, GlobalAveragePooling1D  \n",
    "from keras.layers import Conv1D, AveragePooling1D, MaxPooling1D\n",
    "#from keras.ops import convert_to_tensor, convert_to_numpy\n",
    "#from keras.utils import plot_model\n",
    "from keras import activations\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from keras.callbacks import ModelCheckpoint, CSVLogger, EarlyStopping, LearningRateScheduler, ReduceLROnPlateau\n",
    "import math\n",
    "\n",
    "class LossHistory(tensorflow.keras.callbacks.Callback):  # history = LossHistory()\n",
    "    def init(self):  # history.init()\n",
    "        self.losses = []\n",
    "        # self.accs = []\n",
    "        self.val_losses = []\n",
    "        # self.val_accs = []\n",
    "        self.rmses = []\n",
    "        self.mses = []\n",
    "        self.maes = []\n",
    "        self.mapes = []\n",
    "        self.val_rmses = []\n",
    "        self.val_mses = []\n",
    "        self.val_maes = []\n",
    "        self.val_mapes = []\n",
    "\n",
    "    def on_epoch_end(self, batch, logs={}):\n",
    "        self.losses.append(logs.get('loss'))\n",
    "        # self.accs.append(logs.get('acc'))\n",
    "        self.val_losses.append(logs.get('val_loss'))\n",
    "        # self.val_accs.append(logs.get('val_accuracy\n",
    "        self.rmses.append(logs.get('root_mean_squared_error'))\n",
    "        self.mses.append(logs.get('mean_squared_error'))\n",
    "        self.maes.append(logs.get('mean_absolute_error'))\n",
    "        self.mapes.append(logs.get('mean_absolute_percentage_error'))\n",
    "        self.val_rmses.append(logs.get('val_root_mean_squared_error'))\n",
    "        self.val_mses.append(logs.get('val_mean_squared_error'))\n",
    "        self.val_maes.append(logs.get('val_mean_absolute_error'))\n",
    "        self.val_mapes.append(logs.get('val_mean_absolute_percentage_error'))\n",
    "\n",
    "\n",
    "\n",
    "def root_squared_mean_error(y_true, y_pred):\n",
    "    return K.mean((K.abs(y_pred - y_true))*K.square(y_true-K.mean(y_true)))*100\n",
    "\n",
    "def mse_mae(y_true, y_pred):\n",
    "    return K.mean(K.square(y_pred - y_true))+K.mean(K.abs(y_pred - y_true))\n",
    "\n",
    "from keras.layers.advanced_activations import PReLU\n",
    "\n",
    "def mean_absolute_percentage_error(y_true, y_pred):\n",
    "    y_true, y_pred = np.array(y_true), np.array(y_pred)\n",
    "    return np.mean(np.abs((y_true - y_pred) / y_true)) * 100\n",
    "\n",
    "def root_mean_squared_error(y_true, y_pred):\n",
    "        return K.sqrt(K.mean(K.square(y_pred - y_true))) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e4a18491",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = '0' # 여러개 사용시 '0,1,2' 식으로 하나의 문자열에 입력\n",
    "gpus = tf.config.experimental.list_physical_devices('GPU') # 호스트 러나임에 표시되는 GPU 장치 목록 반환\n",
    "\n",
    "if gpus: # 반환된 GPU 장치 목록이 있다면\n",
    "    try: # 해당 장치에 대한 메모리 증가 활성화 여부 설정\n",
    "        tf.config.experimental.set_memory_growth(gpus[0], True)\n",
    "    except RuntimeError as e: # try문 실패시에 에러문구 출력\n",
    "        print(e)\n",
    "\n",
    "print(tf.config.list_physical_devices('GPU'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4a914ff",
   "metadata": {},
   "source": [
    "## Import Data & Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "91cac1eb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Time-Date stamp</th>\n",
       "      <th>Date</th>\n",
       "      <th>ERCOT Load</th>\n",
       "      <th>Total Wind Output</th>\n",
       "      <th>Total Wind Installed</th>\n",
       "      <th>Wind Output, % of Load</th>\n",
       "      <th>Wind Output, % of Installed</th>\n",
       "      <th>1-hr MW change</th>\n",
       "      <th>1-hr % change</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>01-01-2020 00:00:00</td>\n",
       "      <td>Jan-01</td>\n",
       "      <td>36823</td>\n",
       "      <td>12335</td>\n",
       "      <td>27040</td>\n",
       "      <td>33.5</td>\n",
       "      <td>45.617</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>01-01-2020 01:00:00</td>\n",
       "      <td>Jan-01</td>\n",
       "      <td>36511</td>\n",
       "      <td>13300</td>\n",
       "      <td>27040</td>\n",
       "      <td>36.4</td>\n",
       "      <td>49.187</td>\n",
       "      <td>965.4</td>\n",
       "      <td>7.826</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>01-01-2020 02:00:00</td>\n",
       "      <td>Jan-01</td>\n",
       "      <td>36022</td>\n",
       "      <td>13586</td>\n",
       "      <td>27040</td>\n",
       "      <td>37.7</td>\n",
       "      <td>50.245</td>\n",
       "      <td>286.2</td>\n",
       "      <td>2.152</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>01-01-2020 03:00:00</td>\n",
       "      <td>Jan-01</td>\n",
       "      <td>35790</td>\n",
       "      <td>14107</td>\n",
       "      <td>27040</td>\n",
       "      <td>39.4</td>\n",
       "      <td>52.171</td>\n",
       "      <td>520.9</td>\n",
       "      <td>3.834</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>01-01-2020 04:00:00</td>\n",
       "      <td>Jan-01</td>\n",
       "      <td>35642</td>\n",
       "      <td>14887</td>\n",
       "      <td>27040</td>\n",
       "      <td>41.8</td>\n",
       "      <td>55.055</td>\n",
       "      <td>779.6</td>\n",
       "      <td>5.527</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35060</th>\n",
       "      <td>12-31-2023 20:00:00</td>\n",
       "      <td>Dec-31</td>\n",
       "      <td>44887</td>\n",
       "      <td>17161</td>\n",
       "      <td>38631</td>\n",
       "      <td>38.23</td>\n",
       "      <td>44.42</td>\n",
       "      <td>2858</td>\n",
       "      <td>19.99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35061</th>\n",
       "      <td>12-31-2023 21:00:00</td>\n",
       "      <td>Dec-31</td>\n",
       "      <td>44013</td>\n",
       "      <td>18301</td>\n",
       "      <td>38631</td>\n",
       "      <td>41.58</td>\n",
       "      <td>47.37</td>\n",
       "      <td>1139</td>\n",
       "      <td>6.64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35062</th>\n",
       "      <td>12-31-2023 22:00:00</td>\n",
       "      <td>Dec-31</td>\n",
       "      <td>43280</td>\n",
       "      <td>18607</td>\n",
       "      <td>38631</td>\n",
       "      <td>42.99</td>\n",
       "      <td>48.17</td>\n",
       "      <td>307</td>\n",
       "      <td>1.67</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35063</th>\n",
       "      <td>12-31-2023 23:00:00</td>\n",
       "      <td>Dec-31</td>\n",
       "      <td>42319</td>\n",
       "      <td>17866</td>\n",
       "      <td>38631</td>\n",
       "      <td>42.22</td>\n",
       "      <td>46.25</td>\n",
       "      <td>-741</td>\n",
       "      <td>-3.98</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35064</th>\n",
       "      <td>01-01-2024 00:00:00</td>\n",
       "      <td>Jan-01</td>\n",
       "      <td>41682</td>\n",
       "      <td>15869</td>\n",
       "      <td>38631</td>\n",
       "      <td>38.07</td>\n",
       "      <td>41.08</td>\n",
       "      <td>-1996</td>\n",
       "      <td>-11.17</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>35065 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           Time-Date stamp    Date ERCOT Load Total Wind Output  \\\n",
       "0      01-01-2020 00:00:00  Jan-01      36823             12335   \n",
       "1      01-01-2020 01:00:00  Jan-01      36511             13300   \n",
       "2      01-01-2020 02:00:00  Jan-01      36022             13586   \n",
       "3      01-01-2020 03:00:00  Jan-01      35790             14107   \n",
       "4      01-01-2020 04:00:00  Jan-01      35642             14887   \n",
       "...                    ...     ...        ...               ...   \n",
       "35060  12-31-2023 20:00:00  Dec-31      44887             17161   \n",
       "35061  12-31-2023 21:00:00  Dec-31      44013             18301   \n",
       "35062  12-31-2023 22:00:00  Dec-31      43280             18607   \n",
       "35063  12-31-2023 23:00:00  Dec-31      42319             17866   \n",
       "35064  01-01-2024 00:00:00  Jan-01      41682             15869   \n",
       "\n",
       "      Total Wind Installed Wind Output, % of Load Wind Output, % of Installed  \\\n",
       "0                    27040                   33.5                      45.617   \n",
       "1                    27040                   36.4                      49.187   \n",
       "2                    27040                   37.7                      50.245   \n",
       "3                    27040                   39.4                      52.171   \n",
       "4                    27040                   41.8                      55.055   \n",
       "...                    ...                    ...                         ...   \n",
       "35060                38631                  38.23                       44.42   \n",
       "35061                38631                  41.58                       47.37   \n",
       "35062                38631                  42.99                       48.17   \n",
       "35063                38631                  42.22                       46.25   \n",
       "35064                38631                  38.07                       41.08   \n",
       "\n",
       "      1-hr MW change 1-hr % change  \n",
       "0                NaN           NaN  \n",
       "1              965.4         7.826  \n",
       "2              286.2         2.152  \n",
       "3              520.9         3.834  \n",
       "4              779.6         5.527  \n",
       "...              ...           ...  \n",
       "35060           2858         19.99  \n",
       "35061           1139          6.64  \n",
       "35062            307          1.67  \n",
       "35063           -741         -3.98  \n",
       "35064          -1996        -11.17  \n",
       "\n",
       "[35065 rows x 9 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_path = 'C:/Users/smartgrid_AI/Desktop/windpower_ramprate/ercot_2020.csv'\n",
    "data_source1 = pd.read_csv(data_path)\n",
    "dat_source1 = pd.DataFrame(data_source1)\n",
    "#dat_source1 = dat_source1.iloc[:-3,:]\n",
    "\n",
    "data_path = 'C:/Users/smartgrid_AI/Desktop/windpower_ramprate/ercot_2021.csv'\n",
    "data_source2 = pd.read_csv(data_path)\n",
    "dat_source2 = pd.DataFrame(data_source2)\n",
    "dat_source2 = dat_source2.iloc[:8761,:9]\n",
    "\n",
    "data_path = 'C:/Users/smartgrid_AI/Desktop/windpower_ramprate/ercot_2022.csv'\n",
    "data_source3 = pd.read_csv(data_path)\n",
    "dat_source3 = pd.DataFrame(data_source3)\n",
    "dat_source3 = dat_source3.iloc[:8760,:9]\n",
    "\n",
    "data_path = 'C:/Users/smartgrid_AI/Desktop/windpower_ramprate/ercot_2023.csv'\n",
    "data_source4 = pd.read_csv(data_path)\n",
    "dat_source4 = pd.DataFrame(data_source4)\n",
    "dat_source4 = dat_source4.iloc[:8760,:9]\n",
    "\n",
    "dat_arr1 = np.array(dat_source1)\n",
    "dat_arr2 = np.array(dat_source2)\n",
    "dat_arr3 = np.array(dat_source3)\n",
    "dat_arr4 = np.array(dat_source4)\n",
    "\n",
    "dat_arr = np.concatenate([dat_arr1, dat_arr2, dat_arr3, dat_arr4],axis=0)\n",
    "dat_arr.shape # 8784, 8761, 8760, 8760\n",
    "\n",
    "dat_source = pd.DataFrame(dat_arr, columns=['Time-Date stamp','Date','ERCOT Load','Total Wind Output','Total Wind Installed','Wind Output, % of Load','Wind Output, % of Installed','1-hr MW change','1-hr % change'])\n",
    "dat_source"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55fef21f",
   "metadata": {},
   "source": [
    "### Dividing by Installed Capacity & Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b472240b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MW % change</th>\n",
       "      <th>Total Wind Output</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3.56879</td>\n",
       "      <td>0.491864</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.05769</td>\n",
       "      <td>0.502441</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.92678</td>\n",
       "      <td>0.521709</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2.88462</td>\n",
       "      <td>0.550555</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.580621</td>\n",
       "      <td>0.544749</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35059</th>\n",
       "      <td>7.3982</td>\n",
       "      <td>0.444229</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35060</th>\n",
       "      <td>2.951</td>\n",
       "      <td>0.473739</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35061</th>\n",
       "      <td>0.79211</td>\n",
       "      <td>0.48166</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35062</th>\n",
       "      <td>-1.91815</td>\n",
       "      <td>0.462478</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35063</th>\n",
       "      <td>-5.16942</td>\n",
       "      <td>0.410784</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>35064 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      MW % change Total Wind Output\n",
       "0         3.56879          0.491864\n",
       "1         1.05769          0.502441\n",
       "2         1.92678          0.521709\n",
       "3         2.88462          0.550555\n",
       "4       -0.580621          0.544749\n",
       "...           ...               ...\n",
       "35059      7.3982          0.444229\n",
       "35060       2.951          0.473739\n",
       "35061     0.79211           0.48166\n",
       "35062    -1.91815          0.462478\n",
       "35063    -5.16942          0.410784\n",
       "\n",
       "[35064 rows x 2 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dat = pd.DataFrame()\n",
    "dat['MW % change'] = np.array(dat_source.iloc[1:,3], dtype=float)-np.array(dat_source.iloc[0:-1,3], dtype=float)\n",
    "dat['MW % change'] = np.divide(np.array(dat['MW % change']),np.array(dat_source.iloc[1:,4]))*100\n",
    "dat['Total Wind Output'] = np.divide(np.array(dat_source.iloc[1:,3]), np.array(dat_source.iloc[1:,4]))\n",
    "\n",
    "dat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1a1763dc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Year</th>\n",
       "      <th>MW % change</th>\n",
       "      <th>Total Wind Output</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2020</td>\n",
       "      <td>3.56879</td>\n",
       "      <td>0.491864</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2020</td>\n",
       "      <td>1.05769</td>\n",
       "      <td>0.502441</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2020</td>\n",
       "      <td>1.92678</td>\n",
       "      <td>0.521709</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2020</td>\n",
       "      <td>2.88462</td>\n",
       "      <td>0.550555</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2020</td>\n",
       "      <td>-0.580621</td>\n",
       "      <td>0.544749</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35059</th>\n",
       "      <td>2023</td>\n",
       "      <td>7.3982</td>\n",
       "      <td>0.444229</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35060</th>\n",
       "      <td>2023</td>\n",
       "      <td>2.951</td>\n",
       "      <td>0.473739</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35061</th>\n",
       "      <td>2023</td>\n",
       "      <td>0.79211</td>\n",
       "      <td>0.48166</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35062</th>\n",
       "      <td>2023</td>\n",
       "      <td>-1.91815</td>\n",
       "      <td>0.462478</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35063</th>\n",
       "      <td>2023</td>\n",
       "      <td>-5.16942</td>\n",
       "      <td>0.410784</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>35064 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Year MW % change Total Wind Output\n",
       "0      2020     3.56879          0.491864\n",
       "1      2020     1.05769          0.502441\n",
       "2      2020     1.92678          0.521709\n",
       "3      2020     2.88462          0.550555\n",
       "4      2020   -0.580621          0.544749\n",
       "...     ...         ...               ...\n",
       "35059  2023      7.3982          0.444229\n",
       "35060  2023       2.951          0.473739\n",
       "35061  2023     0.79211           0.48166\n",
       "35062  2023    -1.91815          0.462478\n",
       "35063  2023    -5.16942          0.410784\n",
       "\n",
       "[35064 rows x 3 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ramp_ratio = 20\n",
    "load_ratio = 10\n",
    "year_arr = np.concatenate([np.ones(8784)*2020, np.ones(8760)*2021, np.ones(8760)*2022, np.ones(8760)*2023])\n",
    "year_df = pd.DataFrame(year_arr, columns=['Year'], dtype=int)\n",
    "wind_df = pd.concat([year_df, dat], axis=1)\n",
    "wind_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "14321087",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Year</th>\n",
       "      <th>MW % change</th>\n",
       "      <th>Total Wind Output</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2020</td>\n",
       "      <td>0.620197</td>\n",
       "      <td>0.644724</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2020</td>\n",
       "      <td>0.544580</td>\n",
       "      <td>0.658617</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2020</td>\n",
       "      <td>0.570751</td>\n",
       "      <td>0.683924</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2020</td>\n",
       "      <td>0.599594</td>\n",
       "      <td>0.721813</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2020</td>\n",
       "      <td>0.495246</td>\n",
       "      <td>0.714187</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35058</th>\n",
       "      <td>2023</td>\n",
       "      <td>0.774643</td>\n",
       "      <td>0.484984</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35059</th>\n",
       "      <td>2023</td>\n",
       "      <td>0.735512</td>\n",
       "      <td>0.582157</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35060</th>\n",
       "      <td>2023</td>\n",
       "      <td>0.601593</td>\n",
       "      <td>0.620917</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35061</th>\n",
       "      <td>2023</td>\n",
       "      <td>0.536583</td>\n",
       "      <td>0.631322</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35062</th>\n",
       "      <td>2023</td>\n",
       "      <td>0.454969</td>\n",
       "      <td>0.606127</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>35063 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Year  MW % change  Total Wind Output\n",
       "0      2020     0.620197           0.644724\n",
       "1      2020     0.544580           0.658617\n",
       "2      2020     0.570751           0.683924\n",
       "3      2020     0.599594           0.721813\n",
       "4      2020     0.495246           0.714187\n",
       "...     ...          ...                ...\n",
       "35058  2023     0.774643           0.484984\n",
       "35059  2023     0.735512           0.582157\n",
       "35060  2023     0.601593           0.620917\n",
       "35061  2023     0.536583           0.631322\n",
       "35062  2023     0.454969           0.606127\n",
       "\n",
       "[35063 rows x 3 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wind_df = wind_df.reset_index(drop=True)\n",
    "std_scaler = sklearn.preprocessing.MinMaxScaler()\n",
    "std_scaler_load = sklearn.preprocessing.MinMaxScaler()\n",
    "std_scaler_ramp = sklearn.preprocessing.MinMaxScaler()\n",
    "\n",
    "wind_df[['Total Wind Output']] = std_scaler.fit_transform(wind_df[['Total Wind Output']])\n",
    "wind_df[['MW % change']] = std_scaler_ramp.fit_transform(wind_df[['MW % change']])\n",
    "#wind_df[['Wind Change, % of Load', 'Wind Change']] = std_scaler_ramp.fit_transform(wind_df[['Wind Change, % of Load', 'Wind Change']])\n",
    "wind_df = wind_df.iloc[:-1,:]\n",
    "wind_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1b304073",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Year</th>\n",
       "      <th>Wind Change</th>\n",
       "      <th>Wind Output</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2020</td>\n",
       "      <td>0.620197</td>\n",
       "      <td>0.644724</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2020</td>\n",
       "      <td>0.544580</td>\n",
       "      <td>0.658617</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2020</td>\n",
       "      <td>0.570751</td>\n",
       "      <td>0.683924</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2020</td>\n",
       "      <td>0.599594</td>\n",
       "      <td>0.721813</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2020</td>\n",
       "      <td>0.495246</td>\n",
       "      <td>0.714187</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35058</th>\n",
       "      <td>2023</td>\n",
       "      <td>0.774643</td>\n",
       "      <td>0.484984</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35059</th>\n",
       "      <td>2023</td>\n",
       "      <td>0.735512</td>\n",
       "      <td>0.582157</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35060</th>\n",
       "      <td>2023</td>\n",
       "      <td>0.601593</td>\n",
       "      <td>0.620917</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35061</th>\n",
       "      <td>2023</td>\n",
       "      <td>0.536583</td>\n",
       "      <td>0.631322</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35062</th>\n",
       "      <td>2023</td>\n",
       "      <td>0.454969</td>\n",
       "      <td>0.606127</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>35063 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Year  Wind Change  Wind Output\n",
       "0      2020     0.620197     0.644724\n",
       "1      2020     0.544580     0.658617\n",
       "2      2020     0.570751     0.683924\n",
       "3      2020     0.599594     0.721813\n",
       "4      2020     0.495246     0.714187\n",
       "...     ...          ...          ...\n",
       "35058  2023     0.774643     0.484984\n",
       "35059  2023     0.735512     0.582157\n",
       "35060  2023     0.601593     0.620917\n",
       "35061  2023     0.536583     0.631322\n",
       "35062  2023     0.454969     0.606127\n",
       "\n",
       "[35063 rows x 3 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ramp_df = pd.DataFrame(wind_df)\n",
    "ramp_df.columns=['Year', 'Wind Change', 'Wind Output']\n",
    "ramp_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba9597a4",
   "metadata": {},
   "source": [
    "## Wind Ramp Rate Forecasting"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ef85afa",
   "metadata": {},
   "source": [
    "### SVD-based Feature Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1201d8c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from numpy.linalg import svd\n",
    "import gc\n",
    "\n",
    "def create_dataset(dataset, timesteps, output_timesteps, leadtime):\n",
    "    dataX, dataY = [], []\n",
    "    for i in range(len(dataset) - timesteps -output_timesteps - leadtime - 1):\n",
    "        a = dataset[i:(i + timesteps), :]\n",
    "        dataX.append(a)\n",
    "        dataY.append(dataset[(i + timesteps + leadtime):(i+timesteps+output_timesteps+leadtime), :])\n",
    "    return np.array(dataX), np.array(dataY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "833f7b2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "norm_df = np.array(wind_df['Wind Change']).reshape(-1,1)\n",
    "timesteps = 24*4\n",
    "output_timesteps = 6\n",
    "num_features = 1\n",
    "leadtime = 3\n",
    "X, Y = create_dataset(norm_df, timesteps, output_timesteps, leadtime)\n",
    "b_size = timesteps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b6658e69",
   "metadata": {},
   "outputs": [],
   "source": [
    "dec_num = timesteps\n",
    "high_ind = 35\n",
    "\n",
    "addX = np.zeros((X.shape[0], dec_num, high_ind+1))\n",
    "\n",
    "def svdadd(X, start, end, b_size):\n",
    "    dec_x = X[start:end, :, :]\n",
    "    U, S, Vh = svd(dec_x.reshape(b_size, -1))\n",
    "\n",
    "    high_sig = np.matmul(np.matmul(U[:,:high_ind], np.diag(S[0:high_ind])), Vh[:high_ind,:])\n",
    "    low_sig = X[:dec_num, :, :].reshape(b_size,-1)-high_sig\n",
    "\n",
    "    rec_x = np.zeros((b_size, b_size, high_ind))\n",
    "    #print(sum(S[0:high_ind])/sum(S))\n",
    "    for i in range(high_ind):\n",
    "        rec_x[:,:,i] = np.matmul((U[:,i]*S[i]).reshape(-1,1), Vh[i,:].reshape(1,-1))    \n",
    "    return rec_x, low_sig\n",
    "\n",
    "for k in range(X.shape[0]//dec_num):\n",
    "    rec_x, low_sig = svdadd(X, k*dec_num, (k+1)*dec_num, b_size)\n",
    "    addX[k*dec_num:k*dec_num+dec_num,:, :-1] = rec_x\n",
    "    addX[k*dec_num:k*dec_num+dec_num,:, -1] = low_sig\n",
    "    \n",
    "rec_x, low_sig = svdadd(X, X.shape[0]-dec_num, X.shape[0], b_size)\n",
    "addX[X.shape[0]-dec_num:X.shape[0], :, :-1] = rec_x\n",
    "addX[X.shape[0]-dec_num:X.shape[0],:, -1] = low_sig\n",
    "\n",
    "addX_det = addX[:, :, :-1]\n",
    "addX_det = np.sum(addX_det, axis=2)\n",
    "X = np.concatenate([X, addX], axis=2)\n",
    "num_features = X.shape[2]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84a5a7ec",
   "metadata": {},
   "source": [
    "### Training/Test Set Division & Shuffled Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "87a919aa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((31461, 96, 37), (31461, 6), (3496, 96, 37), (3496, 6))"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trvaX, teX, trvaY, teY = train_test_split(X, Y, test_size=0.1, shuffle=False)\n",
    "\n",
    "idx = np.arange(trvaX.shape[0])\n",
    "np.random.shuffle(idx)\n",
    "strvaX = trvaX[idx]\n",
    "strvaY = trvaY[idx]\n",
    "strvaY = strvaY.reshape(-1, output_timesteps)\n",
    "\n",
    "trvaY = trvaY.reshape(-1, output_timesteps)\n",
    "teY = teY.reshape(-1, output_timesteps)\n",
    "\n",
    "strX, svaX, strY, svaY = train_test_split(strvaX, strvaY, test_size=0.3, shuffle=False)\n",
    "trX, vaX, trY, vaY = train_test_split(trvaX, trvaY, test_size=0.3, shuffle=False)\n",
    "\n",
    "trvaX.shape, trvaY.shape, teX.shape, teY.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8339f317",
   "metadata": {},
   "source": [
    "## Wind Ramp Rate Forecasting Basic Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1032632d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def MAEMD(y_true, y_pred):\n",
    "    return K.mean((K.abs(y_pred - y_true))*K.square(y_true-K.mean(y_true)))*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "cb0cb111",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers.advanced_activations import PReLU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f8c9f62b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            [(None, 96, 37)]     0                                            \n",
      "__________________________________________________________________________________________________\n",
      "permute (Permute)               (None, 37, 96)       0           input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_2 (Dense)                 (None, 96, 37)       1406        input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_3 (Dense)                 (None, 96, 37)       1406        input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, 37, 96)       9312        permute[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 37, 96)       9312        permute[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "multiply_2 (Multiply)           (None, 96, 37)       0           dense_2[0][0]                    \n",
      "                                                                 dense_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "multiply (Multiply)             (None, 37, 96)       0           dense[0][0]                      \n",
      "                                                                 dense_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "permute_1 (Permute)             (None, 37, 96)       0           input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "attention_vec2 (Permute)        (None, 37, 96)       0           multiply_2[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "attention_vec (Permute)         (None, 96, 37)       0           multiply[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "multiply_3 (Multiply)           (None, 37, 96)       0           permute_1[0][0]                  \n",
      "                                                                 attention_vec2[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "multiply_1 (Multiply)           (None, 96, 37)       0           input_1[0][0]                    \n",
      "                                                                 attention_vec[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_10 (Conv1D)              (None, 37, 168)      16296       multiply_3[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv1d (Conv1D)                 (None, 96, 168)      6384        multiply_1[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_20 (Activation)      (None, 37, 168)      0           conv1d_10[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_21 (Activation)      (None, 37, 168)      0           conv1d_10[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation (Activation)         (None, 96, 168)      0           conv1d[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "activation_1 (Activation)       (None, 96, 168)      0           conv1d[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "multiply_14 (Multiply)          (None, 37, 168)      0           activation_20[0][0]              \n",
      "                                                                 activation_21[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "multiply_4 (Multiply)           (None, 96, 168)      0           activation[0][0]                 \n",
      "                                                                 activation_1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_11 (Conv1D)              (None, 37, 96)       32352       multiply_14[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_1 (Conv1D)               (None, 96, 37)       12469       multiply_4[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_22 (Activation)      (None, 37, 96)       0           conv1d_11[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_23 (Activation)      (None, 37, 96)       0           conv1d_11[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_2 (Activation)       (None, 96, 37)       0           conv1d_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_3 (Activation)       (None, 96, 37)       0           conv1d_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "multiply_15 (Multiply)          (None, 37, 96)       0           activation_22[0][0]              \n",
      "                                                                 activation_23[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "multiply_5 (Multiply)           (None, 96, 37)       0           activation_2[0][0]               \n",
      "                                                                 activation_3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "add_3 (Add)                     (None, 37, 96)       0           multiply_3[0][0]                 \n",
      "                                                                 multiply_15[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "subtract_3 (Subtract)           (None, 37, 96)       0           multiply_3[0][0]                 \n",
      "                                                                 multiply_15[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "add (Add)                       (None, 96, 37)       0           multiply_1[0][0]                 \n",
      "                                                                 multiply_5[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "subtract (Subtract)             (None, 96, 37)       0           multiply_1[0][0]                 \n",
      "                                                                 multiply_5[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_12 (Conv1D)              (None, 37, 168)      16296       add_3[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_14 (Conv1D)              (None, 37, 168)      16296       subtract_3[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_2 (Conv1D)               (None, 96, 168)      6384        add[0][0]                        \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_4 (Conv1D)               (None, 96, 168)      6384        subtract[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_24 (Activation)      (None, 37, 168)      0           conv1d_12[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_25 (Activation)      (None, 37, 168)      0           conv1d_12[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_28 (Activation)      (None, 37, 168)      0           conv1d_14[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_29 (Activation)      (None, 37, 168)      0           conv1d_14[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_4 (Activation)       (None, 96, 168)      0           conv1d_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_5 (Activation)       (None, 96, 168)      0           conv1d_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_8 (Activation)       (None, 96, 168)      0           conv1d_4[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_9 (Activation)       (None, 96, 168)      0           conv1d_4[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "multiply_16 (Multiply)          (None, 37, 168)      0           activation_24[0][0]              \n",
      "                                                                 activation_25[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "multiply_18 (Multiply)          (None, 37, 168)      0           activation_28[0][0]              \n",
      "                                                                 activation_29[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "multiply_6 (Multiply)           (None, 96, 168)      0           activation_4[0][0]               \n",
      "                                                                 activation_5[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "multiply_8 (Multiply)           (None, 96, 168)      0           activation_8[0][0]               \n",
      "                                                                 activation_9[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_13 (Conv1D)              (None, 37, 96)       32352       multiply_16[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_15 (Conv1D)              (None, 37, 96)       32352       multiply_18[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_3 (Conv1D)               (None, 96, 37)       12469       multiply_6[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_5 (Conv1D)               (None, 96, 37)       12469       multiply_8[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_26 (Activation)      (None, 37, 96)       0           conv1d_13[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_27 (Activation)      (None, 37, 96)       0           conv1d_13[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_30 (Activation)      (None, 37, 96)       0           conv1d_15[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_31 (Activation)      (None, 37, 96)       0           conv1d_15[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_6 (Activation)       (None, 96, 37)       0           conv1d_3[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_7 (Activation)       (None, 96, 37)       0           conv1d_3[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_10 (Activation)      (None, 96, 37)       0           conv1d_5[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_11 (Activation)      (None, 96, 37)       0           conv1d_5[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "multiply_17 (Multiply)          (None, 37, 96)       0           activation_26[0][0]              \n",
      "                                                                 activation_27[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "multiply_19 (Multiply)          (None, 37, 96)       0           activation_30[0][0]              \n",
      "                                                                 activation_31[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "multiply_7 (Multiply)           (None, 96, 37)       0           activation_6[0][0]               \n",
      "                                                                 activation_7[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "multiply_9 (Multiply)           (None, 96, 37)       0           activation_10[0][0]              \n",
      "                                                                 activation_11[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "add_4 (Add)                     (None, 37, 96)       0           add_3[0][0]                      \n",
      "                                                                 multiply_17[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "subtract_4 (Subtract)           (None, 37, 96)       0           subtract_3[0][0]                 \n",
      "                                                                 multiply_19[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "add_1 (Add)                     (None, 96, 37)       0           add[0][0]                        \n",
      "                                                                 multiply_7[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "subtract_1 (Subtract)           (None, 96, 37)       0           subtract[0][0]                   \n",
      "                                                                 multiply_9[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_2 (Concatenate)     (None, 37, 384)      0           add_4[0][0]                      \n",
      "                                                                 subtract_4[0][0]                 \n",
      "                                                                 add_3[0][0]                      \n",
      "                                                                 subtract_3[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "concatenate (Concatenate)       (None, 96, 148)      0           add_1[0][0]                      \n",
      "                                                                 subtract_1[0][0]                 \n",
      "                                                                 add[0][0]                        \n",
      "                                                                 subtract[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_16 (Conv1D)              (None, 37, 168)      64680       concatenate_2[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_18 (Conv1D)              (None, 37, 168)      64680       concatenate_2[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_6 (Conv1D)               (None, 96, 168)      25032       concatenate[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_8 (Conv1D)               (None, 96, 168)      25032       concatenate[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "activation_32 (Activation)      (None, 37, 168)      0           conv1d_16[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_33 (Activation)      (None, 37, 168)      0           conv1d_16[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_36 (Activation)      (None, 37, 168)      0           conv1d_18[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_37 (Activation)      (None, 37, 168)      0           conv1d_18[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_12 (Activation)      (None, 96, 168)      0           conv1d_6[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_13 (Activation)      (None, 96, 168)      0           conv1d_6[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_16 (Activation)      (None, 96, 168)      0           conv1d_8[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_17 (Activation)      (None, 96, 168)      0           conv1d_8[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "multiply_20 (Multiply)          (None, 37, 168)      0           activation_32[0][0]              \n",
      "                                                                 activation_33[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "multiply_22 (Multiply)          (None, 37, 168)      0           activation_36[0][0]              \n",
      "                                                                 activation_37[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "multiply_10 (Multiply)          (None, 96, 168)      0           activation_12[0][0]              \n",
      "                                                                 activation_13[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "multiply_12 (Multiply)          (None, 96, 168)      0           activation_16[0][0]              \n",
      "                                                                 activation_17[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_17 (Conv1D)              (None, 37, 96)       32352       multiply_20[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_19 (Conv1D)              (None, 37, 96)       32352       multiply_22[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_7 (Conv1D)               (None, 96, 37)       12469       multiply_10[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_9 (Conv1D)               (None, 96, 37)       12469       multiply_12[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "activation_34 (Activation)      (None, 37, 96)       0           conv1d_17[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_35 (Activation)      (None, 37, 96)       0           conv1d_17[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_38 (Activation)      (None, 37, 96)       0           conv1d_19[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_39 (Activation)      (None, 37, 96)       0           conv1d_19[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_14 (Activation)      (None, 96, 37)       0           conv1d_7[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_15 (Activation)      (None, 96, 37)       0           conv1d_7[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_18 (Activation)      (None, 96, 37)       0           conv1d_9[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_19 (Activation)      (None, 96, 37)       0           conv1d_9[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "multiply_21 (Multiply)          (None, 37, 96)       0           activation_34[0][0]              \n",
      "                                                                 activation_35[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "multiply_23 (Multiply)          (None, 37, 96)       0           activation_38[0][0]              \n",
      "                                                                 activation_39[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "multiply_11 (Multiply)          (None, 96, 37)       0           activation_14[0][0]              \n",
      "                                                                 activation_15[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "multiply_13 (Multiply)          (None, 96, 37)       0           activation_18[0][0]              \n",
      "                                                                 activation_19[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "add_5 (Add)                     (None, 37, 96)       0           add_4[0][0]                      \n",
      "                                                                 multiply_21[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "subtract_5 (Subtract)           (None, 37, 96)       0           subtract_4[0][0]                 \n",
      "                                                                 multiply_23[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "add_2 (Add)                     (None, 96, 37)       0           add_1[0][0]                      \n",
      "                                                                 multiply_11[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "subtract_2 (Subtract)           (None, 96, 37)       0           subtract_1[0][0]                 \n",
      "                                                                 multiply_13[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_3 (Concatenate)     (None, 37, 576)      0           add_5[0][0]                      \n",
      "                                                                 subtract_5[0][0]                 \n",
      "                                                                 concatenate_2[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, 96, 222)      0           add_2[0][0]                      \n",
      "                                                                 subtract_2[0][0]                 \n",
      "                                                                 concatenate[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_20 (Conv1D)              (None, 37, 168)      103152      concatenate_3[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_21 (Conv1D)              (None, 96, 168)      53592       concatenate_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout (Dropout)               (None, 37, 168)      0           conv1d_20[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)             (None, 96, 168)      0           conv1d_21[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_4 (Concatenate)     (None, 133, 168)     0           dropout[0][0]                    \n",
      "                                                                 dropout_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_22 (Conv1D)              (None, 133, 168)     50736       concatenate_4[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_2 (Dropout)             (None, 133, 168)     0           conv1d_22[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling1d (Globa (None, 168)          0           dropout_2[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_4 (Dense)                 (None, 6)            1014        global_average_pooling1d[0][0]   \n",
      "==================================================================================================\n",
      "Total params: 701,499\n",
      "Trainable params: 701,499\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "from keras import regularizers\n",
    "\n",
    "num_features = trvaX.shape[2]\n",
    "output_timesteps = trvaY.shape[1]\n",
    "\n",
    "with tf.device('/gpu:0'):\n",
    "    alpha=1.0\n",
    "    gamma=1\n",
    "    beta = 1\n",
    "    hfilters = 168\n",
    "    hkernel_size1 = 1\n",
    "    hkernel_size2 = 2\n",
    "    visible1 = Input(shape=(timesteps, num_features))\n",
    "   \n",
    "    ## Attention Block\n",
    "    pera = Permute((2,1))(visible1)\n",
    "    den1a = Dense(timesteps, activation='tanh')(pera)\n",
    "    den1b = Dense(timesteps, activation='sigmoid')(pera)\n",
    "    den1 = Multiply()([den1a, den1b])\n",
    "    per2 = Permute((2,1), name='attention_vec')(den1)\n",
    "    mul1 = Multiply()([visible1, per2])   \n",
    "    \n",
    "    ## Permuted Attention Block\n",
    "    per1 = Permute((2,1))(visible1)\n",
    "    den2a = Dense(num_features, activation='tanh')(visible1)\n",
    "    den2b = Dense(num_features, activation='sigmoid')(visible1)\n",
    "    den2 = Multiply()([den2a, den2b])\n",
    "    perb2 = Permute((2,1), name='attention_vec2')(den2)\n",
    "    \n",
    "    mul2 = Multiply()([per1, perb2])     \n",
    "    \n",
    "    ## Parallel DCCNN Blocks 1-1 ~ 3-1\n",
    "    d1 = Conv1D(filters=round(hfilters*alpha), kernel_size=round(hkernel_size1*beta), padding='causal', dilation_rate=1)(mul1)\n",
    "    d1a = Activation(activations.tanh)(d1)\n",
    "    d1b = Activation(activations.sigmoid)(d1)\n",
    "    d1 = Multiply()([d1a, d1b])\n",
    "    \n",
    "    d1 = Conv1D(filters=num_features, kernel_size=round(hkernel_size2*beta), padding='causal', dilation_rate=2)(d1)\n",
    "    d1a = Activation(activations.tanh)(d1)\n",
    "    d1b = Activation(activations.sigmoid)(d1)\n",
    "    d1 = Multiply()([d1a, d1b])\n",
    "    \n",
    "    rres01a = Add()([mul1, d1])   # (100, 25) (100, 25)\n",
    "    rres01b = Subtract()([mul1, d1])\n",
    "    \n",
    "    d1 = Conv1D(filters=round(hfilters*alpha), kernel_size=round(hkernel_size1*beta), padding='causal', dilation_rate=2)(rres01a)\n",
    "    d1a = Activation(activations.tanh)(d1)\n",
    "    d1b = Activation(activations.sigmoid)(d1)\n",
    "    d1 = Multiply()([d1a, d1b])\n",
    "    \n",
    "    d1 = Conv1D(filters=num_features, kernel_size=round(hkernel_size2*beta), padding='causal', dilation_rate=4)(d1)    \n",
    "    d1a = Activation(activations.tanh)(d1)\n",
    "    d1b = Activation(activations.sigmoid)(d1)\n",
    "    \n",
    "    d1 = Multiply()([d1a, d1b])\n",
    "    rres02a = Add()([rres01a, d1])   # (100, 25) (100, 25)\n",
    "    \n",
    "    d2 = Conv1D(filters=round(hfilters*alpha), kernel_size=round(hkernel_size1*beta), padding='causal', dilation_rate=2)(rres01b) \n",
    "    d2a = Activation(activations.tanh)(d2)\n",
    "    d2b = Activation(activations.sigmoid)(d2)\n",
    "    d2 = Multiply()([d2a, d2b])\n",
    "    \n",
    "    d2 = Conv1D(filters=num_features, kernel_size=round(hkernel_size2*beta), padding='causal', dilation_rate=4)(d2) \n",
    "    d2a = Activation(activations.tanh)(d2)\n",
    "    d2b = Activation(activations.sigmoid)(d2)\n",
    "    d2 = Multiply()([d2a, d2b])\n",
    "    \n",
    "    rres02b = Subtract()([rres01b, d2])   # (100, 25) (100, 25) \n",
    "    rres02 = Concatenate()([rres02a, rres02b, rres01a, rres01b])\n",
    "    #rres02 = Dropout(0.2)(rres02)\n",
    "    \n",
    "    d1 = Conv1D(filters=round(hfilters*alpha), kernel_size=round(hkernel_size1*beta), padding='causal', dilation_rate=4)(rres02)\n",
    "    d1a = Activation(activations.tanh)(d1)\n",
    "    d1b = Activation(activations.sigmoid)(d1)\n",
    "    d1 = Multiply()([d1a, d1b])\n",
    "    \n",
    "    d1 = Conv1D(filters=num_features, kernel_size=round(hkernel_size2*beta), padding='causal', dilation_rate=2)(d1)    \n",
    "    d1a = Activation(activations.tanh)(d1)\n",
    "    d1b = Activation(activations.sigmoid)(d1)\n",
    "    d1 = Multiply()([d1a, d1b])\n",
    "    \n",
    "    rres03a = Add()([rres02a, d1])   # (100, 25) (100, 25)\n",
    "    \n",
    "    d2 = Conv1D(filters=round(hfilters*alpha), kernel_size=round(hkernel_size1*beta), padding='causal', dilation_rate=4)(rres02) \n",
    "    d2a = Activation(activations.tanh)(d2)\n",
    "    d2b = Activation(activations.sigmoid)(d2)\n",
    "    d2 = Multiply()([d2a, d2b])\n",
    "    \n",
    "    d2 = Conv1D(filters=num_features, kernel_size=round(hkernel_size2*beta), padding='causal', dilation_rate=2)(d2) \n",
    "    d2a = Activation(activations.tanh)(d2)\n",
    "    d2b = Activation(activations.sigmoid)(d2)\n",
    "    d2 = Multiply()([d2a, d2b])\n",
    "    rres03b = Subtract()([rres02b, d2])\n",
    "    rres10 = Concatenate()([rres03a, rres03b, rres02])\n",
    "\n",
    "    ## Right-half DCCNN Blocks 1-2 ~ 3-2\n",
    "    d1 = Conv1D(filters=round(hfilters*alpha), kernel_size=round(hkernel_size1*beta), padding='causal', dilation_rate=1)(mul2)\n",
    "    d1a = Activation(activations.tanh)(d1)\n",
    "    d1b = Activation(activations.sigmoid)(d1)\n",
    "    d1 = Multiply()([d1a, d1b])\n",
    "    \n",
    "    d1 = Conv1D(filters=timesteps, kernel_size=round(hkernel_size2*beta), padding='causal', dilation_rate=2)(d1)\n",
    "    d1a = Activation(activations.tanh)(d1)\n",
    "    d1b = Activation(activations.sigmoid)(d1)\n",
    "    d1 = Multiply()([d1a, d1b])\n",
    "    \n",
    "    res01a = Add()([mul2, d1])   # (100, 25) (100, 25)\n",
    "    res01b = Subtract()([mul2, d1])\n",
    "    \n",
    "    \n",
    "    d1 = Conv1D(filters=round(hfilters*alpha), kernel_size=round(hkernel_size1*beta), padding='causal', dilation_rate=2)(res01a)\n",
    "    d1a = Activation(activations.tanh)(d1)\n",
    "    d1b = Activation(activations.sigmoid)(d1)\n",
    "    d1 = Multiply()([d1a, d1b])\n",
    "    \n",
    "    d1 = Conv1D(filters=timesteps, kernel_size=round(hkernel_size2*beta), padding='causal', dilation_rate=4)(d1)    \n",
    "    d1a = Activation(activations.tanh)(d1)\n",
    "    d1b = Activation(activations.sigmoid)(d1)\n",
    "    \n",
    "    d1 = Multiply()([d1a, d1b])\n",
    "    res02a = Add()([res01a, d1])   # (100, 25) (100, 25)\n",
    "    \n",
    "    d2 = Conv1D(filters=round(hfilters*alpha), kernel_size=round(hkernel_size1*beta), padding='causal', dilation_rate=2)(res01b) \n",
    "    d2a = Activation(activations.tanh)(d2)\n",
    "    d2b = Activation(activations.sigmoid)(d2)\n",
    "    d2 = Multiply()([d2a, d2b])\n",
    "    \n",
    "    d2 = Conv1D(filters=timesteps, kernel_size=round(hkernel_size2*beta), padding='causal', dilation_rate=4)(d2) \n",
    "    d2a = Activation(activations.tanh)(d2)\n",
    "    d2b = Activation(activations.sigmoid)(d2)\n",
    "    d2 = Multiply()([d2a, d2b])\n",
    "    \n",
    "    res02b = Subtract()([res01b, d2])   # (100, 25) (100, 25) \n",
    "    res02 = Concatenate()([res02a, res02b, res01a, res01b])\n",
    "    #res02 = Dropout(0.2)(res02)\n",
    "    \n",
    "    d1 = Conv1D(filters=round(hfilters*alpha), kernel_size=round(hkernel_size1*beta), padding='causal', dilation_rate=4)(res02)\n",
    "    d1a = Activation(activations.tanh)(d1)\n",
    "    d1b = Activation(activations.sigmoid)(d1)\n",
    "    d1 = Multiply()([d1a, d1b])\n",
    "    \n",
    "    d1 = Conv1D(filters=timesteps, kernel_size=round(hkernel_size2*beta), padding='causal', dilation_rate=2)(d1)    \n",
    "    d1a = Activation(activations.tanh)(d1)\n",
    "    d1b = Activation(activations.sigmoid)(d1)\n",
    "    d1 = Multiply()([d1a, d1b])\n",
    "    \n",
    "    res03a = Add()([res02a, d1])   # (100, 25) (100, 25)\n",
    "    \n",
    "    d2 = Conv1D(filters=round(hfilters*alpha), kernel_size=round(hkernel_size1*beta), padding='causal', dilation_rate=4)(res02) \n",
    "    d2a = Activation(activations.tanh)(d2)\n",
    "    d2b = Activation(activations.sigmoid)(d2)\n",
    "    d2 = Multiply()([d2a, d2b])\n",
    "    \n",
    "    d2 = Conv1D(filters=timesteps, kernel_size=round(hkernel_size2*beta), padding='causal', dilation_rate=2)(d2) \n",
    "    d2a = Activation(activations.tanh)(d2)\n",
    "    d2b = Activation(activations.sigmoid)(d2)\n",
    "    d2 = Multiply()([d2a, d2b])\n",
    "    \n",
    "    res03b = Subtract()([res02b, d2])\n",
    "    res10 = Concatenate()([res03a, res03b, res02])\n",
    "\n",
    "    ## Output Blocks\n",
    "    out1 = Conv1D(24*7, 1, padding='same', activation=PReLU())(res10)   # 256, 11X10=110\n",
    "    out1 = Dropout(0.2)(out1)  \n",
    "    \n",
    "    out2 = Conv1D(24*7, 1, padding='same', activation=PReLU())(rres10)   # 256, 11X10=110\n",
    "    out2 = Dropout(0.2)(out2)\n",
    "    \n",
    "    out = Concatenate(axis=1)([out1, out2])\n",
    "    \n",
    "    ## Output Block\n",
    "    out = Conv1D(24*7, 1, padding='same', activation=PReLU())(out) # 512,  110X5=550\n",
    "    out = Dropout(0.2)(out)\n",
    "\n",
    "    #, kernel_regularizer=regularizers.L1L2(l1=1e-5, l2=1e-4)\n",
    "    out = GlobalAveragePooling1D()(out) \n",
    "\n",
    "    out = Dense(output_timesteps)(out) \n",
    "    model = Model(inputs=[visible1], outputs=[out])\n",
    "    \n",
    "    print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "77b31354",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1969"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "29a65760",
   "metadata": {},
   "outputs": [],
   "source": [
    "    model.compile(loss=MAEMD, optimizer='adam', metrics=['mse','mae', MAEMD])\n",
    "    early_stopping =EarlyStopping(monitor='val_loss', patience=50)\n",
    "    batch_size = timesteps\n",
    "    epochs = 1000\n",
    "    #root_squared_mean_error\n",
    "    history = LossHistory()\n",
    "    history.init()\n",
    "    \n",
    "    #hist = model.fit(trX, trY, epochs=epochs, batch_size=batch_size, shuffle=False, validation_data=(vaX, vaY), callbacks=[history, early_stopping])  # , checkpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "618beecd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "230/230 [==============================] - 30s 113ms/step - loss: 0.1804 - mse: 0.0210 - mae: 0.1076 - MAEMD: 0.1805 - val_loss: 0.1488 - val_mse: 0.0169 - val_mae: 0.1020 - val_MAEMD: 0.1491\n",
      "Epoch 2/1000\n",
      "230/230 [==============================] - 20s 89ms/step - loss: 0.1429 - mse: 0.0156 - mae: 0.0986 - MAEMD: 0.1431 - val_loss: 0.1363 - val_mse: 0.0152 - val_mae: 0.0969 - val_MAEMD: 0.1366\n",
      "Epoch 3/1000\n",
      "230/230 [==============================] - 27s 116ms/step - loss: 0.1326 - mse: 0.0155 - mae: 0.0987 - MAEMD: 0.1327 - val_loss: 0.1308 - val_mse: 0.0161 - val_mae: 0.1000 - val_MAEMD: 0.1309\n",
      "Epoch 4/1000\n",
      "230/230 [==============================] - 23s 99ms/step - loss: 0.1269 - mse: 0.0157 - mae: 0.0995 - MAEMD: 0.1269 - val_loss: 0.1265 - val_mse: 0.0163 - val_mae: 0.1012 - val_MAEMD: 0.1266\n",
      "Epoch 5/1000\n",
      "230/230 [==============================] - 24s 105ms/step - loss: 0.1226 - mse: 0.0153 - mae: 0.0980 - MAEMD: 0.1226 - val_loss: 0.1240 - val_mse: 0.0155 - val_mae: 0.0985 - val_MAEMD: 0.1241\n",
      "Epoch 6/1000\n",
      "230/230 [==============================] - 24s 103ms/step - loss: 0.1199 - mse: 0.0150 - mae: 0.0969 - MAEMD: 0.1200 - val_loss: 0.1220 - val_mse: 0.0153 - val_mae: 0.0977 - val_MAEMD: 0.1221\n",
      "Epoch 7/1000\n",
      "230/230 [==============================] - 24s 103ms/step - loss: 0.1169 - mse: 0.0147 - mae: 0.0961 - MAEMD: 0.1170 - val_loss: 0.1206 - val_mse: 0.0159 - val_mae: 0.1003 - val_MAEMD: 0.1207\n",
      "Epoch 8/1000\n",
      "230/230 [==============================] - 23s 102ms/step - loss: 0.1147 - mse: 0.0145 - mae: 0.0955 - MAEMD: 0.1147 - val_loss: 0.1201 - val_mse: 0.0152 - val_mae: 0.0974 - val_MAEMD: 0.1202\n",
      "Epoch 9/1000\n",
      "230/230 [==============================] - 24s 105ms/step - loss: 0.1125 - mse: 0.0144 - mae: 0.0950 - MAEMD: 0.1125 - val_loss: 0.1192 - val_mse: 0.0154 - val_mae: 0.0985 - val_MAEMD: 0.1192\n",
      "Epoch 10/1000\n",
      "230/230 [==============================] - 24s 105ms/step - loss: 0.1112 - mse: 0.0144 - mae: 0.0949 - MAEMD: 0.1112 - val_loss: 0.1180 - val_mse: 0.0154 - val_mae: 0.0984 - val_MAEMD: 0.1181\n",
      "Epoch 11/1000\n",
      "230/230 [==============================] - 25s 107ms/step - loss: 0.1078 - mse: 0.0141 - mae: 0.0940 - MAEMD: 0.1078 - val_loss: 0.1180 - val_mse: 0.0148 - val_mae: 0.0960 - val_MAEMD: 0.1182\n",
      "Epoch 12/1000\n",
      "230/230 [==============================] - 23s 99ms/step - loss: 0.1059 - mse: 0.0141 - mae: 0.0938 - MAEMD: 0.1058 - val_loss: 0.1170 - val_mse: 0.0152 - val_mae: 0.0977 - val_MAEMD: 0.1171\n",
      "Epoch 13/1000\n",
      "230/230 [==============================] - 24s 104ms/step - loss: 0.1034 - mse: 0.0139 - mae: 0.0930 - MAEMD: 0.1034 - val_loss: 0.1168 - val_mse: 0.0154 - val_mae: 0.0986 - val_MAEMD: 0.1169\n",
      "Epoch 14/1000\n",
      "230/230 [==============================] - 24s 106ms/step - loss: 0.1016 - mse: 0.0137 - mae: 0.0925 - MAEMD: 0.1016 - val_loss: 0.1173 - val_mse: 0.0157 - val_mae: 0.0995 - val_MAEMD: 0.1174\n",
      "Epoch 15/1000\n",
      "230/230 [==============================] - 24s 105ms/step - loss: 0.1000 - mse: 0.0139 - mae: 0.0929 - MAEMD: 0.1000 - val_loss: 0.1168 - val_mse: 0.0153 - val_mae: 0.0979 - val_MAEMD: 0.1169\n",
      "Epoch 16/1000\n",
      "230/230 [==============================] - 23s 100ms/step - loss: 0.0983 - mse: 0.0139 - mae: 0.0930 - MAEMD: 0.0983 - val_loss: 0.1162 - val_mse: 0.0149 - val_mae: 0.0964 - val_MAEMD: 0.1162\n",
      "Epoch 17/1000\n",
      "230/230 [==============================] - 25s 108ms/step - loss: 0.0964 - mse: 0.0136 - mae: 0.0920 - MAEMD: 0.0963 - val_loss: 0.1169 - val_mse: 0.0150 - val_mae: 0.0970 - val_MAEMD: 0.1170\n",
      "Epoch 18/1000\n",
      "230/230 [==============================] - 23s 100ms/step - loss: 0.0950 - mse: 0.0136 - mae: 0.0920 - MAEMD: 0.0949 - val_loss: 0.1167 - val_mse: 0.0153 - val_mae: 0.0981 - val_MAEMD: 0.1168\n",
      "Epoch 19/1000\n",
      "230/230 [==============================] - 25s 108ms/step - loss: 0.0943 - mse: 0.0135 - mae: 0.0916 - MAEMD: 0.0943 - val_loss: 0.1170 - val_mse: 0.0151 - val_mae: 0.0974 - val_MAEMD: 0.1170\n",
      "Epoch 20/1000\n",
      "230/230 [==============================] - 23s 100ms/step - loss: 0.0938 - mse: 0.0137 - mae: 0.0924 - MAEMD: 0.0938 - val_loss: 0.1193 - val_mse: 0.0162 - val_mae: 0.1006 - val_MAEMD: 0.1193\n",
      "Epoch 21/1000\n",
      "230/230 [==============================] - 24s 105ms/step - loss: 0.0939 - mse: 0.0136 - mae: 0.0920 - MAEMD: 0.0938 - val_loss: 0.1186 - val_mse: 0.0162 - val_mae: 0.1010 - val_MAEMD: 0.1186\n",
      "Epoch 22/1000\n",
      "230/230 [==============================] - 24s 106ms/step - loss: 0.0923 - mse: 0.0136 - mae: 0.0920 - MAEMD: 0.0923 - val_loss: 0.1167 - val_mse: 0.0148 - val_mae: 0.0966 - val_MAEMD: 0.1168\n",
      "Epoch 23/1000\n",
      "230/230 [==============================] - 24s 103ms/step - loss: 0.0918 - mse: 0.0135 - mae: 0.0916 - MAEMD: 0.0918 - val_loss: 0.1163 - val_mse: 0.0149 - val_mae: 0.0970 - val_MAEMD: 0.1163\n",
      "Epoch 24/1000\n",
      "230/230 [==============================] - 23s 99ms/step - loss: 0.0901 - mse: 0.0133 - mae: 0.0907 - MAEMD: 0.0900 - val_loss: 0.1163 - val_mse: 0.0145 - val_mae: 0.0951 - val_MAEMD: 0.1164\n",
      "Epoch 25/1000\n",
      "230/230 [==============================] - 24s 103ms/step - loss: 0.0875 - mse: 0.0131 - mae: 0.0901 - MAEMD: 0.0874 - val_loss: 0.1165 - val_mse: 0.0147 - val_mae: 0.0962 - val_MAEMD: 0.1165\n",
      "Epoch 26/1000\n",
      "230/230 [==============================] - 24s 103ms/step - loss: 0.0861 - mse: 0.0130 - mae: 0.0895 - MAEMD: 0.0861 - val_loss: 0.1164 - val_mse: 0.0152 - val_mae: 0.0978 - val_MAEMD: 0.1164\n",
      "Epoch 27/1000\n",
      "230/230 [==============================] - 24s 103ms/step - loss: 0.0853 - mse: 0.0129 - mae: 0.0894 - MAEMD: 0.0853 - val_loss: 0.1161 - val_mse: 0.0154 - val_mae: 0.0986 - val_MAEMD: 0.1162\n",
      "Epoch 28/1000\n",
      "230/230 [==============================] - 23s 102ms/step - loss: 0.0838 - mse: 0.0128 - mae: 0.0889 - MAEMD: 0.0838 - val_loss: 0.1168 - val_mse: 0.0145 - val_mae: 0.0952 - val_MAEMD: 0.1168\n",
      "Epoch 29/1000\n",
      "230/230 [==============================] - 23s 100ms/step - loss: 0.0844 - mse: 0.0129 - mae: 0.0890 - MAEMD: 0.0844 - val_loss: 0.1155 - val_mse: 0.0141 - val_mae: 0.0942 - val_MAEMD: 0.1155\n",
      "Epoch 30/1000\n",
      "230/230 [==============================] - 24s 106ms/step - loss: 0.0839 - mse: 0.0129 - mae: 0.0891 - MAEMD: 0.0838 - val_loss: 0.1152 - val_mse: 0.0145 - val_mae: 0.0956 - val_MAEMD: 0.1153\n",
      "Epoch 31/1000\n",
      "230/230 [==============================] - 23s 100ms/step - loss: 0.0823 - mse: 0.0126 - mae: 0.0882 - MAEMD: 0.0823 - val_loss: 0.1178 - val_mse: 0.0149 - val_mae: 0.0969 - val_MAEMD: 0.1179\n",
      "Epoch 32/1000\n",
      "230/230 [==============================] - 24s 103ms/step - loss: 0.0828 - mse: 0.0128 - mae: 0.0888 - MAEMD: 0.0827 - val_loss: 0.1180 - val_mse: 0.0139 - val_mae: 0.0935 - val_MAEMD: 0.1181\n",
      "Epoch 33/1000\n",
      "230/230 [==============================] - 23s 99ms/step - loss: 0.0821 - mse: 0.0126 - mae: 0.0881 - MAEMD: 0.0821 - val_loss: 0.1203 - val_mse: 0.0157 - val_mae: 0.1000 - val_MAEMD: 0.1205\n",
      "Epoch 34/1000\n",
      "230/230 [==============================] - 24s 103ms/step - loss: 0.0816 - mse: 0.0125 - mae: 0.0879 - MAEMD: 0.0816 - val_loss: 0.1193 - val_mse: 0.0152 - val_mae: 0.0981 - val_MAEMD: 0.1194\n",
      "Epoch 35/1000\n",
      "230/230 [==============================] - 23s 102ms/step - loss: 0.0810 - mse: 0.0125 - mae: 0.0878 - MAEMD: 0.0810 - val_loss: 0.1162 - val_mse: 0.0144 - val_mae: 0.0952 - val_MAEMD: 0.1162\n",
      "Epoch 36/1000\n",
      "230/230 [==============================] - 24s 105ms/step - loss: 0.0806 - mse: 0.0123 - mae: 0.0870 - MAEMD: 0.0806 - val_loss: 0.1143 - val_mse: 0.0136 - val_mae: 0.0925 - val_MAEMD: 0.1144\n",
      "Epoch 37/1000\n",
      "230/230 [==============================] - 24s 104ms/step - loss: 0.0775 - mse: 0.0120 - mae: 0.0859 - MAEMD: 0.0774 - val_loss: 0.1137 - val_mse: 0.0137 - val_mae: 0.0928 - val_MAEMD: 0.1138\n",
      "Epoch 38/1000\n",
      "230/230 [==============================] - 23s 101ms/step - loss: 0.0758 - mse: 0.0117 - mae: 0.0848 - MAEMD: 0.0758 - val_loss: 0.1156 - val_mse: 0.0142 - val_mae: 0.0947 - val_MAEMD: 0.1157\n",
      "Epoch 39/1000\n",
      "230/230 [==============================] - 23s 101ms/step - loss: 0.0758 - mse: 0.0117 - mae: 0.0847 - MAEMD: 0.0758 - val_loss: 0.1133 - val_mse: 0.0134 - val_mae: 0.0914 - val_MAEMD: 0.1133\n",
      "Epoch 40/1000\n",
      "230/230 [==============================] - 22s 98ms/step - loss: 0.0744 - mse: 0.0117 - mae: 0.0845 - MAEMD: 0.0743 - val_loss: 0.1131 - val_mse: 0.0133 - val_mae: 0.0914 - val_MAEMD: 0.1132\n",
      "Epoch 41/1000\n",
      "230/230 [==============================] - 23s 101ms/step - loss: 0.0740 - mse: 0.0116 - mae: 0.0842 - MAEMD: 0.0740 - val_loss: 0.1119 - val_mse: 0.0132 - val_mae: 0.0907 - val_MAEMD: 0.1120\n",
      "Epoch 42/1000\n",
      "230/230 [==============================] - 24s 105ms/step - loss: 0.0729 - mse: 0.0114 - mae: 0.0834 - MAEMD: 0.0728 - val_loss: 0.1118 - val_mse: 0.0131 - val_mae: 0.0907 - val_MAEMD: 0.1119\n",
      "Epoch 43/1000\n",
      "230/230 [==============================] - 23s 100ms/step - loss: 0.0722 - mse: 0.0113 - mae: 0.0831 - MAEMD: 0.0721 - val_loss: 0.1110 - val_mse: 0.0136 - val_mae: 0.0923 - val_MAEMD: 0.1112\n",
      "Epoch 44/1000\n",
      "230/230 [==============================] - 23s 100ms/step - loss: 0.0707 - mse: 0.0112 - mae: 0.0826 - MAEMD: 0.0707 - val_loss: 0.1110 - val_mse: 0.0130 - val_mae: 0.0904 - val_MAEMD: 0.1111\n",
      "Epoch 45/1000\n",
      "230/230 [==============================] - 23s 101ms/step - loss: 0.0699 - mse: 0.0110 - mae: 0.0818 - MAEMD: 0.0699 - val_loss: 0.1101 - val_mse: 0.0131 - val_mae: 0.0904 - val_MAEMD: 0.1102\n",
      "Epoch 46/1000\n",
      "230/230 [==============================] - 23s 99ms/step - loss: 0.0702 - mse: 0.0110 - mae: 0.0819 - MAEMD: 0.0702 - val_loss: 0.1099 - val_mse: 0.0132 - val_mae: 0.0909 - val_MAEMD: 0.1101\n",
      "Epoch 47/1000\n",
      "230/230 [==============================] - 23s 99ms/step - loss: 0.0696 - mse: 0.0108 - mae: 0.0812 - MAEMD: 0.0696 - val_loss: 0.1097 - val_mse: 0.0130 - val_mae: 0.0903 - val_MAEMD: 0.1099\n",
      "Epoch 48/1000\n",
      "230/230 [==============================] - 22s 96ms/step - loss: 0.0692 - mse: 0.0109 - mae: 0.0814 - MAEMD: 0.0692 - val_loss: 0.1090 - val_mse: 0.0129 - val_mae: 0.0902 - val_MAEMD: 0.1091\n",
      "Epoch 49/1000\n",
      "230/230 [==============================] - 24s 103ms/step - loss: 0.0684 - mse: 0.0108 - mae: 0.0809 - MAEMD: 0.0684 - val_loss: 0.1102 - val_mse: 0.0126 - val_mae: 0.0887 - val_MAEMD: 0.1103\n",
      "Epoch 50/1000\n",
      "230/230 [==============================] - 24s 103ms/step - loss: 0.0697 - mse: 0.0109 - mae: 0.0813 - MAEMD: 0.0697 - val_loss: 0.1114 - val_mse: 0.0131 - val_mae: 0.0909 - val_MAEMD: 0.1116\n",
      "Epoch 51/1000\n",
      "230/230 [==============================] - 24s 103ms/step - loss: 0.0709 - mse: 0.0108 - mae: 0.0814 - MAEMD: 0.0709 - val_loss: 0.1095 - val_mse: 0.0131 - val_mae: 0.0911 - val_MAEMD: 0.1097\n",
      "Epoch 52/1000\n",
      "230/230 [==============================] - 23s 100ms/step - loss: 0.0690 - mse: 0.0107 - mae: 0.0808 - MAEMD: 0.0691 - val_loss: 0.1086 - val_mse: 0.0133 - val_mae: 0.0914 - val_MAEMD: 0.1087\n",
      "Epoch 53/1000\n",
      "230/230 [==============================] - 23s 100ms/step - loss: 0.0688 - mse: 0.0104 - mae: 0.0800 - MAEMD: 0.0688 - val_loss: 0.1096 - val_mse: 0.0132 - val_mae: 0.0907 - val_MAEMD: 0.1097\n",
      "Epoch 54/1000\n",
      "230/230 [==============================] - 25s 110ms/step - loss: 0.0664 - mse: 0.0103 - mae: 0.0792 - MAEMD: 0.0664 - val_loss: 0.1085 - val_mse: 0.0127 - val_mae: 0.0890 - val_MAEMD: 0.1086\n",
      "Epoch 55/1000\n",
      "230/230 [==============================] - 23s 100ms/step - loss: 0.0655 - mse: 0.0102 - mae: 0.0786 - MAEMD: 0.0655 - val_loss: 0.1118 - val_mse: 0.0135 - val_mae: 0.0917 - val_MAEMD: 0.1119\n",
      "Epoch 56/1000\n",
      "230/230 [==============================] - 22s 97ms/step - loss: 0.0658 - mse: 0.0101 - mae: 0.0784 - MAEMD: 0.0658 - val_loss: 0.1085 - val_mse: 0.0127 - val_mae: 0.0894 - val_MAEMD: 0.1086\n",
      "Epoch 57/1000\n",
      "230/230 [==============================] - 24s 105ms/step - loss: 0.0643 - mse: 0.0100 - mae: 0.0777 - MAEMD: 0.0643 - val_loss: 0.1075 - val_mse: 0.0135 - val_mae: 0.0920 - val_MAEMD: 0.1075\n",
      "Epoch 58/1000\n",
      "230/230 [==============================] - 23s 101ms/step - loss: 0.0639 - mse: 0.0099 - mae: 0.0776 - MAEMD: 0.0639 - val_loss: 0.1083 - val_mse: 0.0128 - val_mae: 0.0896 - val_MAEMD: 0.1084\n",
      "Epoch 59/1000\n",
      "230/230 [==============================] - 24s 105ms/step - loss: 0.0639 - mse: 0.0099 - mae: 0.0775 - MAEMD: 0.0639 - val_loss: 0.1076 - val_mse: 0.0129 - val_mae: 0.0896 - val_MAEMD: 0.1077\n",
      "Epoch 60/1000\n",
      "230/230 [==============================] - 24s 104ms/step - loss: 0.0626 - mse: 0.0097 - mae: 0.0766 - MAEMD: 0.0625 - val_loss: 0.1076 - val_mse: 0.0120 - val_mae: 0.0867 - val_MAEMD: 0.1076\n",
      "Epoch 61/1000\n",
      "230/230 [==============================] - 23s 99ms/step - loss: 0.0643 - mse: 0.0099 - mae: 0.0773 - MAEMD: 0.0643 - val_loss: 0.1074 - val_mse: 0.0122 - val_mae: 0.0872 - val_MAEMD: 0.1075\n",
      "Epoch 62/1000\n",
      "230/230 [==============================] - 24s 104ms/step - loss: 0.0626 - mse: 0.0096 - mae: 0.0760 - MAEMD: 0.0626 - val_loss: 0.1046 - val_mse: 0.0118 - val_mae: 0.0858 - val_MAEMD: 0.1047\n",
      "Epoch 63/1000\n",
      "230/230 [==============================] - 24s 106ms/step - loss: 0.0624 - mse: 0.0096 - mae: 0.0763 - MAEMD: 0.0624 - val_loss: 0.1044 - val_mse: 0.0115 - val_mae: 0.0849 - val_MAEMD: 0.1045\n",
      "Epoch 64/1000\n",
      "230/230 [==============================] - 24s 103ms/step - loss: 0.0624 - mse: 0.0096 - mae: 0.0760 - MAEMD: 0.0624 - val_loss: 0.1075 - val_mse: 0.0115 - val_mae: 0.0849 - val_MAEMD: 0.1076\n",
      "Epoch 65/1000\n",
      "230/230 [==============================] - 23s 100ms/step - loss: 0.0611 - mse: 0.0094 - mae: 0.0752 - MAEMD: 0.0611 - val_loss: 0.1074 - val_mse: 0.0112 - val_mae: 0.0840 - val_MAEMD: 0.1075\n",
      "Epoch 66/1000\n",
      "230/230 [==============================] - 24s 105ms/step - loss: 0.0612 - mse: 0.0093 - mae: 0.0749 - MAEMD: 0.0612 - val_loss: 0.1065 - val_mse: 0.0115 - val_mae: 0.0849 - val_MAEMD: 0.1066\n",
      "Epoch 67/1000\n",
      "230/230 [==============================] - 24s 104ms/step - loss: 0.0611 - mse: 0.0093 - mae: 0.0750 - MAEMD: 0.0612 - val_loss: 0.1131 - val_mse: 0.0125 - val_mae: 0.0890 - val_MAEMD: 0.1132\n",
      "Epoch 68/1000\n",
      "230/230 [==============================] - 24s 104ms/step - loss: 0.0617 - mse: 0.0093 - mae: 0.0752 - MAEMD: 0.0618 - val_loss: 0.1096 - val_mse: 0.0119 - val_mae: 0.0868 - val_MAEMD: 0.1097\n",
      "Epoch 69/1000\n",
      "230/230 [==============================] - 23s 100ms/step - loss: 0.0619 - mse: 0.0093 - mae: 0.0751 - MAEMD: 0.0618 - val_loss: 0.1076 - val_mse: 0.0119 - val_mae: 0.0867 - val_MAEMD: 0.1078\n",
      "Epoch 70/1000\n",
      "230/230 [==============================] - 23s 101ms/step - loss: 0.0604 - mse: 0.0091 - mae: 0.0741 - MAEMD: 0.0604 - val_loss: 0.1050 - val_mse: 0.0111 - val_mae: 0.0836 - val_MAEMD: 0.1051\n",
      "Epoch 71/1000\n",
      "230/230 [==============================] - 24s 104ms/step - loss: 0.0601 - mse: 0.0091 - mae: 0.0739 - MAEMD: 0.0602 - val_loss: 0.1022 - val_mse: 0.0108 - val_mae: 0.0821 - val_MAEMD: 0.1023\n",
      "Epoch 72/1000\n",
      "230/230 [==============================] - 24s 104ms/step - loss: 0.0599 - mse: 0.0089 - mae: 0.0735 - MAEMD: 0.0599 - val_loss: 0.1045 - val_mse: 0.0114 - val_mae: 0.0843 - val_MAEMD: 0.1046\n",
      "Epoch 73/1000\n",
      "230/230 [==============================] - 22s 96ms/step - loss: 0.0584 - mse: 0.0088 - mae: 0.0726 - MAEMD: 0.0584 - val_loss: 0.1041 - val_mse: 0.0114 - val_mae: 0.0842 - val_MAEMD: 0.1042\n",
      "Epoch 74/1000\n",
      "230/230 [==============================] - 23s 99ms/step - loss: 0.0580 - mse: 0.0086 - mae: 0.0722 - MAEMD: 0.0581 - val_loss: 0.1040 - val_mse: 0.0112 - val_mae: 0.0834 - val_MAEMD: 0.1041\n",
      "Epoch 75/1000\n",
      "230/230 [==============================] - 23s 99ms/step - loss: 0.0574 - mse: 0.0085 - mae: 0.0716 - MAEMD: 0.0574 - val_loss: 0.1016 - val_mse: 0.0108 - val_mae: 0.0820 - val_MAEMD: 0.1016\n",
      "Epoch 76/1000\n",
      "230/230 [==============================] - 23s 99ms/step - loss: 0.0565 - mse: 0.0084 - mae: 0.0710 - MAEMD: 0.0564 - val_loss: 0.1019 - val_mse: 0.0108 - val_mae: 0.0819 - val_MAEMD: 0.1020\n",
      "Epoch 77/1000\n",
      "230/230 [==============================] - 22s 96ms/step - loss: 0.0562 - mse: 0.0084 - mae: 0.0709 - MAEMD: 0.0562 - val_loss: 0.1037 - val_mse: 0.0101 - val_mae: 0.0794 - val_MAEMD: 0.1037\n",
      "Epoch 78/1000\n",
      "230/230 [==============================] - 23s 99ms/step - loss: 0.0558 - mse: 0.0083 - mae: 0.0706 - MAEMD: 0.0558 - val_loss: 0.1060 - val_mse: 0.0115 - val_mae: 0.0849 - val_MAEMD: 0.1061\n",
      "Epoch 79/1000\n",
      "230/230 [==============================] - 23s 99ms/step - loss: 0.0557 - mse: 0.0083 - mae: 0.0703 - MAEMD: 0.0557 - val_loss: 0.1044 - val_mse: 0.0110 - val_mae: 0.0829 - val_MAEMD: 0.1045\n",
      "Epoch 80/1000\n",
      "230/230 [==============================] - 23s 98ms/step - loss: 0.0557 - mse: 0.0083 - mae: 0.0703 - MAEMD: 0.0557 - val_loss: 0.1027 - val_mse: 0.0107 - val_mae: 0.0819 - val_MAEMD: 0.1027\n",
      "Epoch 81/1000\n",
      "230/230 [==============================] - 22s 98ms/step - loss: 0.0560 - mse: 0.0083 - mae: 0.0703 - MAEMD: 0.0560 - val_loss: 0.1041 - val_mse: 0.0106 - val_mae: 0.0814 - val_MAEMD: 0.1042\n",
      "Epoch 82/1000\n",
      "230/230 [==============================] - 23s 99ms/step - loss: 0.0548 - mse: 0.0081 - mae: 0.0694 - MAEMD: 0.0548 - val_loss: 0.1045 - val_mse: 0.0107 - val_mae: 0.0815 - val_MAEMD: 0.1045\n",
      "Epoch 83/1000\n",
      "230/230 [==============================] - 23s 100ms/step - loss: 0.0562 - mse: 0.0082 - mae: 0.0699 - MAEMD: 0.0562 - val_loss: 0.1011 - val_mse: 0.0108 - val_mae: 0.0819 - val_MAEMD: 0.1011\n",
      "Epoch 84/1000\n",
      "230/230 [==============================] - 22s 95ms/step - loss: 0.0557 - mse: 0.0082 - mae: 0.0698 - MAEMD: 0.0557 - val_loss: 0.1025 - val_mse: 0.0104 - val_mae: 0.0803 - val_MAEMD: 0.1026\n",
      "Epoch 85/1000\n",
      "230/230 [==============================] - 23s 101ms/step - loss: 0.0549 - mse: 0.0080 - mae: 0.0693 - MAEMD: 0.0549 - val_loss: 0.1022 - val_mse: 0.0103 - val_mae: 0.0799 - val_MAEMD: 0.1023\n",
      "Epoch 86/1000\n",
      "230/230 [==============================] - 25s 108ms/step - loss: 0.0541 - mse: 0.0079 - mae: 0.0686 - MAEMD: 0.0541 - val_loss: 0.1014 - val_mse: 0.0102 - val_mae: 0.0798 - val_MAEMD: 0.1014\n",
      "Epoch 87/1000\n",
      "230/230 [==============================] - 24s 105ms/step - loss: 0.0530 - mse: 0.0078 - mae: 0.0679 - MAEMD: 0.0531 - val_loss: 0.1034 - val_mse: 0.0108 - val_mae: 0.0820 - val_MAEMD: 0.1035\n",
      "Epoch 88/1000\n",
      "230/230 [==============================] - 23s 100ms/step - loss: 0.0529 - mse: 0.0077 - mae: 0.0678 - MAEMD: 0.0529 - val_loss: 0.1076 - val_mse: 0.0114 - val_mae: 0.0846 - val_MAEMD: 0.1077\n",
      "Epoch 89/1000\n",
      "230/230 [==============================] - 24s 102ms/step - loss: 0.0523 - mse: 0.0077 - mae: 0.0674 - MAEMD: 0.0524 - val_loss: 0.1081 - val_mse: 0.0108 - val_mae: 0.0822 - val_MAEMD: 0.1081\n",
      "Epoch 90/1000\n",
      "230/230 [==============================] - 23s 101ms/step - loss: 0.0526 - mse: 0.0076 - mae: 0.0673 - MAEMD: 0.0526 - val_loss: 0.1124 - val_mse: 0.0128 - val_mae: 0.0905 - val_MAEMD: 0.1125\n",
      "Epoch 91/1000\n",
      "230/230 [==============================] - 26s 114ms/step - loss: 0.0522 - mse: 0.0076 - mae: 0.0671 - MAEMD: 0.0522 - val_loss: 0.1078 - val_mse: 0.0107 - val_mae: 0.0819 - val_MAEMD: 0.1080\n",
      "Epoch 92/1000\n",
      "230/230 [==============================] - 23s 99ms/step - loss: 0.0519 - mse: 0.0076 - mae: 0.0671 - MAEMD: 0.0519 - val_loss: 0.1075 - val_mse: 0.0105 - val_mae: 0.0812 - val_MAEMD: 0.1076\n",
      "Epoch 93/1000\n",
      "230/230 [==============================] - 24s 105ms/step - loss: 0.0521 - mse: 0.0076 - mae: 0.0671 - MAEMD: 0.0522 - val_loss: 0.1094 - val_mse: 0.0111 - val_mae: 0.0836 - val_MAEMD: 0.1095\n",
      "Epoch 94/1000\n",
      "230/230 [==============================] - 25s 108ms/step - loss: 0.0534 - mse: 0.0077 - mae: 0.0675 - MAEMD: 0.0534 - val_loss: 0.1023 - val_mse: 0.0104 - val_mae: 0.0805 - val_MAEMD: 0.1023\n",
      "Epoch 95/1000\n",
      "230/230 [==============================] - 25s 109ms/step - loss: 0.0520 - mse: 0.0075 - mae: 0.0668 - MAEMD: 0.0521 - val_loss: 0.1003 - val_mse: 0.0098 - val_mae: 0.0782 - val_MAEMD: 0.1003\n",
      "Epoch 96/1000\n",
      "230/230 [==============================] - 24s 106ms/step - loss: 0.0515 - mse: 0.0075 - mae: 0.0667 - MAEMD: 0.0515 - val_loss: 0.1000 - val_mse: 0.0099 - val_mae: 0.0786 - val_MAEMD: 0.1001\n",
      "Epoch 97/1000\n",
      "230/230 [==============================] - 24s 105ms/step - loss: 0.0511 - mse: 0.0074 - mae: 0.0662 - MAEMD: 0.0511 - val_loss: 0.1003 - val_mse: 0.0098 - val_mae: 0.0781 - val_MAEMD: 0.1003\n",
      "Epoch 98/1000\n",
      "230/230 [==============================] - 26s 111ms/step - loss: 0.0499 - mse: 0.0073 - mae: 0.0655 - MAEMD: 0.0499 - val_loss: 0.1012 - val_mse: 0.0096 - val_mae: 0.0773 - val_MAEMD: 0.1013\n",
      "Epoch 99/1000\n",
      "230/230 [==============================] - 26s 114ms/step - loss: 0.0496 - mse: 0.0072 - mae: 0.0650 - MAEMD: 0.0496 - val_loss: 0.1007 - val_mse: 0.0096 - val_mae: 0.0773 - val_MAEMD: 0.1008\n",
      "Epoch 100/1000\n",
      "230/230 [==============================] - 25s 108ms/step - loss: 0.0500 - mse: 0.0072 - mae: 0.0652 - MAEMD: 0.0500 - val_loss: 0.1010 - val_mse: 0.0095 - val_mae: 0.0768 - val_MAEMD: 0.1010\n",
      "Epoch 101/1000\n",
      "230/230 [==============================] - 27s 116ms/step - loss: 0.0499 - mse: 0.0072 - mae: 0.0654 - MAEMD: 0.0499 - val_loss: 0.0994 - val_mse: 0.0096 - val_mae: 0.0771 - val_MAEMD: 0.0995\n",
      "Epoch 102/1000\n",
      "230/230 [==============================] - 26s 114ms/step - loss: 0.0500 - mse: 0.0072 - mae: 0.0653 - MAEMD: 0.0500 - val_loss: 0.1001 - val_mse: 0.0094 - val_mae: 0.0763 - val_MAEMD: 0.1002\n",
      "Epoch 103/1000\n",
      "230/230 [==============================] - 26s 111ms/step - loss: 0.0497 - mse: 0.0072 - mae: 0.0654 - MAEMD: 0.0497 - val_loss: 0.1001 - val_mse: 0.0097 - val_mae: 0.0778 - val_MAEMD: 0.1001\n",
      "Epoch 104/1000\n",
      "230/230 [==============================] - 26s 112ms/step - loss: 0.0510 - mse: 0.0073 - mae: 0.0660 - MAEMD: 0.0510 - val_loss: 0.0999 - val_mse: 0.0098 - val_mae: 0.0780 - val_MAEMD: 0.1000\n",
      "Epoch 105/1000\n",
      "230/230 [==============================] - 26s 114ms/step - loss: 0.0507 - mse: 0.0073 - mae: 0.0658 - MAEMD: 0.0507 - val_loss: 0.1033 - val_mse: 0.0100 - val_mae: 0.0791 - val_MAEMD: 0.1033\n",
      "Epoch 106/1000\n",
      "230/230 [==============================] - 24s 105ms/step - loss: 0.0505 - mse: 0.0073 - mae: 0.0655 - MAEMD: 0.0505 - val_loss: 0.1034 - val_mse: 0.0095 - val_mae: 0.0767 - val_MAEMD: 0.1034\n",
      "Epoch 107/1000\n",
      "230/230 [==============================] - 25s 107ms/step - loss: 0.0505 - mse: 0.0072 - mae: 0.0653 - MAEMD: 0.0505 - val_loss: 0.1017 - val_mse: 0.0097 - val_mae: 0.0779 - val_MAEMD: 0.1018\n",
      "Epoch 108/1000\n",
      "230/230 [==============================] - 24s 104ms/step - loss: 0.0507 - mse: 0.0072 - mae: 0.0652 - MAEMD: 0.0507 - val_loss: 0.1017 - val_mse: 0.0098 - val_mae: 0.0783 - val_MAEMD: 0.1017\n",
      "Epoch 109/1000\n",
      "230/230 [==============================] - 24s 105ms/step - loss: 0.0499 - mse: 0.0071 - mae: 0.0648 - MAEMD: 0.0499 - val_loss: 0.1011 - val_mse: 0.0097 - val_mae: 0.0777 - val_MAEMD: 0.1011\n",
      "Epoch 110/1000\n",
      "230/230 [==============================] - 25s 107ms/step - loss: 0.0486 - mse: 0.0070 - mae: 0.0640 - MAEMD: 0.0486 - val_loss: 0.1014 - val_mse: 0.0098 - val_mae: 0.0781 - val_MAEMD: 0.1015\n",
      "Epoch 111/1000\n",
      "230/230 [==============================] - 24s 105ms/step - loss: 0.0478 - mse: 0.0069 - mae: 0.0635 - MAEMD: 0.0478 - val_loss: 0.1028 - val_mse: 0.0097 - val_mae: 0.0777 - val_MAEMD: 0.1029\n",
      "Epoch 112/1000\n",
      "230/230 [==============================] - 23s 102ms/step - loss: 0.0476 - mse: 0.0069 - mae: 0.0634 - MAEMD: 0.0476 - val_loss: 0.1033 - val_mse: 0.0101 - val_mae: 0.0794 - val_MAEMD: 0.1033\n",
      "Epoch 113/1000\n",
      "230/230 [==============================] - 24s 105ms/step - loss: 0.0469 - mse: 0.0068 - mae: 0.0630 - MAEMD: 0.0469 - val_loss: 0.1010 - val_mse: 0.0107 - val_mae: 0.0819 - val_MAEMD: 0.1010\n",
      "Epoch 114/1000\n",
      "230/230 [==============================] - 24s 105ms/step - loss: 0.0471 - mse: 0.0067 - mae: 0.0628 - MAEMD: 0.0472 - val_loss: 0.1023 - val_mse: 0.0106 - val_mae: 0.0815 - val_MAEMD: 0.1022\n",
      "Epoch 115/1000\n",
      "230/230 [==============================] - 25s 108ms/step - loss: 0.0470 - mse: 0.0068 - mae: 0.0629 - MAEMD: 0.0470 - val_loss: 0.1038 - val_mse: 0.0099 - val_mae: 0.0788 - val_MAEMD: 0.1038\n",
      "Epoch 116/1000\n",
      "230/230 [==============================] - 24s 102ms/step - loss: 0.0469 - mse: 0.0066 - mae: 0.0621 - MAEMD: 0.0469 - val_loss: 0.1029 - val_mse: 0.0095 - val_mae: 0.0770 - val_MAEMD: 0.1029\n",
      "Epoch 117/1000\n",
      "230/230 [==============================] - 24s 104ms/step - loss: 0.0480 - mse: 0.0068 - mae: 0.0631 - MAEMD: 0.0480 - val_loss: 0.1003 - val_mse: 0.0092 - val_mae: 0.0756 - val_MAEMD: 0.1004\n",
      "Epoch 118/1000\n",
      "230/230 [==============================] - 24s 105ms/step - loss: 0.0471 - mse: 0.0067 - mae: 0.0628 - MAEMD: 0.0472 - val_loss: 0.1007 - val_mse: 0.0097 - val_mae: 0.0778 - val_MAEMD: 0.1008\n",
      "Epoch 119/1000\n",
      "230/230 [==============================] - 25s 107ms/step - loss: 0.0468 - mse: 0.0066 - mae: 0.0620 - MAEMD: 0.0468 - val_loss: 0.0990 - val_mse: 0.0093 - val_mae: 0.0760 - val_MAEMD: 0.0991\n",
      "Epoch 120/1000\n",
      "230/230 [==============================] - 24s 105ms/step - loss: 0.0459 - mse: 0.0065 - mae: 0.0616 - MAEMD: 0.0459 - val_loss: 0.0999 - val_mse: 0.0094 - val_mae: 0.0761 - val_MAEMD: 0.0999\n",
      "Epoch 121/1000\n",
      "230/230 [==============================] - 23s 101ms/step - loss: 0.0456 - mse: 0.0065 - mae: 0.0614 - MAEMD: 0.0456 - val_loss: 0.1000 - val_mse: 0.0099 - val_mae: 0.0785 - val_MAEMD: 0.1000\n",
      "Epoch 122/1000\n",
      "230/230 [==============================] - 24s 104ms/step - loss: 0.0461 - mse: 0.0065 - mae: 0.0615 - MAEMD: 0.0461 - val_loss: 0.1001 - val_mse: 0.0095 - val_mae: 0.0766 - val_MAEMD: 0.1002\n",
      "Epoch 123/1000\n",
      "230/230 [==============================] - 24s 106ms/step - loss: 0.0458 - mse: 0.0065 - mae: 0.0614 - MAEMD: 0.0458 - val_loss: 0.0993 - val_mse: 0.0092 - val_mae: 0.0755 - val_MAEMD: 0.0993\n",
      "Epoch 124/1000\n",
      "230/230 [==============================] - 23s 98ms/step - loss: 0.0456 - mse: 0.0064 - mae: 0.0612 - MAEMD: 0.0456 - val_loss: 0.0999 - val_mse: 0.0088 - val_mae: 0.0736 - val_MAEMD: 0.1000\n",
      "Epoch 125/1000\n",
      "230/230 [==============================] - 24s 104ms/step - loss: 0.0464 - mse: 0.0065 - mae: 0.0618 - MAEMD: 0.0464 - val_loss: 0.1004 - val_mse: 0.0091 - val_mae: 0.0749 - val_MAEMD: 0.1004\n",
      "Epoch 126/1000\n",
      "230/230 [==============================] - 24s 103ms/step - loss: 0.0458 - mse: 0.0065 - mae: 0.0615 - MAEMD: 0.0459 - val_loss: 0.0994 - val_mse: 0.0095 - val_mae: 0.0769 - val_MAEMD: 0.0994\n",
      "Epoch 127/1000\n",
      "230/230 [==============================] - 26s 111ms/step - loss: 0.0457 - mse: 0.0064 - mae: 0.0612 - MAEMD: 0.0457 - val_loss: 0.1004 - val_mse: 0.0094 - val_mae: 0.0765 - val_MAEMD: 0.1004\n",
      "Epoch 128/1000\n",
      "230/230 [==============================] - 23s 100ms/step - loss: 0.0453 - mse: 0.0064 - mae: 0.0610 - MAEMD: 0.0453 - val_loss: 0.1032 - val_mse: 0.0092 - val_mae: 0.0756 - val_MAEMD: 0.1033\n",
      "Epoch 129/1000\n",
      "230/230 [==============================] - 24s 103ms/step - loss: 0.0467 - mse: 0.0065 - mae: 0.0616 - MAEMD: 0.0467 - val_loss: 0.1041 - val_mse: 0.0093 - val_mae: 0.0761 - val_MAEMD: 0.1041\n",
      "Epoch 130/1000\n",
      "230/230 [==============================] - 24s 103ms/step - loss: 0.0454 - mse: 0.0063 - mae: 0.0607 - MAEMD: 0.0454 - val_loss: 0.1022 - val_mse: 0.0095 - val_mae: 0.0768 - val_MAEMD: 0.1022\n",
      "Epoch 131/1000\n",
      "230/230 [==============================] - 24s 103ms/step - loss: 0.0460 - mse: 0.0064 - mae: 0.0611 - MAEMD: 0.0460 - val_loss: 0.1067 - val_mse: 0.0102 - val_mae: 0.0801 - val_MAEMD: 0.1068\n",
      "Epoch 132/1000\n",
      "230/230 [==============================] - 24s 107ms/step - loss: 0.0458 - mse: 0.0063 - mae: 0.0608 - MAEMD: 0.0458 - val_loss: 0.1038 - val_mse: 0.0100 - val_mae: 0.0793 - val_MAEMD: 0.1038\n",
      "Epoch 133/1000\n",
      "230/230 [==============================] - 24s 103ms/step - loss: 0.0462 - mse: 0.0063 - mae: 0.0608 - MAEMD: 0.0462 - val_loss: 0.0994 - val_mse: 0.0094 - val_mae: 0.0766 - val_MAEMD: 0.0995\n",
      "Epoch 134/1000\n",
      "230/230 [==============================] - 27s 116ms/step - loss: 0.0449 - mse: 0.0062 - mae: 0.0599 - MAEMD: 0.0449 - val_loss: 0.0991 - val_mse: 0.0088 - val_mae: 0.0740 - val_MAEMD: 0.0991\n",
      "Epoch 135/1000\n",
      "230/230 [==============================] - 24s 106ms/step - loss: 0.0440 - mse: 0.0061 - mae: 0.0596 - MAEMD: 0.0440 - val_loss: 0.0989 - val_mse: 0.0088 - val_mae: 0.0737 - val_MAEMD: 0.0989\n",
      "Epoch 136/1000\n",
      "230/230 [==============================] - 23s 100ms/step - loss: 0.0436 - mse: 0.0061 - mae: 0.0593 - MAEMD: 0.0436 - val_loss: 0.0981 - val_mse: 0.0091 - val_mae: 0.0751 - val_MAEMD: 0.0981\n",
      "Epoch 137/1000\n",
      "230/230 [==============================] - 24s 106ms/step - loss: 0.0428 - mse: 0.0060 - mae: 0.0588 - MAEMD: 0.0428 - val_loss: 0.0988 - val_mse: 0.0088 - val_mae: 0.0737 - val_MAEMD: 0.0988\n",
      "Epoch 138/1000\n",
      "230/230 [==============================] - 26s 112ms/step - loss: 0.0430 - mse: 0.0060 - mae: 0.0589 - MAEMD: 0.0430 - val_loss: 0.0991 - val_mse: 0.0089 - val_mae: 0.0741 - val_MAEMD: 0.0992\n",
      "Epoch 139/1000\n",
      "230/230 [==============================] - 25s 110ms/step - loss: 0.0430 - mse: 0.0060 - mae: 0.0591 - MAEMD: 0.0430 - val_loss: 0.1014 - val_mse: 0.0086 - val_mae: 0.0730 - val_MAEMD: 0.1015\n",
      "Epoch 140/1000\n",
      "230/230 [==============================] - 25s 109ms/step - loss: 0.0431 - mse: 0.0059 - mae: 0.0585 - MAEMD: 0.0431 - val_loss: 0.0997 - val_mse: 0.0088 - val_mae: 0.0737 - val_MAEMD: 0.0997\n",
      "Epoch 141/1000\n",
      "230/230 [==============================] - 25s 107ms/step - loss: 0.0428 - mse: 0.0059 - mae: 0.0585 - MAEMD: 0.0428 - val_loss: 0.0982 - val_mse: 0.0092 - val_mae: 0.0754 - val_MAEMD: 0.0984\n",
      "Epoch 142/1000\n",
      "230/230 [==============================] - 25s 107ms/step - loss: 0.0424 - mse: 0.0059 - mae: 0.0583 - MAEMD: 0.0424 - val_loss: 0.0979 - val_mse: 0.0093 - val_mae: 0.0758 - val_MAEMD: 0.0979\n",
      "Epoch 143/1000\n",
      "230/230 [==============================] - 25s 108ms/step - loss: 0.0426 - mse: 0.0060 - mae: 0.0586 - MAEMD: 0.0426 - val_loss: 0.1009 - val_mse: 0.0088 - val_mae: 0.0736 - val_MAEMD: 0.1010\n",
      "Epoch 144/1000\n",
      "230/230 [==============================] - 25s 109ms/step - loss: 0.0425 - mse: 0.0059 - mae: 0.0585 - MAEMD: 0.0425 - val_loss: 0.1003 - val_mse: 0.0087 - val_mae: 0.0731 - val_MAEMD: 0.1005\n",
      "Epoch 145/1000\n",
      "230/230 [==============================] - 24s 104ms/step - loss: 0.0438 - mse: 0.0060 - mae: 0.0589 - MAEMD: 0.0438 - val_loss: 0.1013 - val_mse: 0.0095 - val_mae: 0.0768 - val_MAEMD: 0.1014\n",
      "Epoch 146/1000\n",
      "230/230 [==============================] - 24s 105ms/step - loss: 0.0434 - mse: 0.0059 - mae: 0.0586 - MAEMD: 0.0434 - val_loss: 0.1031 - val_mse: 0.0095 - val_mae: 0.0766 - val_MAEMD: 0.1032\n",
      "Epoch 147/1000\n",
      "230/230 [==============================] - 24s 104ms/step - loss: 0.0440 - mse: 0.0061 - mae: 0.0593 - MAEMD: 0.0440 - val_loss: 0.1060 - val_mse: 0.0100 - val_mae: 0.0788 - val_MAEMD: 0.1061\n",
      "Epoch 148/1000\n",
      "230/230 [==============================] - 24s 104ms/step - loss: 0.0444 - mse: 0.0060 - mae: 0.0592 - MAEMD: 0.0444 - val_loss: 0.1063 - val_mse: 0.0097 - val_mae: 0.0781 - val_MAEMD: 0.1064\n",
      "Epoch 149/1000\n",
      "230/230 [==============================] - 22s 97ms/step - loss: 0.0444 - mse: 0.0060 - mae: 0.0593 - MAEMD: 0.0444 - val_loss: 0.1066 - val_mse: 0.0092 - val_mae: 0.0756 - val_MAEMD: 0.1068\n",
      "Epoch 150/1000\n",
      "230/230 [==============================] - 23s 100ms/step - loss: 0.0438 - mse: 0.0060 - mae: 0.0588 - MAEMD: 0.0439 - val_loss: 0.1043 - val_mse: 0.0097 - val_mae: 0.0778 - val_MAEMD: 0.1044\n",
      "Epoch 151/1000\n",
      "230/230 [==============================] - 23s 100ms/step - loss: 0.0426 - mse: 0.0058 - mae: 0.0578 - MAEMD: 0.0426 - val_loss: 0.1056 - val_mse: 0.0094 - val_mae: 0.0764 - val_MAEMD: 0.1057\n",
      "Epoch 152/1000\n",
      "230/230 [==============================] - 24s 104ms/step - loss: 0.0416 - mse: 0.0057 - mae: 0.0573 - MAEMD: 0.0417 - val_loss: 0.1055 - val_mse: 0.0093 - val_mae: 0.0763 - val_MAEMD: 0.1056\n",
      "Epoch 153/1000\n",
      "230/230 [==============================] - 24s 103ms/step - loss: 0.0416 - mse: 0.0057 - mae: 0.0573 - MAEMD: 0.0416 - val_loss: 0.1038 - val_mse: 0.0089 - val_mae: 0.0743 - val_MAEMD: 0.1038\n",
      "Epoch 154/1000\n",
      "230/230 [==============================] - 24s 104ms/step - loss: 0.0416 - mse: 0.0056 - mae: 0.0569 - MAEMD: 0.0416 - val_loss: 0.1006 - val_mse: 0.0089 - val_mae: 0.0741 - val_MAEMD: 0.1007\n",
      "Epoch 155/1000\n",
      "230/230 [==============================] - 24s 104ms/step - loss: 0.0406 - mse: 0.0056 - mae: 0.0565 - MAEMD: 0.0406 - val_loss: 0.1011 - val_mse: 0.0084 - val_mae: 0.0718 - val_MAEMD: 0.1012\n",
      "Epoch 156/1000\n",
      "230/230 [==============================] - 24s 103ms/step - loss: 0.0399 - mse: 0.0055 - mae: 0.0558 - MAEMD: 0.0399 - val_loss: 0.1000 - val_mse: 0.0084 - val_mae: 0.0722 - val_MAEMD: 0.1000\n",
      "Epoch 157/1000\n",
      "230/230 [==============================] - 20s 87ms/step - loss: 0.0398 - mse: 0.0055 - mae: 0.0559 - MAEMD: 0.0398 - val_loss: 0.1000 - val_mse: 0.0086 - val_mae: 0.0728 - val_MAEMD: 0.1000\n",
      "Epoch 158/1000\n",
      "230/230 [==============================] - 19s 83ms/step - loss: 0.0400 - mse: 0.0054 - mae: 0.0555 - MAEMD: 0.0400 - val_loss: 0.0994 - val_mse: 0.0084 - val_mae: 0.0721 - val_MAEMD: 0.0994\n",
      "Epoch 159/1000\n",
      "230/230 [==============================] - 27s 118ms/step - loss: 0.0397 - mse: 0.0055 - mae: 0.0558 - MAEMD: 0.0398 - val_loss: 0.1004 - val_mse: 0.0083 - val_mae: 0.0716 - val_MAEMD: 0.1004\n",
      "Epoch 160/1000\n",
      "230/230 [==============================] - 34s 146ms/step - loss: 0.0396 - mse: 0.0054 - mae: 0.0555 - MAEMD: 0.0397 - val_loss: 0.0987 - val_mse: 0.0089 - val_mae: 0.0742 - val_MAEMD: 0.0987\n",
      "Epoch 161/1000\n",
      "230/230 [==============================] - 34s 149ms/step - loss: 0.0397 - mse: 0.0054 - mae: 0.0556 - MAEMD: 0.0397 - val_loss: 0.1001 - val_mse: 0.0085 - val_mae: 0.0725 - val_MAEMD: 0.1001\n",
      "Epoch 162/1000\n",
      "230/230 [==============================] - 34s 149ms/step - loss: 0.0395 - mse: 0.0054 - mae: 0.0554 - MAEMD: 0.0395 - val_loss: 0.0986 - val_mse: 0.0086 - val_mae: 0.0728 - val_MAEMD: 0.0986\n",
      "Epoch 163/1000\n",
      "230/230 [==============================] - 35s 151ms/step - loss: 0.0402 - mse: 0.0055 - mae: 0.0560 - MAEMD: 0.0402 - val_loss: 0.0988 - val_mse: 0.0085 - val_mae: 0.0725 - val_MAEMD: 0.0988\n",
      "Epoch 164/1000\n",
      "230/230 [==============================] - 34s 150ms/step - loss: 0.0404 - mse: 0.0055 - mae: 0.0559 - MAEMD: 0.0404 - val_loss: 0.1007 - val_mse: 0.0087 - val_mae: 0.0736 - val_MAEMD: 0.1007\n",
      "Epoch 165/1000\n",
      "230/230 [==============================] - 35s 152ms/step - loss: 0.0409 - mse: 0.0055 - mae: 0.0562 - MAEMD: 0.0409 - val_loss: 0.1033 - val_mse: 0.0092 - val_mae: 0.0756 - val_MAEMD: 0.1034\n",
      "Epoch 166/1000\n",
      "230/230 [==============================] - 26s 111ms/step - loss: 0.0424 - mse: 0.0056 - mae: 0.0570 - MAEMD: 0.0424 - val_loss: 0.1090 - val_mse: 0.0102 - val_mae: 0.0802 - val_MAEMD: 0.1091\n",
      "Epoch 167/1000\n",
      "230/230 [==============================] - 33s 145ms/step - loss: 0.0411 - mse: 0.0055 - mae: 0.0562 - MAEMD: 0.0411 - val_loss: 0.1043 - val_mse: 0.0096 - val_mae: 0.0774 - val_MAEMD: 0.1044\n",
      "Epoch 168/1000\n",
      "230/230 [==============================] - 35s 152ms/step - loss: 0.0405 - mse: 0.0055 - mae: 0.0559 - MAEMD: 0.0406 - val_loss: 0.1042 - val_mse: 0.0089 - val_mae: 0.0744 - val_MAEMD: 0.1042\n",
      "Epoch 169/1000\n",
      "230/230 [==============================] - 35s 150ms/step - loss: 0.0394 - mse: 0.0054 - mae: 0.0552 - MAEMD: 0.0394 - val_loss: 0.1037 - val_mse: 0.0086 - val_mae: 0.0729 - val_MAEMD: 0.1038\n",
      "Epoch 170/1000\n",
      "230/230 [==============================] - 35s 153ms/step - loss: 0.0399 - mse: 0.0054 - mae: 0.0553 - MAEMD: 0.0399 - val_loss: 0.1019 - val_mse: 0.0085 - val_mae: 0.0727 - val_MAEMD: 0.1021\n",
      "Epoch 171/1000\n",
      "230/230 [==============================] - 34s 150ms/step - loss: 0.0398 - mse: 0.0054 - mae: 0.0554 - MAEMD: 0.0399 - val_loss: 0.0989 - val_mse: 0.0084 - val_mae: 0.0720 - val_MAEMD: 0.0989\n",
      "Epoch 172/1000\n",
      "230/230 [==============================] - 35s 150ms/step - loss: 0.0394 - mse: 0.0053 - mae: 0.0549 - MAEMD: 0.0394 - val_loss: 0.1011 - val_mse: 0.0079 - val_mae: 0.0697 - val_MAEMD: 0.1011\n",
      "Epoch 173/1000\n",
      "230/230 [==============================] - 35s 151ms/step - loss: 0.0389 - mse: 0.0053 - mae: 0.0548 - MAEMD: 0.0389 - val_loss: 0.0991 - val_mse: 0.0083 - val_mae: 0.0713 - val_MAEMD: 0.0991\n",
      "Epoch 174/1000\n",
      "230/230 [==============================] - 36s 158ms/step - loss: 0.0386 - mse: 0.0052 - mae: 0.0543 - MAEMD: 0.0386 - val_loss: 0.0997 - val_mse: 0.0081 - val_mae: 0.0706 - val_MAEMD: 0.0998\n",
      "Epoch 175/1000\n",
      "230/230 [==============================] - 32s 140ms/step - loss: 0.0390 - mse: 0.0052 - mae: 0.0545 - MAEMD: 0.0390 - val_loss: 0.1002 - val_mse: 0.0084 - val_mae: 0.0723 - val_MAEMD: 0.1003\n",
      "Epoch 176/1000\n",
      "230/230 [==============================] - 35s 151ms/step - loss: 0.0383 - mse: 0.0051 - mae: 0.0539 - MAEMD: 0.0383 - val_loss: 0.1012 - val_mse: 0.0084 - val_mae: 0.0719 - val_MAEMD: 0.1013\n",
      "Epoch 177/1000\n",
      "230/230 [==============================] - 35s 154ms/step - loss: 0.0390 - mse: 0.0052 - mae: 0.0546 - MAEMD: 0.0390 - val_loss: 0.1007 - val_mse: 0.0086 - val_mae: 0.0729 - val_MAEMD: 0.1009\n",
      "Epoch 178/1000\n",
      "230/230 [==============================] - 35s 153ms/step - loss: 0.0386 - mse: 0.0052 - mae: 0.0542 - MAEMD: 0.0387 - val_loss: 0.1014 - val_mse: 0.0086 - val_mae: 0.0728 - val_MAEMD: 0.1015\n",
      "Epoch 179/1000\n",
      "230/230 [==============================] - 35s 154ms/step - loss: 0.0388 - mse: 0.0052 - mae: 0.0542 - MAEMD: 0.0388 - val_loss: 0.1014 - val_mse: 0.0084 - val_mae: 0.0721 - val_MAEMD: 0.1014\n",
      "Epoch 180/1000\n",
      "230/230 [==============================] - 35s 154ms/step - loss: 0.0388 - mse: 0.0052 - mae: 0.0543 - MAEMD: 0.0388 - val_loss: 0.1041 - val_mse: 0.0085 - val_mae: 0.0727 - val_MAEMD: 0.1042\n",
      "Epoch 181/1000\n",
      "230/230 [==============================] - 35s 152ms/step - loss: 0.0380 - mse: 0.0051 - mae: 0.0539 - MAEMD: 0.0380 - val_loss: 0.1036 - val_mse: 0.0089 - val_mae: 0.0742 - val_MAEMD: 0.1036\n",
      "Epoch 182/1000\n",
      "230/230 [==============================] - 35s 152ms/step - loss: 0.0385 - mse: 0.0052 - mae: 0.0541 - MAEMD: 0.0385 - val_loss: 0.1017 - val_mse: 0.0086 - val_mae: 0.0727 - val_MAEMD: 0.1018\n",
      "Epoch 183/1000\n",
      "230/230 [==============================] - 33s 144ms/step - loss: 0.0382 - mse: 0.0052 - mae: 0.0540 - MAEMD: 0.0382 - val_loss: 0.1021 - val_mse: 0.0086 - val_mae: 0.0730 - val_MAEMD: 0.1022\n",
      "Epoch 184/1000\n",
      "230/230 [==============================] - 35s 151ms/step - loss: 0.0374 - mse: 0.0051 - mae: 0.0534 - MAEMD: 0.0374 - val_loss: 0.1021 - val_mse: 0.0083 - val_mae: 0.0717 - val_MAEMD: 0.1023\n",
      "Epoch 185/1000\n",
      "230/230 [==============================] - 35s 151ms/step - loss: 0.0373 - mse: 0.0050 - mae: 0.0533 - MAEMD: 0.0374 - val_loss: 0.1007 - val_mse: 0.0085 - val_mae: 0.0724 - val_MAEMD: 0.1008\n",
      "Epoch 186/1000\n",
      "230/230 [==============================] - 35s 153ms/step - loss: 0.0376 - mse: 0.0050 - mae: 0.0532 - MAEMD: 0.0376 - val_loss: 0.0989 - val_mse: 0.0086 - val_mae: 0.0730 - val_MAEMD: 0.0990\n",
      "Epoch 187/1000\n",
      "230/230 [==============================] - 35s 154ms/step - loss: 0.0374 - mse: 0.0050 - mae: 0.0532 - MAEMD: 0.0374 - val_loss: 0.0984 - val_mse: 0.0084 - val_mae: 0.0722 - val_MAEMD: 0.0985\n",
      "Epoch 188/1000\n",
      "230/230 [==============================] - 35s 152ms/step - loss: 0.0373 - mse: 0.0050 - mae: 0.0531 - MAEMD: 0.0374 - val_loss: 0.0991 - val_mse: 0.0082 - val_mae: 0.0713 - val_MAEMD: 0.0992\n",
      "Epoch 189/1000\n",
      "230/230 [==============================] - 36s 154ms/step - loss: 0.0371 - mse: 0.0050 - mae: 0.0530 - MAEMD: 0.0372 - val_loss: 0.1020 - val_mse: 0.0081 - val_mae: 0.0706 - val_MAEMD: 0.1021\n",
      "Epoch 190/1000\n",
      "230/230 [==============================] - 35s 154ms/step - loss: 0.0373 - mse: 0.0050 - mae: 0.0529 - MAEMD: 0.0373 - val_loss: 0.0995 - val_mse: 0.0087 - val_mae: 0.0735 - val_MAEMD: 0.0996\n",
      "Epoch 191/1000\n",
      "230/230 [==============================] - 32s 141ms/step - loss: 0.0377 - mse: 0.0050 - mae: 0.0532 - MAEMD: 0.0377 - val_loss: 0.1024 - val_mse: 0.0085 - val_mae: 0.0727 - val_MAEMD: 0.1025\n",
      "Epoch 192/1000\n",
      "230/230 [==============================] - 35s 154ms/step - loss: 0.0376 - mse: 0.0050 - mae: 0.0531 - MAEMD: 0.0377 - val_loss: 0.1048 - val_mse: 0.0095 - val_mae: 0.0771 - val_MAEMD: 0.1049\n",
      "Wall time: 1h 22min 7s\n"
     ]
    }
   ],
   "source": [
    "    %%time\n",
    "    b_size = timesteps\n",
    "    #hist = model.fit(strvaX, strvaY, epochs=epochs, batch_size=b_size, shuffle=False, validation_data=(teX, teY), callbacks=[history, early_stopping])  # , checkpoint\n",
    "    hist = model.fit(strX, strY, epochs=epochs, batch_size=b_size, shuffle=False, validation_data=(svaX, svaY), callbacks=[history, early_stopping])  # , checkpoint"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3937c99e",
   "metadata": {},
   "source": [
    "### Saving Basic Model Training Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b3517cda",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('Basic Ramp Model Final_fh6.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "4524e084",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4592"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "5c61212c",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_history = hist.history['loss']\n",
    "valloss_history = hist.history['val_loss']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4571e14",
   "metadata": {},
   "source": [
    "## Basic Model Test Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "c0beaa88",
   "metadata": {},
   "outputs": [],
   "source": [
    "testPredict = model.predict(teX, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "903f6589",
   "metadata": {},
   "outputs": [],
   "source": [
    "def npMAEMS(y_true, y_pred):\n",
    "    return np.mean((abs(y_pred - y_true))*np.square(y_true))*100\n",
    "def npMAEMD(y_true, y_pred):\n",
    "    return np.mean((abs(y_pred - y_true))*np.square(y_true-np.mean(y_true)))*100\n",
    "def npMSE(y_true, y_pred):\n",
    "    return np.mean(np.square(-y_true+y_pred))\n",
    "def npMAE(y_true, y_pred):\n",
    "    return np.mean(abs(-y_true+y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "c6c9656a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error Test Score > MSE ==  0.010124202472662495  MAE ==  0.07958302142275088  MAEMS ==  0.09609176915486234\n"
     ]
    }
   ],
   "source": [
    "tePredict = testPredict.reshape(-1)\n",
    "testY = teY.reshape(-1)\n",
    "print('Error Test Score > MSE == ', npMSE(testY, tePredict), ' MAE == ', npMAE(testY, tePredict), ' MAEMS == ', npMAEMD(testY, tePredict))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4faf01b",
   "metadata": {},
   "source": [
    "## Wind Ramp Rate FFEL Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "7f213d57",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_timesteps = 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "a7463259",
   "metadata": {},
   "outputs": [],
   "source": [
    "trX, vaX, trY, vaY = train_test_split(trvaX, trvaY, test_size=1/6, shuffle=False)\n",
    "trY = trY.reshape(-1,output_timesteps)\n",
    "vaY = vaY.reshape(-1,output_timesteps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "4de12cb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainPredict = model.predict(trX, batch_size=batch_size)\n",
    "validPredict = model.predict(vaX, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "bc078fb6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(31461, 6)\n",
      "(31461, 6)\n"
     ]
    }
   ],
   "source": [
    "e_tr = trainPredict - trY\n",
    "e_va = validPredict - vaY\n",
    "errors = np.vstack([e_tr, e_va])\n",
    "prediction = np.vstack([trainPredict, validPredict])\n",
    "print(errors.shape)\n",
    "print(prediction.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "b1586ad7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Normalized Ramp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.620197</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.544580</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.570751</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.599594</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.495246</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Normalized Ramp\n",
       "0         0.620197\n",
       "1         0.544580\n",
       "2         0.570751\n",
       "3         0.599594\n",
       "4         0.495246"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "norm_df2 = pd.DataFrame(norm_df).iloc[:prediction.shape[0], :]\n",
    "norm_df2.columns = ['Normalized Ramp']\n",
    "norm_df2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "68e922e7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Prediction1</th>\n",
       "      <th>Prediction2</th>\n",
       "      <th>Prediction3</th>\n",
       "      <th>Prediction4</th>\n",
       "      <th>Prediction5</th>\n",
       "      <th>Prediction6</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.355205</td>\n",
       "      <td>0.321475</td>\n",
       "      <td>0.440193</td>\n",
       "      <td>0.543288</td>\n",
       "      <td>0.592235</td>\n",
       "      <td>0.541352</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.371166</td>\n",
       "      <td>0.354698</td>\n",
       "      <td>0.365372</td>\n",
       "      <td>0.318627</td>\n",
       "      <td>0.305659</td>\n",
       "      <td>0.359306</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.372288</td>\n",
       "      <td>0.330047</td>\n",
       "      <td>0.252493</td>\n",
       "      <td>0.290060</td>\n",
       "      <td>0.545327</td>\n",
       "      <td>0.783457</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.352383</td>\n",
       "      <td>0.266103</td>\n",
       "      <td>0.291428</td>\n",
       "      <td>0.474720</td>\n",
       "      <td>0.743481</td>\n",
       "      <td>0.625581</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.305317</td>\n",
       "      <td>0.285573</td>\n",
       "      <td>0.512916</td>\n",
       "      <td>0.848632</td>\n",
       "      <td>0.447361</td>\n",
       "      <td>0.082599</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31456</th>\n",
       "      <td>0.675862</td>\n",
       "      <td>0.652084</td>\n",
       "      <td>0.562497</td>\n",
       "      <td>0.450074</td>\n",
       "      <td>0.340417</td>\n",
       "      <td>0.323767</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31457</th>\n",
       "      <td>0.753039</td>\n",
       "      <td>0.718695</td>\n",
       "      <td>0.574176</td>\n",
       "      <td>0.386479</td>\n",
       "      <td>0.311519</td>\n",
       "      <td>0.359828</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31458</th>\n",
       "      <td>0.690589</td>\n",
       "      <td>0.590808</td>\n",
       "      <td>0.512256</td>\n",
       "      <td>0.398704</td>\n",
       "      <td>0.386623</td>\n",
       "      <td>0.370924</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31459</th>\n",
       "      <td>0.565859</td>\n",
       "      <td>0.491545</td>\n",
       "      <td>0.471758</td>\n",
       "      <td>0.465640</td>\n",
       "      <td>0.393753</td>\n",
       "      <td>0.329032</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31460</th>\n",
       "      <td>0.303243</td>\n",
       "      <td>0.227925</td>\n",
       "      <td>0.364172</td>\n",
       "      <td>0.559562</td>\n",
       "      <td>0.577048</td>\n",
       "      <td>0.420398</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>31461 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Prediction1  Prediction2  Prediction3  Prediction4  Prediction5  \\\n",
       "0         0.355205     0.321475     0.440193     0.543288     0.592235   \n",
       "1         0.371166     0.354698     0.365372     0.318627     0.305659   \n",
       "2         0.372288     0.330047     0.252493     0.290060     0.545327   \n",
       "3         0.352383     0.266103     0.291428     0.474720     0.743481   \n",
       "4         0.305317     0.285573     0.512916     0.848632     0.447361   \n",
       "...            ...          ...          ...          ...          ...   \n",
       "31456     0.675862     0.652084     0.562497     0.450074     0.340417   \n",
       "31457     0.753039     0.718695     0.574176     0.386479     0.311519   \n",
       "31458     0.690589     0.590808     0.512256     0.398704     0.386623   \n",
       "31459     0.565859     0.491545     0.471758     0.465640     0.393753   \n",
       "31460     0.303243     0.227925     0.364172     0.559562     0.577048   \n",
       "\n",
       "       Prediction6  \n",
       "0         0.541352  \n",
       "1         0.359306  \n",
       "2         0.783457  \n",
       "3         0.625581  \n",
       "4         0.082599  \n",
       "...            ...  \n",
       "31456     0.323767  \n",
       "31457     0.359828  \n",
       "31458     0.370924  \n",
       "31459     0.329032  \n",
       "31460     0.420398  \n",
       "\n",
       "[31461 rows x 6 columns]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Prindex = ['Prediction1', 'Prediction2','Prediction3','Prediction4','Prediction5','Prediction6']\n",
    "Erindex = ['Error1', 'Error2','Error3','Error4','Error5','Error6']\n",
    "\n",
    "pr_df = pd.DataFrame(prediction, columns=Prindex)\n",
    "pr_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "ae56b61d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Error1</th>\n",
       "      <th>Error2</th>\n",
       "      <th>Error3</th>\n",
       "      <th>Error4</th>\n",
       "      <th>Error5</th>\n",
       "      <th>Error6</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.086252</td>\n",
       "      <td>-0.101718</td>\n",
       "      <td>0.059875</td>\n",
       "      <td>0.143259</td>\n",
       "      <td>0.267488</td>\n",
       "      <td>0.191326</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.052027</td>\n",
       "      <td>-0.025619</td>\n",
       "      <td>-0.034657</td>\n",
       "      <td>-0.006119</td>\n",
       "      <td>-0.044368</td>\n",
       "      <td>-0.024353</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.008030</td>\n",
       "      <td>-0.069982</td>\n",
       "      <td>-0.072253</td>\n",
       "      <td>-0.059966</td>\n",
       "      <td>0.161669</td>\n",
       "      <td>-0.090428</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.047646</td>\n",
       "      <td>-0.058644</td>\n",
       "      <td>-0.058599</td>\n",
       "      <td>0.091061</td>\n",
       "      <td>-0.130404</td>\n",
       "      <td>0.099376</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.019430</td>\n",
       "      <td>-0.064454</td>\n",
       "      <td>0.129258</td>\n",
       "      <td>-0.025253</td>\n",
       "      <td>-0.078844</td>\n",
       "      <td>-0.037905</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31456</th>\n",
       "      <td>0.005838</td>\n",
       "      <td>-0.030489</td>\n",
       "      <td>-0.041748</td>\n",
       "      <td>-0.030126</td>\n",
       "      <td>-0.000392</td>\n",
       "      <td>0.030513</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31457</th>\n",
       "      <td>0.070467</td>\n",
       "      <td>0.114450</td>\n",
       "      <td>0.093976</td>\n",
       "      <td>0.045670</td>\n",
       "      <td>0.018266</td>\n",
       "      <td>-0.075454</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31458</th>\n",
       "      <td>0.086343</td>\n",
       "      <td>0.110608</td>\n",
       "      <td>0.171447</td>\n",
       "      <td>0.105451</td>\n",
       "      <td>-0.048659</td>\n",
       "      <td>-0.336826</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31459</th>\n",
       "      <td>0.085659</td>\n",
       "      <td>0.150736</td>\n",
       "      <td>0.178505</td>\n",
       "      <td>0.030359</td>\n",
       "      <td>-0.313997</td>\n",
       "      <td>-0.257470</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31460</th>\n",
       "      <td>-0.037566</td>\n",
       "      <td>-0.065328</td>\n",
       "      <td>-0.071110</td>\n",
       "      <td>-0.148187</td>\n",
       "      <td>-0.009454</td>\n",
       "      <td>-0.024474</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>31461 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         Error1    Error2    Error3    Error4    Error5    Error6\n",
       "0     -0.086252 -0.101718  0.059875  0.143259  0.267488  0.191326\n",
       "1     -0.052027 -0.025619 -0.034657 -0.006119 -0.044368 -0.024353\n",
       "2     -0.008030 -0.069982 -0.072253 -0.059966  0.161669 -0.090428\n",
       "3     -0.047646 -0.058644 -0.058599  0.091061 -0.130404  0.099376\n",
       "4     -0.019430 -0.064454  0.129258 -0.025253 -0.078844 -0.037905\n",
       "...         ...       ...       ...       ...       ...       ...\n",
       "31456  0.005838 -0.030489 -0.041748 -0.030126 -0.000392  0.030513\n",
       "31457  0.070467  0.114450  0.093976  0.045670  0.018266 -0.075454\n",
       "31458  0.086343  0.110608  0.171447  0.105451 -0.048659 -0.336826\n",
       "31459  0.085659  0.150736  0.178505  0.030359 -0.313997 -0.257470\n",
       "31460 -0.037566 -0.065328 -0.071110 -0.148187 -0.009454 -0.024474\n",
       "\n",
       "[31461 rows x 6 columns]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "er_df = pd.DataFrame(errors, columns=Erindex)\n",
    "er_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "493c0919",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Normalized Ramp</th>\n",
       "      <th>Prediction1</th>\n",
       "      <th>Prediction2</th>\n",
       "      <th>Prediction3</th>\n",
       "      <th>Prediction4</th>\n",
       "      <th>Prediction5</th>\n",
       "      <th>Prediction6</th>\n",
       "      <th>Error1</th>\n",
       "      <th>Error2</th>\n",
       "      <th>Error3</th>\n",
       "      <th>Error4</th>\n",
       "      <th>Error5</th>\n",
       "      <th>Error6</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.620197</td>\n",
       "      <td>0.355205</td>\n",
       "      <td>0.321475</td>\n",
       "      <td>0.440193</td>\n",
       "      <td>0.543288</td>\n",
       "      <td>0.592235</td>\n",
       "      <td>0.541352</td>\n",
       "      <td>-0.086252</td>\n",
       "      <td>-0.101718</td>\n",
       "      <td>0.059875</td>\n",
       "      <td>0.143259</td>\n",
       "      <td>0.267488</td>\n",
       "      <td>0.191326</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.544580</td>\n",
       "      <td>0.371166</td>\n",
       "      <td>0.354698</td>\n",
       "      <td>0.365372</td>\n",
       "      <td>0.318627</td>\n",
       "      <td>0.305659</td>\n",
       "      <td>0.359306</td>\n",
       "      <td>-0.052027</td>\n",
       "      <td>-0.025619</td>\n",
       "      <td>-0.034657</td>\n",
       "      <td>-0.006119</td>\n",
       "      <td>-0.044368</td>\n",
       "      <td>-0.024353</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.570751</td>\n",
       "      <td>0.372288</td>\n",
       "      <td>0.330047</td>\n",
       "      <td>0.252493</td>\n",
       "      <td>0.290060</td>\n",
       "      <td>0.545327</td>\n",
       "      <td>0.783457</td>\n",
       "      <td>-0.008030</td>\n",
       "      <td>-0.069982</td>\n",
       "      <td>-0.072253</td>\n",
       "      <td>-0.059966</td>\n",
       "      <td>0.161669</td>\n",
       "      <td>-0.090428</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.599594</td>\n",
       "      <td>0.352383</td>\n",
       "      <td>0.266103</td>\n",
       "      <td>0.291428</td>\n",
       "      <td>0.474720</td>\n",
       "      <td>0.743481</td>\n",
       "      <td>0.625581</td>\n",
       "      <td>-0.047646</td>\n",
       "      <td>-0.058644</td>\n",
       "      <td>-0.058599</td>\n",
       "      <td>0.091061</td>\n",
       "      <td>-0.130404</td>\n",
       "      <td>0.099376</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.495246</td>\n",
       "      <td>0.305317</td>\n",
       "      <td>0.285573</td>\n",
       "      <td>0.512916</td>\n",
       "      <td>0.848632</td>\n",
       "      <td>0.447361</td>\n",
       "      <td>0.082599</td>\n",
       "      <td>-0.019430</td>\n",
       "      <td>-0.064454</td>\n",
       "      <td>0.129258</td>\n",
       "      <td>-0.025253</td>\n",
       "      <td>-0.078844</td>\n",
       "      <td>-0.037905</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Normalized Ramp  Prediction1  Prediction2  Prediction3  Prediction4  \\\n",
       "0         0.620197     0.355205     0.321475     0.440193     0.543288   \n",
       "1         0.544580     0.371166     0.354698     0.365372     0.318627   \n",
       "2         0.570751     0.372288     0.330047     0.252493     0.290060   \n",
       "3         0.599594     0.352383     0.266103     0.291428     0.474720   \n",
       "4         0.495246     0.305317     0.285573     0.512916     0.848632   \n",
       "\n",
       "   Prediction5  Prediction6    Error1    Error2    Error3    Error4    Error5  \\\n",
       "0     0.592235     0.541352 -0.086252 -0.101718  0.059875  0.143259  0.267488   \n",
       "1     0.305659     0.359306 -0.052027 -0.025619 -0.034657 -0.006119 -0.044368   \n",
       "2     0.545327     0.783457 -0.008030 -0.069982 -0.072253 -0.059966  0.161669   \n",
       "3     0.743481     0.625581 -0.047646 -0.058644 -0.058599  0.091061 -0.130404   \n",
       "4     0.447361     0.082599 -0.019430 -0.064454  0.129258 -0.025253 -0.078844   \n",
       "\n",
       "     Error6  \n",
       "0  0.191326  \n",
       "1 -0.024353  \n",
       "2 -0.090428  \n",
       "3  0.099376  \n",
       "4 -0.037905  "
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "norm_df2 = pd.concat([norm_df2, pr_df, er_df],axis=1)\n",
    "norm_df2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "b4e65b5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "norm_df22 = pd.DataFrame(norm_df).iloc[prediction.shape[0]+timesteps:, :]\n",
    "norm_df22.columns = ['Normalized Wind']\n",
    "npnorm22 = np.array(norm_df22)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "7702680c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.362638</td>\n",
       "      <td>0.360067</td>\n",
       "      <td>0.320813</td>\n",
       "      <td>0.358743</td>\n",
       "      <td>0.406330</td>\n",
       "      <td>0.442248</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.458406</td>\n",
       "      <td>0.425269</td>\n",
       "      <td>0.369052</td>\n",
       "      <td>0.373581</td>\n",
       "      <td>0.412202</td>\n",
       "      <td>0.456250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.415771</td>\n",
       "      <td>0.416348</td>\n",
       "      <td>0.396263</td>\n",
       "      <td>0.406548</td>\n",
       "      <td>0.428573</td>\n",
       "      <td>0.460973</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.389874</td>\n",
       "      <td>0.368727</td>\n",
       "      <td>0.373699</td>\n",
       "      <td>0.401948</td>\n",
       "      <td>0.438417</td>\n",
       "      <td>0.636120</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.278604</td>\n",
       "      <td>0.333515</td>\n",
       "      <td>0.366870</td>\n",
       "      <td>0.446477</td>\n",
       "      <td>0.623106</td>\n",
       "      <td>0.448852</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3491</th>\n",
       "      <td>0.609953</td>\n",
       "      <td>0.652093</td>\n",
       "      <td>0.609014</td>\n",
       "      <td>0.591178</td>\n",
       "      <td>0.509967</td>\n",
       "      <td>0.415477</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3492</th>\n",
       "      <td>0.576092</td>\n",
       "      <td>0.561833</td>\n",
       "      <td>0.552108</td>\n",
       "      <td>0.615220</td>\n",
       "      <td>0.546546</td>\n",
       "      <td>0.490200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3493</th>\n",
       "      <td>0.478875</td>\n",
       "      <td>0.582181</td>\n",
       "      <td>0.570662</td>\n",
       "      <td>0.505341</td>\n",
       "      <td>0.481847</td>\n",
       "      <td>0.601246</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3494</th>\n",
       "      <td>0.549657</td>\n",
       "      <td>0.616933</td>\n",
       "      <td>0.569664</td>\n",
       "      <td>0.572226</td>\n",
       "      <td>0.595581</td>\n",
       "      <td>0.572503</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3495</th>\n",
       "      <td>0.548567</td>\n",
       "      <td>0.526709</td>\n",
       "      <td>0.459979</td>\n",
       "      <td>0.517110</td>\n",
       "      <td>0.501687</td>\n",
       "      <td>0.445933</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3496 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             0         1         2         3         4         5\n",
       "0     0.362638  0.360067  0.320813  0.358743  0.406330  0.442248\n",
       "1     0.458406  0.425269  0.369052  0.373581  0.412202  0.456250\n",
       "2     0.415771  0.416348  0.396263  0.406548  0.428573  0.460973\n",
       "3     0.389874  0.368727  0.373699  0.401948  0.438417  0.636120\n",
       "4     0.278604  0.333515  0.366870  0.446477  0.623106  0.448852\n",
       "...        ...       ...       ...       ...       ...       ...\n",
       "3491  0.609953  0.652093  0.609014  0.591178  0.509967  0.415477\n",
       "3492  0.576092  0.561833  0.552108  0.615220  0.546546  0.490200\n",
       "3493  0.478875  0.582181  0.570662  0.505341  0.481847  0.601246\n",
       "3494  0.549657  0.616933  0.569664  0.572226  0.595581  0.572503\n",
       "3495  0.548567  0.526709  0.459979  0.517110  0.501687  0.445933\n",
       "\n",
       "[3496 rows x 6 columns]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pr_df = pd.DataFrame(tePredict.reshape(-1,6))\n",
    "pr_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "fc8e6ed6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Error1</th>\n",
       "      <th>Error2</th>\n",
       "      <th>Error3</th>\n",
       "      <th>Error4</th>\n",
       "      <th>Error5</th>\n",
       "      <th>Error6</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.069385</td>\n",
       "      <td>-0.075215</td>\n",
       "      <td>-0.386937</td>\n",
       "      <td>-0.227759</td>\n",
       "      <td>-0.038543</td>\n",
       "      <td>-0.059133</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.023124</td>\n",
       "      <td>-0.282480</td>\n",
       "      <td>-0.217450</td>\n",
       "      <td>-0.071292</td>\n",
       "      <td>-0.089178</td>\n",
       "      <td>-0.093645</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.291979</td>\n",
       "      <td>-0.170154</td>\n",
       "      <td>-0.048609</td>\n",
       "      <td>-0.094833</td>\n",
       "      <td>-0.121323</td>\n",
       "      <td>0.023613</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.196627</td>\n",
       "      <td>-0.076146</td>\n",
       "      <td>-0.127682</td>\n",
       "      <td>-0.147947</td>\n",
       "      <td>0.001058</td>\n",
       "      <td>0.148966</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.166269</td>\n",
       "      <td>-0.167866</td>\n",
       "      <td>-0.183026</td>\n",
       "      <td>0.009117</td>\n",
       "      <td>0.135952</td>\n",
       "      <td>0.095814</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3491</th>\n",
       "      <td>0.014830</td>\n",
       "      <td>0.178416</td>\n",
       "      <td>0.133544</td>\n",
       "      <td>0.051166</td>\n",
       "      <td>-0.043063</td>\n",
       "      <td>-0.165694</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3492</th>\n",
       "      <td>0.102415</td>\n",
       "      <td>0.086364</td>\n",
       "      <td>0.012096</td>\n",
       "      <td>0.062190</td>\n",
       "      <td>-0.034625</td>\n",
       "      <td>-0.090658</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3493</th>\n",
       "      <td>0.003405</td>\n",
       "      <td>0.042169</td>\n",
       "      <td>0.017632</td>\n",
       "      <td>-0.075830</td>\n",
       "      <td>-0.099011</td>\n",
       "      <td>-0.173396</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3494</th>\n",
       "      <td>0.009644</td>\n",
       "      <td>0.063903</td>\n",
       "      <td>-0.011506</td>\n",
       "      <td>-0.008633</td>\n",
       "      <td>-0.179062</td>\n",
       "      <td>-0.163009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3495</th>\n",
       "      <td>-0.004463</td>\n",
       "      <td>-0.054461</td>\n",
       "      <td>-0.120879</td>\n",
       "      <td>-0.257533</td>\n",
       "      <td>-0.233825</td>\n",
       "      <td>-0.155660</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3496 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        Error1    Error2    Error3    Error4    Error5    Error6\n",
       "0     0.069385 -0.075215 -0.386937 -0.227759 -0.038543 -0.059133\n",
       "1     0.023124 -0.282480 -0.217450 -0.071292 -0.089178 -0.093645\n",
       "2    -0.291979 -0.170154 -0.048609 -0.094833 -0.121323  0.023613\n",
       "3    -0.196627 -0.076146 -0.127682 -0.147947  0.001058  0.148966\n",
       "4    -0.166269 -0.167866 -0.183026  0.009117  0.135952  0.095814\n",
       "...        ...       ...       ...       ...       ...       ...\n",
       "3491  0.014830  0.178416  0.133544  0.051166 -0.043063 -0.165694\n",
       "3492  0.102415  0.086364  0.012096  0.062190 -0.034625 -0.090658\n",
       "3493  0.003405  0.042169  0.017632 -0.075830 -0.099011 -0.173396\n",
       "3494  0.009644  0.063903 -0.011506 -0.008633 -0.179062 -0.163009\n",
       "3495 -0.004463 -0.054461 -0.120879 -0.257533 -0.233825 -0.155660\n",
       "\n",
       "[3496 rows x 6 columns]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "teY = testY.reshape(-1,6)\n",
    "e_te = testPredict-teY\n",
    "er_df = pd.DataFrame(e_te, columns=Erindex)\n",
    "er_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "441187e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3496, 6)\n"
     ]
    }
   ],
   "source": [
    "prnorm = np.array(pr_df)\n",
    "ernorm =np.array(er_df)\n",
    "print(ernorm.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "7fd0d09d",
   "metadata": {},
   "outputs": [],
   "source": [
    "etedat = np.concatenate((npnorm22[:prnorm.shape[0],:], prnorm, ernorm), axis=1)\n",
    "#etedat[169:171,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "e1258e2a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3398, 1, 13)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eteX, eteY = create_dataset(etedat, timesteps, 1, 0)\n",
    "eteY.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "ff6962a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "eteY = eteY[:,:,-6:].reshape(-1,6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "5ec9fd35",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(31363, 1, 13)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "norm_df2 = np.array(norm_df2)\n",
    "output_timesteps = 1\n",
    "Xe, Ye = create_dataset(norm_df2, timesteps, 1, 0)\n",
    "Ye.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "334c5831",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(31363, 96, 13)\n",
      "(31363, 6)\n"
     ]
    }
   ],
   "source": [
    "Ye = Ye[:,:,-6:].reshape(-1, 6)\n",
    "print(Xe.shape)\n",
    "print(Ye.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "dee54e7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "trXe, vaXe, trYe, vaYe = train_test_split(Xe, Ye, test_size=0.3, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "f173f246",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6285"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "70a4a975",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((3398, 96, 13), (3398, 6), (31363, 96, 13), (31363, 6))"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eteX.shape, eteY.shape, Xe.shape, Ye.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "82aa785a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mse_mae(y_true, y_pred):\n",
    "    return K.mean(K.square(y_pred - y_true))*10+K.mean(K.abs(y_pred - y_true))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "88820850",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_2 (InputLayer)            [(None, 96, 13)]     0                                            \n",
      "__________________________________________________________________________________________________\n",
      "permute_2 (Permute)             (None, 13, 96)       0           input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_5 (Dense)                 (None, 13, 96)       9312        permute_2[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_6 (Dense)                 (None, 13, 96)       9312        permute_2[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "multiply_24 (Multiply)          (None, 13, 96)       0           dense_5[0][0]                    \n",
      "                                                                 dense_6[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "attention_vec (Permute)         (None, 96, 13)       0           multiply_24[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "multiply_25 (Multiply)          (None, 96, 13)       0           input_2[0][0]                    \n",
      "                                                                 attention_vec[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_23 (Conv1D)              (None, 96, 256)      3584        multiply_25[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "activation_40 (Activation)      (None, 96, 256)      0           conv1d_23[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_41 (Activation)      (None, 96, 256)      0           conv1d_23[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "multiply_26 (Multiply)          (None, 96, 256)      0           activation_40[0][0]              \n",
      "                                                                 activation_41[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_24 (Conv1D)              (None, 96, 13)       6669        multiply_26[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "activation_42 (Activation)      (None, 96, 13)       0           conv1d_24[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_43 (Activation)      (None, 96, 13)       0           conv1d_24[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "multiply_27 (Multiply)          (None, 96, 13)       0           activation_42[0][0]              \n",
      "                                                                 activation_43[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "add_6 (Add)                     (None, 96, 13)       0           input_2[0][0]                    \n",
      "                                                                 multiply_27[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "subtract_6 (Subtract)           (None, 96, 13)       0           input_2[0][0]                    \n",
      "                                                                 multiply_27[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_25 (Conv1D)              (None, 96, 256)      3584        add_6[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_27 (Conv1D)              (None, 96, 256)      3584        subtract_6[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_44 (Activation)      (None, 96, 256)      0           conv1d_25[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_45 (Activation)      (None, 96, 256)      0           conv1d_25[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_48 (Activation)      (None, 96, 256)      0           conv1d_27[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_49 (Activation)      (None, 96, 256)      0           conv1d_27[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "multiply_28 (Multiply)          (None, 96, 256)      0           activation_44[0][0]              \n",
      "                                                                 activation_45[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "multiply_30 (Multiply)          (None, 96, 256)      0           activation_48[0][0]              \n",
      "                                                                 activation_49[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_26 (Conv1D)              (None, 96, 13)       6669        multiply_28[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_28 (Conv1D)              (None, 96, 13)       6669        multiply_30[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "activation_46 (Activation)      (None, 96, 13)       0           conv1d_26[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_47 (Activation)      (None, 96, 13)       0           conv1d_26[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_50 (Activation)      (None, 96, 13)       0           conv1d_28[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_51 (Activation)      (None, 96, 13)       0           conv1d_28[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "multiply_29 (Multiply)          (None, 96, 13)       0           activation_46[0][0]              \n",
      "                                                                 activation_47[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "multiply_31 (Multiply)          (None, 96, 13)       0           activation_50[0][0]              \n",
      "                                                                 activation_51[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "add_7 (Add)                     (None, 96, 13)       0           add_6[0][0]                      \n",
      "                                                                 multiply_29[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "subtract_7 (Subtract)           (None, 96, 13)       0           subtract_6[0][0]                 \n",
      "                                                                 multiply_31[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_5 (Concatenate)     (None, 96, 52)       0           add_7[0][0]                      \n",
      "                                                                 subtract_7[0][0]                 \n",
      "                                                                 add_6[0][0]                      \n",
      "                                                                 subtract_6[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_29 (Conv1D)              (None, 96, 256)      13568       concatenate_5[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_31 (Conv1D)              (None, 96, 256)      13568       concatenate_5[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_52 (Activation)      (None, 96, 256)      0           conv1d_29[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_53 (Activation)      (None, 96, 256)      0           conv1d_29[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_56 (Activation)      (None, 96, 256)      0           conv1d_31[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_57 (Activation)      (None, 96, 256)      0           conv1d_31[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "multiply_32 (Multiply)          (None, 96, 256)      0           activation_52[0][0]              \n",
      "                                                                 activation_53[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "multiply_34 (Multiply)          (None, 96, 256)      0           activation_56[0][0]              \n",
      "                                                                 activation_57[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_30 (Conv1D)              (None, 96, 13)       6669        multiply_32[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_32 (Conv1D)              (None, 96, 13)       6669        multiply_34[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "activation_54 (Activation)      (None, 96, 13)       0           conv1d_30[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_55 (Activation)      (None, 96, 13)       0           conv1d_30[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_58 (Activation)      (None, 96, 13)       0           conv1d_32[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_59 (Activation)      (None, 96, 13)       0           conv1d_32[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "multiply_33 (Multiply)          (None, 96, 13)       0           activation_54[0][0]              \n",
      "                                                                 activation_55[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "multiply_35 (Multiply)          (None, 96, 13)       0           activation_58[0][0]              \n",
      "                                                                 activation_59[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "add_8 (Add)                     (None, 96, 13)       0           add_7[0][0]                      \n",
      "                                                                 multiply_33[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "subtract_8 (Subtract)           (None, 96, 13)       0           subtract_7[0][0]                 \n",
      "                                                                 multiply_35[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_6 (Concatenate)     (None, 96, 78)       0           add_8[0][0]                      \n",
      "                                                                 subtract_8[0][0]                 \n",
      "                                                                 concatenate_5[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_33 (Conv1D)              (None, 96, 256)      20224       concatenate_6[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_35 (Conv1D)              (None, 96, 256)      20224       concatenate_6[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_60 (Activation)      (None, 96, 256)      0           conv1d_33[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_61 (Activation)      (None, 96, 256)      0           conv1d_33[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_64 (Activation)      (None, 96, 256)      0           conv1d_35[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_65 (Activation)      (None, 96, 256)      0           conv1d_35[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "multiply_36 (Multiply)          (None, 96, 256)      0           activation_60[0][0]              \n",
      "                                                                 activation_61[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "multiply_38 (Multiply)          (None, 96, 256)      0           activation_64[0][0]              \n",
      "                                                                 activation_65[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_34 (Conv1D)              (None, 96, 13)       6669        multiply_36[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_36 (Conv1D)              (None, 96, 13)       6669        multiply_38[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "activation_62 (Activation)      (None, 96, 13)       0           conv1d_34[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_63 (Activation)      (None, 96, 13)       0           conv1d_34[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_66 (Activation)      (None, 96, 13)       0           conv1d_36[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_67 (Activation)      (None, 96, 13)       0           conv1d_36[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "multiply_37 (Multiply)          (None, 96, 13)       0           activation_62[0][0]              \n",
      "                                                                 activation_63[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "multiply_39 (Multiply)          (None, 96, 13)       0           activation_66[0][0]              \n",
      "                                                                 activation_67[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "add_9 (Add)                     (None, 96, 13)       0           add_8[0][0]                      \n",
      "                                                                 multiply_37[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "subtract_9 (Subtract)           (None, 96, 13)       0           subtract_7[0][0]                 \n",
      "                                                                 multiply_39[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_7 (Concatenate)     (None, 96, 104)      0           add_9[0][0]                      \n",
      "                                                                 subtract_9[0][0]                 \n",
      "                                                                 concatenate_6[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_37 (Conv1D)              (None, 96, 256)      26880       concatenate_7[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_39 (Conv1D)              (None, 96, 256)      26880       concatenate_7[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_68 (Activation)      (None, 96, 256)      0           conv1d_37[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_69 (Activation)      (None, 96, 256)      0           conv1d_37[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_72 (Activation)      (None, 96, 256)      0           conv1d_39[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_73 (Activation)      (None, 96, 256)      0           conv1d_39[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "multiply_40 (Multiply)          (None, 96, 256)      0           activation_68[0][0]              \n",
      "                                                                 activation_69[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "multiply_42 (Multiply)          (None, 96, 256)      0           activation_72[0][0]              \n",
      "                                                                 activation_73[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_38 (Conv1D)              (None, 96, 13)       6669        multiply_40[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_40 (Conv1D)              (None, 96, 13)       6669        multiply_42[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "activation_70 (Activation)      (None, 96, 13)       0           conv1d_38[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_71 (Activation)      (None, 96, 13)       0           conv1d_38[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_74 (Activation)      (None, 96, 13)       0           conv1d_40[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_75 (Activation)      (None, 96, 13)       0           conv1d_40[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "multiply_41 (Multiply)          (None, 96, 13)       0           activation_70[0][0]              \n",
      "                                                                 activation_71[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "multiply_43 (Multiply)          (None, 96, 13)       0           activation_74[0][0]              \n",
      "                                                                 activation_75[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "add_10 (Add)                    (None, 96, 13)       0           add_9[0][0]                      \n",
      "                                                                 multiply_41[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "subtract_10 (Subtract)          (None, 96, 13)       0           subtract_9[0][0]                 \n",
      "                                                                 multiply_43[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_8 (Concatenate)     (None, 96, 130)      0           add_10[0][0]                     \n",
      "                                                                 subtract_10[0][0]                \n",
      "                                                                 concatenate_7[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_9 (Concatenate)     (None, 96, 26)       0           add_10[0][0]                     \n",
      "                                                                 subtract_10[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_10 (Concatenate)    (None, 96, 390)      0           concatenate_5[0][0]              \n",
      "                                                                 concatenate_6[0][0]              \n",
      "                                                                 concatenate_7[0][0]              \n",
      "                                                                 concatenate_8[0][0]              \n",
      "                                                                 concatenate_9[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_45 (Conv1D)              (None, 96, 480)      233760      concatenate_10[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout_3 (Dropout)             (None, 96, 480)      0           conv1d_45[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_46 (Conv1D)              (None, 96, 288)      166176      dropout_3[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_4 (Dropout)             (None, 96, 288)      0           conv1d_46[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling1d_1 (Glo (None, 288)          0           dropout_4[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_7 (Dense)                 (None, 6)            1734        global_average_pooling1d_1[0][0] \n",
      "==================================================================================================\n",
      "Total params: 612,411\n",
      "Trainable params: 612,411\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "num_features = Xe.shape[2]\n",
    "\n",
    "with tf.device('/gpu:0'):\n",
    "    alpha=1.0\n",
    "    gamma=1.2\n",
    "    beta = 1\n",
    "    hfilters = 256\n",
    "    hkernel_size1 = 1\n",
    "    hkernel_size2 = 2\n",
    "    visible1e = Input(shape=(timesteps, num_features))\n",
    "   \n",
    "    per1e = Permute((2,1))(visible1e)\n",
    "    den1ae = Dense(timesteps, activation='tanh')(per1e)\n",
    "    den1be = Dense(timesteps, activation='sigmoid')(per1e)\n",
    "    den1e = Multiply()([den1ae, den1be])\n",
    "    per2e = Permute((2,1), name='attention_vec')(den1e)\n",
    "    mul1e = Multiply()([visible1e, per2e])\n",
    "    \n",
    "    d1e = Conv1D(filters=round(hfilters*alpha), kernel_size=round(hkernel_size1*beta), padding='causal', dilation_rate=1)(mul1e)\n",
    "    d1ae = Activation(activations.tanh)(d1e)\n",
    "    d1be = Activation(activations.sigmoid)(d1e)\n",
    "    d1e = Multiply()([d1ae, d1be])\n",
    "    \n",
    "    d1e = Conv1D(filters=num_features, kernel_size=round(hkernel_size2*beta), padding='causal', dilation_rate=2)(d1e)\n",
    "    d1ae = Activation(activations.tanh)(d1e)\n",
    "    d1be = Activation(activations.sigmoid)(d1e)\n",
    "    d1e = Multiply()([d1ae, d1be])\n",
    "    \n",
    "    res01ae = Add()([visible1e, d1e])   # (100, 25) (100, 25)\n",
    "    res01be = Subtract()([visible1e, d1e])\n",
    "\n",
    "    d1e = Conv1D(filters=round(hfilters*alpha), kernel_size=round(hkernel_size1*beta), padding='causal', dilation_rate=2)(res01ae)\n",
    "    d1ae = Activation(activations.tanh)(d1e)\n",
    "    d1be = Activation(activations.sigmoid)(d1e)\n",
    "    d1e = Multiply()([d1ae, d1be])\n",
    "    \n",
    "    d1e = Conv1D(filters=num_features, kernel_size=round(hkernel_size2*beta), padding='causal', dilation_rate=4)(d1e)    \n",
    "    d1ae = Activation(activations.tanh)(d1e)\n",
    "    d1be = Activation(activations.sigmoid)(d1e)\n",
    "    \n",
    "    d1e = Multiply()([d1ae, d1be])\n",
    "    res02ae = Add()([res01ae, d1e])   # (100, 25) (100, 25)\n",
    "    \n",
    "    d2e = Conv1D(filters=round(hfilters*alpha), kernel_size=round(hkernel_size1*beta), padding='causal', dilation_rate=2)(res01be) \n",
    "    d2ae = Activation(activations.tanh)(d2e)\n",
    "    d2be = Activation(activations.sigmoid)(d2e)\n",
    "    d2e = Multiply()([d2ae, d2be])\n",
    "    \n",
    "    d2e = Conv1D(filters=num_features, kernel_size=round(hkernel_size2*beta), padding='causal', dilation_rate=4)(d2e) \n",
    "    d2ae = Activation(activations.tanh)(d2e)\n",
    "    d2be = Activation(activations.sigmoid)(d2e)\n",
    "    d2e = Multiply()([d2ae, d2be])\n",
    "    \n",
    "    res02be = Subtract()([res01be, d2e])   # (100, 25) (100, 25) \n",
    "    res02e = Concatenate()([res02ae, res02be, res01ae, res01be])\n",
    "    \n",
    "    d1e = Conv1D(filters=round(hfilters*alpha), kernel_size=round(hkernel_size1*beta), padding='causal', dilation_rate=4)(res02e)\n",
    "    d1ae = Activation(activations.tanh)(d1e)\n",
    "    d1be = Activation(activations.sigmoid)(d1e)\n",
    "    d1e = Multiply()([d1ae, d1be])\n",
    "    \n",
    "    d1e = Conv1D(filters=num_features, kernel_size=round(hkernel_size2*beta), padding='causal', dilation_rate=8)(d1e)    \n",
    "    d1ae = Activation(activations.tanh)(d1e)\n",
    "    d1be = Activation(activations.sigmoid)(d1e)\n",
    "    d1e = Multiply()([d1ae, d1be])\n",
    "    \n",
    "    res03ae = Add()([res02ae, d1e])   # (100, 25) (100, 25)\n",
    "    \n",
    "    d2e = Conv1D(filters=round(hfilters*alpha), kernel_size=round(hkernel_size1*beta), padding='causal', dilation_rate=4)(res02e) \n",
    "    d2ae = Activation(activations.tanh)(d2e)\n",
    "    d2be = Activation(activations.sigmoid)(d2e)\n",
    "    d2e = Multiply()([d2ae, d2be])\n",
    "    \n",
    "    d2e = Conv1D(filters=num_features, kernel_size=round(hkernel_size2*beta), padding='causal', dilation_rate=8)(d2e) \n",
    "    d2ae = Activation(activations.tanh)(d2e)\n",
    "    d2be = Activation(activations.sigmoid)(d2e)\n",
    "    d2e = Multiply()([d2ae, d2be])\n",
    "    \n",
    "    res03be = Subtract()([res02be, d2e])   # (100, 25) (100, 25)\n",
    "    res03e = Concatenate()([res03ae, res03be, res02e])\n",
    "    \n",
    "    d1e = Conv1D(filters=round(hfilters*alpha), kernel_size=round(hkernel_size1*beta), padding='causal', dilation_rate=8)(res03e)\n",
    "    d1ae = Activation(activations.tanh)(d1e)\n",
    "    d1be = Activation(activations.sigmoid)(d1e)\n",
    "    d1e = Multiply()([d1ae, d1be])\n",
    "    d1e = Conv1D(filters=num_features, kernel_size=round(hkernel_size2*beta), padding='causal', dilation_rate=4)(d1e)    \n",
    "    d1ae = Activation(activations.tanh)(d1e)\n",
    "    d1be = Activation(activations.sigmoid)(d1e)\n",
    "    d1e = Multiply()([d1ae, d1be])\n",
    "    res04ae = Add()([res03ae, d1e])   # (100, 25) (100, 25)\n",
    "    \n",
    "    d2e = Conv1D(filters=round(hfilters*alpha), kernel_size=round(hkernel_size1*beta), padding='causal', dilation_rate=8)(res03e) \n",
    "    d2ae = Activation(activations.tanh)(d2e)\n",
    "    d2be = Activation(activations.sigmoid)(d2e)\n",
    "    d2e = Multiply()([d2ae, d2be])\n",
    "    \n",
    "    d2e = Conv1D(filters=num_features, kernel_size=round(hkernel_size2*beta), padding='causal', dilation_rate=4)(d2e) \n",
    "    d2ae = Activation(activations.tanh)(d2e)\n",
    "    d2be = Activation(activations.sigmoid)(d2e)\n",
    "    d2e = Multiply()([d2ae, d2be])\n",
    "    \n",
    "    res04be = Subtract()([res02be, d2e])   # (100, 25) (100, 25)\n",
    "    res04e = Concatenate()([res04ae, res04be, res03e])\n",
    "    \n",
    "    d1e = Conv1D(filters=round(hfilters*alpha), kernel_size=round(hkernel_size1*beta), padding='causal', dilation_rate=4)(res04e)\n",
    "    d1ae = Activation(activations.tanh)(d1e)\n",
    "    d1be = Activation(activations.sigmoid)(d1e)\n",
    "    d1e = Multiply()([d1ae, d1be])\n",
    "    \n",
    "    d1e = Conv1D(filters=num_features, kernel_size=round(hkernel_size2*beta), padding='causal', dilation_rate=2)(d1e)    \n",
    "    d1ae = Activation(activations.tanh)(d1e)\n",
    "    d1be = Activation(activations.sigmoid)(d1e)\n",
    "    d1e = Multiply()([d1ae, d1be])\n",
    "    \n",
    "    res05ae = Add()([res04ae, d1e])   # (100, 25) (100, 25)\n",
    "    \n",
    "    d2e = Conv1D(filters=round(hfilters*alpha), kernel_size=round(hkernel_size1*beta), padding='causal', dilation_rate=4)(res04e) \n",
    "    d2ae = Activation(activations.tanh)(d2e)\n",
    "    d2be = Activation(activations.sigmoid)(d2e)\n",
    "    d2e = Multiply()([d2ae, d2be])\n",
    "    \n",
    "    d2e = Conv1D(filters=num_features, kernel_size=round(hkernel_size2*beta), padding='causal', dilation_rate=2)(d2e) \n",
    "    d2ae = Activation(activations.tanh)(d2e)\n",
    "    d2be = Activation(activations.sigmoid)(d2e)\n",
    "    d2e = Multiply()([d2ae, d2be])\n",
    "    \n",
    "    res05be = Subtract()([res04be, d2e])   # (100, 25) (100, 25)\n",
    "    res05e = Concatenate()([res05ae, res05be, res04e])\n",
    "    \n",
    "    d1e = Conv1D(filters=round(hfilters*alpha), kernel_size=round(hkernel_size1*beta), padding='causal', dilation_rate=2)(res05e)\n",
    "    d1ae = Activation(activations.tanh)(d1e)\n",
    "    d1be = Activation(activations.sigmoid)(d1e)\n",
    "    d1e = Multiply()([d1ae, d1be])\n",
    "    \n",
    "    d1e = Conv1D(filters=num_features, kernel_size=round(hkernel_size2*beta), padding='causal', dilation_rate=1)(d1e)    \n",
    "    d1ae = Activation(activations.tanh)(d1e)\n",
    "    d1be = Activation(activations.sigmoid)(d1e)\n",
    "    d1e = Multiply()([d1ae, d1be])\n",
    "\n",
    "    res06ae = Add()([res05ae, d1e])   # (100, 25) (100, 25)\n",
    "    \n",
    "    d2e = Conv1D(filters=round(hfilters*alpha), kernel_size=round(hkernel_size1*beta), padding='causal', dilation_rate=2)(res05e) \n",
    "    d2ae = Activation(activations.tanh)(d2e)\n",
    "    d2be = Activation(activations.sigmoid)(d2e)\n",
    "    d2e = Multiply()([d2ae, d2be])\n",
    "    d2e = Conv1D(filters=num_features, kernel_size=round(hkernel_size2*beta), padding='causal', dilation_rate=1)(d2e) \n",
    "    d2ae = Activation(activations.tanh)(d2e)\n",
    "    d2be = Activation(activations.sigmoid)(d2e)\n",
    "    d2e = Multiply()([d2ae, d2be])\n",
    "\n",
    "    res06be = Subtract()([res05be, d2e])   # (100, 25) (100, 25)\n",
    "    res06e = Concatenate()([res05ae, res05be])\n",
    "    \n",
    "    res10e = Concatenate()([res02e, res03e, res04e, res05e, res06e])   # \n",
    "    \n",
    "    #print('res10 :', res10.shape)  # (None, 24, 11) \n",
    "    \n",
    "    oute = Conv1D(timesteps*5, 1, padding='same', activation=PReLU())(res10e)   # 256, 11X10=110\n",
    "    oute = Dropout(0.2)(oute)   #SpatialDropout1D\n",
    "    \n",
    "    oute = Conv1D(timesteps*3, 1, padding='same', activation=PReLU())(oute) # 512,  110X5=550\n",
    "    oute = Dropout(0.2)(oute)\n",
    "    \n",
    "    oute = GlobalAveragePooling1D()(oute) # pool_size=2, strides=1\n",
    "    \n",
    "    oute = Dense(6)(oute) \n",
    "    modele = Model(inputs=[visible1e], outputs=[oute])\n",
    "    \n",
    "    print(modele.summary())\n",
    "    \n",
    "    modele.compile(loss=mse_mae, optimizer='adam', metrics=['mse','mae','mape'])\n",
    "    early_stopping =EarlyStopping(monitor='val_loss', patience=10)\n",
    "    batch_size = 168\n",
    "    epochs = 1000\n",
    "\n",
    "    history_e = LossHistory()\n",
    "    history_e.init()\n",
    "    \n",
    "    #hist = model.fit(trX, trY, epochs=epochs, batch_size=batch_size, shuffle=False, validation_data=(vaX, vaY), callbacks=[history, early_stopping])  # , checkpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "bb5f31f7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2538"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "9d2f6fcc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "229/229 [==============================] - 59s 220ms/step - loss: 0.1534 - mse: 0.0090 - mae: 0.0637 - mape: 481.0083 - val_loss: 0.0952 - val_mse: 0.0044 - val_mae: 0.0508 - val_mape: 786.1519\n",
      "Epoch 2/1000\n",
      "229/229 [==============================] - 42s 181ms/step - loss: 0.1055 - mse: 0.0051 - mae: 0.0541 - mape: 378.7788 - val_loss: 0.0839 - val_mse: 0.0037 - val_mae: 0.0466 - val_mape: 722.4144\n",
      "Epoch 3/1000\n",
      "229/229 [==============================] - 42s 182ms/step - loss: 0.0901 - mse: 0.0041 - mae: 0.0487 - mape: 390.9835 - val_loss: 0.0715 - val_mse: 0.0030 - val_mae: 0.0418 - val_mape: 484.3049\n",
      "Epoch 4/1000\n",
      "229/229 [==============================] - 40s 175ms/step - loss: 0.0810 - mse: 0.0036 - mae: 0.0454 - mape: 414.9786 - val_loss: 0.0686 - val_mse: 0.0028 - val_mae: 0.0406 - val_mape: 695.7495\n",
      "Epoch 5/1000\n",
      "229/229 [==============================] - 43s 190ms/step - loss: 0.0779 - mse: 0.0034 - mae: 0.0442 - mape: 378.9064 - val_loss: 0.0677 - val_mse: 0.0027 - val_mae: 0.0402 - val_mape: 707.2062\n",
      "Epoch 6/1000\n",
      "229/229 [==============================] - 44s 193ms/step - loss: 0.0764 - mse: 0.0033 - mae: 0.0436 - mape: 368.6754 - val_loss: 0.0678 - val_mse: 0.0028 - val_mae: 0.0403 - val_mape: 740.2795\n",
      "Epoch 7/1000\n",
      "229/229 [==============================] - 44s 194ms/step - loss: 0.0754 - mse: 0.0032 - mae: 0.0432 - mape: 374.5107 - val_loss: 0.0674 - val_mse: 0.0027 - val_mae: 0.0401 - val_mape: 661.0253\n",
      "Epoch 8/1000\n",
      "229/229 [==============================] - 44s 192ms/step - loss: 0.0745 - mse: 0.0032 - mae: 0.0428 - mape: 373.6035 - val_loss: 0.0668 - val_mse: 0.0027 - val_mae: 0.0399 - val_mape: 624.2562\n",
      "Epoch 9/1000\n",
      "229/229 [==============================] - 44s 193ms/step - loss: 0.0739 - mse: 0.0031 - mae: 0.0426 - mape: 377.4059 - val_loss: 0.0666 - val_mse: 0.0027 - val_mae: 0.0398 - val_mape: 528.2250\n",
      "Epoch 10/1000\n",
      "229/229 [==============================] - 44s 192ms/step - loss: 0.0733 - mse: 0.0031 - mae: 0.0423 - mape: 355.8401 - val_loss: 0.0660 - val_mse: 0.0026 - val_mae: 0.0395 - val_mape: 448.7098\n",
      "Epoch 11/1000\n",
      "229/229 [==============================] - 39s 173ms/step - loss: 0.0729 - mse: 0.0031 - mae: 0.0422 - mape: 370.3301 - val_loss: 0.0663 - val_mse: 0.0027 - val_mae: 0.0397 - val_mape: 478.7491\n",
      "Epoch 12/1000\n",
      "229/229 [==============================] - 44s 193ms/step - loss: 0.0726 - mse: 0.0031 - mae: 0.0421 - mape: 358.5305 - val_loss: 0.0660 - val_mse: 0.0026 - val_mae: 0.0395 - val_mape: 458.3246\n",
      "Epoch 13/1000\n",
      "229/229 [==============================] - 45s 198ms/step - loss: 0.0723 - mse: 0.0030 - mae: 0.0419 - mape: 358.6404 - val_loss: 0.0666 - val_mse: 0.0027 - val_mae: 0.0398 - val_mape: 426.8515\n",
      "Epoch 14/1000\n",
      "229/229 [==============================] - 46s 199ms/step - loss: 0.0718 - mse: 0.0030 - mae: 0.0417 - mape: 382.9482 - val_loss: 0.0661 - val_mse: 0.0027 - val_mae: 0.0396 - val_mape: 440.3648\n",
      "Epoch 15/1000\n",
      "229/229 [==============================] - 45s 197ms/step - loss: 0.0715 - mse: 0.0030 - mae: 0.0416 - mape: 365.6335 - val_loss: 0.0660 - val_mse: 0.0026 - val_mae: 0.0395 - val_mape: 385.0276\n",
      "Epoch 16/1000\n",
      "229/229 [==============================] - 45s 199ms/step - loss: 0.0712 - mse: 0.0030 - mae: 0.0415 - mape: 345.9144 - val_loss: 0.0658 - val_mse: 0.0026 - val_mae: 0.0394 - val_mape: 391.5968\n",
      "Epoch 17/1000\n",
      "229/229 [==============================] - 42s 182ms/step - loss: 0.0710 - mse: 0.0030 - mae: 0.0414 - mape: 363.1507 - val_loss: 0.0645 - val_mse: 0.0026 - val_mae: 0.0388 - val_mape: 337.4165\n",
      "Epoch 18/1000\n",
      "229/229 [==============================] - 45s 194ms/step - loss: 0.0710 - mse: 0.0030 - mae: 0.0414 - mape: 379.5939 - val_loss: 0.0645 - val_mse: 0.0026 - val_mae: 0.0388 - val_mape: 385.0406\n",
      "Epoch 19/1000\n",
      "229/229 [==============================] - 45s 195ms/step - loss: 0.0708 - mse: 0.0029 - mae: 0.0413 - mape: 354.3788 - val_loss: 0.0649 - val_mse: 0.0026 - val_mae: 0.0390 - val_mape: 419.1558\n",
      "Epoch 20/1000\n",
      "229/229 [==============================] - 44s 194ms/step - loss: 0.0705 - mse: 0.0029 - mae: 0.0412 - mape: 348.6707 - val_loss: 0.0649 - val_mse: 0.0026 - val_mae: 0.0390 - val_mape: 363.3958\n",
      "Epoch 21/1000\n",
      "229/229 [==============================] - 44s 194ms/step - loss: 0.0701 - mse: 0.0029 - mae: 0.0410 - mape: 346.1819 - val_loss: 0.0648 - val_mse: 0.0026 - val_mae: 0.0390 - val_mape: 404.2586\n",
      "Epoch 22/1000\n",
      "229/229 [==============================] - 46s 201ms/step - loss: 0.0694 - mse: 0.0029 - mae: 0.0407 - mape: 366.0621 - val_loss: 0.0651 - val_mse: 0.0026 - val_mae: 0.0391 - val_mape: 412.0864\n",
      "Epoch 23/1000\n",
      "229/229 [==============================] - 42s 183ms/step - loss: 0.0693 - mse: 0.0029 - mae: 0.0407 - mape: 376.2790 - val_loss: 0.0656 - val_mse: 0.0026 - val_mae: 0.0393 - val_mape: 562.7382\n",
      "Epoch 24/1000\n",
      "229/229 [==============================] - 44s 193ms/step - loss: 0.0690 - mse: 0.0028 - mae: 0.0405 - mape: 384.2637 - val_loss: 0.0651 - val_mse: 0.0026 - val_mae: 0.0392 - val_mape: 372.0722\n",
      "Epoch 25/1000\n",
      "229/229 [==============================] - 44s 194ms/step - loss: 0.0687 - mse: 0.0028 - mae: 0.0404 - mape: 360.7318 - val_loss: 0.0657 - val_mse: 0.0026 - val_mae: 0.0394 - val_mape: 474.6303\n",
      "Epoch 26/1000\n",
      "229/229 [==============================] - 45s 195ms/step - loss: 0.0684 - mse: 0.0028 - mae: 0.0403 - mape: 381.7303 - val_loss: 0.0662 - val_mse: 0.0027 - val_mae: 0.0396 - val_mape: 409.5229\n",
      "Epoch 27/1000\n",
      "229/229 [==============================] - 44s 193ms/step - loss: 0.0681 - mse: 0.0028 - mae: 0.0402 - mape: 409.4276 - val_loss: 0.0673 - val_mse: 0.0027 - val_mae: 0.0402 - val_mape: 536.5786\n",
      "Epoch 28/1000\n",
      "229/229 [==============================] - 45s 198ms/step - loss: 0.0676 - mse: 0.0028 - mae: 0.0399 - mape: 362.6228 - val_loss: 0.0679 - val_mse: 0.0027 - val_mae: 0.0404 - val_mape: 843.4019\n"
     ]
    }
   ],
   "source": [
    "# %%time\n",
    "    histe = modele.fit(trXe, trYe, epochs=epochs, batch_size=b_size, shuffle=False, validation_data=(vaXe, vaYe), callbacks=[history_e, early_stopping])  # , checkpoint"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea7eabb3",
   "metadata": {},
   "source": [
    "### Saving FFEL Model Training Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "a727e194",
   "metadata": {},
   "outputs": [],
   "source": [
    "eloss_history = histe.history['loss']\n",
    "valeloss_history = histe.history['val_loss']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "feced69a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#np.savetxt('ramp_elosshistory.txt',(eloss_history, valeloss_history))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "e3e88d2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "modele.save('Error Learning Ramp Model_fh6.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "9db38458",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4570"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d01da686",
   "metadata": {},
   "source": [
    "## FFEL Model Test Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "ac859281",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainePredict = modele.predict(Xe, batch_size=batch_size)\n",
    "etePredict = modele.predict(eteX, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "84c50281",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error Training Score > MSE ==  0.0027508268982510123  MAE ==  0.04010213203201518  RMSE ==  0.052448325981398224\n"
     ]
    }
   ],
   "source": [
    "trePredict = trainePredict.reshape([-1])\n",
    "trainYe = Ye.reshape([-1])\n",
    "\n",
    "print('Error Training Score > MSE == ', (np.mean(np.square(trainYe-trePredict))), ' MAE == ', mean_absolute_error(trainYe,trePredict), ' RMSE == ', np.sqrt(np.mean(np.square(trainYe-trePredict))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "0e62e24e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error Training Score > MSE ==  0.004184260277979722  MAE ==  0.05045028076227565  RMSE ==  0.06468585840799922\n"
     ]
    }
   ],
   "source": [
    "etestPredict = etePredict.reshape([-1])\n",
    "testYe = eteY.reshape([-1])\n",
    "\n",
    "print('Error Training Score > MSE == ', (np.mean(np.square(testYe-etestPredict))), ' MAE == ', mean_absolute_error(testYe,etestPredict), ' RMSE == ', np.sqrt(np.mean(np.square(testYe-etestPredict))))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8de4956",
   "metadata": {},
   "source": [
    "## Final Prediction Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "8e71afc0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3398, 6)\n"
     ]
    }
   ],
   "source": [
    "testPredict = tePredict.reshape(-1,6)\n",
    "addtestPredict = -etePredict + testPredict[timesteps:-2,:]\n",
    "print(addtestPredict.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "83bb3ab0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error Test Score > MSE ==  0.010049596148361997  MAE ==  0.0792748119060706 MAPE ==  15.831536508159912\n",
      "Error Test Score > MSE ==  0.0041842602580344345  MAE ==  0.05045028057592434 MAPE ==  10.55787095438928\n"
     ]
    }
   ],
   "source": [
    "print('Error Test Score > MSE == ', (np.mean(np.square(teY[timesteps:-2,:]-testPredict[timesteps:-2,:]))), ' MAE == ', mean_absolute_error(teY[timesteps:-2,:], testPredict[timesteps:-2,:]), 'MAPE == ', mean_absolute_percentage_error(teY[timesteps:-2,:], testPredict[timesteps:-2,:]))\n",
    "print('Error Test Score > MSE == ', (np.mean(np.square(teY[timesteps:-2,:]-addtestPredict))), ' MAE == ', mean_absolute_error(teY[timesteps:-2,:], addtestPredict), 'MAPE == ', mean_absolute_percentage_error(teY[timesteps:-2,:], addtestPredict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4c9a9e0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6aa1e30a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
