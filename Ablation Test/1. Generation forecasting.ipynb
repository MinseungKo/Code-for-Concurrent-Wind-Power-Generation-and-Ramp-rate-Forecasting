{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "017e2c87",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "import pandas as pd\n",
    "import codecs\n",
    "import numpy as np\n",
    "import math\n",
    "import csv\n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.metrics import recall_score, precision_score # New\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn import preprocessing\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow.keras.preprocessing\n",
    "#from tensorflow.keras.callbacks import ModelCheckpoint, CSVLogger, EarlyStopping, LearningRateScheduler, ReduceLROnPlateau\n",
    "from tensorflow.keras.models import Sequential, Model\n",
    "from tensorflow.keras.layers import Dense, Input, Flatten, Add, Multiply, Subtract\n",
    "from tensorflow.keras import backend as K\n",
    "from tensorflow.keras.layers import Activation, BatchNormalization\n",
    "# regularizers\n",
    "from tensorflow.keras.layers import Conv1D, Conv2D\n",
    "from tensorflow.keras.layers import MaxPooling1D\n",
    "from tensorflow.keras.layers import concatenate\n",
    "from tensorflow.keras.layers import LSTM, Bidirectional\n",
    "from tensorflow.keras.utils import plot_model\n",
    "from tensorflow.keras.layers import Dropout, SpatialDropout1D\n",
    "from scipy import signal\n",
    "import openpyxl\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "from matplotlib import pylab as plt\n",
    "import matplotlib.dates as mdates\n",
    "import seaborn as sns\n",
    "import sklearn\n",
    "from sklearn.model_selection import train_test_split\n",
    "from numpy.linalg import svd\n",
    "import gc\n",
    "from keijzer import *\n",
    "from tensorflow import keras\n",
    "from keras.models import Model\n",
    "from keras.layers import *\n",
    "from tensorflow.keras.optimizers import Adam,SGD\n",
    "from keras.layers import Dense, Input, Flatten, Add, concatenate, Dropout, Activation, Multiply, Embedding, Layer, Reshape\n",
    "from keras.layers import LSTM, Bidirectional, GlobalMaxPooling1D, GlobalAveragePooling1D  \n",
    "from keras.layers import Conv1D, AveragePooling1D, MaxPooling1D\n",
    "#from keras.ops import convert_to_tensor, convert_to_numpy\n",
    "#from keras.utils import plot_model\n",
    "from keras import activations\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from keras.callbacks import ModelCheckpoint, CSVLogger, EarlyStopping, LearningRateScheduler, ReduceLROnPlateau\n",
    "import math\n",
    "\n",
    "class LossHistory(tensorflow.keras.callbacks.Callback):  # history = LossHistory()\n",
    "    def init(self):  # history.init()\n",
    "        self.losses = []\n",
    "        # self.accs = []\n",
    "        self.val_losses = []\n",
    "        # self.val_accs = []\n",
    "        self.rmses = []\n",
    "        self.mses = []\n",
    "        self.maes = []\n",
    "        self.mapes = []\n",
    "        self.val_rmses = []\n",
    "        self.val_mses = []\n",
    "        self.val_maes = []\n",
    "        self.val_mapes = []\n",
    "\n",
    "    def on_epoch_end(self, batch, logs={}):\n",
    "        self.losses.append(logs.get('loss'))\n",
    "        # self.accs.append(logs.get('acc'))\n",
    "        self.val_losses.append(logs.get('val_loss'))\n",
    "        # self.val_accs.append(logs.get('val_accuracy\n",
    "        self.rmses.append(logs.get('root_mean_squared_error'))\n",
    "        self.mses.append(logs.get('mean_squared_error'))\n",
    "        self.maes.append(logs.get('mean_absolute_error'))\n",
    "        self.mapes.append(logs.get('mean_absolute_percentage_error'))\n",
    "        self.val_rmses.append(logs.get('val_root_mean_squared_error'))\n",
    "        self.val_mses.append(logs.get('val_mean_squared_error'))\n",
    "        self.val_maes.append(logs.get('val_mean_absolute_error'))\n",
    "        self.val_mapes.append(logs.get('val_mean_absolute_percentage_error'))\n",
    "\n",
    "\n",
    "\n",
    "def root_squared_mean_error(y_true, y_pred):\n",
    "    return K.mean((K.abs(y_pred - y_true))*K.square(y_true-K.mean(y_true)))*100\n",
    "\n",
    "def mse_mae(y_true, y_pred):\n",
    "    return K.mean(K.square(y_pred - y_true))+K.mean(K.abs(y_pred - y_true))\n",
    "\n",
    "from keras.layers.advanced_activations import PReLU\n",
    "\n",
    "def mean_absolute_percentage_error(y_true, y_pred):\n",
    "    y_true, y_pred = np.array(y_true), np.array(y_pred)\n",
    "    return np.mean(np.abs((y_true - y_pred) / y_true)) * 100\n",
    "\n",
    "def root_mean_squared_error(y_true, y_pred):\n",
    "        return K.sqrt(K.mean(K.square(y_pred - y_true))) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3a423b4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy as sc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0ab8856f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = '0' # 여러개 사용시 '0,1,2' 식으로 하나의 문자열에 입력\n",
    "gpus = tf.config.experimental.list_physical_devices('GPU') # 호스트 러나임에 표시되는 GPU 장치 목록 반환\n",
    "\n",
    "if gpus: # 반환된 GPU 장치 목록이 있다면\n",
    "    try: # 해당 장치에 대한 메모리 증가 활성화 여부 설정\n",
    "        tf.config.experimental.set_memory_growth(gpus[0], True)\n",
    "    except RuntimeError as e: # try문 실패시에 에러문구 출력\n",
    "        print(e)\n",
    "\n",
    "print(tf.config.list_physical_devices('GPU'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a588283e",
   "metadata": {},
   "source": [
    "## Import Data & Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "07dfdc29",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Time-Date stamp</th>\n",
       "      <th>Date</th>\n",
       "      <th>ERCOT Load</th>\n",
       "      <th>Total Wind Output</th>\n",
       "      <th>Total Wind Installed</th>\n",
       "      <th>Wind Output, % of Load</th>\n",
       "      <th>Wind Output, % of Installed</th>\n",
       "      <th>1-hr MW change</th>\n",
       "      <th>1-hr % change</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>01-01-2020 00:00:00</td>\n",
       "      <td>Jan-01</td>\n",
       "      <td>36823</td>\n",
       "      <td>12335</td>\n",
       "      <td>27040</td>\n",
       "      <td>33.5</td>\n",
       "      <td>45.617</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>01-01-2020 01:00:00</td>\n",
       "      <td>Jan-01</td>\n",
       "      <td>36511</td>\n",
       "      <td>13300</td>\n",
       "      <td>27040</td>\n",
       "      <td>36.4</td>\n",
       "      <td>49.187</td>\n",
       "      <td>965.4</td>\n",
       "      <td>7.826</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>01-01-2020 02:00:00</td>\n",
       "      <td>Jan-01</td>\n",
       "      <td>36022</td>\n",
       "      <td>13586</td>\n",
       "      <td>27040</td>\n",
       "      <td>37.7</td>\n",
       "      <td>50.245</td>\n",
       "      <td>286.2</td>\n",
       "      <td>2.152</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>01-01-2020 03:00:00</td>\n",
       "      <td>Jan-01</td>\n",
       "      <td>35790</td>\n",
       "      <td>14107</td>\n",
       "      <td>27040</td>\n",
       "      <td>39.4</td>\n",
       "      <td>52.171</td>\n",
       "      <td>520.9</td>\n",
       "      <td>3.834</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>01-01-2020 04:00:00</td>\n",
       "      <td>Jan-01</td>\n",
       "      <td>35642</td>\n",
       "      <td>14887</td>\n",
       "      <td>27040</td>\n",
       "      <td>41.8</td>\n",
       "      <td>55.055</td>\n",
       "      <td>779.6</td>\n",
       "      <td>5.527</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35060</th>\n",
       "      <td>12-31-2023 20:00:00</td>\n",
       "      <td>Dec-31</td>\n",
       "      <td>44887</td>\n",
       "      <td>17161</td>\n",
       "      <td>38631</td>\n",
       "      <td>38.23</td>\n",
       "      <td>44.42</td>\n",
       "      <td>2858</td>\n",
       "      <td>19.99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35061</th>\n",
       "      <td>12-31-2023 21:00:00</td>\n",
       "      <td>Dec-31</td>\n",
       "      <td>44013</td>\n",
       "      <td>18301</td>\n",
       "      <td>38631</td>\n",
       "      <td>41.58</td>\n",
       "      <td>47.37</td>\n",
       "      <td>1139</td>\n",
       "      <td>6.64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35062</th>\n",
       "      <td>12-31-2023 22:00:00</td>\n",
       "      <td>Dec-31</td>\n",
       "      <td>43280</td>\n",
       "      <td>18607</td>\n",
       "      <td>38631</td>\n",
       "      <td>42.99</td>\n",
       "      <td>48.17</td>\n",
       "      <td>307</td>\n",
       "      <td>1.67</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35063</th>\n",
       "      <td>12-31-2023 23:00:00</td>\n",
       "      <td>Dec-31</td>\n",
       "      <td>42319</td>\n",
       "      <td>17866</td>\n",
       "      <td>38631</td>\n",
       "      <td>42.22</td>\n",
       "      <td>46.25</td>\n",
       "      <td>-741</td>\n",
       "      <td>-3.98</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35064</th>\n",
       "      <td>01-01-2024 00:00:00</td>\n",
       "      <td>Jan-01</td>\n",
       "      <td>41682</td>\n",
       "      <td>15869</td>\n",
       "      <td>38631</td>\n",
       "      <td>38.07</td>\n",
       "      <td>41.08</td>\n",
       "      <td>-1996</td>\n",
       "      <td>-11.17</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>35065 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           Time-Date stamp    Date ERCOT Load Total Wind Output  \\\n",
       "0      01-01-2020 00:00:00  Jan-01      36823             12335   \n",
       "1      01-01-2020 01:00:00  Jan-01      36511             13300   \n",
       "2      01-01-2020 02:00:00  Jan-01      36022             13586   \n",
       "3      01-01-2020 03:00:00  Jan-01      35790             14107   \n",
       "4      01-01-2020 04:00:00  Jan-01      35642             14887   \n",
       "...                    ...     ...        ...               ...   \n",
       "35060  12-31-2023 20:00:00  Dec-31      44887             17161   \n",
       "35061  12-31-2023 21:00:00  Dec-31      44013             18301   \n",
       "35062  12-31-2023 22:00:00  Dec-31      43280             18607   \n",
       "35063  12-31-2023 23:00:00  Dec-31      42319             17866   \n",
       "35064  01-01-2024 00:00:00  Jan-01      41682             15869   \n",
       "\n",
       "      Total Wind Installed Wind Output, % of Load Wind Output, % of Installed  \\\n",
       "0                    27040                   33.5                      45.617   \n",
       "1                    27040                   36.4                      49.187   \n",
       "2                    27040                   37.7                      50.245   \n",
       "3                    27040                   39.4                      52.171   \n",
       "4                    27040                   41.8                      55.055   \n",
       "...                    ...                    ...                         ...   \n",
       "35060                38631                  38.23                       44.42   \n",
       "35061                38631                  41.58                       47.37   \n",
       "35062                38631                  42.99                       48.17   \n",
       "35063                38631                  42.22                       46.25   \n",
       "35064                38631                  38.07                       41.08   \n",
       "\n",
       "      1-hr MW change 1-hr % change  \n",
       "0                NaN           NaN  \n",
       "1              965.4         7.826  \n",
       "2              286.2         2.152  \n",
       "3              520.9         3.834  \n",
       "4              779.6         5.527  \n",
       "...              ...           ...  \n",
       "35060           2858         19.99  \n",
       "35061           1139          6.64  \n",
       "35062            307          1.67  \n",
       "35063           -741         -3.98  \n",
       "35064          -1996        -11.17  \n",
       "\n",
       "[35065 rows x 9 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_path = 'C:/Users/smartgrid_AI/Desktop/windpower_ramprate/ercot_2020.csv'\n",
    "data_source1 = pd.read_csv(data_path)\n",
    "dat_source1 = pd.DataFrame(data_source1)\n",
    "#dat_source1 = dat_source1.iloc[:-3,:]\n",
    "\n",
    "data_path = 'C:/Users/smartgrid_AI/Desktop/windpower_ramprate/ercot_2021.csv'\n",
    "data_source2 = pd.read_csv(data_path)\n",
    "dat_source2 = pd.DataFrame(data_source2)\n",
    "dat_source2 = dat_source2.iloc[:8761,:9]\n",
    "\n",
    "data_path = 'C:/Users/smartgrid_AI/Desktop/windpower_ramprate/ercot_2022.csv'\n",
    "data_source3 = pd.read_csv(data_path)\n",
    "dat_source3 = pd.DataFrame(data_source3)\n",
    "dat_source3 = dat_source3.iloc[:8760,:9]\n",
    "\n",
    "data_path = 'C:/Users/smartgrid_AI/Desktop/windpower_ramprate/ercot_2023.csv'\n",
    "data_source4 = pd.read_csv(data_path)\n",
    "dat_source4 = pd.DataFrame(data_source4)\n",
    "dat_source4 = dat_source4.iloc[:8760,:9]\n",
    "\n",
    "dat_arr1 = np.array(dat_source1)\n",
    "dat_arr2 = np.array(dat_source2)\n",
    "dat_arr3 = np.array(dat_source3)\n",
    "dat_arr4 = np.array(dat_source4)\n",
    "\n",
    "dat_arr = np.concatenate([dat_arr1, dat_arr2, dat_arr3, dat_arr4],axis=0)\n",
    "dat_arr.shape # 8784, 8761, 8760, 8760\n",
    "\n",
    "dat_source = pd.DataFrame(dat_arr, columns=['Time-Date stamp','Date','ERCOT Load','Total Wind Output','Total Wind Installed','Wind Output, % of Load','Wind Output, % of Installed','1-hr MW change','1-hr % change'])\n",
    "dat_source"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0e3ef4f",
   "metadata": {},
   "source": [
    "### Dividing by Installed Capacity & Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4454d31e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MW % change</th>\n",
       "      <th>Total Wind Output</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3.56879</td>\n",
       "      <td>0.491864</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.05769</td>\n",
       "      <td>0.502441</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.92678</td>\n",
       "      <td>0.521709</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2.88462</td>\n",
       "      <td>0.550555</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.580621</td>\n",
       "      <td>0.544749</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35059</th>\n",
       "      <td>7.3982</td>\n",
       "      <td>0.444229</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35060</th>\n",
       "      <td>2.951</td>\n",
       "      <td>0.473739</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35061</th>\n",
       "      <td>0.79211</td>\n",
       "      <td>0.48166</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35062</th>\n",
       "      <td>-1.91815</td>\n",
       "      <td>0.462478</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35063</th>\n",
       "      <td>-5.16942</td>\n",
       "      <td>0.410784</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>35064 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      MW % change Total Wind Output\n",
       "0         3.56879          0.491864\n",
       "1         1.05769          0.502441\n",
       "2         1.92678          0.521709\n",
       "3         2.88462          0.550555\n",
       "4       -0.580621          0.544749\n",
       "...           ...               ...\n",
       "35059      7.3982          0.444229\n",
       "35060       2.951          0.473739\n",
       "35061     0.79211           0.48166\n",
       "35062    -1.91815          0.462478\n",
       "35063    -5.16942          0.410784\n",
       "\n",
       "[35064 rows x 2 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dat = pd.DataFrame()\n",
    "dat['MW % change'] = np.array(dat_source.iloc[1:,3], dtype=float)-np.array(dat_source.iloc[0:-1,3], dtype=float)\n",
    "dat['MW % change'] = np.divide(np.array(dat['MW % change']),np.array(dat_source.iloc[1:,4]))*100\n",
    "dat['Total Wind Output'] = np.divide(np.array(dat_source.iloc[1:,3]), np.array(dat_source.iloc[1:,4]))\n",
    "\n",
    "dat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "28df0705",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Year</th>\n",
       "      <th>MW % change</th>\n",
       "      <th>Total Wind Output</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2020</td>\n",
       "      <td>3.56879</td>\n",
       "      <td>0.491864</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2020</td>\n",
       "      <td>1.05769</td>\n",
       "      <td>0.502441</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2020</td>\n",
       "      <td>1.92678</td>\n",
       "      <td>0.521709</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2020</td>\n",
       "      <td>2.88462</td>\n",
       "      <td>0.550555</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2020</td>\n",
       "      <td>-0.580621</td>\n",
       "      <td>0.544749</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35059</th>\n",
       "      <td>2023</td>\n",
       "      <td>7.3982</td>\n",
       "      <td>0.444229</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35060</th>\n",
       "      <td>2023</td>\n",
       "      <td>2.951</td>\n",
       "      <td>0.473739</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35061</th>\n",
       "      <td>2023</td>\n",
       "      <td>0.79211</td>\n",
       "      <td>0.48166</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35062</th>\n",
       "      <td>2023</td>\n",
       "      <td>-1.91815</td>\n",
       "      <td>0.462478</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35063</th>\n",
       "      <td>2023</td>\n",
       "      <td>-5.16942</td>\n",
       "      <td>0.410784</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>35064 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Year MW % change Total Wind Output\n",
       "0      2020     3.56879          0.491864\n",
       "1      2020     1.05769          0.502441\n",
       "2      2020     1.92678          0.521709\n",
       "3      2020     2.88462          0.550555\n",
       "4      2020   -0.580621          0.544749\n",
       "...     ...         ...               ...\n",
       "35059  2023      7.3982          0.444229\n",
       "35060  2023       2.951          0.473739\n",
       "35061  2023     0.79211           0.48166\n",
       "35062  2023    -1.91815          0.462478\n",
       "35063  2023    -5.16942          0.410784\n",
       "\n",
       "[35064 rows x 3 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ramp_ratio = 20\n",
    "load_ratio = 10\n",
    "year_arr = np.concatenate([np.ones(8784)*2020, np.ones(8760)*2021, np.ones(8760)*2022, np.ones(8760)*2023])\n",
    "year_df = pd.DataFrame(year_arr, columns=['Year'], dtype=int)\n",
    "wind_df = pd.concat([year_df, dat], axis=1)\n",
    "wind_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "182d9772",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Year</th>\n",
       "      <th>MW % change</th>\n",
       "      <th>Total Wind Output</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2020</td>\n",
       "      <td>0.620197</td>\n",
       "      <td>0.644724</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2020</td>\n",
       "      <td>0.544580</td>\n",
       "      <td>0.658617</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2020</td>\n",
       "      <td>0.570751</td>\n",
       "      <td>0.683924</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2020</td>\n",
       "      <td>0.599594</td>\n",
       "      <td>0.721813</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2020</td>\n",
       "      <td>0.495246</td>\n",
       "      <td>0.714187</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35058</th>\n",
       "      <td>2023</td>\n",
       "      <td>0.774643</td>\n",
       "      <td>0.484984</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35059</th>\n",
       "      <td>2023</td>\n",
       "      <td>0.735512</td>\n",
       "      <td>0.582157</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35060</th>\n",
       "      <td>2023</td>\n",
       "      <td>0.601593</td>\n",
       "      <td>0.620917</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35061</th>\n",
       "      <td>2023</td>\n",
       "      <td>0.536583</td>\n",
       "      <td>0.631322</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35062</th>\n",
       "      <td>2023</td>\n",
       "      <td>0.454969</td>\n",
       "      <td>0.606127</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>35063 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Year  MW % change  Total Wind Output\n",
       "0      2020     0.620197           0.644724\n",
       "1      2020     0.544580           0.658617\n",
       "2      2020     0.570751           0.683924\n",
       "3      2020     0.599594           0.721813\n",
       "4      2020     0.495246           0.714187\n",
       "...     ...          ...                ...\n",
       "35058  2023     0.774643           0.484984\n",
       "35059  2023     0.735512           0.582157\n",
       "35060  2023     0.601593           0.620917\n",
       "35061  2023     0.536583           0.631322\n",
       "35062  2023     0.454969           0.606127\n",
       "\n",
       "[35063 rows x 3 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wind_df = wind_df.reset_index(drop=True)\n",
    "\n",
    "std_scaler = sklearn.preprocessing.MinMaxScaler()\n",
    "std_scaler_load = sklearn.preprocessing.MinMaxScaler()\n",
    "std_scaler_ramp = sklearn.preprocessing.MinMaxScaler()\n",
    "\n",
    "wind_df[['Total Wind Output']] = std_scaler.fit_transform(wind_df[['Total Wind Output']])\n",
    "wind_df[['MW % change']] = std_scaler_ramp.fit_transform(wind_df[['MW % change']])\n",
    "wind_df = wind_df.iloc[:-1,:]\n",
    "wind_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8931dc71",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Year</th>\n",
       "      <th>Wind Change</th>\n",
       "      <th>Wind Output</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2020</td>\n",
       "      <td>0.620197</td>\n",
       "      <td>0.644724</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2020</td>\n",
       "      <td>0.544580</td>\n",
       "      <td>0.658617</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2020</td>\n",
       "      <td>0.570751</td>\n",
       "      <td>0.683924</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2020</td>\n",
       "      <td>0.599594</td>\n",
       "      <td>0.721813</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2020</td>\n",
       "      <td>0.495246</td>\n",
       "      <td>0.714187</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35058</th>\n",
       "      <td>2023</td>\n",
       "      <td>0.774643</td>\n",
       "      <td>0.484984</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35059</th>\n",
       "      <td>2023</td>\n",
       "      <td>0.735512</td>\n",
       "      <td>0.582157</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35060</th>\n",
       "      <td>2023</td>\n",
       "      <td>0.601593</td>\n",
       "      <td>0.620917</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35061</th>\n",
       "      <td>2023</td>\n",
       "      <td>0.536583</td>\n",
       "      <td>0.631322</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35062</th>\n",
       "      <td>2023</td>\n",
       "      <td>0.454969</td>\n",
       "      <td>0.606127</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>35063 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Year  Wind Change  Wind Output\n",
       "0      2020     0.620197     0.644724\n",
       "1      2020     0.544580     0.658617\n",
       "2      2020     0.570751     0.683924\n",
       "3      2020     0.599594     0.721813\n",
       "4      2020     0.495246     0.714187\n",
       "...     ...          ...          ...\n",
       "35058  2023     0.774643     0.484984\n",
       "35059  2023     0.735512     0.582157\n",
       "35060  2023     0.601593     0.620917\n",
       "35061  2023     0.536583     0.631322\n",
       "35062  2023     0.454969     0.606127\n",
       "\n",
       "[35063 rows x 3 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ramp_df = pd.DataFrame(wind_df)\n",
    "ramp_df.columns=['Year', 'Wind Change', 'Wind Output']\n",
    "ramp_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20af115c",
   "metadata": {},
   "source": [
    "## Wind Generation Forecasting"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "121174fb",
   "metadata": {},
   "source": [
    "### SVD-based Feature Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7891a548",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_dataset(dataset, timesteps, output_timesteps, leadtime):\n",
    "    dataX, dataY = [], []\n",
    "    for i in range(len(dataset) - timesteps -output_timesteps - leadtime - 1):\n",
    "        a = dataset[i:(i + timesteps), :]\n",
    "        dataX.append(a)\n",
    "        dataY.append(dataset[(i + timesteps + leadtime):(i+timesteps+output_timesteps+leadtime), :])\n",
    "    return np.array(dataX), np.array(dataY)\n",
    "\n",
    "def svdadd(X, start, end, b_size):\n",
    "    dec_x = X[start:end, :, :]\n",
    "    U, S, Vh = svd(dec_x.reshape(b_size, -1), full_matrices=True)\n",
    "\n",
    "    high_sig = np.matmul(np.matmul(U[:,:high_ind], np.diag(S[0:high_ind])), Vh[:high_ind,:])\n",
    "    low_sig = X[:dec_num, :, :].reshape(b_size,-1)-high_sig\n",
    "\n",
    "    rec_x = np.zeros((b_size, b_size, high_ind))\n",
    "    \n",
    "    for i in range(high_ind):\n",
    "        rec_x[:,:,i] = np.matmul((U[:,i]*S[i]).reshape(-1,1), Vh[i,:].reshape(1,-1))    \n",
    "    return rec_x, low_sig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "03c38cc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "norm_df = np.array(wind_df.iloc[:,2]).reshape(-1,1)\n",
    "timesteps = 24*7\n",
    "output_timesteps = 24\n",
    "leadtime = 6\n",
    "num_features = 1\n",
    "X, Y = create_dataset(norm_df, timesteps, output_timesteps, leadtime)\n",
    "b_size = timesteps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b4ddcdbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "dec_num = timesteps\n",
    "high_ind = 35\n",
    "\n",
    "addX = np.zeros((X.shape[0], dec_num, high_ind+1))\n",
    "\n",
    "for k in range(X.shape[0]//dec_num):\n",
    "    rec_x, low_sig = svdadd(X, k*dec_num, (k+1)*dec_num, b_size)\n",
    "    addX[k*dec_num:k*dec_num+dec_num,:, :-1] = rec_x\n",
    "    addX[k*dec_num:k*dec_num+dec_num,:, -1] = low_sig\n",
    "    \n",
    "rec_x, low_sig = svdadd(X, X.shape[0]-dec_num, X.shape[0], b_size)\n",
    "addX[X.shape[0]-dec_num:X.shape[0], :, :-1] = rec_x\n",
    "addX[X.shape[0]-dec_num:X.shape[0],:, -1] = low_sig\n",
    "\n",
    "addX_det = addX[:, :, :-1]\n",
    "addX_det = np.sum(addX_det, axis=2)\n",
    "X = np.concatenate([X, addX], axis=2)\n",
    "num_features = X.shape[2]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0796d75",
   "metadata": {},
   "source": [
    "### Training/Test Set Division & Shuffled Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b066dfa7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((31377, 168, 37), (31377, 24), (3487, 168, 37), (3487, 24))"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trvaX, teX, trvaY, teY = train_test_split(X, Y, test_size=0.1, shuffle=False)\n",
    "\n",
    "idx = np.arange(trvaX.shape[0])\n",
    "np.random.shuffle(idx)\n",
    "strvaX = trvaX[idx]\n",
    "strvaY = trvaY[idx]\n",
    "strvaY = strvaY.reshape(-1, output_timesteps)\n",
    "\n",
    "trvaY = trvaY.reshape(-1, output_timesteps)\n",
    "teY = teY.reshape(-1, output_timesteps)\n",
    "\n",
    "strX, svaX, strY, svaY = train_test_split(strvaX, strvaY, test_size=0.3, shuffle=False)\n",
    "trX, vaX, trY, vaY = train_test_split(trvaX, trvaY, test_size=0.3, shuffle=False)\n",
    "\n",
    "trvaX.shape, trvaY.shape, teX.shape, teY.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5538c05",
   "metadata": {},
   "source": [
    "## Wind Generation Forecasting Model without Attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ecc489dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def MAEMS(y_true, y_pred):\n",
    "    return K.mean((K.abs(y_pred - y_true))*K.square(y_true))*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "72d8d323",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers.advanced_activations import PReLU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "54e1785d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            [(None, 168, 37)]    0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv1d (Conv1D)                 (None, 168, 256)     9728        input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "activation (Activation)         (None, 168, 256)     0           conv1d[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "activation_1 (Activation)       (None, 168, 256)     0           conv1d[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "multiply (Multiply)             (None, 168, 256)     0           activation[0][0]                 \n",
      "                                                                 activation_1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_1 (Conv1D)               (None, 168, 37)      18981       multiply[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_2 (Activation)       (None, 168, 37)      0           conv1d_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_3 (Activation)       (None, 168, 37)      0           conv1d_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "multiply_1 (Multiply)           (None, 168, 37)      0           activation_2[0][0]               \n",
      "                                                                 activation_3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "add (Add)                       (None, 168, 37)      0           input_1[0][0]                    \n",
      "                                                                 multiply_1[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "subtract (Subtract)             (None, 168, 37)      0           input_1[0][0]                    \n",
      "                                                                 multiply_1[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_2 (Conv1D)               (None, 168, 256)     9728        add[0][0]                        \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_4 (Conv1D)               (None, 168, 256)     9728        subtract[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_4 (Activation)       (None, 168, 256)     0           conv1d_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_5 (Activation)       (None, 168, 256)     0           conv1d_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_8 (Activation)       (None, 168, 256)     0           conv1d_4[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_9 (Activation)       (None, 168, 256)     0           conv1d_4[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "multiply_2 (Multiply)           (None, 168, 256)     0           activation_4[0][0]               \n",
      "                                                                 activation_5[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "multiply_4 (Multiply)           (None, 168, 256)     0           activation_8[0][0]               \n",
      "                                                                 activation_9[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_3 (Conv1D)               (None, 168, 37)      18981       multiply_2[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_5 (Conv1D)               (None, 168, 37)      18981       multiply_4[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_6 (Activation)       (None, 168, 37)      0           conv1d_3[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_7 (Activation)       (None, 168, 37)      0           conv1d_3[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_10 (Activation)      (None, 168, 37)      0           conv1d_5[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_11 (Activation)      (None, 168, 37)      0           conv1d_5[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "multiply_3 (Multiply)           (None, 168, 37)      0           activation_6[0][0]               \n",
      "                                                                 activation_7[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "multiply_5 (Multiply)           (None, 168, 37)      0           activation_10[0][0]              \n",
      "                                                                 activation_11[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "add_1 (Add)                     (None, 168, 37)      0           add[0][0]                        \n",
      "                                                                 multiply_3[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "subtract_1 (Subtract)           (None, 168, 37)      0           subtract[0][0]                   \n",
      "                                                                 multiply_5[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "concatenate (Concatenate)       (None, 168, 148)     0           add_1[0][0]                      \n",
      "                                                                 subtract_1[0][0]                 \n",
      "                                                                 add[0][0]                        \n",
      "                                                                 subtract[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_6 (Conv1D)               (None, 168, 256)     38144       concatenate[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_8 (Conv1D)               (None, 168, 256)     38144       concatenate[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "activation_12 (Activation)      (None, 168, 256)     0           conv1d_6[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_13 (Activation)      (None, 168, 256)     0           conv1d_6[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_16 (Activation)      (None, 168, 256)     0           conv1d_8[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_17 (Activation)      (None, 168, 256)     0           conv1d_8[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "multiply_6 (Multiply)           (None, 168, 256)     0           activation_12[0][0]              \n",
      "                                                                 activation_13[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "multiply_8 (Multiply)           (None, 168, 256)     0           activation_16[0][0]              \n",
      "                                                                 activation_17[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_7 (Conv1D)               (None, 168, 37)      18981       multiply_6[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_9 (Conv1D)               (None, 168, 37)      18981       multiply_8[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_14 (Activation)      (None, 168, 37)      0           conv1d_7[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_15 (Activation)      (None, 168, 37)      0           conv1d_7[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_18 (Activation)      (None, 168, 37)      0           conv1d_9[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_19 (Activation)      (None, 168, 37)      0           conv1d_9[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "multiply_7 (Multiply)           (None, 168, 37)      0           activation_14[0][0]              \n",
      "                                                                 activation_15[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "multiply_9 (Multiply)           (None, 168, 37)      0           activation_18[0][0]              \n",
      "                                                                 activation_19[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "add_2 (Add)                     (None, 168, 37)      0           add_1[0][0]                      \n",
      "                                                                 multiply_7[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "subtract_2 (Subtract)           (None, 168, 37)      0           subtract_1[0][0]                 \n",
      "                                                                 multiply_9[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, 168, 222)     0           add_2[0][0]                      \n",
      "                                                                 subtract_2[0][0]                 \n",
      "                                                                 concatenate[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_10 (Conv1D)              (None, 168, 256)     57088       concatenate_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_12 (Conv1D)              (None, 168, 256)     57088       concatenate_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_20 (Activation)      (None, 168, 256)     0           conv1d_10[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_21 (Activation)      (None, 168, 256)     0           conv1d_10[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_24 (Activation)      (None, 168, 256)     0           conv1d_12[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_25 (Activation)      (None, 168, 256)     0           conv1d_12[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "multiply_10 (Multiply)          (None, 168, 256)     0           activation_20[0][0]              \n",
      "                                                                 activation_21[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "multiply_12 (Multiply)          (None, 168, 256)     0           activation_24[0][0]              \n",
      "                                                                 activation_25[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_11 (Conv1D)              (None, 168, 37)      18981       multiply_10[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_13 (Conv1D)              (None, 168, 37)      18981       multiply_12[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "activation_22 (Activation)      (None, 168, 37)      0           conv1d_11[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_23 (Activation)      (None, 168, 37)      0           conv1d_11[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_26 (Activation)      (None, 168, 37)      0           conv1d_13[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_27 (Activation)      (None, 168, 37)      0           conv1d_13[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "multiply_11 (Multiply)          (None, 168, 37)      0           activation_22[0][0]              \n",
      "                                                                 activation_23[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "multiply_13 (Multiply)          (None, 168, 37)      0           activation_26[0][0]              \n",
      "                                                                 activation_27[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "add_3 (Add)                     (None, 168, 37)      0           add_2[0][0]                      \n",
      "                                                                 multiply_11[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "subtract_3 (Subtract)           (None, 168, 37)      0           subtract_1[0][0]                 \n",
      "                                                                 multiply_13[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_2 (Concatenate)     (None, 168, 296)     0           add_3[0][0]                      \n",
      "                                                                 subtract_3[0][0]                 \n",
      "                                                                 concatenate_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_14 (Conv1D)              (None, 168, 256)     76032       concatenate_2[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_16 (Conv1D)              (None, 168, 256)     76032       concatenate_2[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_28 (Activation)      (None, 168, 256)     0           conv1d_14[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_29 (Activation)      (None, 168, 256)     0           conv1d_14[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_32 (Activation)      (None, 168, 256)     0           conv1d_16[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_33 (Activation)      (None, 168, 256)     0           conv1d_16[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "multiply_14 (Multiply)          (None, 168, 256)     0           activation_28[0][0]              \n",
      "                                                                 activation_29[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "multiply_16 (Multiply)          (None, 168, 256)     0           activation_32[0][0]              \n",
      "                                                                 activation_33[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_15 (Conv1D)              (None, 168, 37)      18981       multiply_14[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_17 (Conv1D)              (None, 168, 37)      18981       multiply_16[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "activation_30 (Activation)      (None, 168, 37)      0           conv1d_15[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_31 (Activation)      (None, 168, 37)      0           conv1d_15[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_34 (Activation)      (None, 168, 37)      0           conv1d_17[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_35 (Activation)      (None, 168, 37)      0           conv1d_17[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "multiply_15 (Multiply)          (None, 168, 37)      0           activation_30[0][0]              \n",
      "                                                                 activation_31[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "multiply_17 (Multiply)          (None, 168, 37)      0           activation_34[0][0]              \n",
      "                                                                 activation_35[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "add_4 (Add)                     (None, 168, 37)      0           add_3[0][0]                      \n",
      "                                                                 multiply_15[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "subtract_4 (Subtract)           (None, 168, 37)      0           subtract_3[0][0]                 \n",
      "                                                                 multiply_17[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_3 (Concatenate)     (None, 168, 370)     0           add_4[0][0]                      \n",
      "                                                                 subtract_4[0][0]                 \n",
      "                                                                 concatenate_2[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_4 (Concatenate)     (None, 168, 74)      0           add_4[0][0]                      \n",
      "                                                                 subtract_4[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_5 (Concatenate)     (None, 168, 1110)    0           concatenate[0][0]                \n",
      "                                                                 concatenate_1[0][0]              \n",
      "                                                                 concatenate_2[0][0]              \n",
      "                                                                 concatenate_3[0][0]              \n",
      "                                                                 concatenate_4[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_22 (Conv1D)              (None, 168, 720)     920880      concatenate_5[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout (Dropout)               (None, 168, 720)     0           conv1d_22[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_23 (Conv1D)              (None, 168, 360)     320040      dropout[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)             (None, 168, 360)     0           conv1d_23[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling1d (Globa (None, 360)          0           dropout_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, 24)           8664        global_average_pooling1d[0][0]   \n",
      "==================================================================================================\n",
      "Total params: 1,792,125\n",
      "Trainable params: 1,792,125\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "num_features = trvaX.shape[2]\n",
    "output_timesteps = trvaY.shape[1]\n",
    "\n",
    "with tf.device('/gpu:0'):\n",
    "    alpha=1.0\n",
    "    gamma=1.2\n",
    "    beta = 1\n",
    "    hfilters = 256\n",
    "    hkernel_size1 = 1\n",
    "    hkernel_size2 = 2\n",
    "    \n",
    "    visible1 = Input(shape=(timesteps, num_features))\n",
    "    \n",
    "    ## Series PN DCCNN Blocks 1 ~ 6\n",
    "    d1 = Conv1D(filters=round(hfilters*alpha), kernel_size=round(hkernel_size1*beta), padding='causal', dilation_rate=1)(visible1)\n",
    "    d1a = Activation(activations.tanh)(d1)\n",
    "    d1b = Activation(activations.sigmoid)(d1)\n",
    "    d1 = Multiply()([d1a, d1b])\n",
    "    \n",
    "    d1 = Conv1D(filters=num_features, kernel_size=round(hkernel_size2*beta), padding='causal', dilation_rate=2)(d1)\n",
    "    d1a = Activation(activations.tanh)(d1)\n",
    "    d1b = Activation(activations.sigmoid)(d1)\n",
    "    d1 = Multiply()([d1a, d1b])\n",
    "    \n",
    "    res01a = Add()([visible1, d1])   # (100, 25) (100, 25)\n",
    "    res01b = Subtract()([visible1, d1])\n",
    "\n",
    "    d1 = Conv1D(filters=round(hfilters*alpha), kernel_size=round(hkernel_size1*beta), padding='causal', dilation_rate=2)(res01a)\n",
    "    d1a = Activation(activations.tanh)(d1)\n",
    "    d1b = Activation(activations.sigmoid)(d1)\n",
    "    d1 = Multiply()([d1a, d1b])\n",
    "    \n",
    "    d1 = Conv1D(filters=num_features, kernel_size=round(hkernel_size2*beta), padding='causal', dilation_rate=4)(d1)    \n",
    "    d1a = Activation(activations.tanh)(d1)\n",
    "    d1b = Activation(activations.sigmoid)(d1)\n",
    "    \n",
    "    d1 = Multiply()([d1a, d1b])\n",
    "    res02a = Add()([res01a, d1])   # (100, 25) (100, 25)\n",
    "    \n",
    "    d2 = Conv1D(filters=round(hfilters*alpha), kernel_size=round(hkernel_size1*beta), padding='causal', dilation_rate=2)(res01b) \n",
    "    d2a = Activation(activations.tanh)(d2)\n",
    "    d2b = Activation(activations.sigmoid)(d2)\n",
    "    d2 = Multiply()([d2a, d2b])\n",
    "    \n",
    "    d2 = Conv1D(filters=num_features, kernel_size=round(hkernel_size2*beta), padding='causal', dilation_rate=4)(d2) \n",
    "    d2a = Activation(activations.tanh)(d2)\n",
    "    d2b = Activation(activations.sigmoid)(d2)\n",
    "    d2 = Multiply()([d2a, d2b])\n",
    "    \n",
    "    res02b = Subtract()([res01b, d2])   # (100, 25) (100, 25) \n",
    "    res02 = Concatenate()([res02a, res02b, res01a, res01b])\n",
    "    \n",
    "    d1 = Conv1D(filters=round(hfilters*alpha), kernel_size=round(hkernel_size1*beta), padding='causal', dilation_rate=4)(res02)\n",
    "    d1a = Activation(activations.tanh)(d1)\n",
    "    d1b = Activation(activations.sigmoid)(d1)\n",
    "    d1 = Multiply()([d1a, d1b])\n",
    "    \n",
    "    d1 = Conv1D(filters=num_features, kernel_size=round(hkernel_size2*beta), padding='causal', dilation_rate=8)(d1)    \n",
    "    d1a = Activation(activations.tanh)(d1)\n",
    "    d1b = Activation(activations.sigmoid)(d1)\n",
    "    d1 = Multiply()([d1a, d1b])\n",
    "    \n",
    "    res03a = Add()([res02a, d1])   # (100, 25) (100, 25)\n",
    "    \n",
    "    d2 = Conv1D(filters=round(hfilters*alpha), kernel_size=round(hkernel_size1*beta), padding='causal', dilation_rate=4)(res02) \n",
    "    d2a = Activation(activations.tanh)(d2)\n",
    "    d2b = Activation(activations.sigmoid)(d2)\n",
    "    d2 = Multiply()([d2a, d2b])\n",
    "    \n",
    "    d2 = Conv1D(filters=num_features, kernel_size=round(hkernel_size2*beta), padding='causal', dilation_rate=8)(d2) \n",
    "    d2a = Activation(activations.tanh)(d2)\n",
    "    d2b = Activation(activations.sigmoid)(d2)\n",
    "    d2 = Multiply()([d2a, d2b])\n",
    "    \n",
    "    res03b = Subtract()([res02b, d2])   # (100, 25) (100, 25)\n",
    "    res03 = Concatenate()([res03a, res03b, res02])\n",
    "    \n",
    "    d1 = Conv1D(filters=round(hfilters*alpha), kernel_size=round(hkernel_size1*beta), padding='causal', dilation_rate=8)(res03)\n",
    "    d1a = Activation(activations.tanh)(d1)\n",
    "    d1b = Activation(activations.sigmoid)(d1)\n",
    "    d1 = Multiply()([d1a, d1b])\n",
    "    d1 = Conv1D(filters=num_features, kernel_size=round(hkernel_size2*beta), padding='causal', dilation_rate=4)(d1)    \n",
    "    d1a = Activation(activations.tanh)(d1)\n",
    "    d1b = Activation(activations.sigmoid)(d1)\n",
    "    d1 = Multiply()([d1a, d1b])\n",
    "    res04a = Add()([res03a, d1])   # (100, 25) (100, 25)\n",
    "    \n",
    "    d2 = Conv1D(filters=round(hfilters*alpha), kernel_size=round(hkernel_size1*beta), padding='causal', dilation_rate=8)(res03) \n",
    "    d2a = Activation(activations.tanh)(d2)\n",
    "    d2b = Activation(activations.sigmoid)(d2)\n",
    "    d2 = Multiply()([d2a, d2b])\n",
    "    \n",
    "    d2 = Conv1D(filters=num_features, kernel_size=round(hkernel_size2*beta), padding='causal', dilation_rate=4)(d2) \n",
    "    d2a = Activation(activations.tanh)(d2)\n",
    "    d2b = Activation(activations.sigmoid)(d2)\n",
    "    d2 = Multiply()([d2a, d2b])\n",
    "    \n",
    "    res04b = Subtract()([res02b, d2])   # (100, 25) (100, 25)\n",
    "    res04 = Concatenate()([res04a, res04b, res03])\n",
    "    \n",
    "    d1 = Conv1D(filters=round(hfilters*alpha), kernel_size=round(hkernel_size1*beta), padding='causal', dilation_rate=4)(res04)\n",
    "    d1a = Activation(activations.tanh)(d1)\n",
    "    d1b = Activation(activations.sigmoid)(d1)\n",
    "    d1 = Multiply()([d1a, d1b])\n",
    "    \n",
    "    d1 = Conv1D(filters=num_features, kernel_size=round(hkernel_size2*beta), padding='causal', dilation_rate=2)(d1)    \n",
    "    d1a = Activation(activations.tanh)(d1)\n",
    "    d1b = Activation(activations.sigmoid)(d1)\n",
    "    d1 = Multiply()([d1a, d1b])\n",
    "    \n",
    "    res05a = Add()([res04a, d1])   # (100, 25) (100, 25)\n",
    "    \n",
    "    d2 = Conv1D(filters=round(hfilters*alpha), kernel_size=round(hkernel_size1*beta), padding='causal', dilation_rate=4)(res04) \n",
    "    d2a = Activation(activations.tanh)(d2)\n",
    "    d2b = Activation(activations.sigmoid)(d2)\n",
    "    d2 = Multiply()([d2a, d2b])\n",
    "    \n",
    "    d2 = Conv1D(filters=num_features, kernel_size=round(hkernel_size2*beta), padding='causal', dilation_rate=2)(d2) \n",
    "    d2a = Activation(activations.tanh)(d2)\n",
    "    d2b = Activation(activations.sigmoid)(d2)\n",
    "    d2 = Multiply()([d2a, d2b])\n",
    "    \n",
    "    res05b = Subtract()([res04b, d2])   # (100, 25) (100, 25)\n",
    "    res05 = Concatenate()([res05a, res05b, res04])\n",
    "    \n",
    "    d1 = Conv1D(filters=round(hfilters*alpha), kernel_size=round(hkernel_size1*beta), padding='causal', dilation_rate=2)(res05)\n",
    "    d1a = Activation(activations.tanh)(d1)\n",
    "    d1b = Activation(activations.sigmoid)(d1)\n",
    "    d1 = Multiply()([d1a, d1b])\n",
    "    \n",
    "    d1 = Conv1D(filters=num_features, kernel_size=round(hkernel_size2*beta), padding='causal', dilation_rate=1)(d1)    \n",
    "    d1a = Activation(activations.tanh)(d1)\n",
    "    d1b = Activation(activations.sigmoid)(d1)\n",
    "    d1 = Multiply()([d1a, d1b])\n",
    "\n",
    "    res06a = Add()([res05a, d1])   # (100, 25) (100, 25)\n",
    "    \n",
    "    d2 = Conv1D(filters=round(hfilters*alpha), kernel_size=round(hkernel_size1*beta), padding='causal', dilation_rate=2)(res05) \n",
    "    d2a = Activation(activations.tanh)(d2)\n",
    "    d2b = Activation(activations.sigmoid)(d2)\n",
    "    d2 = Multiply()([d2a, d2b])\n",
    "    d2 = Conv1D(filters=num_features, kernel_size=round(hkernel_size2*beta), padding='causal', dilation_rate=1)(d2) \n",
    "    d2a = Activation(activations.tanh)(d2)\n",
    "    d2b = Activation(activations.sigmoid)(d2)\n",
    "    d2 = Multiply()([d2a, d2b])\n",
    "\n",
    "    res06b = Subtract()([res05b, d2])   # (100, 25) (100, 25)\n",
    "    res06 = Concatenate()([res05a, res05b])\n",
    "    \n",
    "    res10 = Concatenate()([res02, res03, res04, res05, res06])   # \n",
    "    \n",
    "    #print('res10 :', res10.shap)  # (None, 24, 11) \n",
    "    \n",
    "    ## Output Block\n",
    "    out = Conv1D(720, 1, padding='same', activation=PReLU())(res10)   # 256, 11X10=110\n",
    "    out = Dropout(0.2)(out)   #SpatialDropout1D\n",
    "    \n",
    "    out = Conv1D(360, 1, padding='same', activation=PReLU())(out) # 512,  110X5=550\n",
    "    out = Dropout(0.2)(out)\n",
    "    \n",
    "    out = GlobalAveragePooling1D()(out) # pool_size=2, strides=1\n",
    "    \n",
    "    out = Dense(24)(out) \n",
    "    model = Model(inputs=[visible1], outputs=[out])\n",
    "    \n",
    "    print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "4ce760df",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1046"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "7f6d9a67",
   "metadata": {},
   "outputs": [],
   "source": [
    "    model.compile(loss=MAEMS, optimizer='adam', metrics=['mse','mae', MAEMS])\n",
    "    early_stopping =EarlyStopping(monitor='val_loss', patience=10)\n",
    "    batch_size = 100\n",
    "    epochs = 1000\n",
    "    #root_squared_mean_error\n",
    "    history = LossHistory()\n",
    "    history.init()\n",
    "    \n",
    "    #hist = model.fit(trX, trY, epochs=epochs, batch_size=batch_size, shuffle=False, validation_data=(vaX, vaY), callbacks=[history, early_stopping])  # , checkpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "816c2629",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "  6/131 [>.............................] - ETA: 14s - loss: 8.1351 - mse: 0.1518 - mae: 0.3158 - MAEMS: 8.1351WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0491s vs `on_train_batch_end` time: 0.0581s). Check your callbacks.\n",
      "131/131 [==============================] - 23s 150ms/step - loss: 3.8225 - mse: 0.1001 - mae: 0.2584 - MAEMS: 3.8211 - val_loss: 3.4550 - val_mse: 0.0842 - val_mae: 0.2368 - val_MAEMS: 3.4660\n",
      "Epoch 2/1000\n",
      "131/131 [==============================] - 18s 136ms/step - loss: 3.2203 - mse: 0.0782 - mae: 0.2264 - MAEMS: 3.2195 - val_loss: 3.0627 - val_mse: 0.0598 - val_mae: 0.1976 - val_MAEMS: 3.0641\n",
      "Epoch 3/1000\n",
      "131/131 [==============================] - 18s 137ms/step - loss: 2.9615 - mse: 0.0628 - mae: 0.2012 - MAEMS: 2.9610 - val_loss: 2.9920 - val_mse: 0.0495 - val_mae: 0.1788 - val_MAEMS: 2.9977\n",
      "Epoch 4/1000\n",
      "131/131 [==============================] - 18s 136ms/step - loss: 2.8418 - mse: 0.0584 - mae: 0.1922 - MAEMS: 2.8413 - val_loss: 2.7933 - val_mse: 0.0496 - val_mae: 0.1762 - val_MAEMS: 2.7943\n",
      "Epoch 5/1000\n",
      "131/131 [==============================] - 18s 136ms/step - loss: 2.7385 - mse: 0.0550 - mae: 0.1847 - MAEMS: 2.7378 - val_loss: 2.6659 - val_mse: 0.0476 - val_mae: 0.1708 - val_MAEMS: 2.6627\n",
      "Epoch 6/1000\n",
      "131/131 [==============================] - 18s 136ms/step - loss: 2.6062 - mse: 0.0518 - mae: 0.1775 - MAEMS: 2.6056 - val_loss: 2.5650 - val_mse: 0.0440 - val_mae: 0.1622 - val_MAEMS: 2.5574\n",
      "Epoch 7/1000\n",
      "131/131 [==============================] - 18s 136ms/step - loss: 2.4639 - mse: 0.0479 - mae: 0.1689 - MAEMS: 2.4634 - val_loss: 2.4264 - val_mse: 0.0406 - val_mae: 0.1542 - val_MAEMS: 2.4162\n",
      "Epoch 8/1000\n",
      "131/131 [==============================] - 18s 136ms/step - loss: 2.3389 - mse: 0.0444 - mae: 0.1610 - MAEMS: 2.3385 - val_loss: 2.2758 - val_mse: 0.0437 - val_mae: 0.1587 - val_MAEMS: 2.2679\n",
      "Epoch 9/1000\n",
      "131/131 [==============================] - 18s 137ms/step - loss: 2.2133 - mse: 0.0412 - mae: 0.1537 - MAEMS: 2.2126 - val_loss: 2.2617 - val_mse: 0.0329 - val_mae: 0.1373 - val_MAEMS: 2.2561\n",
      "Epoch 10/1000\n",
      "131/131 [==============================] - 18s 137ms/step - loss: 2.0846 - mse: 0.0379 - mae: 0.1459 - MAEMS: 2.0844 - val_loss: 2.1250 - val_mse: 0.0313 - val_mae: 0.1331 - val_MAEMS: 2.1198\n",
      "Epoch 11/1000\n",
      "131/131 [==============================] - 18s 137ms/step - loss: 2.0193 - mse: 0.0358 - mae: 0.1411 - MAEMS: 2.0190 - val_loss: 2.0757 - val_mse: 0.0299 - val_mae: 0.1295 - val_MAEMS: 2.0683\n",
      "Epoch 12/1000\n",
      "131/131 [==============================] - 18s 137ms/step - loss: 1.9215 - mse: 0.0336 - mae: 0.1354 - MAEMS: 1.9212 - val_loss: 1.9095 - val_mse: 0.0299 - val_mae: 0.1275 - val_MAEMS: 1.9018\n",
      "Epoch 13/1000\n",
      "131/131 [==============================] - 18s 137ms/step - loss: 1.8068 - mse: 0.0312 - mae: 0.1289 - MAEMS: 1.8065 - val_loss: 1.8050 - val_mse: 0.0287 - val_mae: 0.1239 - val_MAEMS: 1.7998\n",
      "Epoch 14/1000\n",
      "131/131 [==============================] - 18s 137ms/step - loss: 1.7246 - mse: 0.0290 - mae: 0.1234 - MAEMS: 1.7243 - val_loss: 1.7146 - val_mse: 0.0275 - val_mae: 0.1200 - val_MAEMS: 1.7102\n",
      "Epoch 15/1000\n",
      "131/131 [==============================] - 18s 137ms/step - loss: 1.6822 - mse: 0.0278 - mae: 0.1203 - MAEMS: 1.6818 - val_loss: 1.7500 - val_mse: 0.0234 - val_mae: 0.1110 - val_MAEMS: 1.7448\n",
      "Epoch 16/1000\n",
      "131/131 [==============================] - 18s 137ms/step - loss: 1.6867 - mse: 0.0269 - mae: 0.1185 - MAEMS: 1.6868 - val_loss: 1.8471 - val_mse: 0.0228 - val_mae: 0.1110 - val_MAEMS: 1.8453\n",
      "Epoch 17/1000\n",
      "131/131 [==============================] - 18s 137ms/step - loss: 1.6106 - mse: 0.0257 - mae: 0.1148 - MAEMS: 1.6103 - val_loss: 1.6030 - val_mse: 0.0247 - val_mae: 0.1126 - val_MAEMS: 1.5996\n",
      "Epoch 18/1000\n",
      "131/131 [==============================] - 18s 137ms/step - loss: 1.5542 - mse: 0.0244 - mae: 0.1112 - MAEMS: 1.5540 - val_loss: 1.5453 - val_mse: 0.0226 - val_mae: 0.1068 - val_MAEMS: 1.5421\n",
      "Epoch 19/1000\n",
      "131/131 [==============================] - 18s 137ms/step - loss: 1.4845 - mse: 0.0231 - mae: 0.1072 - MAEMS: 1.4843 - val_loss: 1.5289 - val_mse: 0.0242 - val_mae: 0.1108 - val_MAEMS: 1.5269\n",
      "Epoch 20/1000\n",
      "131/131 [==============================] - 18s 137ms/step - loss: 1.4481 - mse: 0.0221 - mae: 0.1045 - MAEMS: 1.4478 - val_loss: 1.4315 - val_mse: 0.0230 - val_mae: 0.1064 - val_MAEMS: 1.4304\n",
      "Epoch 21/1000\n",
      "131/131 [==============================] - 18s 137ms/step - loss: 1.4398 - mse: 0.0215 - mae: 0.1031 - MAEMS: 1.4397 - val_loss: 1.4825 - val_mse: 0.0203 - val_mae: 0.1006 - val_MAEMS: 1.4766\n",
      "Epoch 22/1000\n",
      "131/131 [==============================] - 18s 137ms/step - loss: 1.4557 - mse: 0.0211 - mae: 0.1024 - MAEMS: 1.4553 - val_loss: 1.4185 - val_mse: 0.0197 - val_mae: 0.0983 - val_MAEMS: 1.4202\n",
      "Epoch 23/1000\n",
      "131/131 [==============================] - 18s 137ms/step - loss: 1.4353 - mse: 0.0206 - mae: 0.1009 - MAEMS: 1.4350 - val_loss: 1.7960 - val_mse: 0.0169 - val_mae: 0.0958 - val_MAEMS: 1.7949\n",
      "Epoch 24/1000\n",
      "131/131 [==============================] - 18s 137ms/step - loss: 1.3721 - mse: 0.0198 - mae: 0.0981 - MAEMS: 1.3720 - val_loss: 1.5528 - val_mse: 0.0177 - val_mae: 0.0950 - val_MAEMS: 1.5477\n",
      "Epoch 25/1000\n",
      "131/131 [==============================] - 18s 136ms/step - loss: 1.3027 - mse: 0.0187 - mae: 0.0944 - MAEMS: 1.3025 - val_loss: 1.4599 - val_mse: 0.0167 - val_mae: 0.0913 - val_MAEMS: 1.4627\n",
      "Epoch 26/1000\n",
      "131/131 [==============================] - 18s 136ms/step - loss: 1.2679 - mse: 0.0179 - mae: 0.0920 - MAEMS: 1.2677 - val_loss: 1.6098 - val_mse: 0.0154 - val_mae: 0.0899 - val_MAEMS: 1.6102\n",
      "Epoch 27/1000\n",
      "131/131 [==============================] - 18s 136ms/step - loss: 1.2854 - mse: 0.0178 - mae: 0.0918 - MAEMS: 1.2851 - val_loss: 1.5712 - val_mse: 0.0153 - val_mae: 0.0892 - val_MAEMS: 1.5684\n",
      "Epoch 28/1000\n",
      "131/131 [==============================] - 18s 135ms/step - loss: 1.2796 - mse: 0.0174 - mae: 0.0909 - MAEMS: 1.2797 - val_loss: 1.3206 - val_mse: 0.0172 - val_mae: 0.0909 - val_MAEMS: 1.3191\n",
      "Epoch 29/1000\n",
      "131/131 [==============================] - 18s 135ms/step - loss: 1.2643 - mse: 0.0171 - mae: 0.0897 - MAEMS: 1.2644 - val_loss: 1.2915 - val_mse: 0.0188 - val_mae: 0.0946 - val_MAEMS: 1.2902\n",
      "Epoch 30/1000\n",
      "131/131 [==============================] - 18s 135ms/step - loss: 1.2640 - mse: 0.0168 - mae: 0.0889 - MAEMS: 1.2638 - val_loss: 1.3094 - val_mse: 0.0192 - val_mae: 0.0962 - val_MAEMS: 1.3073\n",
      "Epoch 31/1000\n",
      "131/131 [==============================] - 18s 135ms/step - loss: 1.3187 - mse: 0.0171 - mae: 0.0907 - MAEMS: 1.3189 - val_loss: 1.4781 - val_mse: 0.0148 - val_mae: 0.0863 - val_MAEMS: 1.4779\n",
      "Epoch 32/1000\n",
      "131/131 [==============================] - 18s 136ms/step - loss: 1.2320 - mse: 0.0163 - mae: 0.0873 - MAEMS: 1.2319 - val_loss: 1.5444 - val_mse: 0.0137 - val_mae: 0.0845 - val_MAEMS: 1.5458\n",
      "Epoch 33/1000\n",
      "131/131 [==============================] - 18s 135ms/step - loss: 1.1861 - mse: 0.0156 - mae: 0.0849 - MAEMS: 1.1857 - val_loss: 1.4408 - val_mse: 0.0134 - val_mae: 0.0822 - val_MAEMS: 1.4463\n",
      "Epoch 34/1000\n",
      "131/131 [==============================] - 18s 135ms/step - loss: 1.1812 - mse: 0.0153 - mae: 0.0839 - MAEMS: 1.1812 - val_loss: 1.3152 - val_mse: 0.0139 - val_mae: 0.0819 - val_MAEMS: 1.3141\n",
      "Epoch 35/1000\n",
      "131/131 [==============================] - 18s 135ms/step - loss: 1.1834 - mse: 0.0149 - mae: 0.0830 - MAEMS: 1.1832 - val_loss: 1.1945 - val_mse: 0.0146 - val_mae: 0.0824 - val_MAEMS: 1.1899\n",
      "Epoch 36/1000\n",
      "131/131 [==============================] - 18s 135ms/step - loss: 1.1871 - mse: 0.0149 - mae: 0.0829 - MAEMS: 1.1868 - val_loss: 1.2543 - val_mse: 0.0134 - val_mae: 0.0797 - val_MAEMS: 1.2527\n",
      "Epoch 37/1000\n",
      "131/131 [==============================] - 18s 136ms/step - loss: 1.1654 - mse: 0.0145 - mae: 0.0818 - MAEMS: 1.1652 - val_loss: 1.1647 - val_mse: 0.0148 - val_mae: 0.0828 - val_MAEMS: 1.1639\n",
      "Epoch 38/1000\n",
      "131/131 [==============================] - 18s 135ms/step - loss: 1.1380 - mse: 0.0142 - mae: 0.0805 - MAEMS: 1.1379 - val_loss: 1.2170 - val_mse: 0.0149 - val_mae: 0.0839 - val_MAEMS: 1.2163\n",
      "Epoch 39/1000\n",
      "131/131 [==============================] - 18s 135ms/step - loss: 1.1853 - mse: 0.0142 - mae: 0.0813 - MAEMS: 1.1853 - val_loss: 1.3761 - val_mse: 0.0146 - val_mae: 0.0850 - val_MAEMS: 1.3734\n",
      "Epoch 40/1000\n",
      "131/131 [==============================] - 18s 136ms/step - loss: 1.2207 - mse: 0.0145 - mae: 0.0827 - MAEMS: 1.2206 - val_loss: 1.6077 - val_mse: 0.0127 - val_mae: 0.0824 - val_MAEMS: 1.6118\n",
      "Epoch 41/1000\n",
      "131/131 [==============================] - 18s 136ms/step - loss: 1.1216 - mse: 0.0137 - mae: 0.0788 - MAEMS: 1.1214 - val_loss: 1.3493 - val_mse: 0.0122 - val_mae: 0.0779 - val_MAEMS: 1.3560\n",
      "Epoch 42/1000\n",
      "131/131 [==============================] - 18s 135ms/step - loss: 1.0934 - mse: 0.0132 - mae: 0.0771 - MAEMS: 1.0932 - val_loss: 1.3040 - val_mse: 0.0122 - val_mae: 0.0769 - val_MAEMS: 1.3056\n",
      "Epoch 43/1000\n",
      "131/131 [==============================] - 18s 136ms/step - loss: 1.1005 - mse: 0.0131 - mae: 0.0770 - MAEMS: 1.1004 - val_loss: 1.3816 - val_mse: 0.0115 - val_mae: 0.0762 - val_MAEMS: 1.3839\n",
      "Epoch 44/1000\n",
      "131/131 [==============================] - 18s 136ms/step - loss: 1.0798 - mse: 0.0128 - mae: 0.0756 - MAEMS: 1.0799 - val_loss: 1.6066 - val_mse: 0.0116 - val_mae: 0.0791 - val_MAEMS: 1.6125\n",
      "Epoch 45/1000\n",
      "131/131 [==============================] - 18s 135ms/step - loss: 1.0680 - mse: 0.0126 - mae: 0.0750 - MAEMS: 1.0679 - val_loss: 1.5048 - val_mse: 0.0108 - val_mae: 0.0759 - val_MAEMS: 1.5150\n",
      "Epoch 46/1000\n",
      "131/131 [==============================] - 18s 136ms/step - loss: 1.0614 - mse: 0.0124 - mae: 0.0743 - MAEMS: 1.0613 - val_loss: 1.4248 - val_mse: 0.0109 - val_mae: 0.0747 - val_MAEMS: 1.4250\n",
      "Epoch 47/1000\n",
      "131/131 [==============================] - 18s 136ms/step - loss: 1.0480 - mse: 0.0121 - mae: 0.0732 - MAEMS: 1.0478 - val_loss: 1.3639 - val_mse: 0.0110 - val_mae: 0.0745 - val_MAEMS: 1.3683\n",
      "Wall time: 14min 3s\n"
     ]
    }
   ],
   "source": [
    "    %%time\n",
    "    b_size = 168\n",
    "    hist = model.fit(strX, strY, epochs=epochs, batch_size=b_size, shuffle=False, validation_data=(svaX, svaY), callbacks=[history, early_stopping])  # , checkpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "9d3aa4a6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4601"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "1f2877f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#np.savetxt('losshistory.txt',(loss_history,valloss_history))\n",
    "model.save('Basic Model_woAttention.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "00049683",
   "metadata": {},
   "outputs": [],
   "source": [
    "testPredict = model.predict(teX, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "631507f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.device('/gpu:0'):\n",
    "    model = keras.models.load_model('Basic Model_woAttention.h5', custom_objects={'MAEMS': MAEMS})\n",
    "    gc.collect()\n",
    "    testPredict = model.predict(teX, batch_size=b_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9d9478a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def npMAEMS(y_true, y_pred):\n",
    "    return np.mean((abs(y_pred - y_true))*np.square(y_true))*100\n",
    "def npMAEMD(y_true, y_pred):\n",
    "    return np.mean((abs(y_pred - y_true))*np.square(y_true-np.mean(y_true)))*100\n",
    "def npMSE(y_true, y_pred):\n",
    "    return np.mean(np.square(-y_true+y_pred))\n",
    "def npMAE(y_true, y_pred):\n",
    "    return np.mean(abs(-y_true+y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "49cf7d6c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error Test Score > MSE ==  0.030224472135409457  MAE ==  0.1411006623545907  MAEMS ==  2.4878017545532636\n"
     ]
    }
   ],
   "source": [
    "tePredict = testPredict.reshape(-1)\n",
    "testY = teY.reshape(-1)\n",
    "print('Error Test Score > MSE == ', npMSE(testY, tePredict), ' MAE == ', npMAE(testY, tePredict), ' MAEMS == ', npMAEMS(testY, tePredict))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97c3bcbb",
   "metadata": {},
   "source": [
    "## Without Output Block"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "b8521fc6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_2 (InputLayer)            [(None, 168, 37)]    0                                            \n",
      "__________________________________________________________________________________________________\n",
      "permute (Permute)               (None, 37, 168)      0           input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 37, 168)      28392       permute[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_2 (Dense)                 (None, 37, 168)      28392       permute[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "multiply_22 (Multiply)          (None, 37, 168)      0           dense_1[0][0]                    \n",
      "                                                                 dense_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "attention_vec (Permute)         (None, 168, 37)      0           multiply_22[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "multiply_23 (Multiply)          (None, 168, 37)      0           input_2[0][0]                    \n",
      "                                                                 attention_vec[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_24 (Conv1D)              (None, 168, 256)     9728        multiply_23[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "activation_44 (Activation)      (None, 168, 256)     0           conv1d_24[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_45 (Activation)      (None, 168, 256)     0           conv1d_24[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "multiply_24 (Multiply)          (None, 168, 256)     0           activation_44[0][0]              \n",
      "                                                                 activation_45[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_25 (Conv1D)              (None, 168, 37)      18981       multiply_24[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "activation_46 (Activation)      (None, 168, 37)      0           conv1d_25[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_47 (Activation)      (None, 168, 37)      0           conv1d_25[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "multiply_25 (Multiply)          (None, 168, 37)      0           activation_46[0][0]              \n",
      "                                                                 activation_47[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "add_6 (Add)                     (None, 168, 37)      0           input_2[0][0]                    \n",
      "                                                                 multiply_25[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "subtract_6 (Subtract)           (None, 168, 37)      0           input_2[0][0]                    \n",
      "                                                                 multiply_25[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_26 (Conv1D)              (None, 168, 256)     9728        add_6[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_28 (Conv1D)              (None, 168, 256)     9728        subtract_6[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_48 (Activation)      (None, 168, 256)     0           conv1d_26[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_49 (Activation)      (None, 168, 256)     0           conv1d_26[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_52 (Activation)      (None, 168, 256)     0           conv1d_28[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_53 (Activation)      (None, 168, 256)     0           conv1d_28[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "multiply_26 (Multiply)          (None, 168, 256)     0           activation_48[0][0]              \n",
      "                                                                 activation_49[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "multiply_28 (Multiply)          (None, 168, 256)     0           activation_52[0][0]              \n",
      "                                                                 activation_53[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_27 (Conv1D)              (None, 168, 37)      18981       multiply_26[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_29 (Conv1D)              (None, 168, 37)      18981       multiply_28[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "activation_50 (Activation)      (None, 168, 37)      0           conv1d_27[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_51 (Activation)      (None, 168, 37)      0           conv1d_27[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_54 (Activation)      (None, 168, 37)      0           conv1d_29[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_55 (Activation)      (None, 168, 37)      0           conv1d_29[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "multiply_27 (Multiply)          (None, 168, 37)      0           activation_50[0][0]              \n",
      "                                                                 activation_51[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "multiply_29 (Multiply)          (None, 168, 37)      0           activation_54[0][0]              \n",
      "                                                                 activation_55[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "add_7 (Add)                     (None, 168, 37)      0           add_6[0][0]                      \n",
      "                                                                 multiply_27[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "subtract_7 (Subtract)           (None, 168, 37)      0           subtract_6[0][0]                 \n",
      "                                                                 multiply_29[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_6 (Concatenate)     (None, 168, 148)     0           add_7[0][0]                      \n",
      "                                                                 subtract_7[0][0]                 \n",
      "                                                                 add_6[0][0]                      \n",
      "                                                                 subtract_6[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_30 (Conv1D)              (None, 168, 256)     38144       concatenate_6[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_32 (Conv1D)              (None, 168, 256)     38144       concatenate_6[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_56 (Activation)      (None, 168, 256)     0           conv1d_30[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_57 (Activation)      (None, 168, 256)     0           conv1d_30[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_60 (Activation)      (None, 168, 256)     0           conv1d_32[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_61 (Activation)      (None, 168, 256)     0           conv1d_32[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "multiply_30 (Multiply)          (None, 168, 256)     0           activation_56[0][0]              \n",
      "                                                                 activation_57[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "multiply_32 (Multiply)          (None, 168, 256)     0           activation_60[0][0]              \n",
      "                                                                 activation_61[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_31 (Conv1D)              (None, 168, 37)      18981       multiply_30[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_33 (Conv1D)              (None, 168, 37)      18981       multiply_32[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "activation_58 (Activation)      (None, 168, 37)      0           conv1d_31[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_59 (Activation)      (None, 168, 37)      0           conv1d_31[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_62 (Activation)      (None, 168, 37)      0           conv1d_33[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_63 (Activation)      (None, 168, 37)      0           conv1d_33[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "multiply_31 (Multiply)          (None, 168, 37)      0           activation_58[0][0]              \n",
      "                                                                 activation_59[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "multiply_33 (Multiply)          (None, 168, 37)      0           activation_62[0][0]              \n",
      "                                                                 activation_63[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "add_8 (Add)                     (None, 168, 37)      0           add_7[0][0]                      \n",
      "                                                                 multiply_31[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "subtract_8 (Subtract)           (None, 168, 37)      0           subtract_7[0][0]                 \n",
      "                                                                 multiply_33[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_7 (Concatenate)     (None, 168, 222)     0           add_8[0][0]                      \n",
      "                                                                 subtract_8[0][0]                 \n",
      "                                                                 concatenate_6[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_34 (Conv1D)              (None, 168, 256)     57088       concatenate_7[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_36 (Conv1D)              (None, 168, 256)     57088       concatenate_7[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_64 (Activation)      (None, 168, 256)     0           conv1d_34[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_65 (Activation)      (None, 168, 256)     0           conv1d_34[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_68 (Activation)      (None, 168, 256)     0           conv1d_36[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_69 (Activation)      (None, 168, 256)     0           conv1d_36[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "multiply_34 (Multiply)          (None, 168, 256)     0           activation_64[0][0]              \n",
      "                                                                 activation_65[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "multiply_36 (Multiply)          (None, 168, 256)     0           activation_68[0][0]              \n",
      "                                                                 activation_69[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_35 (Conv1D)              (None, 168, 37)      18981       multiply_34[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_37 (Conv1D)              (None, 168, 37)      18981       multiply_36[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "activation_66 (Activation)      (None, 168, 37)      0           conv1d_35[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_67 (Activation)      (None, 168, 37)      0           conv1d_35[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_70 (Activation)      (None, 168, 37)      0           conv1d_37[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_71 (Activation)      (None, 168, 37)      0           conv1d_37[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "multiply_35 (Multiply)          (None, 168, 37)      0           activation_66[0][0]              \n",
      "                                                                 activation_67[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "multiply_37 (Multiply)          (None, 168, 37)      0           activation_70[0][0]              \n",
      "                                                                 activation_71[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "add_9 (Add)                     (None, 168, 37)      0           add_8[0][0]                      \n",
      "                                                                 multiply_35[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "subtract_9 (Subtract)           (None, 168, 37)      0           subtract_7[0][0]                 \n",
      "                                                                 multiply_37[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_8 (Concatenate)     (None, 168, 296)     0           add_9[0][0]                      \n",
      "                                                                 subtract_9[0][0]                 \n",
      "                                                                 concatenate_7[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_38 (Conv1D)              (None, 168, 256)     76032       concatenate_8[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_40 (Conv1D)              (None, 168, 256)     76032       concatenate_8[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_72 (Activation)      (None, 168, 256)     0           conv1d_38[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_73 (Activation)      (None, 168, 256)     0           conv1d_38[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_76 (Activation)      (None, 168, 256)     0           conv1d_40[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_77 (Activation)      (None, 168, 256)     0           conv1d_40[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "multiply_38 (Multiply)          (None, 168, 256)     0           activation_72[0][0]              \n",
      "                                                                 activation_73[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "multiply_40 (Multiply)          (None, 168, 256)     0           activation_76[0][0]              \n",
      "                                                                 activation_77[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_39 (Conv1D)              (None, 168, 37)      18981       multiply_38[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_41 (Conv1D)              (None, 168, 37)      18981       multiply_40[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "activation_74 (Activation)      (None, 168, 37)      0           conv1d_39[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_75 (Activation)      (None, 168, 37)      0           conv1d_39[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_78 (Activation)      (None, 168, 37)      0           conv1d_41[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_79 (Activation)      (None, 168, 37)      0           conv1d_41[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "multiply_39 (Multiply)          (None, 168, 37)      0           activation_74[0][0]              \n",
      "                                                                 activation_75[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "multiply_41 (Multiply)          (None, 168, 37)      0           activation_78[0][0]              \n",
      "                                                                 activation_79[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "add_10 (Add)                    (None, 168, 37)      0           add_9[0][0]                      \n",
      "                                                                 multiply_39[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "subtract_10 (Subtract)          (None, 168, 37)      0           subtract_9[0][0]                 \n",
      "                                                                 multiply_41[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_9 (Concatenate)     (None, 168, 370)     0           add_10[0][0]                     \n",
      "                                                                 subtract_10[0][0]                \n",
      "                                                                 concatenate_8[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_10 (Concatenate)    (None, 168, 74)      0           add_10[0][0]                     \n",
      "                                                                 subtract_10[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_11 (Concatenate)    (None, 168, 1110)    0           concatenate_6[0][0]              \n",
      "                                                                 concatenate_7[0][0]              \n",
      "                                                                 concatenate_8[0][0]              \n",
      "                                                                 concatenate_9[0][0]              \n",
      "                                                                 concatenate_10[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling1d_1 (Glo (None, 1110)         0           concatenate_11[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dense_3 (Dense)                 (None, 24)           26664       global_average_pooling1d_1[0][0] \n",
      "==================================================================================================\n",
      "Total params: 625,989\n",
      "Trainable params: 625,989\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "num_features = trvaX.shape[2]\n",
    "output_timesteps = trvaY.shape[1]\n",
    "\n",
    "with tf.device('/gpu:0'):\n",
    "    alpha=1.0\n",
    "    gamma=1.2\n",
    "    beta = 1\n",
    "    hfilters = 256\n",
    "    hkernel_size1 = 1\n",
    "    hkernel_size2 = 2\n",
    "    \n",
    "    visible1 = Input(shape=(timesteps, num_features))\n",
    "   \n",
    "    ## Attention Block\n",
    "    per1 = Permute((2,1))(visible1)\n",
    "    den1a = Dense(timesteps, activation='tanh')(per1)\n",
    "    den1b = Dense(timesteps, activation='sigmoid')(per1)\n",
    "    den1 = Multiply()([den1a, den1b])\n",
    "    per2 = Permute((2,1), name='attention_vec')(den1)\n",
    "    mul1 = Multiply()([visible1, per2])\n",
    "    \n",
    "    ## Series PN DCCNN Blocks 1 ~ 6\n",
    "    d1 = Conv1D(filters=round(hfilters*alpha), kernel_size=round(hkernel_size1*beta), padding='causal', dilation_rate=1)(mul1)\n",
    "    d1a = Activation(activations.tanh)(d1)\n",
    "    d1b = Activation(activations.sigmoid)(d1)\n",
    "    d1 = Multiply()([d1a, d1b])\n",
    "    \n",
    "    d1 = Conv1D(filters=num_features, kernel_size=round(hkernel_size2*beta), padding='causal', dilation_rate=2)(d1)\n",
    "    d1a = Activation(activations.tanh)(d1)\n",
    "    d1b = Activation(activations.sigmoid)(d1)\n",
    "    d1 = Multiply()([d1a, d1b])\n",
    "    \n",
    "    res01a = Add()([visible1, d1])   # (100, 25) (100, 25)\n",
    "    res01b = Subtract()([visible1, d1])\n",
    "\n",
    "    d1 = Conv1D(filters=round(hfilters*alpha), kernel_size=round(hkernel_size1*beta), padding='causal', dilation_rate=2)(res01a)\n",
    "    d1a = Activation(activations.tanh)(d1)\n",
    "    d1b = Activation(activations.sigmoid)(d1)\n",
    "    d1 = Multiply()([d1a, d1b])\n",
    "    \n",
    "    d1 = Conv1D(filters=num_features, kernel_size=round(hkernel_size2*beta), padding='causal', dilation_rate=4)(d1)    \n",
    "    d1a = Activation(activations.tanh)(d1)\n",
    "    d1b = Activation(activations.sigmoid)(d1)\n",
    "    \n",
    "    d1 = Multiply()([d1a, d1b])\n",
    "    res02a = Add()([res01a, d1])   # (100, 25) (100, 25)\n",
    "    \n",
    "    d2 = Conv1D(filters=round(hfilters*alpha), kernel_size=round(hkernel_size1*beta), padding='causal', dilation_rate=2)(res01b) \n",
    "    d2a = Activation(activations.tanh)(d2)\n",
    "    d2b = Activation(activations.sigmoid)(d2)\n",
    "    d2 = Multiply()([d2a, d2b])\n",
    "    \n",
    "    d2 = Conv1D(filters=num_features, kernel_size=round(hkernel_size2*beta), padding='causal', dilation_rate=4)(d2) \n",
    "    d2a = Activation(activations.tanh)(d2)\n",
    "    d2b = Activation(activations.sigmoid)(d2)\n",
    "    d2 = Multiply()([d2a, d2b])\n",
    "    \n",
    "    res02b = Subtract()([res01b, d2])   # (100, 25) (100, 25) \n",
    "    res02 = Concatenate()([res02a, res02b, res01a, res01b])\n",
    "    \n",
    "    d1 = Conv1D(filters=round(hfilters*alpha), kernel_size=round(hkernel_size1*beta), padding='causal', dilation_rate=4)(res02)\n",
    "    d1a = Activation(activations.tanh)(d1)\n",
    "    d1b = Activation(activations.sigmoid)(d1)\n",
    "    d1 = Multiply()([d1a, d1b])\n",
    "    \n",
    "    d1 = Conv1D(filters=num_features, kernel_size=round(hkernel_size2*beta), padding='causal', dilation_rate=8)(d1)    \n",
    "    d1a = Activation(activations.tanh)(d1)\n",
    "    d1b = Activation(activations.sigmoid)(d1)\n",
    "    d1 = Multiply()([d1a, d1b])\n",
    "    \n",
    "    res03a = Add()([res02a, d1])   # (100, 25) (100, 25)\n",
    "    \n",
    "    d2 = Conv1D(filters=round(hfilters*alpha), kernel_size=round(hkernel_size1*beta), padding='causal', dilation_rate=4)(res02) \n",
    "    d2a = Activation(activations.tanh)(d2)\n",
    "    d2b = Activation(activations.sigmoid)(d2)\n",
    "    d2 = Multiply()([d2a, d2b])\n",
    "    \n",
    "    d2 = Conv1D(filters=num_features, kernel_size=round(hkernel_size2*beta), padding='causal', dilation_rate=8)(d2) \n",
    "    d2a = Activation(activations.tanh)(d2)\n",
    "    d2b = Activation(activations.sigmoid)(d2)\n",
    "    d2 = Multiply()([d2a, d2b])\n",
    "    \n",
    "    res03b = Subtract()([res02b, d2])   # (100, 25) (100, 25)\n",
    "    res03 = Concatenate()([res03a, res03b, res02])\n",
    "    \n",
    "    d1 = Conv1D(filters=round(hfilters*alpha), kernel_size=round(hkernel_size1*beta), padding='causal', dilation_rate=8)(res03)\n",
    "    d1a = Activation(activations.tanh)(d1)\n",
    "    d1b = Activation(activations.sigmoid)(d1)\n",
    "    d1 = Multiply()([d1a, d1b])\n",
    "    d1 = Conv1D(filters=num_features, kernel_size=round(hkernel_size2*beta), padding='causal', dilation_rate=4)(d1)    \n",
    "    d1a = Activation(activations.tanh)(d1)\n",
    "    d1b = Activation(activations.sigmoid)(d1)\n",
    "    d1 = Multiply()([d1a, d1b])\n",
    "    res04a = Add()([res03a, d1])   # (100, 25) (100, 25)\n",
    "    \n",
    "    d2 = Conv1D(filters=round(hfilters*alpha), kernel_size=round(hkernel_size1*beta), padding='causal', dilation_rate=8)(res03) \n",
    "    d2a = Activation(activations.tanh)(d2)\n",
    "    d2b = Activation(activations.sigmoid)(d2)\n",
    "    d2 = Multiply()([d2a, d2b])\n",
    "    \n",
    "    d2 = Conv1D(filters=num_features, kernel_size=round(hkernel_size2*beta), padding='causal', dilation_rate=4)(d2) \n",
    "    d2a = Activation(activations.tanh)(d2)\n",
    "    d2b = Activation(activations.sigmoid)(d2)\n",
    "    d2 = Multiply()([d2a, d2b])\n",
    "    \n",
    "    res04b = Subtract()([res02b, d2])   # (100, 25) (100, 25)\n",
    "    res04 = Concatenate()([res04a, res04b, res03])\n",
    "    \n",
    "    d1 = Conv1D(filters=round(hfilters*alpha), kernel_size=round(hkernel_size1*beta), padding='causal', dilation_rate=4)(res04)\n",
    "    d1a = Activation(activations.tanh)(d1)\n",
    "    d1b = Activation(activations.sigmoid)(d1)\n",
    "    d1 = Multiply()([d1a, d1b])\n",
    "    \n",
    "    d1 = Conv1D(filters=num_features, kernel_size=round(hkernel_size2*beta), padding='causal', dilation_rate=2)(d1)    \n",
    "    d1a = Activation(activations.tanh)(d1)\n",
    "    d1b = Activation(activations.sigmoid)(d1)\n",
    "    d1 = Multiply()([d1a, d1b])\n",
    "    \n",
    "    res05a = Add()([res04a, d1])   # (100, 25) (100, 25)\n",
    "    \n",
    "    d2 = Conv1D(filters=round(hfilters*alpha), kernel_size=round(hkernel_size1*beta), padding='causal', dilation_rate=4)(res04) \n",
    "    d2a = Activation(activations.tanh)(d2)\n",
    "    d2b = Activation(activations.sigmoid)(d2)\n",
    "    d2 = Multiply()([d2a, d2b])\n",
    "    \n",
    "    d2 = Conv1D(filters=num_features, kernel_size=round(hkernel_size2*beta), padding='causal', dilation_rate=2)(d2) \n",
    "    d2a = Activation(activations.tanh)(d2)\n",
    "    d2b = Activation(activations.sigmoid)(d2)\n",
    "    d2 = Multiply()([d2a, d2b])\n",
    "    \n",
    "    res05b = Subtract()([res04b, d2])   # (100, 25) (100, 25)\n",
    "    res05 = Concatenate()([res05a, res05b, res04])\n",
    "    \n",
    "    d1 = Conv1D(filters=round(hfilters*alpha), kernel_size=round(hkernel_size1*beta), padding='causal', dilation_rate=2)(res05)\n",
    "    d1a = Activation(activations.tanh)(d1)\n",
    "    d1b = Activation(activations.sigmoid)(d1)\n",
    "    d1 = Multiply()([d1a, d1b])\n",
    "    \n",
    "    d1 = Conv1D(filters=num_features, kernel_size=round(hkernel_size2*beta), padding='causal', dilation_rate=1)(d1)    \n",
    "    d1a = Activation(activations.tanh)(d1)\n",
    "    d1b = Activation(activations.sigmoid)(d1)\n",
    "    d1 = Multiply()([d1a, d1b])\n",
    "\n",
    "    res06a = Add()([res05a, d1])   # (100, 25) (100, 25)\n",
    "    \n",
    "    d2 = Conv1D(filters=round(hfilters*alpha), kernel_size=round(hkernel_size1*beta), padding='causal', dilation_rate=2)(res05) \n",
    "    d2a = Activation(activations.tanh)(d2)\n",
    "    d2b = Activation(activations.sigmoid)(d2)\n",
    "    d2 = Multiply()([d2a, d2b])\n",
    "    d2 = Conv1D(filters=num_features, kernel_size=round(hkernel_size2*beta), padding='causal', dilation_rate=1)(d2) \n",
    "    d2a = Activation(activations.tanh)(d2)\n",
    "    d2b = Activation(activations.sigmoid)(d2)\n",
    "    d2 = Multiply()([d2a, d2b])\n",
    "\n",
    "    res06b = Subtract()([res05b, d2])   # (100, 25) (100, 25)\n",
    "    res06 = Concatenate()([res05a, res05b])\n",
    "    \n",
    "    res10 = Concatenate()([res02, res03, res04, res05, res06])   # \n",
    "    \n",
    "    out = GlobalAveragePooling1D()(res10) # pool_size=2, strides=1\n",
    "    out = Dense(24)(out) \n",
    "    model2 = Model(inputs=[visible1], outputs=[out])\n",
    "    \n",
    "    print(model2.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "fd22c014",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3133"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "c0799fea",
   "metadata": {},
   "outputs": [],
   "source": [
    "    model2.compile(loss=MAEMS, optimizer='adam', metrics=['mse','mae', MAEMS])\n",
    "    early_stopping =EarlyStopping(monitor='val_loss', patience=10)\n",
    "    batch_size = 100\n",
    "    epochs = 1000\n",
    "    #root_squared_mean_error\n",
    "    history2 = LossHistory()\n",
    "    history2.init()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "4c10e690",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "131/131 [==============================] - 16s 101ms/step - loss: 3.9346 - mse: 0.1026 - mae: 0.2621 - MAEMS: 3.9334 - val_loss: 3.5247 - val_mse: 0.0986 - val_mae: 0.2572 - val_MAEMS: 3.5297\n",
      "Epoch 2/1000\n",
      "131/131 [==============================] - 12s 94ms/step - loss: 3.4240 - mse: 0.0903 - mae: 0.2460 - MAEMS: 3.4235 - val_loss: 3.3948 - val_mse: 0.0683 - val_mae: 0.2144 - val_MAEMS: 3.3923\n",
      "Epoch 3/1000\n",
      "131/131 [==============================] - 12s 94ms/step - loss: 3.2803 - mse: 0.0816 - mae: 0.2329 - MAEMS: 3.2797 - val_loss: 3.2211 - val_mse: 0.0677 - val_mae: 0.2119 - val_MAEMS: 3.2134\n",
      "Epoch 4/1000\n",
      "131/131 [==============================] - 12s 93ms/step - loss: 3.1936 - mse: 0.0772 - mae: 0.2258 - MAEMS: 3.1929 - val_loss: 3.1434 - val_mse: 0.0652 - val_mae: 0.2072 - val_MAEMS: 3.1340\n",
      "Epoch 5/1000\n",
      "131/131 [==============================] - 12s 94ms/step - loss: 3.1183 - mse: 0.0734 - mae: 0.2195 - MAEMS: 3.1177 - val_loss: 3.0551 - val_mse: 0.0625 - val_mae: 0.2019 - val_MAEMS: 3.0441\n",
      "Epoch 6/1000\n",
      "131/131 [==============================] - 12s 95ms/step - loss: 3.0077 - mse: 0.0675 - mae: 0.2093 - MAEMS: 3.0072 - val_loss: 2.9460 - val_mse: 0.0599 - val_mae: 0.1963 - val_MAEMS: 2.9347\n",
      "Epoch 7/1000\n",
      "131/131 [==============================] - 12s 94ms/step - loss: 2.9157 - mse: 0.0618 - mae: 0.1989 - MAEMS: 2.9152 - val_loss: 2.8524 - val_mse: 0.0617 - val_mae: 0.1977 - val_MAEMS: 2.8379\n",
      "Epoch 8/1000\n",
      "131/131 [==============================] - 12s 94ms/step - loss: 2.8526 - mse: 0.0587 - mae: 0.1929 - MAEMS: 2.8521 - val_loss: 2.8087 - val_mse: 0.0613 - val_mae: 0.1963 - val_MAEMS: 2.7931\n",
      "Epoch 9/1000\n",
      "131/131 [==============================] - 12s 94ms/step - loss: 2.7920 - mse: 0.0567 - mae: 0.1886 - MAEMS: 2.7916 - val_loss: 2.7582 - val_mse: 0.0529 - val_mae: 0.1814 - val_MAEMS: 2.7473\n",
      "Epoch 10/1000\n",
      "131/131 [==============================] - 12s 94ms/step - loss: 2.7497 - mse: 0.0549 - mae: 0.1850 - MAEMS: 2.7492 - val_loss: 2.7268 - val_mse: 0.0518 - val_mae: 0.1789 - val_MAEMS: 2.7175\n",
      "Epoch 11/1000\n",
      "131/131 [==============================] - 12s 94ms/step - loss: 2.7102 - mse: 0.0536 - mae: 0.1820 - MAEMS: 2.7097 - val_loss: 2.7070 - val_mse: 0.0497 - val_mae: 0.1749 - val_MAEMS: 2.6977\n",
      "Epoch 12/1000\n",
      "131/131 [==============================] - 12s 95ms/step - loss: 2.6664 - mse: 0.0522 - mae: 0.1790 - MAEMS: 2.6659 - val_loss: 2.6665 - val_mse: 0.0495 - val_mae: 0.1738 - val_MAEMS: 2.6563\n",
      "Epoch 13/1000\n",
      "131/131 [==============================] - 12s 94ms/step - loss: 2.6279 - mse: 0.0510 - mae: 0.1763 - MAEMS: 2.6275 - val_loss: 2.6401 - val_mse: 0.0468 - val_mae: 0.1686 - val_MAEMS: 2.6299\n",
      "Epoch 14/1000\n",
      "131/131 [==============================] - 12s 94ms/step - loss: 2.5826 - mse: 0.0497 - mae: 0.1734 - MAEMS: 2.5821 - val_loss: 2.6045 - val_mse: 0.0457 - val_mae: 0.1658 - val_MAEMS: 2.5940\n",
      "Epoch 15/1000\n",
      "131/131 [==============================] - 12s 94ms/step - loss: 2.5310 - mse: 0.0483 - mae: 0.1703 - MAEMS: 2.5306 - val_loss: 2.5543 - val_mse: 0.0445 - val_mae: 0.1630 - val_MAEMS: 2.5433\n",
      "Epoch 16/1000\n",
      "131/131 [==============================] - 12s 94ms/step - loss: 2.4849 - mse: 0.0472 - mae: 0.1677 - MAEMS: 2.4845 - val_loss: 2.5106 - val_mse: 0.0444 - val_mae: 0.1624 - val_MAEMS: 2.4988\n",
      "Epoch 17/1000\n",
      "131/131 [==============================] - 13s 96ms/step - loss: 2.4252 - mse: 0.0458 - mae: 0.1644 - MAEMS: 2.4248 - val_loss: 2.4545 - val_mse: 0.0450 - val_mae: 0.1630 - val_MAEMS: 2.4420\n",
      "Epoch 18/1000\n",
      "131/131 [==============================] - 12s 94ms/step - loss: 2.3718 - mse: 0.0444 - mae: 0.1612 - MAEMS: 2.3714 - val_loss: 2.4101 - val_mse: 0.0439 - val_mae: 0.1603 - val_MAEMS: 2.3977\n",
      "Epoch 19/1000\n",
      "131/131 [==============================] - 12s 94ms/step - loss: 2.3125 - mse: 0.0429 - mae: 0.1576 - MAEMS: 2.3120 - val_loss: 2.3574 - val_mse: 0.0433 - val_mae: 0.1588 - val_MAEMS: 2.3453\n",
      "Epoch 20/1000\n",
      "131/131 [==============================] - 12s 94ms/step - loss: 2.2658 - mse: 0.0416 - mae: 0.1546 - MAEMS: 2.2653 - val_loss: 2.3256 - val_mse: 0.0410 - val_mae: 0.1542 - val_MAEMS: 2.3149\n",
      "Epoch 21/1000\n",
      "131/131 [==============================] - 12s 94ms/step - loss: 2.2153 - mse: 0.0404 - mae: 0.1517 - MAEMS: 2.2149 - val_loss: 2.2775 - val_mse: 0.0407 - val_mae: 0.1531 - val_MAEMS: 2.2679\n",
      "Epoch 22/1000\n",
      "131/131 [==============================] - 12s 94ms/step - loss: 2.1874 - mse: 0.0394 - mae: 0.1493 - MAEMS: 2.1870 - val_loss: 2.2955 - val_mse: 0.0449 - val_mae: 0.1613 - val_MAEMS: 2.2846\n",
      "Epoch 23/1000\n",
      "131/131 [==============================] - 12s 94ms/step - loss: 2.1507 - mse: 0.0385 - mae: 0.1474 - MAEMS: 2.1502 - val_loss: 2.3064 - val_mse: 0.0475 - val_mae: 0.1663 - val_MAEMS: 2.2942\n",
      "Epoch 24/1000\n",
      "131/131 [==============================] - 12s 95ms/step - loss: 2.0990 - mse: 0.0374 - mae: 0.1445 - MAEMS: 2.0987 - val_loss: 2.2672 - val_mse: 0.0453 - val_mae: 0.1616 - val_MAEMS: 2.2560\n",
      "Epoch 25/1000\n",
      "131/131 [==============================] - 12s 94ms/step - loss: 2.0921 - mse: 0.0366 - mae: 0.1429 - MAEMS: 2.0925 - val_loss: 2.2665 - val_mse: 0.0336 - val_mae: 0.1390 - val_MAEMS: 2.2591\n",
      "Epoch 26/1000\n",
      "131/131 [==============================] - 12s 95ms/step - loss: 2.1046 - mse: 0.0371 - mae: 0.1441 - MAEMS: 2.1042 - val_loss: 2.3469 - val_mse: 0.0302 - val_mae: 0.1325 - val_MAEMS: 2.3423\n",
      "Epoch 27/1000\n",
      "131/131 [==============================] - 12s 94ms/step - loss: 2.0292 - mse: 0.0356 - mae: 0.1401 - MAEMS: 2.0287 - val_loss: 2.3033 - val_mse: 0.0300 - val_mae: 0.1315 - val_MAEMS: 2.2976\n",
      "Epoch 28/1000\n",
      "131/131 [==============================] - 12s 94ms/step - loss: 1.9654 - mse: 0.0344 - mae: 0.1369 - MAEMS: 1.9650 - val_loss: 2.2364 - val_mse: 0.0299 - val_mae: 0.1305 - val_MAEMS: 2.2304\n",
      "Epoch 29/1000\n",
      "131/131 [==============================] - 12s 94ms/step - loss: 1.9208 - mse: 0.0333 - mae: 0.1341 - MAEMS: 1.9204 - val_loss: 2.2210 - val_mse: 0.0286 - val_mae: 0.1277 - val_MAEMS: 2.2156\n",
      "Epoch 30/1000\n",
      "131/131 [==============================] - 13s 96ms/step - loss: 1.9125 - mse: 0.0328 - mae: 0.1330 - MAEMS: 1.9126 - val_loss: 2.1955 - val_mse: 0.0295 - val_mae: 0.1294 - val_MAEMS: 2.1887\n",
      "Epoch 31/1000\n",
      "131/131 [==============================] - 12s 95ms/step - loss: 1.9149 - mse: 0.0327 - mae: 0.1328 - MAEMS: 1.9155 - val_loss: 2.0289 - val_mse: 0.0362 - val_mae: 0.1418 - val_MAEMS: 2.0176\n",
      "Epoch 32/1000\n",
      "131/131 [==============================] - 12s 94ms/step - loss: 1.8638 - mse: 0.0318 - mae: 0.1304 - MAEMS: 1.8638 - val_loss: 1.9863 - val_mse: 0.0325 - val_mae: 0.1334 - val_MAEMS: 1.9776\n",
      "Epoch 33/1000\n",
      "131/131 [==============================] - 12s 94ms/step - loss: 1.7970 - mse: 0.0306 - mae: 0.1270 - MAEMS: 1.7968 - val_loss: 1.9375 - val_mse: 0.0312 - val_mae: 0.1301 - val_MAEMS: 1.9295\n",
      "Epoch 34/1000\n",
      "131/131 [==============================] - 12s 94ms/step - loss: 1.7740 - mse: 0.0299 - mae: 0.1250 - MAEMS: 1.7739 - val_loss: 2.1124 - val_mse: 0.0343 - val_mae: 0.1375 - val_MAEMS: 2.1053\n",
      "Epoch 35/1000\n",
      "131/131 [==============================] - 12s 94ms/step - loss: 1.7624 - mse: 0.0294 - mae: 0.1239 - MAEMS: 1.7621 - val_loss: 1.9180 - val_mse: 0.0294 - val_mae: 0.1259 - val_MAEMS: 1.9097\n",
      "Epoch 36/1000\n",
      "131/131 [==============================] - 12s 94ms/step - loss: 1.7116 - mse: 0.0285 - mae: 0.1214 - MAEMS: 1.7114 - val_loss: 1.8973 - val_mse: 0.0292 - val_mae: 0.1248 - val_MAEMS: 1.8902\n",
      "Epoch 37/1000\n",
      "131/131 [==============================] - 12s 95ms/step - loss: 1.6968 - mse: 0.0280 - mae: 0.1201 - MAEMS: 1.6965 - val_loss: 1.8658 - val_mse: 0.0300 - val_mae: 0.1260 - val_MAEMS: 1.8580\n",
      "Epoch 38/1000\n",
      "131/131 [==============================] - 12s 94ms/step - loss: 1.6665 - mse: 0.0275 - mae: 0.1186 - MAEMS: 1.6662 - val_loss: 1.8307 - val_mse: 0.0302 - val_mae: 0.1265 - val_MAEMS: 1.8225\n",
      "Epoch 39/1000\n",
      "131/131 [==============================] - 12s 95ms/step - loss: 1.6930 - mse: 0.0274 - mae: 0.1187 - MAEMS: 1.6932 - val_loss: 1.8578 - val_mse: 0.0298 - val_mae: 0.1268 - val_MAEMS: 1.8499\n",
      "Epoch 40/1000\n",
      "131/131 [==============================] - 12s 94ms/step - loss: 1.6997 - mse: 0.0275 - mae: 0.1192 - MAEMS: 1.6999 - val_loss: 2.1507 - val_mse: 0.0406 - val_mae: 0.1519 - val_MAEMS: 2.1444\n",
      "Epoch 41/1000\n",
      "131/131 [==============================] - 12s 94ms/step - loss: 1.7555 - mse: 0.0279 - mae: 0.1207 - MAEMS: 1.7551 - val_loss: 1.9032 - val_mse: 0.0358 - val_mae: 0.1399 - val_MAEMS: 1.8929\n",
      "Epoch 42/1000\n",
      "131/131 [==============================] - 12s 95ms/step - loss: 1.7517 - mse: 0.0278 - mae: 0.1206 - MAEMS: 1.7513 - val_loss: 1.8092 - val_mse: 0.0332 - val_mae: 0.1337 - val_MAEMS: 1.8014\n",
      "Epoch 43/1000\n",
      "131/131 [==============================] - 12s 95ms/step - loss: 1.6466 - mse: 0.0266 - mae: 0.1165 - MAEMS: 1.6463 - val_loss: 1.8687 - val_mse: 0.0348 - val_mae: 0.1374 - val_MAEMS: 1.8597\n",
      "Epoch 44/1000\n",
      "131/131 [==============================] - 12s 95ms/step - loss: 1.5419 - mse: 0.0254 - mae: 0.1125 - MAEMS: 1.5418 - val_loss: 1.7921 - val_mse: 0.0329 - val_mae: 0.1324 - val_MAEMS: 1.7832\n",
      "Epoch 45/1000\n",
      "131/131 [==============================] - 12s 95ms/step - loss: 1.4869 - mse: 0.0246 - mae: 0.1097 - MAEMS: 1.4869 - val_loss: 1.7370 - val_mse: 0.0308 - val_mae: 0.1273 - val_MAEMS: 1.7290\n",
      "Epoch 46/1000\n",
      "131/131 [==============================] - 12s 94ms/step - loss: 1.4584 - mse: 0.0240 - mae: 0.1079 - MAEMS: 1.4585 - val_loss: 1.6980 - val_mse: 0.0295 - val_mae: 0.1239 - val_MAEMS: 1.6912\n",
      "Epoch 47/1000\n",
      "131/131 [==============================] - 12s 94ms/step - loss: 1.4529 - mse: 0.0235 - mae: 0.1068 - MAEMS: 1.4530 - val_loss: 1.6920 - val_mse: 0.0294 - val_mae: 0.1235 - val_MAEMS: 1.6875\n",
      "Epoch 48/1000\n",
      "131/131 [==============================] - 12s 94ms/step - loss: 1.4671 - mse: 0.0233 - mae: 0.1064 - MAEMS: 1.4672 - val_loss: 1.8291 - val_mse: 0.0323 - val_mae: 0.1318 - val_MAEMS: 1.8258\n",
      "Epoch 49/1000\n",
      "131/131 [==============================] - 12s 94ms/step - loss: 1.5229 - mse: 0.0234 - mae: 0.1075 - MAEMS: 1.5229 - val_loss: 2.0321 - val_mse: 0.0371 - val_mae: 0.1443 - val_MAEMS: 2.0284\n",
      "Epoch 50/1000\n",
      "131/131 [==============================] - 12s 94ms/step - loss: 1.5536 - mse: 0.0240 - mae: 0.1093 - MAEMS: 1.5538 - val_loss: 1.7414 - val_mse: 0.0279 - val_mae: 0.1204 - val_MAEMS: 1.7336\n",
      "Epoch 51/1000\n",
      "131/131 [==============================] - 12s 94ms/step - loss: 1.4668 - mse: 0.0230 - mae: 0.1060 - MAEMS: 1.4668 - val_loss: 1.7395 - val_mse: 0.0283 - val_mae: 0.1213 - val_MAEMS: 1.7311\n",
      "Epoch 52/1000\n",
      "131/131 [==============================] - 12s 94ms/step - loss: 1.4463 - mse: 0.0226 - mae: 0.1046 - MAEMS: 1.4465 - val_loss: 1.6645 - val_mse: 0.0248 - val_mae: 0.1124 - val_MAEMS: 1.6605\n",
      "Epoch 53/1000\n",
      "131/131 [==============================] - 12s 94ms/step - loss: 1.5078 - mse: 0.0229 - mae: 0.1063 - MAEMS: 1.5078 - val_loss: 1.6492 - val_mse: 0.0237 - val_mae: 0.1105 - val_MAEMS: 1.6471\n",
      "Epoch 54/1000\n",
      "131/131 [==============================] - 12s 95ms/step - loss: 1.4573 - mse: 0.0223 - mae: 0.1043 - MAEMS: 1.4573 - val_loss: 1.6521 - val_mse: 0.0247 - val_mae: 0.1129 - val_MAEMS: 1.6494\n",
      "Epoch 55/1000\n",
      "131/131 [==============================] - 12s 94ms/step - loss: 1.4288 - mse: 0.0219 - mae: 0.1029 - MAEMS: 1.4287 - val_loss: 1.7082 - val_mse: 0.0269 - val_mae: 0.1190 - val_MAEMS: 1.7056\n",
      "Epoch 56/1000\n",
      "131/131 [==============================] - 12s 94ms/step - loss: 1.4396 - mse: 0.0218 - mae: 0.1027 - MAEMS: 1.4393 - val_loss: 1.6194 - val_mse: 0.0277 - val_mae: 0.1197 - val_MAEMS: 1.6140\n",
      "Epoch 57/1000\n",
      "131/131 [==============================] - 12s 95ms/step - loss: 1.4163 - mse: 0.0215 - mae: 0.1017 - MAEMS: 1.4160 - val_loss: 1.5654 - val_mse: 0.0258 - val_mae: 0.1145 - val_MAEMS: 1.5605\n",
      "Epoch 58/1000\n",
      "131/131 [==============================] - 12s 94ms/step - loss: 1.4034 - mse: 0.0212 - mae: 0.1009 - MAEMS: 1.4032 - val_loss: 1.6185 - val_mse: 0.0274 - val_mae: 0.1189 - val_MAEMS: 1.6134\n",
      "Epoch 59/1000\n",
      "131/131 [==============================] - 12s 93ms/step - loss: 1.4260 - mse: 0.0212 - mae: 0.1013 - MAEMS: 1.4257 - val_loss: 1.8642 - val_mse: 0.0341 - val_mae: 0.1377 - val_MAEMS: 1.8531\n",
      "Epoch 60/1000\n",
      "131/131 [==============================] - 12s 94ms/step - loss: 1.4021 - mse: 0.0212 - mae: 0.1009 - MAEMS: 1.4017 - val_loss: 1.8069 - val_mse: 0.0320 - val_mae: 0.1319 - val_MAEMS: 1.7985\n",
      "Epoch 61/1000\n",
      "131/131 [==============================] - 12s 94ms/step - loss: 1.3967 - mse: 0.0212 - mae: 0.1007 - MAEMS: 1.3963 - val_loss: 1.6024 - val_mse: 0.0283 - val_mae: 0.1208 - val_MAEMS: 1.5990\n",
      "Epoch 62/1000\n",
      "131/131 [==============================] - 12s 94ms/step - loss: 1.3346 - mse: 0.0204 - mae: 0.0979 - MAEMS: 1.3346 - val_loss: 1.5386 - val_mse: 0.0259 - val_mae: 0.1143 - val_MAEMS: 1.5363\n",
      "Epoch 63/1000\n",
      "131/131 [==============================] - 12s 94ms/step - loss: 1.3591 - mse: 0.0204 - mae: 0.0983 - MAEMS: 1.3592 - val_loss: 1.5745 - val_mse: 0.0234 - val_mae: 0.1085 - val_MAEMS: 1.5706\n",
      "Epoch 64/1000\n",
      "131/131 [==============================] - 12s 94ms/step - loss: 1.3586 - mse: 0.0201 - mae: 0.0977 - MAEMS: 1.3587 - val_loss: 1.5962 - val_mse: 0.0240 - val_mae: 0.1097 - val_MAEMS: 1.5911\n",
      "Epoch 65/1000\n",
      "131/131 [==============================] - 12s 94ms/step - loss: 1.3672 - mse: 0.0202 - mae: 0.0979 - MAEMS: 1.3669 - val_loss: 1.4693 - val_mse: 0.0226 - val_mae: 0.1054 - val_MAEMS: 1.4658\n",
      "Epoch 66/1000\n",
      "131/131 [==============================] - 12s 95ms/step - loss: 1.3628 - mse: 0.0202 - mae: 0.0980 - MAEMS: 1.3626 - val_loss: 1.4757 - val_mse: 0.0230 - val_mae: 0.1067 - val_MAEMS: 1.4705\n",
      "Epoch 67/1000\n",
      "131/131 [==============================] - 12s 95ms/step - loss: 1.3742 - mse: 0.0201 - mae: 0.0978 - MAEMS: 1.3746 - val_loss: 1.6656 - val_mse: 0.0205 - val_mae: 0.1028 - val_MAEMS: 1.6608\n",
      "Epoch 68/1000\n",
      "131/131 [==============================] - 12s 95ms/step - loss: 1.4555 - mse: 0.0207 - mae: 0.1005 - MAEMS: 1.4557 - val_loss: 1.9833 - val_mse: 0.0181 - val_mae: 0.1006 - val_MAEMS: 1.9860\n",
      "Epoch 69/1000\n",
      "131/131 [==============================] - 12s 93ms/step - loss: 1.4973 - mse: 0.0210 - mae: 0.1020 - MAEMS: 1.4969 - val_loss: 1.8581 - val_mse: 0.0196 - val_mae: 0.1030 - val_MAEMS: 1.8598\n",
      "Epoch 70/1000\n",
      "131/131 [==============================] - 12s 95ms/step - loss: 1.3430 - mse: 0.0198 - mae: 0.0970 - MAEMS: 1.3428 - val_loss: 1.6990 - val_mse: 0.0181 - val_mae: 0.0971 - val_MAEMS: 1.7022\n",
      "Epoch 71/1000\n",
      "131/131 [==============================] - 12s 94ms/step - loss: 1.2699 - mse: 0.0191 - mae: 0.0940 - MAEMS: 1.2697 - val_loss: 1.6272 - val_mse: 0.0188 - val_mae: 0.0980 - val_MAEMS: 1.6312\n",
      "Epoch 72/1000\n",
      "131/131 [==============================] - 12s 94ms/step - loss: 1.2149 - mse: 0.0185 - mae: 0.0916 - MAEMS: 1.2147 - val_loss: 1.5649 - val_mse: 0.0194 - val_mae: 0.0987 - val_MAEMS: 1.5678\n",
      "Epoch 73/1000\n",
      "131/131 [==============================] - 12s 94ms/step - loss: 1.1633 - mse: 0.0179 - mae: 0.0893 - MAEMS: 1.1632 - val_loss: 1.5041 - val_mse: 0.0188 - val_mae: 0.0961 - val_MAEMS: 1.5084\n",
      "Epoch 74/1000\n",
      "131/131 [==============================] - 12s 95ms/step - loss: 1.1149 - mse: 0.0174 - mae: 0.0871 - MAEMS: 1.1148 - val_loss: 1.4347 - val_mse: 0.0188 - val_mae: 0.0952 - val_MAEMS: 1.4382\n",
      "Epoch 75/1000\n",
      "131/131 [==============================] - 12s 94ms/step - loss: 1.0938 - mse: 0.0169 - mae: 0.0857 - MAEMS: 1.0937 - val_loss: 1.4235 - val_mse: 0.0184 - val_mae: 0.0941 - val_MAEMS: 1.4261\n",
      "Epoch 76/1000\n",
      "131/131 [==============================] - 12s 94ms/step - loss: 1.0929 - mse: 0.0167 - mae: 0.0850 - MAEMS: 1.0929 - val_loss: 1.4116 - val_mse: 0.0181 - val_mae: 0.0932 - val_MAEMS: 1.4145\n",
      "Epoch 77/1000\n",
      "131/131 [==============================] - 12s 94ms/step - loss: 1.1317 - mse: 0.0167 - mae: 0.0857 - MAEMS: 1.1315 - val_loss: 1.4901 - val_mse: 0.0169 - val_mae: 0.0914 - val_MAEMS: 1.4945\n",
      "Epoch 78/1000\n",
      "131/131 [==============================] - 12s 94ms/step - loss: 1.1903 - mse: 0.0168 - mae: 0.0869 - MAEMS: 1.1900 - val_loss: 1.3692 - val_mse: 0.0202 - val_mae: 0.0981 - val_MAEMS: 1.3685\n",
      "Epoch 79/1000\n",
      "131/131 [==============================] - 12s 94ms/step - loss: 1.1895 - mse: 0.0168 - mae: 0.0869 - MAEMS: 1.1894 - val_loss: 1.5091 - val_mse: 0.0181 - val_mae: 0.0944 - val_MAEMS: 1.5129\n",
      "Epoch 80/1000\n",
      "131/131 [==============================] - 12s 94ms/step - loss: 1.1538 - mse: 0.0166 - mae: 0.0858 - MAEMS: 1.1536 - val_loss: 1.4209 - val_mse: 0.0176 - val_mae: 0.0922 - val_MAEMS: 1.4250\n",
      "Epoch 81/1000\n",
      "131/131 [==============================] - 12s 94ms/step - loss: 1.1102 - mse: 0.0162 - mae: 0.0842 - MAEMS: 1.1100 - val_loss: 1.4458 - val_mse: 0.0165 - val_mae: 0.0897 - val_MAEMS: 1.4494\n",
      "Epoch 82/1000\n",
      "131/131 [==============================] - 12s 94ms/step - loss: 1.1529 - mse: 0.0162 - mae: 0.0849 - MAEMS: 1.1526 - val_loss: 1.4975 - val_mse: 0.0163 - val_mae: 0.0900 - val_MAEMS: 1.5003\n",
      "Epoch 83/1000\n",
      "131/131 [==============================] - 12s 94ms/step - loss: 1.2370 - mse: 0.0167 - mae: 0.0873 - MAEMS: 1.2367 - val_loss: 1.6172 - val_mse: 0.0168 - val_mae: 0.0929 - val_MAEMS: 1.6208\n",
      "Epoch 84/1000\n",
      "131/131 [==============================] - 12s 94ms/step - loss: 1.2581 - mse: 0.0170 - mae: 0.0885 - MAEMS: 1.2578 - val_loss: 1.4886 - val_mse: 0.0171 - val_mae: 0.0919 - val_MAEMS: 1.4921\n",
      "Epoch 85/1000\n",
      "131/131 [==============================] - 12s 95ms/step - loss: 1.1352 - mse: 0.0161 - mae: 0.0844 - MAEMS: 1.1350 - val_loss: 1.4819 - val_mse: 0.0159 - val_mae: 0.0888 - val_MAEMS: 1.4856\n",
      "Epoch 86/1000\n",
      "131/131 [==============================] - 12s 94ms/step - loss: 1.0995 - mse: 0.0158 - mae: 0.0829 - MAEMS: 1.0992 - val_loss: 1.5161 - val_mse: 0.0153 - val_mae: 0.0876 - val_MAEMS: 1.5188\n",
      "Epoch 87/1000\n",
      "131/131 [==============================] - 12s 94ms/step - loss: 1.1463 - mse: 0.0159 - mae: 0.0839 - MAEMS: 1.1461 - val_loss: 1.4434 - val_mse: 0.0164 - val_mae: 0.0899 - val_MAEMS: 1.4450\n",
      "Epoch 88/1000\n",
      "131/131 [==============================] - 12s 94ms/step - loss: 1.2548 - mse: 0.0166 - mae: 0.0874 - MAEMS: 1.2545 - val_loss: 1.4864 - val_mse: 0.0166 - val_mae: 0.0907 - val_MAEMS: 1.4927\n",
      "Wall time: 18min 9s\n"
     ]
    }
   ],
   "source": [
    "    %%time\n",
    "    hist2 = model2.fit(strX, strY, epochs=epochs, batch_size=b_size, shuffle=False, validation_data=(svaX, svaY), callbacks=[history2, early_stopping])  # , checkpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "3462070b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#np.savetxt('losshistory.txt',(loss_history,valloss_history))\n",
    "model2.save('Basic Model_woOutput.h5')\n",
    "testPredict2 = model2.predict(teX, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a59a3c78",
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.device('/gpu:0'):\n",
    "    model2 = keras.models.load_model('Basic Model_woOutput.h5', custom_objects={'MAEMS': MAEMS})\n",
    "    gc.collect()\n",
    "    testPredict2 = model2.predict(teX, batch_size=b_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d24a9954",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error Test Score > MSE ==  0.03626047354098841  MAE ==  0.15218740455472746  MAEMS ==  2.480339148049475\n"
     ]
    }
   ],
   "source": [
    "tePredict2 = testPredict2.reshape(-1)\n",
    "print('Error Test Score > MSE == ', npMSE(testY, tePredict2), ' MAE == ', npMAE(testY, tePredict2), ' MAEMS == ', npMAEMS(testY, tePredict2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19b30a5d",
   "metadata": {},
   "source": [
    "## Without PN Residual"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "9ebf3c8b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_5\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_6 (InputLayer)            [(None, 168, 37)]    0                                            \n",
      "__________________________________________________________________________________________________\n",
      "permute_4 (Permute)             (None, 37, 168)      0           input_6[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_13 (Dense)                (None, 37, 168)      28392       permute_4[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_14 (Dense)                (None, 37, 168)      28392       permute_4[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "multiply_118 (Multiply)         (None, 37, 168)      0           dense_13[0][0]                   \n",
      "                                                                 dense_14[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "attention_vec (Permute)         (None, 168, 37)      0           multiply_118[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "multiply_119 (Multiply)         (None, 168, 37)      0           input_6[0][0]                    \n",
      "                                                                 attention_vec[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_118 (Conv1D)             (None, 168, 256)     9728        multiply_119[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "activation_220 (Activation)     (None, 168, 256)     0           conv1d_118[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_221 (Activation)     (None, 168, 256)     0           conv1d_118[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "multiply_120 (Multiply)         (None, 168, 256)     0           activation_220[0][0]             \n",
      "                                                                 activation_221[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_119 (Conv1D)             (None, 168, 37)      18981       multiply_120[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "activation_222 (Activation)     (None, 168, 37)      0           conv1d_119[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_223 (Activation)     (None, 168, 37)      0           conv1d_119[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "multiply_121 (Multiply)         (None, 168, 37)      0           activation_222[0][0]             \n",
      "                                                                 activation_223[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_42 (Add)                    (None, 168, 37)      0           input_6[0][0]                    \n",
      "                                                                 multiply_121[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "add_43 (Add)                    (None, 168, 37)      0           input_6[0][0]                    \n",
      "                                                                 multiply_121[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_120 (Conv1D)             (None, 168, 256)     9728        add_42[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_122 (Conv1D)             (None, 168, 256)     9728        add_43[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "activation_224 (Activation)     (None, 168, 256)     0           conv1d_120[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_225 (Activation)     (None, 168, 256)     0           conv1d_120[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_228 (Activation)     (None, 168, 256)     0           conv1d_122[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_229 (Activation)     (None, 168, 256)     0           conv1d_122[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "multiply_122 (Multiply)         (None, 168, 256)     0           activation_224[0][0]             \n",
      "                                                                 activation_225[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "multiply_124 (Multiply)         (None, 168, 256)     0           activation_228[0][0]             \n",
      "                                                                 activation_229[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_121 (Conv1D)             (None, 168, 37)      18981       multiply_122[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_123 (Conv1D)             (None, 168, 37)      18981       multiply_124[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "activation_226 (Activation)     (None, 168, 37)      0           conv1d_121[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_227 (Activation)     (None, 168, 37)      0           conv1d_121[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_230 (Activation)     (None, 168, 37)      0           conv1d_123[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_231 (Activation)     (None, 168, 37)      0           conv1d_123[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "multiply_123 (Multiply)         (None, 168, 37)      0           activation_226[0][0]             \n",
      "                                                                 activation_227[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "multiply_125 (Multiply)         (None, 168, 37)      0           activation_230[0][0]             \n",
      "                                                                 activation_231[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_44 (Add)                    (None, 168, 37)      0           add_42[0][0]                     \n",
      "                                                                 multiply_123[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "add_45 (Add)                    (None, 168, 37)      0           add_43[0][0]                     \n",
      "                                                                 multiply_125[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_30 (Concatenate)    (None, 168, 148)     0           add_44[0][0]                     \n",
      "                                                                 add_45[0][0]                     \n",
      "                                                                 add_42[0][0]                     \n",
      "                                                                 add_43[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_124 (Conv1D)             (None, 168, 256)     38144       concatenate_30[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_126 (Conv1D)             (None, 168, 256)     38144       concatenate_30[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_232 (Activation)     (None, 168, 256)     0           conv1d_124[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_233 (Activation)     (None, 168, 256)     0           conv1d_124[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_236 (Activation)     (None, 168, 256)     0           conv1d_126[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_237 (Activation)     (None, 168, 256)     0           conv1d_126[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "multiply_126 (Multiply)         (None, 168, 256)     0           activation_232[0][0]             \n",
      "                                                                 activation_233[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "multiply_128 (Multiply)         (None, 168, 256)     0           activation_236[0][0]             \n",
      "                                                                 activation_237[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_125 (Conv1D)             (None, 168, 37)      18981       multiply_126[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_127 (Conv1D)             (None, 168, 37)      18981       multiply_128[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "activation_234 (Activation)     (None, 168, 37)      0           conv1d_125[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_235 (Activation)     (None, 168, 37)      0           conv1d_125[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_238 (Activation)     (None, 168, 37)      0           conv1d_127[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_239 (Activation)     (None, 168, 37)      0           conv1d_127[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "multiply_127 (Multiply)         (None, 168, 37)      0           activation_234[0][0]             \n",
      "                                                                 activation_235[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "multiply_129 (Multiply)         (None, 168, 37)      0           activation_238[0][0]             \n",
      "                                                                 activation_239[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_46 (Add)                    (None, 168, 37)      0           add_44[0][0]                     \n",
      "                                                                 multiply_127[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "add_47 (Add)                    (None, 168, 37)      0           add_45[0][0]                     \n",
      "                                                                 multiply_129[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_31 (Concatenate)    (None, 168, 222)     0           add_46[0][0]                     \n",
      "                                                                 add_47[0][0]                     \n",
      "                                                                 concatenate_30[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_128 (Conv1D)             (None, 168, 256)     57088       concatenate_31[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_130 (Conv1D)             (None, 168, 256)     57088       concatenate_31[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_240 (Activation)     (None, 168, 256)     0           conv1d_128[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_241 (Activation)     (None, 168, 256)     0           conv1d_128[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_244 (Activation)     (None, 168, 256)     0           conv1d_130[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_245 (Activation)     (None, 168, 256)     0           conv1d_130[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "multiply_130 (Multiply)         (None, 168, 256)     0           activation_240[0][0]             \n",
      "                                                                 activation_241[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "multiply_132 (Multiply)         (None, 168, 256)     0           activation_244[0][0]             \n",
      "                                                                 activation_245[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_129 (Conv1D)             (None, 168, 37)      18981       multiply_130[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_131 (Conv1D)             (None, 168, 37)      18981       multiply_132[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "activation_242 (Activation)     (None, 168, 37)      0           conv1d_129[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_243 (Activation)     (None, 168, 37)      0           conv1d_129[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_246 (Activation)     (None, 168, 37)      0           conv1d_131[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_247 (Activation)     (None, 168, 37)      0           conv1d_131[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "multiply_131 (Multiply)         (None, 168, 37)      0           activation_242[0][0]             \n",
      "                                                                 activation_243[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "multiply_133 (Multiply)         (None, 168, 37)      0           activation_246[0][0]             \n",
      "                                                                 activation_247[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_48 (Add)                    (None, 168, 37)      0           add_46[0][0]                     \n",
      "                                                                 multiply_131[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "add_49 (Add)                    (None, 168, 37)      0           add_45[0][0]                     \n",
      "                                                                 multiply_133[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_32 (Concatenate)    (None, 168, 296)     0           add_48[0][0]                     \n",
      "                                                                 add_49[0][0]                     \n",
      "                                                                 concatenate_31[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_132 (Conv1D)             (None, 168, 256)     76032       concatenate_32[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_134 (Conv1D)             (None, 168, 256)     76032       concatenate_32[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_248 (Activation)     (None, 168, 256)     0           conv1d_132[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_249 (Activation)     (None, 168, 256)     0           conv1d_132[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_252 (Activation)     (None, 168, 256)     0           conv1d_134[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_253 (Activation)     (None, 168, 256)     0           conv1d_134[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "multiply_134 (Multiply)         (None, 168, 256)     0           activation_248[0][0]             \n",
      "                                                                 activation_249[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "multiply_136 (Multiply)         (None, 168, 256)     0           activation_252[0][0]             \n",
      "                                                                 activation_253[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_133 (Conv1D)             (None, 168, 37)      18981       multiply_134[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_135 (Conv1D)             (None, 168, 37)      18981       multiply_136[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "activation_250 (Activation)     (None, 168, 37)      0           conv1d_133[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_251 (Activation)     (None, 168, 37)      0           conv1d_133[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_254 (Activation)     (None, 168, 37)      0           conv1d_135[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_255 (Activation)     (None, 168, 37)      0           conv1d_135[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "multiply_135 (Multiply)         (None, 168, 37)      0           activation_250[0][0]             \n",
      "                                                                 activation_251[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "multiply_137 (Multiply)         (None, 168, 37)      0           activation_254[0][0]             \n",
      "                                                                 activation_255[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_50 (Add)                    (None, 168, 37)      0           add_48[0][0]                     \n",
      "                                                                 multiply_135[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "add_51 (Add)                    (None, 168, 37)      0           add_49[0][0]                     \n",
      "                                                                 multiply_137[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_33 (Concatenate)    (None, 168, 370)     0           add_50[0][0]                     \n",
      "                                                                 add_51[0][0]                     \n",
      "                                                                 concatenate_32[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_34 (Concatenate)    (None, 168, 74)      0           add_50[0][0]                     \n",
      "                                                                 add_51[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_35 (Concatenate)    (None, 168, 1110)    0           concatenate_30[0][0]             \n",
      "                                                                 concatenate_31[0][0]             \n",
      "                                                                 concatenate_32[0][0]             \n",
      "                                                                 concatenate_33[0][0]             \n",
      "                                                                 concatenate_34[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_140 (Conv1D)             (None, 168, 720)     920880      concatenate_35[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout_8 (Dropout)             (None, 168, 720)     0           conv1d_140[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_141 (Conv1D)             (None, 168, 360)     320040      dropout_8[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_9 (Dropout)             (None, 168, 360)     0           conv1d_141[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling1d_5 (Glo (None, 360)          0           dropout_9[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_15 (Dense)                (None, 24)           8664        global_average_pooling1d_5[0][0] \n",
      "==================================================================================================\n",
      "Total params: 1,848,909\n",
      "Trainable params: 1,848,909\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "num_features = trvaX.shape[2]\n",
    "output_timesteps = trvaY.shape[1]\n",
    "\n",
    "with tf.device('/gpu:0'):\n",
    "    alpha=1.0\n",
    "    gamma=1.2\n",
    "    beta = 1\n",
    "    hfilters = 256\n",
    "    hkernel_size1 = 1\n",
    "    hkernel_size2 = 2\n",
    "    \n",
    "    visible1 = Input(shape=(timesteps, num_features))\n",
    "   \n",
    "    ## Attention Block\n",
    "    per1 = Permute((2,1))(visible1)\n",
    "    den1a = Dense(timesteps, activation='tanh')(per1)\n",
    "    den1b = Dense(timesteps, activation='sigmoid')(per1)\n",
    "    den1 = Multiply()([den1a, den1b])\n",
    "    per2 = Permute((2,1), name='attention_vec')(den1)\n",
    "    mul1 = Multiply()([visible1, per2])\n",
    "    \n",
    "    ## Series PN DCCNN Blocks 1 ~ 6\n",
    "    d1 = Conv1D(filters=round(hfilters*alpha), kernel_size=round(hkernel_size1*beta), padding='causal', dilation_rate=1)(mul1)\n",
    "    d1a = Activation(activations.tanh)(d1)\n",
    "    d1b = Activation(activations.sigmoid)(d1)\n",
    "    d1 = Multiply()([d1a, d1b])\n",
    "    \n",
    "    d1 = Conv1D(filters=num_features, kernel_size=round(hkernel_size2*beta), padding='causal', dilation_rate=2)(d1)\n",
    "    d1a = Activation(activations.tanh)(d1)\n",
    "    d1b = Activation(activations.sigmoid)(d1)\n",
    "    d1 = Multiply()([d1a, d1b])\n",
    "    \n",
    "    res01a = Add()([visible1, d1])   # (100, 25) (100, 25)\n",
    "    res01b = Add()([visible1, d1])\n",
    "\n",
    "    d1 = Conv1D(filters=round(hfilters*alpha), kernel_size=round(hkernel_size1*beta), padding='causal', dilation_rate=2)(res01a)\n",
    "    d1a = Activation(activations.tanh)(d1)\n",
    "    d1b = Activation(activations.sigmoid)(d1)\n",
    "    d1 = Multiply()([d1a, d1b])\n",
    "    \n",
    "    d1 = Conv1D(filters=num_features, kernel_size=round(hkernel_size2*beta), padding='causal', dilation_rate=4)(d1)    \n",
    "    d1a = Activation(activations.tanh)(d1)\n",
    "    d1b = Activation(activations.sigmoid)(d1)\n",
    "    \n",
    "    d1 = Multiply()([d1a, d1b])\n",
    "    res02a = Add()([res01a, d1])   # (100, 25) (100, 25)\n",
    "    \n",
    "    d2 = Conv1D(filters=round(hfilters*alpha), kernel_size=round(hkernel_size1*beta), padding='causal', dilation_rate=2)(res01b) \n",
    "    d2a = Activation(activations.tanh)(d2)\n",
    "    d2b = Activation(activations.sigmoid)(d2)\n",
    "    d2 = Multiply()([d2a, d2b])\n",
    "    \n",
    "    d2 = Conv1D(filters=num_features, kernel_size=round(hkernel_size2*beta), padding='causal', dilation_rate=4)(d2) \n",
    "    d2a = Activation(activations.tanh)(d2)\n",
    "    d2b = Activation(activations.sigmoid)(d2)\n",
    "    d2 = Multiply()([d2a, d2b])\n",
    "    \n",
    "    res02b = Add()([res01b, d2])   # (100, 25) (100, 25) \n",
    "    res02 = Concatenate()([res02a, res02b, res01a, res01b])\n",
    "    \n",
    "    d1 = Conv1D(filters=round(hfilters*alpha), kernel_size=round(hkernel_size1*beta), padding='causal', dilation_rate=4)(res02)\n",
    "    d1a = Activation(activations.tanh)(d1)\n",
    "    d1b = Activation(activations.sigmoid)(d1)\n",
    "    d1 = Multiply()([d1a, d1b])\n",
    "    \n",
    "    d1 = Conv1D(filters=num_features, kernel_size=round(hkernel_size2*beta), padding='causal', dilation_rate=8)(d1)    \n",
    "    d1a = Activation(activations.tanh)(d1)\n",
    "    d1b = Activation(activations.sigmoid)(d1)\n",
    "    d1 = Multiply()([d1a, d1b])\n",
    "    \n",
    "    res03a = Add()([res02a, d1])   # (100, 25) (100, 25)\n",
    "    \n",
    "    d2 = Conv1D(filters=round(hfilters*alpha), kernel_size=round(hkernel_size1*beta), padding='causal', dilation_rate=4)(res02) \n",
    "    d2a = Activation(activations.tanh)(d2)\n",
    "    d2b = Activation(activations.sigmoid)(d2)\n",
    "    d2 = Multiply()([d2a, d2b])\n",
    "    \n",
    "    d2 = Conv1D(filters=num_features, kernel_size=round(hkernel_size2*beta), padding='causal', dilation_rate=8)(d2) \n",
    "    d2a = Activation(activations.tanh)(d2)\n",
    "    d2b = Activation(activations.sigmoid)(d2)\n",
    "    d2 = Multiply()([d2a, d2b])\n",
    "    \n",
    "    res03b = Add()([res02b, d2])   # (100, 25) (100, 25)\n",
    "    res03 = Concatenate()([res03a, res03b, res02])\n",
    "    \n",
    "    d1 = Conv1D(filters=round(hfilters*alpha), kernel_size=round(hkernel_size1*beta), padding='causal', dilation_rate=8)(res03)\n",
    "    d1a = Activation(activations.tanh)(d1)\n",
    "    d1b = Activation(activations.sigmoid)(d1)\n",
    "    d1 = Multiply()([d1a, d1b])\n",
    "    d1 = Conv1D(filters=num_features, kernel_size=round(hkernel_size2*beta), padding='causal', dilation_rate=4)(d1)    \n",
    "    d1a = Activation(activations.tanh)(d1)\n",
    "    d1b = Activation(activations.sigmoid)(d1)\n",
    "    d1 = Multiply()([d1a, d1b])\n",
    "    res04a = Add()([res03a, d1])   # (100, 25) (100, 25)\n",
    "    \n",
    "    d2 = Conv1D(filters=round(hfilters*alpha), kernel_size=round(hkernel_size1*beta), padding='causal', dilation_rate=8)(res03) \n",
    "    d2a = Activation(activations.tanh)(d2)\n",
    "    d2b = Activation(activations.sigmoid)(d2)\n",
    "    d2 = Multiply()([d2a, d2b])\n",
    "    \n",
    "    d2 = Conv1D(filters=num_features, kernel_size=round(hkernel_size2*beta), padding='causal', dilation_rate=4)(d2) \n",
    "    d2a = Activation(activations.tanh)(d2)\n",
    "    d2b = Activation(activations.sigmoid)(d2)\n",
    "    d2 = Multiply()([d2a, d2b])\n",
    "    \n",
    "    res04b = Add()([res02b, d2])   # (100, 25) (100, 25)\n",
    "    res04 = Concatenate()([res04a, res04b, res03])\n",
    "    \n",
    "    d1 = Conv1D(filters=round(hfilters*alpha), kernel_size=round(hkernel_size1*beta), padding='causal', dilation_rate=4)(res04)\n",
    "    d1a = Activation(activations.tanh)(d1)\n",
    "    d1b = Activation(activations.sigmoid)(d1)\n",
    "    d1 = Multiply()([d1a, d1b])\n",
    "    \n",
    "    d1 = Conv1D(filters=num_features, kernel_size=round(hkernel_size2*beta), padding='causal', dilation_rate=2)(d1)    \n",
    "    d1a = Activation(activations.tanh)(d1)\n",
    "    d1b = Activation(activations.sigmoid)(d1)\n",
    "    d1 = Multiply()([d1a, d1b])\n",
    "    \n",
    "    res05a = Add()([res04a, d1])   # (100, 25) (100, 25)\n",
    "    \n",
    "    d2 = Conv1D(filters=round(hfilters*alpha), kernel_size=round(hkernel_size1*beta), padding='causal', dilation_rate=4)(res04) \n",
    "    d2a = Activation(activations.tanh)(d2)\n",
    "    d2b = Activation(activations.sigmoid)(d2)\n",
    "    d2 = Multiply()([d2a, d2b])\n",
    "    \n",
    "    d2 = Conv1D(filters=num_features, kernel_size=round(hkernel_size2*beta), padding='causal', dilation_rate=2)(d2) \n",
    "    d2a = Activation(activations.tanh)(d2)\n",
    "    d2b = Activation(activations.sigmoid)(d2)\n",
    "    d2 = Multiply()([d2a, d2b])\n",
    "    \n",
    "    res05b = Add()([res04b, d2])   # (100, 25) (100, 25)\n",
    "    res05 = Concatenate()([res05a, res05b, res04])\n",
    "    \n",
    "    d1 = Conv1D(filters=round(hfilters*alpha), kernel_size=round(hkernel_size1*beta), padding='causal', dilation_rate=2)(res05)\n",
    "    d1a = Activation(activations.tanh)(d1)\n",
    "    d1b = Activation(activations.sigmoid)(d1)\n",
    "    d1 = Multiply()([d1a, d1b])\n",
    "    \n",
    "    d1 = Conv1D(filters=num_features, kernel_size=round(hkernel_size2*beta), padding='causal', dilation_rate=1)(d1)    \n",
    "    d1a = Activation(activations.tanh)(d1)\n",
    "    d1b = Activation(activations.sigmoid)(d1)\n",
    "    d1 = Multiply()([d1a, d1b])\n",
    "\n",
    "    res06a = Add()([res05a, d1])   # (100, 25) (100, 25)\n",
    "    \n",
    "    d2 = Conv1D(filters=round(hfilters*alpha), kernel_size=round(hkernel_size1*beta), padding='causal', dilation_rate=2)(res05) \n",
    "    d2a = Activation(activations.tanh)(d2)\n",
    "    d2b = Activation(activations.sigmoid)(d2)\n",
    "    d2 = Multiply()([d2a, d2b])\n",
    "    d2 = Conv1D(filters=num_features, kernel_size=round(hkernel_size2*beta), padding='causal', dilation_rate=1)(d2) \n",
    "    d2a = Activation(activations.tanh)(d2)\n",
    "    d2b = Activation(activations.sigmoid)(d2)\n",
    "    d2 = Multiply()([d2a, d2b])\n",
    "\n",
    "    res06b = Add()([res05b, d2])   # (100, 25) (100, 25)\n",
    "    res06 = Concatenate()([res05a, res05b])\n",
    "    \n",
    "    res10 = Concatenate()([res02, res03, res04, res05, res06])   # \n",
    "    \n",
    "    #print('res10 :', res10.shap)  # (None, 24, 11) \n",
    "    \n",
    "    ## Output Block\n",
    "    out = Conv1D(720, 1, padding='same', activation=PReLU())(res10)   # 256, 11X10=110\n",
    "    out = Dropout(0.2)(out)   #SpatialDropout1D\n",
    "    \n",
    "    out = Conv1D(360, 1, padding='same', activation=PReLU())(out) # 512,  110X5=550\n",
    "    out = Dropout(0.2)(out)\n",
    "    \n",
    "    out = GlobalAveragePooling1D()(out) # pool_size=2, strides=1\n",
    "    \n",
    "    out = Dense(24)(out) \n",
    "    model3 = Model(inputs=[visible1], outputs=[out])\n",
    "    \n",
    "    print(model3.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "2290214e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "bdef70a5",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'model3' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-20-98fb0db4c2c5>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mmodel3\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcompile\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mMAEMS\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'adam'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmetrics\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'mse'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'mae'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mMAEMS\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mearly_stopping\u001b[0m \u001b[1;33m=\u001b[0m\u001b[0mEarlyStopping\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmonitor\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'val_loss'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpatience\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mbatch_size\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m168\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mepochs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m1000\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;31m#root_squared_mean_error\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'model3' is not defined"
     ]
    }
   ],
   "source": [
    "    model3.compile(loss=MAEMS, optimizer='adam', metrics=['mse','mae', MAEMS])\n",
    "    early_stopping =EarlyStopping(monitor='val_loss', patience=10)\n",
    "    batch_size = 168\n",
    "    epochs = 1000\n",
    "    #root_squared_mean_error\n",
    "    history3 = LossHistory()\n",
    "    history3.init()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "d154e88f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "  6/131 [>.............................] - ETA: 15s - loss: 8.9258 - mse: 0.1680 - mae: 0.3312 - MAEMS: 8.9258WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0582s vs `on_train_batch_end` time: 0.0635s). Check your callbacks.\n",
      "131/131 [==============================] - 22s 144ms/step - loss: 3.7252 - mse: 0.0931 - mae: 0.2482 - MAEMS: 3.7237 - val_loss: 3.1789 - val_mse: 0.0770 - val_mae: 0.2253 - val_MAEMS: 3.1751\n",
      "Epoch 2/1000\n",
      "131/131 [==============================] - 18s 138ms/step - loss: 3.1449 - mse: 0.0735 - mae: 0.2193 - MAEMS: 3.1441 - val_loss: 3.0077 - val_mse: 0.0621 - val_mae: 0.2009 - val_MAEMS: 3.0006\n",
      "Epoch 3/1000\n",
      "131/131 [==============================] - 18s 137ms/step - loss: 2.9149 - mse: 0.0616 - mae: 0.1982 - MAEMS: 2.9142 - val_loss: 2.8810 - val_mse: 0.0529 - val_mae: 0.1828 - val_MAEMS: 2.8730\n",
      "Epoch 4/1000\n",
      "131/131 [==============================] - 18s 138ms/step - loss: 2.8491 - mse: 0.0576 - mae: 0.1900 - MAEMS: 2.8485 - val_loss: 2.7178 - val_mse: 0.0538 - val_mae: 0.1815 - val_MAEMS: 2.7065\n",
      "Epoch 5/1000\n",
      "131/131 [==============================] - 18s 137ms/step - loss: 2.7033 - mse: 0.0538 - mae: 0.1817 - MAEMS: 2.7027 - val_loss: 2.6378 - val_mse: 0.0464 - val_mae: 0.1681 - val_MAEMS: 2.6293\n",
      "Epoch 6/1000\n",
      "131/131 [==============================] - 18s 138ms/step - loss: 2.5536 - mse: 0.0497 - mae: 0.1729 - MAEMS: 2.5532 - val_loss: 2.5318 - val_mse: 0.0433 - val_mae: 0.1614 - val_MAEMS: 2.5255\n",
      "Epoch 7/1000\n",
      "131/131 [==============================] - 18s 138ms/step - loss: 2.4427 - mse: 0.0463 - mae: 0.1658 - MAEMS: 2.4421 - val_loss: 2.3851 - val_mse: 0.0439 - val_mae: 0.1608 - val_MAEMS: 2.3781\n",
      "Epoch 8/1000\n",
      "131/131 [==============================] - 18s 136ms/step - loss: 2.3619 - mse: 0.0437 - mae: 0.1601 - MAEMS: 2.3615 - val_loss: 2.2982 - val_mse: 0.0379 - val_mae: 0.1479 - val_MAEMS: 2.2894\n",
      "Epoch 9/1000\n",
      "131/131 [==============================] - 18s 138ms/step - loss: 2.2488 - mse: 0.0410 - mae: 0.1537 - MAEMS: 2.2482 - val_loss: 2.3136 - val_mse: 0.0333 - val_mae: 0.1390 - val_MAEMS: 2.3076\n",
      "Epoch 10/1000\n",
      "131/131 [==============================] - 39s 299ms/step - loss: 2.1065 - mse: 0.0379 - mae: 0.1461 - MAEMS: 2.1062 - val_loss: 2.1141 - val_mse: 0.0378 - val_mae: 0.1455 - val_MAEMS: 2.1064\n",
      "Epoch 11/1000\n",
      "131/131 [==============================] - 20s 137ms/step - loss: 2.0220 - mse: 0.0355 - mae: 0.1404 - MAEMS: 2.0218 - val_loss: 2.2034 - val_mse: 0.0305 - val_mae: 0.1329 - val_MAEMS: 2.2030\n",
      "Epoch 12/1000\n",
      "131/131 [==============================] - 18s 139ms/step - loss: 1.9588 - mse: 0.0337 - mae: 0.1363 - MAEMS: 1.9587 - val_loss: 1.9808 - val_mse: 0.0293 - val_mae: 0.1268 - val_MAEMS: 1.9829\n",
      "Epoch 13/1000\n",
      "131/131 [==============================] - 18s 138ms/step - loss: 1.9365 - mse: 0.0327 - mae: 0.1336 - MAEMS: 1.9359 - val_loss: 1.9254 - val_mse: 0.0287 - val_mae: 0.1255 - val_MAEMS: 1.9232\n",
      "Epoch 14/1000\n",
      "131/131 [==============================] - 18s 139ms/step - loss: 1.8136 - mse: 0.0303 - mae: 0.1274 - MAEMS: 1.8132 - val_loss: 1.9270 - val_mse: 0.0253 - val_mae: 0.1178 - val_MAEMS: 1.9248\n",
      "Epoch 15/1000\n",
      "131/131 [==============================] - 18s 139ms/step - loss: 1.7120 - mse: 0.0282 - mae: 0.1215 - MAEMS: 1.7118 - val_loss: 1.8414 - val_mse: 0.0262 - val_mae: 0.1193 - val_MAEMS: 1.8388\n",
      "Epoch 16/1000\n",
      "131/131 [==============================] - 18s 139ms/step - loss: 1.7044 - mse: 0.0273 - mae: 0.1197 - MAEMS: 1.7042 - val_loss: 1.7108 - val_mse: 0.0267 - val_mae: 0.1174 - val_MAEMS: 1.7110\n",
      "Epoch 17/1000\n",
      "131/131 [==============================] - 18s 139ms/step - loss: 1.6784 - mse: 0.0265 - mae: 0.1176 - MAEMS: 1.6780 - val_loss: 1.7031 - val_mse: 0.0231 - val_mae: 0.1096 - val_MAEMS: 1.7019\n",
      "Epoch 18/1000\n",
      "131/131 [==============================] - 18s 139ms/step - loss: 1.6798 - mse: 0.0261 - mae: 0.1167 - MAEMS: 1.6795 - val_loss: 1.7473 - val_mse: 0.0244 - val_mae: 0.1138 - val_MAEMS: 1.7453\n",
      "Epoch 19/1000\n",
      "131/131 [==============================] - 18s 139ms/step - loss: 1.5790 - mse: 0.0246 - mae: 0.1121 - MAEMS: 1.5787 - val_loss: 1.6452 - val_mse: 0.0220 - val_mae: 0.1072 - val_MAEMS: 1.6443\n",
      "Epoch 20/1000\n",
      "131/131 [==============================] - 18s 139ms/step - loss: 1.4996 - mse: 0.0231 - mae: 0.1075 - MAEMS: 1.4995 - val_loss: 1.7177 - val_mse: 0.0195 - val_mae: 0.1016 - val_MAEMS: 1.7159\n",
      "Epoch 21/1000\n",
      "131/131 [==============================] - 18s 139ms/step - loss: 1.4849 - mse: 0.0223 - mae: 0.1055 - MAEMS: 1.4847 - val_loss: 1.5720 - val_mse: 0.0218 - val_mae: 0.1055 - val_MAEMS: 1.5720\n",
      "Epoch 22/1000\n",
      "131/131 [==============================] - 18s 138ms/step - loss: 1.4457 - mse: 0.0215 - mae: 0.1031 - MAEMS: 1.4457 - val_loss: 1.5689 - val_mse: 0.0203 - val_mae: 0.1019 - val_MAEMS: 1.5672\n",
      "Epoch 23/1000\n",
      "131/131 [==============================] - 18s 138ms/step - loss: 1.4335 - mse: 0.0210 - mae: 0.1018 - MAEMS: 1.4334 - val_loss: 1.5361 - val_mse: 0.0197 - val_mae: 0.0997 - val_MAEMS: 1.5329\n",
      "Epoch 24/1000\n",
      "131/131 [==============================] - 18s 138ms/step - loss: 1.4488 - mse: 0.0207 - mae: 0.1014 - MAEMS: 1.4486 - val_loss: 1.7067 - val_mse: 0.0196 - val_mae: 0.1014 - val_MAEMS: 1.7059\n",
      "Epoch 25/1000\n",
      "131/131 [==============================] - 18s 138ms/step - loss: 1.4738 - mse: 0.0208 - mae: 0.1020 - MAEMS: 1.4734 - val_loss: 1.4901 - val_mse: 0.0192 - val_mae: 0.0978 - val_MAEMS: 1.4876\n",
      "Epoch 26/1000\n",
      "131/131 [==============================] - 18s 139ms/step - loss: 1.4014 - mse: 0.0197 - mae: 0.0983 - MAEMS: 1.4012 - val_loss: 1.3718 - val_mse: 0.0200 - val_mae: 0.0986 - val_MAEMS: 1.3707\n",
      "Epoch 27/1000\n",
      "131/131 [==============================] - 18s 139ms/step - loss: 1.3983 - mse: 0.0193 - mae: 0.0972 - MAEMS: 1.3980 - val_loss: 1.3669 - val_mse: 0.0195 - val_mae: 0.0974 - val_MAEMS: 1.3676\n",
      "Epoch 28/1000\n",
      "131/131 [==============================] - 18s 138ms/step - loss: 1.3528 - mse: 0.0188 - mae: 0.0954 - MAEMS: 1.3527 - val_loss: 1.4555 - val_mse: 0.0166 - val_mae: 0.0908 - val_MAEMS: 1.4541\n",
      "Epoch 29/1000\n",
      "131/131 [==============================] - 18s 139ms/step - loss: 1.3086 - mse: 0.0180 - mae: 0.0928 - MAEMS: 1.3084 - val_loss: 1.3641 - val_mse: 0.0168 - val_mae: 0.0904 - val_MAEMS: 1.3643\n",
      "Epoch 30/1000\n",
      "131/131 [==============================] - 18s 138ms/step - loss: 1.2647 - mse: 0.0172 - mae: 0.0901 - MAEMS: 1.2646 - val_loss: 1.3307 - val_mse: 0.0175 - val_mae: 0.0918 - val_MAEMS: 1.3296\n",
      "Epoch 31/1000\n",
      "131/131 [==============================] - 18s 138ms/step - loss: 1.2719 - mse: 0.0170 - mae: 0.0898 - MAEMS: 1.2716 - val_loss: 1.3280 - val_mse: 0.0159 - val_mae: 0.0876 - val_MAEMS: 1.3252\n",
      "Epoch 32/1000\n",
      "131/131 [==============================] - 18s 139ms/step - loss: 1.3031 - mse: 0.0171 - mae: 0.0903 - MAEMS: 1.3027 - val_loss: 1.2776 - val_mse: 0.0166 - val_mae: 0.0887 - val_MAEMS: 1.2733\n",
      "Epoch 33/1000\n",
      "131/131 [==============================] - 18s 139ms/step - loss: 1.3216 - mse: 0.0172 - mae: 0.0910 - MAEMS: 1.3214 - val_loss: 1.3982 - val_mse: 0.0151 - val_mae: 0.0865 - val_MAEMS: 1.4002\n",
      "Epoch 34/1000\n",
      "131/131 [==============================] - 18s 138ms/step - loss: 1.3559 - mse: 0.0173 - mae: 0.0919 - MAEMS: 1.3557 - val_loss: 1.4903 - val_mse: 0.0148 - val_mae: 0.0866 - val_MAEMS: 1.4907\n",
      "Epoch 35/1000\n",
      "131/131 [==============================] - 18s 139ms/step - loss: 1.2716 - mse: 0.0165 - mae: 0.0885 - MAEMS: 1.2713 - val_loss: 1.5146 - val_mse: 0.0141 - val_mae: 0.0851 - val_MAEMS: 1.5220\n",
      "Epoch 36/1000\n",
      "131/131 [==============================] - 18s 138ms/step - loss: 1.2353 - mse: 0.0159 - mae: 0.0866 - MAEMS: 1.2350 - val_loss: 1.3341 - val_mse: 0.0147 - val_mae: 0.0845 - val_MAEMS: 1.3352\n",
      "Epoch 37/1000\n",
      "131/131 [==============================] - 18s 138ms/step - loss: 1.1864 - mse: 0.0152 - mae: 0.0840 - MAEMS: 1.1861 - val_loss: 1.3143 - val_mse: 0.0141 - val_mae: 0.0824 - val_MAEMS: 1.3124\n",
      "Epoch 38/1000\n",
      "131/131 [==============================] - 18s 138ms/step - loss: 1.1646 - mse: 0.0148 - mae: 0.0824 - MAEMS: 1.1644 - val_loss: 1.2305 - val_mse: 0.0146 - val_mae: 0.0826 - val_MAEMS: 1.2303\n",
      "Epoch 39/1000\n",
      "131/131 [==============================] - 18s 139ms/step - loss: 1.1387 - mse: 0.0144 - mae: 0.0810 - MAEMS: 1.1385 - val_loss: 1.3056 - val_mse: 0.0134 - val_mae: 0.0803 - val_MAEMS: 1.3074\n",
      "Epoch 40/1000\n",
      "131/131 [==============================] - 18s 138ms/step - loss: 1.1552 - mse: 0.0143 - mae: 0.0809 - MAEMS: 1.1551 - val_loss: 1.2235 - val_mse: 0.0151 - val_mae: 0.0841 - val_MAEMS: 1.2247\n",
      "Epoch 41/1000\n",
      "131/131 [==============================] - 18s 139ms/step - loss: 1.1906 - mse: 0.0144 - mae: 0.0818 - MAEMS: 1.1904 - val_loss: 1.2467 - val_mse: 0.0147 - val_mae: 0.0835 - val_MAEMS: 1.2472\n",
      "Epoch 42/1000\n",
      "131/131 [==============================] - 18s 138ms/step - loss: 1.2677 - mse: 0.0150 - mae: 0.0846 - MAEMS: 1.2675 - val_loss: 1.2840 - val_mse: 0.0155 - val_mae: 0.0864 - val_MAEMS: 1.2849\n",
      "Epoch 43/1000\n",
      "131/131 [==============================] - 18s 139ms/step - loss: 1.2351 - mse: 0.0148 - mae: 0.0836 - MAEMS: 1.2355 - val_loss: 1.6925 - val_mse: 0.0132 - val_mae: 0.0849 - val_MAEMS: 1.6974\n",
      "Epoch 44/1000\n",
      "131/131 [==============================] - 18s 138ms/step - loss: 1.2144 - mse: 0.0145 - mae: 0.0826 - MAEMS: 1.2147 - val_loss: 1.9215 - val_mse: 0.0123 - val_mae: 0.0850 - val_MAEMS: 1.9289\n",
      "Epoch 45/1000\n",
      "131/131 [==============================] - 18s 139ms/step - loss: 1.1870 - mse: 0.0142 - mae: 0.0812 - MAEMS: 1.1867 - val_loss: 1.8334 - val_mse: 0.0119 - val_mae: 0.0829 - val_MAEMS: 1.8390\n",
      "Epoch 46/1000\n",
      "131/131 [==============================] - 18s 138ms/step - loss: 1.1238 - mse: 0.0134 - mae: 0.0782 - MAEMS: 1.1236 - val_loss: 1.6261 - val_mse: 0.0115 - val_mae: 0.0793 - val_MAEMS: 1.6296\n",
      "Epoch 47/1000\n",
      "131/131 [==============================] - 18s 139ms/step - loss: 1.0794 - mse: 0.0129 - mae: 0.0760 - MAEMS: 1.0793 - val_loss: 1.4043 - val_mse: 0.0110 - val_mae: 0.0749 - val_MAEMS: 1.4027\n",
      "Epoch 48/1000\n",
      "131/131 [==============================] - 18s 138ms/step - loss: 1.0574 - mse: 0.0125 - mae: 0.0744 - MAEMS: 1.0572 - val_loss: 1.4779 - val_mse: 0.0112 - val_mae: 0.0766 - val_MAEMS: 1.4812\n",
      "Epoch 49/1000\n",
      "131/131 [==============================] - 18s 139ms/step - loss: 1.0577 - mse: 0.0123 - mae: 0.0739 - MAEMS: 1.0576 - val_loss: 1.3069 - val_mse: 0.0117 - val_mae: 0.0757 - val_MAEMS: 1.3087\n",
      "Epoch 50/1000\n",
      "131/131 [==============================] - 18s 138ms/step - loss: 1.0454 - mse: 0.0121 - mae: 0.0732 - MAEMS: 1.0453 - val_loss: 1.4669 - val_mse: 0.0110 - val_mae: 0.0756 - val_MAEMS: 1.4648\n",
      "Wall time: 15min 32s\n"
     ]
    }
   ],
   "source": [
    "    %%time\n",
    "    hist3 = model3.fit(strX, strY, epochs=epochs, batch_size=b_size, shuffle=False, validation_data=(svaX, svaY), callbacks=[history3, early_stopping])  # , checkpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "027ea176",
   "metadata": {},
   "outputs": [],
   "source": [
    "#np.savetxt('losshistory.txt',(loss_history,valloss_history))\n",
    "model3.save('Basic Model_woPN.h5')\n",
    "testPredict3 = model3.predict(teX, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "ed3a26d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.device('/gpu:0'):\n",
    "    model3 = keras.models.load_model('Basic Model_woPN.h5', custom_objects={'MAEMS': MAEMS})\n",
    "    gc.collect()\n",
    "    testPredict3 = model3.predict(teX, batch_size=b_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "ccd0742f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error Test Score > MSE ==  0.030640398373141378  MAE ==  0.14099169732075043  MAEMS ==  2.450423716735973\n"
     ]
    }
   ],
   "source": [
    "tePredict3 = testPredict3.reshape(-1)\n",
    "print('Error Test Score > MSE == ', npMSE(testY, tePredict3), ' MAE == ', npMAE(testY, tePredict3), ' MAEMS == ', npMAEMS(testY, tePredict3))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f4523d8",
   "metadata": {},
   "source": [
    "## Without PReLU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "694e8894",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_3\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_4 (InputLayer)            [(None, 168, 37)]    0                                            \n",
      "__________________________________________________________________________________________________\n",
      "permute_2 (Permute)             (None, 37, 168)      0           input_4[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_7 (Dense)                 (None, 37, 168)      28392       permute_2[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_8 (Dense)                 (None, 37, 168)      28392       permute_2[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "multiply_70 (Multiply)          (None, 37, 168)      0           dense_7[0][0]                    \n",
      "                                                                 dense_8[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "attention_vec (Permute)         (None, 168, 37)      0           multiply_70[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "multiply_71 (Multiply)          (None, 168, 37)      0           input_4[0][0]                    \n",
      "                                                                 attention_vec[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_70 (Conv1D)              (None, 168, 256)     9728        multiply_71[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "activation_132 (Activation)     (None, 168, 256)     0           conv1d_70[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_133 (Activation)     (None, 168, 256)     0           conv1d_70[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "multiply_72 (Multiply)          (None, 168, 256)     0           activation_132[0][0]             \n",
      "                                                                 activation_133[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_71 (Conv1D)              (None, 168, 37)      18981       multiply_72[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "activation_134 (Activation)     (None, 168, 37)      0           conv1d_71[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_135 (Activation)     (None, 168, 37)      0           conv1d_71[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "multiply_73 (Multiply)          (None, 168, 37)      0           activation_134[0][0]             \n",
      "                                                                 activation_135[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_24 (Add)                    (None, 168, 37)      0           input_4[0][0]                    \n",
      "                                                                 multiply_73[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "subtract_12 (Subtract)          (None, 168, 37)      0           input_4[0][0]                    \n",
      "                                                                 multiply_73[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_72 (Conv1D)              (None, 168, 256)     9728        add_24[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_74 (Conv1D)              (None, 168, 256)     9728        subtract_12[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "activation_136 (Activation)     (None, 168, 256)     0           conv1d_72[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_137 (Activation)     (None, 168, 256)     0           conv1d_72[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_140 (Activation)     (None, 168, 256)     0           conv1d_74[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_141 (Activation)     (None, 168, 256)     0           conv1d_74[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "multiply_74 (Multiply)          (None, 168, 256)     0           activation_136[0][0]             \n",
      "                                                                 activation_137[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "multiply_76 (Multiply)          (None, 168, 256)     0           activation_140[0][0]             \n",
      "                                                                 activation_141[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_73 (Conv1D)              (None, 168, 37)      18981       multiply_74[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_75 (Conv1D)              (None, 168, 37)      18981       multiply_76[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "activation_138 (Activation)     (None, 168, 37)      0           conv1d_73[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_139 (Activation)     (None, 168, 37)      0           conv1d_73[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_142 (Activation)     (None, 168, 37)      0           conv1d_75[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_143 (Activation)     (None, 168, 37)      0           conv1d_75[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "multiply_75 (Multiply)          (None, 168, 37)      0           activation_138[0][0]             \n",
      "                                                                 activation_139[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "multiply_77 (Multiply)          (None, 168, 37)      0           activation_142[0][0]             \n",
      "                                                                 activation_143[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_25 (Add)                    (None, 168, 37)      0           add_24[0][0]                     \n",
      "                                                                 multiply_75[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "subtract_13 (Subtract)          (None, 168, 37)      0           subtract_12[0][0]                \n",
      "                                                                 multiply_77[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_18 (Concatenate)    (None, 168, 148)     0           add_25[0][0]                     \n",
      "                                                                 subtract_13[0][0]                \n",
      "                                                                 add_24[0][0]                     \n",
      "                                                                 subtract_12[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_76 (Conv1D)              (None, 168, 256)     38144       concatenate_18[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_78 (Conv1D)              (None, 168, 256)     38144       concatenate_18[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_144 (Activation)     (None, 168, 256)     0           conv1d_76[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_145 (Activation)     (None, 168, 256)     0           conv1d_76[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_148 (Activation)     (None, 168, 256)     0           conv1d_78[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_149 (Activation)     (None, 168, 256)     0           conv1d_78[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "multiply_78 (Multiply)          (None, 168, 256)     0           activation_144[0][0]             \n",
      "                                                                 activation_145[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "multiply_80 (Multiply)          (None, 168, 256)     0           activation_148[0][0]             \n",
      "                                                                 activation_149[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_77 (Conv1D)              (None, 168, 37)      18981       multiply_78[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_79 (Conv1D)              (None, 168, 37)      18981       multiply_80[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "activation_146 (Activation)     (None, 168, 37)      0           conv1d_77[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_147 (Activation)     (None, 168, 37)      0           conv1d_77[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_150 (Activation)     (None, 168, 37)      0           conv1d_79[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_151 (Activation)     (None, 168, 37)      0           conv1d_79[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "multiply_79 (Multiply)          (None, 168, 37)      0           activation_146[0][0]             \n",
      "                                                                 activation_147[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "multiply_81 (Multiply)          (None, 168, 37)      0           activation_150[0][0]             \n",
      "                                                                 activation_151[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_26 (Add)                    (None, 168, 37)      0           add_25[0][0]                     \n",
      "                                                                 multiply_79[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "subtract_14 (Subtract)          (None, 168, 37)      0           subtract_13[0][0]                \n",
      "                                                                 multiply_81[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_19 (Concatenate)    (None, 168, 222)     0           add_26[0][0]                     \n",
      "                                                                 subtract_14[0][0]                \n",
      "                                                                 concatenate_18[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_80 (Conv1D)              (None, 168, 256)     57088       concatenate_19[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_82 (Conv1D)              (None, 168, 256)     57088       concatenate_19[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_152 (Activation)     (None, 168, 256)     0           conv1d_80[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_153 (Activation)     (None, 168, 256)     0           conv1d_80[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_156 (Activation)     (None, 168, 256)     0           conv1d_82[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_157 (Activation)     (None, 168, 256)     0           conv1d_82[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "multiply_82 (Multiply)          (None, 168, 256)     0           activation_152[0][0]             \n",
      "                                                                 activation_153[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "multiply_84 (Multiply)          (None, 168, 256)     0           activation_156[0][0]             \n",
      "                                                                 activation_157[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_81 (Conv1D)              (None, 168, 37)      18981       multiply_82[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_83 (Conv1D)              (None, 168, 37)      18981       multiply_84[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "activation_154 (Activation)     (None, 168, 37)      0           conv1d_81[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_155 (Activation)     (None, 168, 37)      0           conv1d_81[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_158 (Activation)     (None, 168, 37)      0           conv1d_83[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_159 (Activation)     (None, 168, 37)      0           conv1d_83[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "multiply_83 (Multiply)          (None, 168, 37)      0           activation_154[0][0]             \n",
      "                                                                 activation_155[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "multiply_85 (Multiply)          (None, 168, 37)      0           activation_158[0][0]             \n",
      "                                                                 activation_159[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_27 (Add)                    (None, 168, 37)      0           add_26[0][0]                     \n",
      "                                                                 multiply_83[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "subtract_15 (Subtract)          (None, 168, 37)      0           subtract_13[0][0]                \n",
      "                                                                 multiply_85[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_20 (Concatenate)    (None, 168, 296)     0           add_27[0][0]                     \n",
      "                                                                 subtract_15[0][0]                \n",
      "                                                                 concatenate_19[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_84 (Conv1D)              (None, 168, 256)     76032       concatenate_20[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_86 (Conv1D)              (None, 168, 256)     76032       concatenate_20[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_160 (Activation)     (None, 168, 256)     0           conv1d_84[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_161 (Activation)     (None, 168, 256)     0           conv1d_84[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_164 (Activation)     (None, 168, 256)     0           conv1d_86[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_165 (Activation)     (None, 168, 256)     0           conv1d_86[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "multiply_86 (Multiply)          (None, 168, 256)     0           activation_160[0][0]             \n",
      "                                                                 activation_161[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "multiply_88 (Multiply)          (None, 168, 256)     0           activation_164[0][0]             \n",
      "                                                                 activation_165[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_85 (Conv1D)              (None, 168, 37)      18981       multiply_86[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_87 (Conv1D)              (None, 168, 37)      18981       multiply_88[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "activation_162 (Activation)     (None, 168, 37)      0           conv1d_85[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_163 (Activation)     (None, 168, 37)      0           conv1d_85[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_166 (Activation)     (None, 168, 37)      0           conv1d_87[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_167 (Activation)     (None, 168, 37)      0           conv1d_87[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "multiply_87 (Multiply)          (None, 168, 37)      0           activation_162[0][0]             \n",
      "                                                                 activation_163[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "multiply_89 (Multiply)          (None, 168, 37)      0           activation_166[0][0]             \n",
      "                                                                 activation_167[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_28 (Add)                    (None, 168, 37)      0           add_27[0][0]                     \n",
      "                                                                 multiply_87[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "subtract_16 (Subtract)          (None, 168, 37)      0           subtract_15[0][0]                \n",
      "                                                                 multiply_89[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_21 (Concatenate)    (None, 168, 370)     0           add_28[0][0]                     \n",
      "                                                                 subtract_16[0][0]                \n",
      "                                                                 concatenate_20[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_22 (Concatenate)    (None, 168, 74)      0           add_28[0][0]                     \n",
      "                                                                 subtract_16[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_23 (Concatenate)    (None, 168, 1110)    0           concatenate_18[0][0]             \n",
      "                                                                 concatenate_19[0][0]             \n",
      "                                                                 concatenate_20[0][0]             \n",
      "                                                                 concatenate_21[0][0]             \n",
      "                                                                 concatenate_22[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_92 (Conv1D)              (None, 168, 720)     799920      concatenate_23[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout_4 (Dropout)             (None, 168, 720)     0           conv1d_92[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_93 (Conv1D)              (None, 168, 360)     259560      dropout_4[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_5 (Dropout)             (None, 168, 360)     0           conv1d_93[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling1d_3 (Glo (None, 360)          0           dropout_5[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_9 (Dense)                 (None, 24)           8664        global_average_pooling1d_3[0][0] \n",
      "==================================================================================================\n",
      "Total params: 1,667,469\n",
      "Trainable params: 1,667,469\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "num_features = trvaX.shape[2]\n",
    "output_timesteps = trvaY.shape[1]\n",
    "\n",
    "with tf.device('/gpu:0'):\n",
    "    alpha=1.0\n",
    "    gamma=1.2\n",
    "    beta = 1\n",
    "    hfilters = 256\n",
    "    hkernel_size1 = 1\n",
    "    hkernel_size2 = 2\n",
    "    \n",
    "    visible1 = Input(shape=(timesteps, num_features))\n",
    "   \n",
    "    ## Attention Block\n",
    "    per1 = Permute((2,1))(visible1)\n",
    "    den1a = Dense(timesteps, activation='tanh')(per1)\n",
    "    den1b = Dense(timesteps, activation='sigmoid')(per1)\n",
    "    den1 = Multiply()([den1a, den1b])\n",
    "    per2 = Permute((2,1), name='attention_vec')(den1)\n",
    "    mul1 = Multiply()([visible1, per2])\n",
    "    \n",
    "    ## Series PN DCCNN Blocks 1 ~ 6\n",
    "    d1 = Conv1D(filters=round(hfilters*alpha), kernel_size=round(hkernel_size1*beta), padding='causal', dilation_rate=1)(mul1)\n",
    "    d1a = Activation(activations.tanh)(d1)\n",
    "    d1b = Activation(activations.sigmoid)(d1)\n",
    "    d1 = Multiply()([d1a, d1b])\n",
    "    \n",
    "    d1 = Conv1D(filters=num_features, kernel_size=round(hkernel_size2*beta), padding='causal', dilation_rate=2)(d1)\n",
    "    d1a = Activation(activations.tanh)(d1)\n",
    "    d1b = Activation(activations.sigmoid)(d1)\n",
    "    d1 = Multiply()([d1a, d1b])\n",
    "    \n",
    "    res01a = Add()([visible1, d1])   # (100, 25) (100, 25)\n",
    "    res01b = Subtract()([visible1, d1])\n",
    "\n",
    "    d1 = Conv1D(filters=round(hfilters*alpha), kernel_size=round(hkernel_size1*beta), padding='causal', dilation_rate=2)(res01a)\n",
    "    d1a = Activation(activations.tanh)(d1)\n",
    "    d1b = Activation(activations.sigmoid)(d1)\n",
    "    d1 = Multiply()([d1a, d1b])\n",
    "    \n",
    "    d1 = Conv1D(filters=num_features, kernel_size=round(hkernel_size2*beta), padding='causal', dilation_rate=4)(d1)    \n",
    "    d1a = Activation(activations.tanh)(d1)\n",
    "    d1b = Activation(activations.sigmoid)(d1)\n",
    "    \n",
    "    d1 = Multiply()([d1a, d1b])\n",
    "    res02a = Add()([res01a, d1])   # (100, 25) (100, 25)\n",
    "    \n",
    "    d2 = Conv1D(filters=round(hfilters*alpha), kernel_size=round(hkernel_size1*beta), padding='causal', dilation_rate=2)(res01b) \n",
    "    d2a = Activation(activations.tanh)(d2)\n",
    "    d2b = Activation(activations.sigmoid)(d2)\n",
    "    d2 = Multiply()([d2a, d2b])\n",
    "    \n",
    "    d2 = Conv1D(filters=num_features, kernel_size=round(hkernel_size2*beta), padding='causal', dilation_rate=4)(d2) \n",
    "    d2a = Activation(activations.tanh)(d2)\n",
    "    d2b = Activation(activations.sigmoid)(d2)\n",
    "    d2 = Multiply()([d2a, d2b])\n",
    "    \n",
    "    res02b = Subtract()([res01b, d2])   # (100, 25) (100, 25) \n",
    "    res02 = Concatenate()([res02a, res02b, res01a, res01b])\n",
    "    \n",
    "    d1 = Conv1D(filters=round(hfilters*alpha), kernel_size=round(hkernel_size1*beta), padding='causal', dilation_rate=4)(res02)\n",
    "    d1a = Activation(activations.tanh)(d1)\n",
    "    d1b = Activation(activations.sigmoid)(d1)\n",
    "    d1 = Multiply()([d1a, d1b])\n",
    "    \n",
    "    d1 = Conv1D(filters=num_features, kernel_size=round(hkernel_size2*beta), padding='causal', dilation_rate=8)(d1)    \n",
    "    d1a = Activation(activations.tanh)(d1)\n",
    "    d1b = Activation(activations.sigmoid)(d1)\n",
    "    d1 = Multiply()([d1a, d1b])\n",
    "    \n",
    "    res03a = Add()([res02a, d1])   # (100, 25) (100, 25)\n",
    "    \n",
    "    d2 = Conv1D(filters=round(hfilters*alpha), kernel_size=round(hkernel_size1*beta), padding='causal', dilation_rate=4)(res02) \n",
    "    d2a = Activation(activations.tanh)(d2)\n",
    "    d2b = Activation(activations.sigmoid)(d2)\n",
    "    d2 = Multiply()([d2a, d2b])\n",
    "    \n",
    "    d2 = Conv1D(filters=num_features, kernel_size=round(hkernel_size2*beta), padding='causal', dilation_rate=8)(d2) \n",
    "    d2a = Activation(activations.tanh)(d2)\n",
    "    d2b = Activation(activations.sigmoid)(d2)\n",
    "    d2 = Multiply()([d2a, d2b])\n",
    "    \n",
    "    res03b = Subtract()([res02b, d2])   # (100, 25) (100, 25)\n",
    "    res03 = Concatenate()([res03a, res03b, res02])\n",
    "    \n",
    "    d1 = Conv1D(filters=round(hfilters*alpha), kernel_size=round(hkernel_size1*beta), padding='causal', dilation_rate=8)(res03)\n",
    "    d1a = Activation(activations.tanh)(d1)\n",
    "    d1b = Activation(activations.sigmoid)(d1)\n",
    "    d1 = Multiply()([d1a, d1b])\n",
    "    d1 = Conv1D(filters=num_features, kernel_size=round(hkernel_size2*beta), padding='causal', dilation_rate=4)(d1)    \n",
    "    d1a = Activation(activations.tanh)(d1)\n",
    "    d1b = Activation(activations.sigmoid)(d1)\n",
    "    d1 = Multiply()([d1a, d1b])\n",
    "    res04a = Add()([res03a, d1])   # (100, 25) (100, 25)\n",
    "    \n",
    "    d2 = Conv1D(filters=round(hfilters*alpha), kernel_size=round(hkernel_size1*beta), padding='causal', dilation_rate=8)(res03) \n",
    "    d2a = Activation(activations.tanh)(d2)\n",
    "    d2b = Activation(activations.sigmoid)(d2)\n",
    "    d2 = Multiply()([d2a, d2b])\n",
    "    \n",
    "    d2 = Conv1D(filters=num_features, kernel_size=round(hkernel_size2*beta), padding='causal', dilation_rate=4)(d2) \n",
    "    d2a = Activation(activations.tanh)(d2)\n",
    "    d2b = Activation(activations.sigmoid)(d2)\n",
    "    d2 = Multiply()([d2a, d2b])\n",
    "    \n",
    "    res04b = Subtract()([res02b, d2])   # (100, 25) (100, 25)\n",
    "    res04 = Concatenate()([res04a, res04b, res03])\n",
    "    \n",
    "    d1 = Conv1D(filters=round(hfilters*alpha), kernel_size=round(hkernel_size1*beta), padding='causal', dilation_rate=4)(res04)\n",
    "    d1a = Activation(activations.tanh)(d1)\n",
    "    d1b = Activation(activations.sigmoid)(d1)\n",
    "    d1 = Multiply()([d1a, d1b])\n",
    "    \n",
    "    d1 = Conv1D(filters=num_features, kernel_size=round(hkernel_size2*beta), padding='causal', dilation_rate=2)(d1)    \n",
    "    d1a = Activation(activations.tanh)(d1)\n",
    "    d1b = Activation(activations.sigmoid)(d1)\n",
    "    d1 = Multiply()([d1a, d1b])\n",
    "    \n",
    "    res05a = Add()([res04a, d1])   # (100, 25) (100, 25)\n",
    "    \n",
    "    d2 = Conv1D(filters=round(hfilters*alpha), kernel_size=round(hkernel_size1*beta), padding='causal', dilation_rate=4)(res04) \n",
    "    d2a = Activation(activations.tanh)(d2)\n",
    "    d2b = Activation(activations.sigmoid)(d2)\n",
    "    d2 = Multiply()([d2a, d2b])\n",
    "    \n",
    "    d2 = Conv1D(filters=num_features, kernel_size=round(hkernel_size2*beta), padding='causal', dilation_rate=2)(d2) \n",
    "    d2a = Activation(activations.tanh)(d2)\n",
    "    d2b = Activation(activations.sigmoid)(d2)\n",
    "    d2 = Multiply()([d2a, d2b])\n",
    "    \n",
    "    res05b = Subtract()([res04b, d2])   # (100, 25) (100, 25)\n",
    "    res05 = Concatenate()([res05a, res05b, res04])\n",
    "    \n",
    "    d1 = Conv1D(filters=round(hfilters*alpha), kernel_size=round(hkernel_size1*beta), padding='causal', dilation_rate=2)(res05)\n",
    "    d1a = Activation(activations.tanh)(d1)\n",
    "    d1b = Activation(activations.sigmoid)(d1)\n",
    "    d1 = Multiply()([d1a, d1b])\n",
    "    \n",
    "    d1 = Conv1D(filters=num_features, kernel_size=round(hkernel_size2*beta), padding='causal', dilation_rate=1)(d1)    \n",
    "    d1a = Activation(activations.tanh)(d1)\n",
    "    d1b = Activation(activations.sigmoid)(d1)\n",
    "    d1 = Multiply()([d1a, d1b])\n",
    "\n",
    "    res06a = Add()([res05a, d1])   # (100, 25) (100, 25)\n",
    "    \n",
    "    d2 = Conv1D(filters=round(hfilters*alpha), kernel_size=round(hkernel_size1*beta), padding='causal', dilation_rate=2)(res05) \n",
    "    d2a = Activation(activations.tanh)(d2)\n",
    "    d2b = Activation(activations.sigmoid)(d2)\n",
    "    d2 = Multiply()([d2a, d2b])\n",
    "    d2 = Conv1D(filters=num_features, kernel_size=round(hkernel_size2*beta), padding='causal', dilation_rate=1)(d2) \n",
    "    d2a = Activation(activations.tanh)(d2)\n",
    "    d2b = Activation(activations.sigmoid)(d2)\n",
    "    d2 = Multiply()([d2a, d2b])\n",
    "\n",
    "    res06b = Subtract()([res05b, d2])   # (100, 25) (100, 25)\n",
    "    res06 = Concatenate()([res05a, res05b])\n",
    "    \n",
    "    res10 = Concatenate()([res02, res03, res04, res05, res06])   # \n",
    "    \n",
    "    #print('res10 :', res10.shap)  # (None, 24, 11) \n",
    "    \n",
    "    ## Output Block\n",
    "    out = Conv1D(720, 1, padding='same', activation='relu')(res10)   # 256, 11X10=110\n",
    "    out = Dropout(0.2)(out)   #SpatialDropout1D\n",
    "    \n",
    "    out = Conv1D(360, 1, padding='same', activation='relu')(out) # 512,  110X5=550\n",
    "    out = Dropout(0.2)(out)\n",
    "    \n",
    "    out = GlobalAveragePooling1D()(out) # pool_size=2, strides=1\n",
    "    \n",
    "    out = Dense(24)(out) \n",
    "    model4 = Model(inputs=[visible1], outputs=[out])\n",
    "    \n",
    "    print(model4.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "1c6eba09",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2747"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "1a13d4e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "    model4.compile(loss=MAEMS, optimizer='adam', metrics=['mse','mae', MAEMS])\n",
    "    early_stopping =EarlyStopping(monitor='val_loss', patience=10)\n",
    "    batch_size = 100\n",
    "    epochs = 1000\n",
    "    #root_squared_mean_error\n",
    "    history4 = LossHistory()\n",
    "    history4.init()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "2b6c6fff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "  6/131 [>.............................] - ETA: 14s - loss: 8.1110 - mse: 0.1541 - mae: 0.3166 - MAEMS: 8.1110WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0575s vs `on_train_batch_end` time: 0.0612s). Check your callbacks.\n",
      "131/131 [==============================] - 20s 134ms/step - loss: 3.7624 - mse: 0.0962 - mae: 0.2529 - MAEMS: 3.7612 - val_loss: 3.4318 - val_mse: 0.0674 - val_mae: 0.2129 - val_MAEMS: 3.4351\n",
      "Epoch 2/1000\n",
      "131/131 [==============================] - 17s 128ms/step - loss: 3.2165 - mse: 0.0783 - mae: 0.2270 - MAEMS: 3.2157 - val_loss: 3.0969 - val_mse: 0.0689 - val_mae: 0.2123 - val_MAEMS: 3.0856\n",
      "Epoch 3/1000\n",
      "131/131 [==============================] - 17s 129ms/step - loss: 3.0361 - mse: 0.0697 - mae: 0.2125 - MAEMS: 3.0353 - val_loss: 2.9870 - val_mse: 0.0563 - val_mae: 0.1906 - val_MAEMS: 2.9803\n",
      "Epoch 4/1000\n",
      "131/131 [==============================] - 17s 128ms/step - loss: 2.9160 - mse: 0.0627 - mae: 0.1998 - MAEMS: 2.9153 - val_loss: 2.8311 - val_mse: 0.0507 - val_mae: 0.1786 - val_MAEMS: 2.8321\n",
      "Epoch 5/1000\n",
      "131/131 [==============================] - 17s 129ms/step - loss: 2.7941 - mse: 0.0572 - mae: 0.1891 - MAEMS: 2.7935 - val_loss: 2.6944 - val_mse: 0.0485 - val_mae: 0.1720 - val_MAEMS: 2.6926\n",
      "Epoch 6/1000\n",
      "131/131 [==============================] - 17s 128ms/step - loss: 2.6642 - mse: 0.0532 - mae: 0.1804 - MAEMS: 2.6637 - val_loss: 2.5943 - val_mse: 0.0465 - val_mae: 0.1671 - val_MAEMS: 2.5895\n",
      "Epoch 7/1000\n",
      "131/131 [==============================] - 17s 129ms/step - loss: 2.5670 - mse: 0.0497 - mae: 0.1731 - MAEMS: 2.5664 - val_loss: 2.4713 - val_mse: 0.0507 - val_mae: 0.1737 - val_MAEMS: 2.4630\n",
      "Epoch 8/1000\n",
      "131/131 [==============================] - 17s 128ms/step - loss: 2.4677 - mse: 0.0471 - mae: 0.1672 - MAEMS: 2.4671 - val_loss: 2.3752 - val_mse: 0.0463 - val_mae: 0.1641 - val_MAEMS: 2.3674\n",
      "Epoch 9/1000\n",
      "131/131 [==============================] - 17s 128ms/step - loss: 2.3928 - mse: 0.0450 - mae: 0.1623 - MAEMS: 2.3929 - val_loss: 2.3270 - val_mse: 0.0410 - val_mae: 0.1541 - val_MAEMS: 2.3232\n",
      "Epoch 10/1000\n",
      "131/131 [==============================] - 17s 128ms/step - loss: 2.3228 - mse: 0.0428 - mae: 0.1574 - MAEMS: 2.3225 - val_loss: 2.4409 - val_mse: 0.0343 - val_mae: 0.1417 - val_MAEMS: 2.4444\n",
      "Epoch 11/1000\n",
      "131/131 [==============================] - 17s 128ms/step - loss: 2.1957 - mse: 0.0400 - mae: 0.1508 - MAEMS: 2.1953 - val_loss: 2.4681 - val_mse: 0.0325 - val_mae: 0.1382 - val_MAEMS: 2.4675\n",
      "Epoch 12/1000\n",
      "131/131 [==============================] - 17s 129ms/step - loss: 2.0771 - mse: 0.0374 - mae: 0.1445 - MAEMS: 2.0767 - val_loss: 2.3434 - val_mse: 0.0300 - val_mae: 0.1319 - val_MAEMS: 2.3394\n",
      "Epoch 13/1000\n",
      "131/131 [==============================] - 17s 128ms/step - loss: 2.0159 - mse: 0.0354 - mae: 0.1398 - MAEMS: 2.0154 - val_loss: 2.5718 - val_mse: 0.0289 - val_mae: 0.1313 - val_MAEMS: 2.5727\n",
      "Epoch 14/1000\n",
      "131/131 [==============================] - 17s 129ms/step - loss: 2.0210 - mse: 0.0346 - mae: 0.1383 - MAEMS: 2.0204 - val_loss: 2.6218 - val_mse: 0.0261 - val_mae: 0.1252 - val_MAEMS: 2.6211\n",
      "Epoch 15/1000\n",
      "131/131 [==============================] - 17s 128ms/step - loss: 1.9752 - mse: 0.0335 - mae: 0.1355 - MAEMS: 1.9747 - val_loss: 2.6702 - val_mse: 0.0243 - val_mae: 0.1222 - val_MAEMS: 2.6713\n",
      "Epoch 16/1000\n",
      "131/131 [==============================] - 17s 129ms/step - loss: 1.9478 - mse: 0.0325 - mae: 0.1331 - MAEMS: 1.9471 - val_loss: 1.8861 - val_mse: 0.0356 - val_mae: 0.1391 - val_MAEMS: 1.8810\n",
      "Epoch 17/1000\n",
      "131/131 [==============================] - 17s 129ms/step - loss: 1.8001 - mse: 0.0304 - mae: 0.1270 - MAEMS: 1.7995 - val_loss: 1.9255 - val_mse: 0.0268 - val_mae: 0.1198 - val_MAEMS: 1.9211\n",
      "Epoch 18/1000\n",
      "131/131 [==============================] - 17s 128ms/step - loss: 1.7141 - mse: 0.0286 - mae: 0.1221 - MAEMS: 1.7137 - val_loss: 2.1238 - val_mse: 0.0230 - val_mae: 0.1138 - val_MAEMS: 2.1249\n",
      "Epoch 19/1000\n",
      "131/131 [==============================] - 17s 129ms/step - loss: 1.7784 - mse: 0.0286 - mae: 0.1230 - MAEMS: 1.7780 - val_loss: 1.7944 - val_mse: 0.0264 - val_mae: 0.1179 - val_MAEMS: 1.7903\n",
      "Epoch 20/1000\n",
      "131/131 [==============================] - 17s 128ms/step - loss: 1.6260 - mse: 0.0265 - mae: 0.1165 - MAEMS: 1.6257 - val_loss: 1.8611 - val_mse: 0.0229 - val_mae: 0.1109 - val_MAEMS: 1.8579\n",
      "Epoch 21/1000\n",
      "131/131 [==============================] - 17s 128ms/step - loss: 1.6057 - mse: 0.0257 - mae: 0.1144 - MAEMS: 1.6052 - val_loss: 1.8132 - val_mse: 0.0214 - val_mae: 0.1064 - val_MAEMS: 1.8097\n",
      "Epoch 22/1000\n",
      "131/131 [==============================] - 17s 128ms/step - loss: 1.6700 - mse: 0.0258 - mae: 0.1155 - MAEMS: 1.6696 - val_loss: 1.8319 - val_mse: 0.0229 - val_mae: 0.1103 - val_MAEMS: 1.8263\n",
      "Epoch 23/1000\n",
      "131/131 [==============================] - 17s 129ms/step - loss: 1.5900 - mse: 0.0248 - mae: 0.1122 - MAEMS: 1.5897 - val_loss: 1.8582 - val_mse: 0.0204 - val_mae: 0.1049 - val_MAEMS: 1.8574\n",
      "Epoch 24/1000\n",
      "131/131 [==============================] - 17s 128ms/step - loss: 1.5083 - mse: 0.0234 - mae: 0.1079 - MAEMS: 1.5079 - val_loss: 1.5944 - val_mse: 0.0220 - val_mae: 0.1055 - val_MAEMS: 1.5933\n",
      "Epoch 25/1000\n",
      "131/131 [==============================] - 17s 129ms/step - loss: 1.5950 - mse: 0.0239 - mae: 0.1101 - MAEMS: 1.5946 - val_loss: 1.6927 - val_mse: 0.0208 - val_mae: 0.1036 - val_MAEMS: 1.6881\n",
      "Epoch 26/1000\n",
      "131/131 [==============================] - 17s 128ms/step - loss: 1.5838 - mse: 0.0234 - mae: 0.1091 - MAEMS: 1.5835 - val_loss: 1.6715 - val_mse: 0.0209 - val_mae: 0.1043 - val_MAEMS: 1.6687\n",
      "Epoch 27/1000\n",
      "131/131 [==============================] - 17s 129ms/step - loss: 1.5096 - mse: 0.0225 - mae: 0.1063 - MAEMS: 1.5093 - val_loss: 1.8334 - val_mse: 0.0182 - val_mae: 0.0993 - val_MAEMS: 1.8298\n",
      "Epoch 28/1000\n",
      "131/131 [==============================] - 17s 128ms/step - loss: 1.4433 - mse: 0.0215 - mae: 0.1028 - MAEMS: 1.4428 - val_loss: 1.7433 - val_mse: 0.0174 - val_mae: 0.0963 - val_MAEMS: 1.7447\n",
      "Epoch 29/1000\n",
      "131/131 [==============================] - 17s 128ms/step - loss: 1.3772 - mse: 0.0204 - mae: 0.0992 - MAEMS: 1.3769 - val_loss: 1.8427 - val_mse: 0.0173 - val_mae: 0.0972 - val_MAEMS: 1.8403\n",
      "Epoch 30/1000\n",
      "131/131 [==============================] - 17s 129ms/step - loss: 1.3264 - mse: 0.0195 - mae: 0.0964 - MAEMS: 1.3262 - val_loss: 1.8158 - val_mse: 0.0162 - val_mae: 0.0941 - val_MAEMS: 1.8118\n",
      "Epoch 31/1000\n",
      "131/131 [==============================] - 17s 128ms/step - loss: 1.3179 - mse: 0.0191 - mae: 0.0953 - MAEMS: 1.3176 - val_loss: 1.5640 - val_mse: 0.0172 - val_mae: 0.0935 - val_MAEMS: 1.5588\n",
      "Epoch 32/1000\n",
      "131/131 [==============================] - 17s 129ms/step - loss: 1.3153 - mse: 0.0188 - mae: 0.0944 - MAEMS: 1.3151 - val_loss: 1.5761 - val_mse: 0.0166 - val_mae: 0.0921 - val_MAEMS: 1.5717\n",
      "Epoch 33/1000\n",
      "131/131 [==============================] - 17s 129ms/step - loss: 1.3254 - mse: 0.0185 - mae: 0.0939 - MAEMS: 1.3251 - val_loss: 1.8664 - val_mse: 0.0158 - val_mae: 0.0935 - val_MAEMS: 1.8611\n",
      "Epoch 34/1000\n",
      "131/131 [==============================] - 17s 129ms/step - loss: 1.3250 - mse: 0.0183 - mae: 0.0933 - MAEMS: 1.3247 - val_loss: 1.5975 - val_mse: 0.0168 - val_mae: 0.0933 - val_MAEMS: 1.5937\n",
      "Epoch 35/1000\n",
      "131/131 [==============================] - 17s 129ms/step - loss: 1.3719 - mse: 0.0185 - mae: 0.0945 - MAEMS: 1.3716 - val_loss: 1.5915 - val_mse: 0.0162 - val_mae: 0.0913 - val_MAEMS: 1.5897\n",
      "Epoch 36/1000\n",
      "131/131 [==============================] - 17s 129ms/step - loss: 1.3255 - mse: 0.0179 - mae: 0.0925 - MAEMS: 1.3254 - val_loss: 1.6795 - val_mse: 0.0150 - val_mae: 0.0894 - val_MAEMS: 1.6804\n",
      "Epoch 37/1000\n",
      "131/131 [==============================] - 17s 129ms/step - loss: 1.2815 - mse: 0.0174 - mae: 0.0906 - MAEMS: 1.2814 - val_loss: 1.9130 - val_mse: 0.0145 - val_mae: 0.0908 - val_MAEMS: 1.9151\n",
      "Epoch 38/1000\n",
      "131/131 [==============================] - 17s 128ms/step - loss: 1.2993 - mse: 0.0174 - mae: 0.0906 - MAEMS: 1.2989 - val_loss: 2.2829 - val_mse: 0.0146 - val_mae: 0.0956 - val_MAEMS: 2.2860\n",
      "Epoch 39/1000\n",
      "131/131 [==============================] - 17s 128ms/step - loss: 1.3296 - mse: 0.0174 - mae: 0.0913 - MAEMS: 1.3293 - val_loss: 2.3593 - val_mse: 0.0147 - val_mae: 0.0963 - val_MAEMS: 2.3633\n",
      "Epoch 40/1000\n",
      "131/131 [==============================] - 17s 128ms/step - loss: 1.3406 - mse: 0.0175 - mae: 0.0917 - MAEMS: 1.3404 - val_loss: 1.7244 - val_mse: 0.0144 - val_mae: 0.0882 - val_MAEMS: 1.7246\n",
      "Epoch 41/1000\n",
      "131/131 [==============================] - 17s 128ms/step - loss: 1.3108 - mse: 0.0171 - mae: 0.0901 - MAEMS: 1.3104 - val_loss: 1.6975 - val_mse: 0.0145 - val_mae: 0.0880 - val_MAEMS: 1.6917\n",
      "Wall time: 11min 33s\n"
     ]
    }
   ],
   "source": [
    "    %%time\n",
    "    hist4 = model4.fit(strX, strY, epochs=epochs, batch_size=b_size, shuffle=False, validation_data=(svaX, svaY), callbacks=[history, early_stopping])  # , checkpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "31ef76a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#np.savetxt('losshistory.txt',(loss_history,valloss_history))\n",
    "model4.save('Basic Model_woPrelu.h5')\n",
    "testPredict4 = model4.predict(teX, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "264aca8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.device('/gpu:0'):\n",
    "    model4 = keras.models.load_model('Basic Model_woPrelu.h5', custom_objects={'MAEMS': MAEMS})\n",
    "    gc.collect()\n",
    "    testPredict4 = model4.predict(teX, batch_size=b_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "3eb3375a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error Test Score > MSE ==  0.031765698081252514  MAE ==  0.14422164288822828  MAEMS ==  2.5242017433799804\n"
     ]
    }
   ],
   "source": [
    "tePredict4 = testPredict4.reshape(-1)\n",
    "print('Error Test Score > MSE == ', npMSE(testY, tePredict4), ' MAE == ', npMAE(testY, tePredict4), ' MAEMS == ', npMAEMS(testY, tePredict4))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd2a8eac",
   "metadata": {},
   "source": [
    "## Proposed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "20fd8a61",
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.device('/gpu:0'):\n",
    "    wind_model = keras.models.load_model('Basic Model Final_lead.h5', custom_objects={'MAEMS': MAEMS})\n",
    "    gc.collect()\n",
    "    #trainPredict = wind_model.predict(trvaX, batch_size=b_size)\n",
    "    testPredict5 = wind_model.predict(teX, batch_size=b_size)\n",
    "    tePredict5 = testPredict5.reshape(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "6668130d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error Test Score > MAEMS ==  2.4878017545532636\n",
      "Error Test Score > MAEMS ==  2.480339148049475\n",
      "Error Test Score > MAEMS ==  2.450423716735973\n",
      "Error Test Score > MAEMS ==  2.5242017433799804\n",
      "Error Test Score > MAEMS ==  2.3040104722921315\n"
     ]
    }
   ],
   "source": [
    "print('Error Test Score > MAEMS == ', npMAEMS(testY, tePredict))\n",
    "print('Error Test Score > MAEMS == ', npMAEMS(testY, tePredict2))\n",
    "print('Error Test Score > MAEMS == ', npMAEMS(testY, tePredict3))\n",
    "print('Error Test Score > MAEMS == ', npMAEMS(testY, tePredict4))\n",
    "print('Error Test Score > MAEMS == ', npMAEMS(testY, tePredict5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "612ecd3d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
