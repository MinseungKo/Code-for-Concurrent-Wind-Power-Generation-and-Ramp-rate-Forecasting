{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b42db69e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "import pandas as pd\n",
    "import codecs\n",
    "import numpy as np\n",
    "import math\n",
    "import csv\n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.metrics import recall_score, precision_score # New\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn import preprocessing\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow.keras.preprocessing\n",
    "#from tensorflow.keras.callbacks import ModelCheckpoint, CSVLogger, EarlyStopping, LearningRateScheduler, ReduceLROnPlateau\n",
    "from tensorflow.keras.models import Sequential, Model\n",
    "from tensorflow.keras.layers import Dense, Input, Flatten, Add, Multiply, Subtract\n",
    "from tensorflow.keras import backend as K\n",
    "from tensorflow.keras.layers import Activation, BatchNormalization\n",
    "# regularizers\n",
    "from tensorflow.keras.layers import Conv1D, Conv2D\n",
    "from tensorflow.keras.layers import MaxPooling1D\n",
    "from tensorflow.keras.layers import concatenate\n",
    "from tensorflow.keras.layers import LSTM, Bidirectional\n",
    "from tensorflow.keras.utils import plot_model\n",
    "from tensorflow.keras.layers import Dropout, SpatialDropout1D\n",
    "from scipy import signal\n",
    "import openpyxl\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "from matplotlib import pylab as plt\n",
    "import matplotlib.dates as mdates\n",
    "import seaborn as sns\n",
    "import sklearn\n",
    "from sklearn.model_selection import train_test_split\n",
    "from numpy.linalg import svd\n",
    "import gc\n",
    "from keijzer import *\n",
    "from tensorflow import keras\n",
    "from keras.models import Model\n",
    "from keras.layers import *\n",
    "from tensorflow.keras.optimizers import Adam,SGD\n",
    "from keras.layers import Dense, Input, Flatten, Add, concatenate, Dropout, Activation, Multiply, Embedding, Layer, Reshape\n",
    "from keras.layers import LSTM, Bidirectional, GlobalMaxPooling1D, GlobalAveragePooling1D  \n",
    "from keras.layers import Conv1D, AveragePooling1D, MaxPooling1D\n",
    "#from keras.ops import convert_to_tensor, convert_to_numpy\n",
    "#from keras.utils import plot_model\n",
    "from keras import activations\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from keras.callbacks import ModelCheckpoint, CSVLogger, EarlyStopping, LearningRateScheduler, ReduceLROnPlateau\n",
    "import math\n",
    "\n",
    "class LossHistory(tensorflow.keras.callbacks.Callback):  # history = LossHistory()\n",
    "    def init(self):  # history.init()\n",
    "        self.losses = []\n",
    "        # self.accs = []\n",
    "        self.val_losses = []\n",
    "        # self.val_accs = []\n",
    "        self.rmses = []\n",
    "        self.mses = []\n",
    "        self.maes = []\n",
    "        self.mapes = []\n",
    "        self.val_rmses = []\n",
    "        self.val_mses = []\n",
    "        self.val_maes = []\n",
    "        self.val_mapes = []\n",
    "\n",
    "    def on_epoch_end(self, batch, logs={}):\n",
    "        self.losses.append(logs.get('loss'))\n",
    "        # self.accs.append(logs.get('acc'))\n",
    "        self.val_losses.append(logs.get('val_loss'))\n",
    "        # self.val_accs.append(logs.get('val_accuracy\n",
    "        self.rmses.append(logs.get('root_mean_squared_error'))\n",
    "        self.mses.append(logs.get('mean_squared_error'))\n",
    "        self.maes.append(logs.get('mean_absolute_error'))\n",
    "        self.mapes.append(logs.get('mean_absolute_percentage_error'))\n",
    "        self.val_rmses.append(logs.get('val_root_mean_squared_error'))\n",
    "        self.val_mses.append(logs.get('val_mean_squared_error'))\n",
    "        self.val_maes.append(logs.get('val_mean_absolute_error'))\n",
    "        self.val_mapes.append(logs.get('val_mean_absolute_percentage_error'))\n",
    "\n",
    "\n",
    "\n",
    "def root_squared_mean_error(y_true, y_pred):\n",
    "    return K.mean((K.abs(y_pred - y_true))*K.square(y_true-K.mean(y_true)))*100\n",
    "\n",
    "def mse_mae(y_true, y_pred):\n",
    "    return K.mean(K.square(y_pred - y_true))+K.mean(K.abs(y_pred - y_true))\n",
    "\n",
    "from keras.layers.advanced_activations import PReLU\n",
    "\n",
    "def mean_absolute_percentage_error(y_true, y_pred):\n",
    "    y_true, y_pred = np.array(y_true), np.array(y_pred)\n",
    "    return np.mean(np.abs((y_true - y_pred) / y_true)) * 100\n",
    "\n",
    "def root_mean_squared_error(y_true, y_pred):\n",
    "        return K.sqrt(K.mean(K.square(y_pred - y_true))) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c6f9f8aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]\n"
     ]
    }
   ],
   "source": [
    "import scipy as sc\n",
    "import os\n",
    "\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = '0' # 여러개 사용시 '0,1,2' 식으로 하나의 문자열에 입력\n",
    "gpus = tf.config.experimental.list_physical_devices('GPU') # 호스트 러나임에 표시되는 GPU 장치 목록 반환\n",
    "\n",
    "if gpus: # 반환된 GPU 장치 목록이 있다면\n",
    "    try: # 해당 장치에 대한 메모리 증가 활성화 여부 설정\n",
    "        tf.config.experimental.set_memory_growth(gpus[0], True)\n",
    "    except RuntimeError as e: # try문 실패시에 에러문구 출력\n",
    "        print(e)\n",
    "\n",
    "print(tf.config.list_physical_devices('GPU'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bbf63464",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Year</th>\n",
       "      <th>Wind Change</th>\n",
       "      <th>Wind Output</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2020</td>\n",
       "      <td>0.620197</td>\n",
       "      <td>0.644724</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2020</td>\n",
       "      <td>0.544580</td>\n",
       "      <td>0.658617</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2020</td>\n",
       "      <td>0.570751</td>\n",
       "      <td>0.683924</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2020</td>\n",
       "      <td>0.599594</td>\n",
       "      <td>0.721813</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2020</td>\n",
       "      <td>0.495246</td>\n",
       "      <td>0.714187</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35058</th>\n",
       "      <td>2023</td>\n",
       "      <td>0.774643</td>\n",
       "      <td>0.484984</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35059</th>\n",
       "      <td>2023</td>\n",
       "      <td>0.735512</td>\n",
       "      <td>0.582157</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35060</th>\n",
       "      <td>2023</td>\n",
       "      <td>0.601593</td>\n",
       "      <td>0.620917</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35061</th>\n",
       "      <td>2023</td>\n",
       "      <td>0.536583</td>\n",
       "      <td>0.631322</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35062</th>\n",
       "      <td>2023</td>\n",
       "      <td>0.454969</td>\n",
       "      <td>0.606127</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>35063 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Year  Wind Change  Wind Output\n",
       "0      2020     0.620197     0.644724\n",
       "1      2020     0.544580     0.658617\n",
       "2      2020     0.570751     0.683924\n",
       "3      2020     0.599594     0.721813\n",
       "4      2020     0.495246     0.714187\n",
       "...     ...          ...          ...\n",
       "35058  2023     0.774643     0.484984\n",
       "35059  2023     0.735512     0.582157\n",
       "35060  2023     0.601593     0.620917\n",
       "35061  2023     0.536583     0.631322\n",
       "35062  2023     0.454969     0.606127\n",
       "\n",
       "[35063 rows x 3 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_path = 'C:/Users/smartgrid_AI/Desktop/windpower_ramprate/ercot_2020.csv'\n",
    "data_source1 = pd.read_csv(data_path)\n",
    "dat_source1 = pd.DataFrame(data_source1)\n",
    "#dat_source1 = dat_source1.iloc[:-3,:]\n",
    "\n",
    "data_path = 'C:/Users/smartgrid_AI/Desktop/windpower_ramprate/ercot_2021.csv'\n",
    "data_source2 = pd.read_csv(data_path)\n",
    "dat_source2 = pd.DataFrame(data_source2)\n",
    "dat_source2 = dat_source2.iloc[:8761,:9]\n",
    "\n",
    "data_path = 'C:/Users/smartgrid_AI/Desktop/windpower_ramprate/ercot_2022.csv'\n",
    "data_source3 = pd.read_csv(data_path)\n",
    "dat_source3 = pd.DataFrame(data_source3)\n",
    "dat_source3 = dat_source3.iloc[:8760,:9]\n",
    "\n",
    "data_path = 'C:/Users/smartgrid_AI/Desktop/windpower_ramprate/ercot_2023.csv'\n",
    "data_source4 = pd.read_csv(data_path)\n",
    "dat_source4 = pd.DataFrame(data_source4)\n",
    "dat_source4 = dat_source4.iloc[:8760,:9]\n",
    "\n",
    "dat_arr1 = np.array(dat_source1)\n",
    "dat_arr2 = np.array(dat_source2)\n",
    "dat_arr3 = np.array(dat_source3)\n",
    "dat_arr4 = np.array(dat_source4)\n",
    "\n",
    "dat_arr = np.concatenate([dat_arr1, dat_arr2, dat_arr3, dat_arr4],axis=0)\n",
    "dat_arr.shape # 8784, 8761, 8760, 8760\n",
    "\n",
    "dat_source = pd.DataFrame(dat_arr, columns=['Time-Date stamp','Date','ERCOT Load','Total Wind Output','Total Wind Installed','Wind Output, % of Load','Wind Output, % of Installed','1-hr MW change','1-hr % change'])\n",
    "dat = pd.DataFrame()\n",
    "dat['MW % change'] = np.array(dat_source.iloc[1:,3], dtype=float)-np.array(dat_source.iloc[0:-1,3], dtype=float)\n",
    "dat['MW % change'] = np.divide(np.array(dat['MW % change']),np.array(dat_source.iloc[1:,4]))*100\n",
    "dat['Total Wind Output'] = np.divide(np.array(dat_source.iloc[1:,3]), np.array(dat_source.iloc[1:,4]))\n",
    "\n",
    "ramp_ratio = 20\n",
    "load_ratio = 10\n",
    "year_arr = np.concatenate([np.ones(8784)*2020, np.ones(8760)*2021, np.ones(8760)*2022, np.ones(8760)*2023])\n",
    "year_df = pd.DataFrame(year_arr, columns=['Year'], dtype=int)\n",
    "wind_df = pd.concat([year_df, dat], axis=1)\n",
    "wind_df = wind_df.reset_index(drop=True)\n",
    "\n",
    "std_scaler = sklearn.preprocessing.MinMaxScaler()\n",
    "std_scaler_load = sklearn.preprocessing.MinMaxScaler()\n",
    "std_scaler_ramp = sklearn.preprocessing.MinMaxScaler()\n",
    "\n",
    "wind_df[['Total Wind Output']] = std_scaler.fit_transform(wind_df[['Total Wind Output']])\n",
    "wind_df[['MW % change']] = std_scaler_ramp.fit_transform(wind_df[['MW % change']])\n",
    "wind_df = wind_df.iloc[:-1,:]\n",
    "ramp_df = pd.DataFrame(wind_df)\n",
    "ramp_df.columns=['Year', 'Wind Change', 'Wind Output']\n",
    "ramp_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1579b632",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_dataset(dataset, timesteps, output_timesteps, leadtime):\n",
    "    dataX, dataY = [], []\n",
    "    for i in range(len(dataset) - timesteps -output_timesteps - leadtime - 1):\n",
    "        a = dataset[i:(i + timesteps), :]\n",
    "        dataX.append(a)\n",
    "        dataY.append(dataset[(i + timesteps + leadtime):(i+timesteps+output_timesteps+leadtime), :])\n",
    "    return np.array(dataX), np.array(dataY)\n",
    "\n",
    "def svdadd(X, start, end, b_size):\n",
    "    dec_x = X[start:end, :, :]\n",
    "    U, S, Vh = svd(dec_x.reshape(b_size, -1), full_matrices=True)\n",
    "\n",
    "    high_sig = np.matmul(np.matmul(U[:,:high_ind], np.diag(S[0:high_ind])), Vh[:high_ind,:])\n",
    "    low_sig = X[:dec_num, :, :].reshape(b_size,-1)-high_sig\n",
    "\n",
    "    rec_x = np.zeros((b_size, b_size, high_ind))\n",
    "    \n",
    "    for i in range(high_ind):\n",
    "        rec_x[:,:,i] = np.matmul((U[:,i]*S[i]).reshape(-1,1), Vh[i,:].reshape(1,-1))    \n",
    "    return rec_x, low_sig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1a2cee9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "norm_df = np.array(wind_df.iloc[:,2]).reshape(-1,1)\n",
    "timesteps = 24*7\n",
    "output_timesteps = 24\n",
    "leadtime = 6\n",
    "num_features = 1\n",
    "X, Y = create_dataset(norm_df, timesteps, output_timesteps, leadtime)\n",
    "b_size = timesteps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "86ccb732",
   "metadata": {},
   "outputs": [],
   "source": [
    "dec_num = timesteps\n",
    "high_ind = 35\n",
    "\n",
    "addX = np.zeros((X.shape[0], dec_num, high_ind+1))\n",
    "\n",
    "for k in range(X.shape[0]//dec_num):\n",
    "    rec_x, low_sig = svdadd(X, k*dec_num, (k+1)*dec_num, b_size)\n",
    "    addX[k*dec_num:k*dec_num+dec_num,:, :-1] = rec_x\n",
    "    addX[k*dec_num:k*dec_num+dec_num,:, -1] = low_sig\n",
    "    \n",
    "rec_x, low_sig = svdadd(X, X.shape[0]-dec_num, X.shape[0], b_size)\n",
    "addX[X.shape[0]-dec_num:X.shape[0], :, :-1] = rec_x\n",
    "addX[X.shape[0]-dec_num:X.shape[0],:, -1] = low_sig\n",
    "\n",
    "addX_det = addX[:, :, :-1]\n",
    "addX_det = np.sum(addX_det, axis=2)\n",
    "X = np.concatenate([X, addX], axis=2)\n",
    "num_features = X.shape[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "aced8246",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((31377, 168, 37), (31377, 24), (3487, 168, 37), (3487, 24))"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trvaX, teX, trvaY, teY = train_test_split(X, Y, test_size=0.1, shuffle=False)\n",
    "\n",
    "idx = np.arange(trvaX.shape[0])\n",
    "np.random.shuffle(idx)\n",
    "strvaX = trvaX[idx]\n",
    "strvaY = trvaY[idx]\n",
    "strvaY = strvaY.reshape(-1, output_timesteps)\n",
    "\n",
    "trvaY = trvaY.reshape(-1, output_timesteps)\n",
    "teY = teY.reshape(-1, output_timesteps)\n",
    "\n",
    "strX, svaX, strY, svaY = train_test_split(strvaX, strvaY, test_size=0.3, shuffle=False)\n",
    "trX, vaX, trY, vaY = train_test_split(trvaX, trvaY, test_size=0.3, shuffle=False)\n",
    "\n",
    "trvaX.shape, trvaY.shape, teX.shape, teY.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d15c5f40",
   "metadata": {},
   "outputs": [],
   "source": [
    "def MAEMS(y_true, y_pred):\n",
    "    return K.mean((K.abs(y_pred - y_true))*K.square(y_true))*100"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ced033e",
   "metadata": {},
   "source": [
    "## PatchMixer - With SVD With Shuffling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b10996de",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "import numpy as np\n",
    "\n",
    "# PatchMixerLayer definition\n",
    "class PatchMixerLayer(keras.layers.Layer):\n",
    "    def __init__(self, dim, a, kernel_size=8):\n",
    "        super(PatchMixerLayer, self).__init__()\n",
    "        self.resnet = keras.Sequential([\n",
    "            layers.Conv1D(dim, kernel_size, groups=dim, padding=\"same\"),\n",
    "            layers.Activation(\"gelu\"),\n",
    "            layers.BatchNormalization()\n",
    "        ])\n",
    "        self.conv_1x1 = keras.Sequential([\n",
    "            layers.Conv1D(a, 1),\n",
    "            layers.Activation(\"gelu\"),\n",
    "            layers.BatchNormalization()\n",
    "        ])\n",
    "    \n",
    "    def call(self, x):\n",
    "        x = x + self.resnet(x)\n",
    "        x = self.conv_1x1(x)\n",
    "        return x\n",
    "\n",
    "# RevIN implementation\n",
    "class RevIN(layers.Layer):\n",
    "    def __init__(self, num_features, eps=1e-5, affine=True, subtract_last=False):\n",
    "        super(RevIN, self).__init__()\n",
    "        self.num_features = num_features\n",
    "        self.eps = eps\n",
    "        self.affine = affine\n",
    "        self.subtract_last = subtract_last\n",
    "        if self.affine:\n",
    "            self.affine_weight = self.add_weight(shape=(num_features,), initializer=\"ones\", trainable=True)\n",
    "            self.affine_bias = self.add_weight(shape=(num_features,), initializer=\"zeros\", trainable=True)\n",
    "    \n",
    "    def call(self, x, mode):\n",
    "        if mode == \"norm\":\n",
    "            return self._normalize(x)\n",
    "        elif mode == \"denorm\":\n",
    "            return self._denormalize(x)\n",
    "        else:\n",
    "            raise NotImplementedError\n",
    "\n",
    "    def _normalize(self, x):\n",
    "        mean = tf.reduce_mean(x, axis=(1, 2), keepdims=True)\n",
    "        stdev = tf.math.sqrt(tf.reduce_variance(x, axis=(1, 2), keepdims=True) + self.eps)\n",
    "        if self.subtract_last:\n",
    "            last = tf.expand_dims(x[:, -1, :], axis=1)\n",
    "            x = (x - last) / stdev\n",
    "        else:\n",
    "            x = (x - mean) / stdev\n",
    "        if self.affine:\n",
    "            x = x * self.affine_weight + self.affine_bias\n",
    "        return x\n",
    "\n",
    "    def _denormalize(self, x):\n",
    "        if self.affine:\n",
    "            x = (x - self.affine_bias) / self.affine_weight\n",
    "        stdev = tf.math.sqrt(tf.reduce_variance(x, axis=(1, 2), keepdims=True) + self.eps)\n",
    "        mean = tf.reduce_mean(x, axis=(1, 2), keepdims=True)\n",
    "        x = x * stdev + mean\n",
    "        return x\n",
    "\n",
    "# Main PatchMixer model definition\n",
    "class PatchMixerModel(keras.Model):\n",
    "    def __init__(self, input_shape, patch_size, stride, d_model, depth, kernel_size, forecasting, head_dropout):\n",
    "        super(PatchMixerModel, self).__init__()\n",
    "        self.lookback = input_shape[1]\n",
    "        self.patch_size = patch_size\n",
    "        self.stride = stride\n",
    "        self.patch_num = (self.lookback - self.patch_size) // self.stride + 1\n",
    "        self.d_model = d_model\n",
    "        self.depth = depth\n",
    "        self.kernel_size = kernel_size\n",
    "        self.forecasting = forecasting\n",
    "        self.head_dropout = head_dropout\n",
    "\n",
    "        self.patch_mixer_blocks = [PatchMixerLayer(self.patch_num, self.patch_num, kernel_size) for _ in range(depth)]\n",
    "        self.W_P = layers.Dense(d_model)\n",
    "        \n",
    "        self.head0 = keras.Sequential([\n",
    "            layers.Flatten(),\n",
    "            layers.Dense(forecasting),\n",
    "            layers.Dropout(head_dropout)\n",
    "        ])\n",
    "        self.head1 = keras.Sequential([\n",
    "            layers.Flatten(),\n",
    "            layers.Dense(forecasting * 2, activation=\"gelu\"),\n",
    "            layers.Dropout(head_dropout),\n",
    "            layers.Dense(forecasting),\n",
    "            layers.Dropout(head_dropout)\n",
    "        ])\n",
    "    \n",
    "    def call(self, x):\n",
    "        batch_size = tf.shape(x)[0]\n",
    "        x = tf.transpose(x, perm=[0, 2, 1])\n",
    "        x_padded = tf.image.extract_patches(\n",
    "            images=tf.expand_dims(x, axis=-1),\n",
    "            sizes=[1, self.patch_size, 1, 1],\n",
    "            strides=[1, self.stride, 1, 1],\n",
    "            rates=[1, 1, 1, 1],\n",
    "            padding=\"VALID\"\n",
    "        )\n",
    "        #print(x_padded.shape)\n",
    "        x = self.W_P(x_padded)\n",
    "        x = tf.reshape(x, (batch_size, -1, self.d_model))\n",
    "        u = self.head0(x)\n",
    "        #print(x.shape, (self.lookback - self.patch_size),self.stride, self.patch_num)\n",
    "        for block in self.patch_mixer_blocks:\n",
    "            x = block(x)\n",
    "        x = self.head1(x)\n",
    "        return u + x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ba71d064",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"patch_mixer_model_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "patch_mixer_layer_3 (PatchMi multiple                  1551      \n",
      "_________________________________________________________________\n",
      "patch_mixer_layer_4 (PatchMi multiple                  1551      \n",
      "_________________________________________________________________\n",
      "patch_mixer_layer_5 (PatchMi multiple                  1551      \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              multiple                  297       \n",
      "_________________________________________________________________\n",
      "sequential_14 (Sequential)   (168, 24)                 798360    \n",
      "_________________________________________________________________\n",
      "sequential_15 (Sequential)   (168, 24)                 1597896   \n",
      "=================================================================\n",
      "Total params: 2,401,206\n",
      "Trainable params: 2,400,810\n",
      "Non-trainable params: 396\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "input_shape = (None, 168, 37)  # Example input shape\n",
    "\n",
    "with tf.device('/gpu:0'):\n",
    "    model = PatchMixerModel(\n",
    "        input_shape=input_shape,\n",
    "        patch_size=8,\n",
    "        stride=5,\n",
    "        d_model=33,\n",
    "        depth=3,\n",
    "        kernel_size=4,\n",
    "        forecasting=24,\n",
    "        head_dropout=0.1)\n",
    "    model.build(input_shape=(168, 168, 37))\n",
    "    model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "3a3b3838",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6482"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "ec9dcfe7",
   "metadata": {},
   "outputs": [],
   "source": [
    "    model.compile(loss=MAEMS, optimizer='adam', metrics=['mse','mae', MAEMS])\n",
    "    early_stopping =EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)\n",
    "    batch_size = 168\n",
    "    epochs = 1000\n",
    "    history = LossHistory()\n",
    "    history.init()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "cc7653e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "131/131 [==============================] - 10s 56ms/step - loss: 7.0601 - mse: 0.3781 - mae: 0.3090 - MAEMS: 7.0548 - val_loss: 3.6172 - val_mse: 0.0478 - val_mae: 0.1789 - val_MAEMS: 3.6010\n",
      "Epoch 2/1000\n",
      "131/131 [==============================] - 7s 52ms/step - loss: 4.4660 - mse: 0.0792 - mae: 0.2223 - MAEMS: 4.4658 - val_loss: 3.3693 - val_mse: 0.0484 - val_mae: 0.1781 - val_MAEMS: 3.3564\n",
      "Epoch 3/1000\n",
      "131/131 [==============================] - 7s 52ms/step - loss: 4.3301 - mse: 0.0751 - mae: 0.2164 - MAEMS: 4.3299 - val_loss: 3.4239 - val_mse: 0.0461 - val_mae: 0.1738 - val_MAEMS: 3.4144\n",
      "Epoch 4/1000\n",
      "131/131 [==============================] - 7s 52ms/step - loss: 4.2354 - mse: 0.0723 - mae: 0.2119 - MAEMS: 4.2356 - val_loss: 3.2457 - val_mse: 0.0484 - val_mae: 0.1775 - val_MAEMS: 3.2333\n",
      "Epoch 5/1000\n",
      "131/131 [==============================] - 7s 52ms/step - loss: 4.1692 - mse: 0.0701 - mae: 0.2087 - MAEMS: 4.1690 - val_loss: 3.0749 - val_mse: 0.0500 - val_mae: 0.1790 - val_MAEMS: 3.0648\n",
      "Epoch 6/1000\n",
      "131/131 [==============================] - 7s 52ms/step - loss: 4.0799 - mse: 0.0685 - mae: 0.2062 - MAEMS: 4.0796 - val_loss: 3.4222 - val_mse: 0.0427 - val_mae: 0.1686 - val_MAEMS: 3.4101\n",
      "Epoch 7/1000\n",
      "131/131 [==============================] - 7s 52ms/step - loss: 4.0195 - mse: 0.0675 - mae: 0.2048 - MAEMS: 4.0191 - val_loss: 3.1133 - val_mse: 0.0471 - val_mae: 0.1748 - val_MAEMS: 3.1068\n",
      "Epoch 8/1000\n",
      "131/131 [==============================] - 7s 52ms/step - loss: 3.9583 - mse: 0.0664 - mae: 0.2031 - MAEMS: 3.9583 - val_loss: 2.9416 - val_mse: 0.0521 - val_mae: 0.1825 - val_MAEMS: 2.9343\n",
      "Epoch 9/1000\n",
      "131/131 [==============================] - 7s 52ms/step - loss: 3.9639 - mse: 0.0660 - mae: 0.2026 - MAEMS: 3.9636 - val_loss: 2.9407 - val_mse: 0.0522 - val_mae: 0.1825 - val_MAEMS: 2.9315\n",
      "Epoch 10/1000\n",
      "131/131 [==============================] - 7s 52ms/step - loss: 3.9007 - mse: 0.0655 - mae: 0.2019 - MAEMS: 3.9005 - val_loss: 2.9635 - val_mse: 0.0507 - val_mae: 0.1800 - val_MAEMS: 2.9540\n",
      "Epoch 11/1000\n",
      "131/131 [==============================] - 7s 52ms/step - loss: 3.8863 - mse: 0.0653 - mae: 0.2016 - MAEMS: 3.8864 - val_loss: 2.9624 - val_mse: 0.0504 - val_mae: 0.1798 - val_MAEMS: 2.9543\n",
      "Epoch 12/1000\n",
      "131/131 [==============================] - 7s 52ms/step - loss: 3.8696 - mse: 0.0651 - mae: 0.2014 - MAEMS: 3.8696 - val_loss: 3.0258 - val_mse: 0.0478 - val_mae: 0.1760 - val_MAEMS: 3.0164\n",
      "Epoch 13/1000\n",
      "131/131 [==============================] - 7s 52ms/step - loss: 3.8493 - mse: 0.0646 - mae: 0.2007 - MAEMS: 3.8492 - val_loss: 3.0567 - val_mse: 0.0466 - val_mae: 0.1741 - val_MAEMS: 3.0451\n",
      "Epoch 14/1000\n",
      "131/131 [==============================] - 7s 52ms/step - loss: 3.8255 - mse: 0.0646 - mae: 0.2007 - MAEMS: 3.8256 - val_loss: 3.0699 - val_mse: 0.0460 - val_mae: 0.1731 - val_MAEMS: 3.0611\n",
      "Epoch 15/1000\n",
      "131/131 [==============================] - 7s 52ms/step - loss: 3.8245 - mse: 0.0647 - mae: 0.2007 - MAEMS: 3.8242 - val_loss: 3.0911 - val_mse: 0.0456 - val_mae: 0.1724 - val_MAEMS: 3.0826\n",
      "Epoch 16/1000\n",
      "131/131 [==============================] - 7s 52ms/step - loss: 3.7943 - mse: 0.0643 - mae: 0.2000 - MAEMS: 3.7940 - val_loss: 3.0765 - val_mse: 0.0459 - val_mae: 0.1729 - val_MAEMS: 3.0652\n",
      "Epoch 17/1000\n",
      "131/131 [==============================] - 7s 52ms/step - loss: 3.7871 - mse: 0.0643 - mae: 0.2000 - MAEMS: 3.7871 - val_loss: 3.0827 - val_mse: 0.0455 - val_mae: 0.1723 - val_MAEMS: 3.0732\n",
      "Epoch 18/1000\n",
      "131/131 [==============================] - 7s 52ms/step - loss: 3.7866 - mse: 0.0641 - mae: 0.1998 - MAEMS: 3.7864 - val_loss: 3.0619 - val_mse: 0.0458 - val_mae: 0.1727 - val_MAEMS: 3.0530\n",
      "Epoch 19/1000\n",
      "131/131 [==============================] - 7s 52ms/step - loss: 3.7636 - mse: 0.0641 - mae: 0.1997 - MAEMS: 3.7632 - val_loss: 3.0784 - val_mse: 0.0454 - val_mae: 0.1721 - val_MAEMS: 3.0688\n",
      "Wall time: 2min 12s\n"
     ]
    }
   ],
   "source": [
    "    %%time\n",
    "    b_size = 168\n",
    "    hist = model.fit(strX, strY, epochs=epochs, batch_size=b_size, shuffle=False, validation_data=(svaX, svaY), callbacks=[history, early_stopping])  # , checkpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "0f35fab1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "154515"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "883d7977",
   "metadata": {},
   "outputs": [],
   "source": [
    "#model3.save('SCINet', save_format='tf')\n",
    "testPredict = model.predict(teX, batch_size=b_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "18a825ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "def npMAEMS(y_true, y_pred):\n",
    "    return np.mean((abs(y_pred - y_true))*np.square(y_true))*100\n",
    "def npMAEMD(y_true, y_pred):\n",
    "    return np.mean((abs(y_pred - y_true))*np.square(y_true-np.mean(y_true)))*100\n",
    "def npMSE(y_true, y_pred):\n",
    "    return np.mean(np.square(-y_true+y_pred))\n",
    "def npMAE(y_true, y_pred):\n",
    "    return np.mean(abs(-y_true+y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "851ca02b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error Test Score > MSE ==  0.05777416028290359  MAE ==  0.19821962767480678  MAEMS ==  2.299234600962123\n"
     ]
    }
   ],
   "source": [
    "tePredict = testPredict.reshape(-1)\n",
    "testY = teY.reshape(-1)\n",
    "print('Error Test Score > MSE == ', npMSE(testY, tePredict), ' MAE == ', npMAE(testY, tePredict), ' MAEMS == ', npMAEMS(testY, tePredict))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3103338",
   "metadata": {},
   "source": [
    "## Without Shuffling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "2660d1d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"patch_mixer_model_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "patch_mixer_layer_6 (PatchMi multiple                  1683      \n",
      "_________________________________________________________________\n",
      "patch_mixer_layer_7 (PatchMi multiple                  1683      \n",
      "_________________________________________________________________\n",
      "patch_mixer_layer_8 (PatchMi multiple                  1683      \n",
      "_________________________________________________________________\n",
      "patch_mixer_layer_9 (PatchMi multiple                  1683      \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              multiple                  297       \n",
      "_________________________________________________________________\n",
      "sequential_24 (Sequential)   (168, 24)                 798360    \n",
      "_________________________________________________________________\n",
      "sequential_25 (Sequential)   (168, 24)                 1597896   \n",
      "=================================================================\n",
      "Total params: 2,403,285\n",
      "Trainable params: 2,402,757\n",
      "Non-trainable params: 528\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "input_shape = (None, 168, 37)  # Example input shape\n",
    "\n",
    "with tf.device('/gpu:0'):\n",
    "    model2 = PatchMixerModel(\n",
    "        input_shape=input_shape,\n",
    "        patch_size=8,\n",
    "        stride=5,\n",
    "        d_model=33,\n",
    "        depth=4,\n",
    "        kernel_size=8,\n",
    "        forecasting=24,\n",
    "        head_dropout=0.1)\n",
    "    model2.build(input_shape=(168, 168, 37))\n",
    "    model2.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "6759496e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5748"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "ed337e6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "    model2.compile(loss=MAEMS, optimizer='adam', metrics=['mse','mae', MAEMS])\n",
    "    early_stopping =EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)\n",
    "    batch_size = 100\n",
    "    epochs = 1000\n",
    "    history2 = LossHistory()\n",
    "    history2.init()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "9b9005bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "  6/131 [>.............................] - ETA: 8s - loss: 32.7904 - mse: 4.1339 - mae: 1.2524 - MAEMS: 32.7904WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0291s vs `on_train_batch_end` time: 0.0347s). Check your callbacks.\n",
      "131/131 [==============================] - 12s 72ms/step - loss: 8.5269 - mse: 0.3184 - mae: 0.3376 - MAEMS: 8.5150 - val_loss: 6.1218 - val_mse: 0.0669 - val_mae: 0.2054 - val_MAEMS: 6.0531\n",
      "Epoch 2/1000\n",
      "131/131 [==============================] - 9s 68ms/step - loss: 6.2262 - mse: 0.1018 - mae: 0.2544 - MAEMS: 6.2182 - val_loss: 4.3963 - val_mse: 0.0521 - val_mae: 0.1827 - val_MAEMS: 4.3563\n",
      "Epoch 3/1000\n",
      "131/131 [==============================] - 9s 68ms/step - loss: 5.5337 - mse: 0.0901 - mae: 0.2374 - MAEMS: 5.5271 - val_loss: 3.6005 - val_mse: 0.0522 - val_mae: 0.1860 - val_MAEMS: 3.5777\n",
      "Epoch 4/1000\n",
      "131/131 [==============================] - 9s 69ms/step - loss: 5.0313 - mse: 0.0832 - mae: 0.2273 - MAEMS: 5.0250 - val_loss: 3.5354 - val_mse: 0.0501 - val_mae: 0.1854 - val_MAEMS: 3.5096\n",
      "Epoch 5/1000\n",
      "131/131 [==============================] - 9s 68ms/step - loss: 4.7393 - mse: 0.0809 - mae: 0.2239 - MAEMS: 4.7331 - val_loss: 3.7905 - val_mse: 0.0460 - val_mae: 0.1788 - val_MAEMS: 3.7514\n",
      "Epoch 6/1000\n",
      "131/131 [==============================] - 9s 68ms/step - loss: 4.6386 - mse: 0.0795 - mae: 0.2218 - MAEMS: 4.6325 - val_loss: 4.1520 - val_mse: 0.0443 - val_mae: 0.1753 - val_MAEMS: 4.1077\n",
      "Epoch 7/1000\n",
      "131/131 [==============================] - 9s 68ms/step - loss: 4.6092 - mse: 0.0788 - mae: 0.2211 - MAEMS: 4.6032 - val_loss: 3.8830 - val_mse: 0.0451 - val_mae: 0.1775 - val_MAEMS: 3.8412\n",
      "Epoch 8/1000\n",
      "131/131 [==============================] - 9s 68ms/step - loss: 4.5130 - mse: 0.0788 - mae: 0.2214 - MAEMS: 4.5075 - val_loss: 3.5720 - val_mse: 0.0470 - val_mae: 0.1815 - val_MAEMS: 3.5360\n",
      "Epoch 9/1000\n",
      "131/131 [==============================] - 9s 69ms/step - loss: 4.4774 - mse: 0.0765 - mae: 0.2181 - MAEMS: 4.4718 - val_loss: 3.4978 - val_mse: 0.0472 - val_mae: 0.1818 - val_MAEMS: 3.4626\n",
      "Epoch 10/1000\n",
      "131/131 [==============================] - 9s 69ms/step - loss: 4.4290 - mse: 0.0757 - mae: 0.2176 - MAEMS: 4.4242 - val_loss: 3.3186 - val_mse: 0.0524 - val_mae: 0.1906 - val_MAEMS: 3.2899\n",
      "Epoch 11/1000\n",
      "131/131 [==============================] - 9s 69ms/step - loss: 4.3779 - mse: 0.0758 - mae: 0.2174 - MAEMS: 4.3736 - val_loss: 3.0884 - val_mse: 0.0618 - val_mae: 0.2063 - val_MAEMS: 3.0767\n",
      "Epoch 12/1000\n",
      "131/131 [==============================] - 9s 69ms/step - loss: 4.3517 - mse: 0.0752 - mae: 0.2169 - MAEMS: 4.3472 - val_loss: 3.3118 - val_mse: 0.0557 - val_mae: 0.1959 - val_MAEMS: 3.2905\n",
      "Epoch 13/1000\n",
      "131/131 [==============================] - 9s 69ms/step - loss: 4.2884 - mse: 0.0749 - mae: 0.2162 - MAEMS: 4.2840 - val_loss: 3.1490 - val_mse: 0.0585 - val_mae: 0.2010 - val_MAEMS: 3.1334\n",
      "Epoch 14/1000\n",
      "131/131 [==============================] - 9s 69ms/step - loss: 4.2924 - mse: 0.0752 - mae: 0.2168 - MAEMS: 4.2890 - val_loss: 3.0466 - val_mse: 0.0768 - val_mae: 0.2303 - val_MAEMS: 3.0546\n",
      "Epoch 15/1000\n",
      "131/131 [==============================] - 9s 69ms/step - loss: 4.3228 - mse: 0.0760 - mae: 0.2179 - MAEMS: 4.3183 - val_loss: 3.1225 - val_mse: 0.0607 - val_mae: 0.2038 - val_MAEMS: 3.1110\n",
      "Epoch 16/1000\n",
      "131/131 [==============================] - 9s 69ms/step - loss: 4.2842 - mse: 0.0742 - mae: 0.2155 - MAEMS: 4.2805 - val_loss: 3.0165 - val_mse: 0.0673 - val_mae: 0.2154 - val_MAEMS: 3.0167\n",
      "Epoch 17/1000\n",
      "131/131 [==============================] - 9s 69ms/step - loss: 4.2533 - mse: 0.0740 - mae: 0.2149 - MAEMS: 4.2496 - val_loss: 3.0464 - val_mse: 0.0666 - val_mae: 0.2139 - val_MAEMS: 3.0457\n",
      "Epoch 18/1000\n",
      "131/131 [==============================] - 9s 69ms/step - loss: 4.2281 - mse: 0.0735 - mae: 0.2142 - MAEMS: 4.2238 - val_loss: 3.1224 - val_mse: 0.0579 - val_mae: 0.2002 - val_MAEMS: 3.1081\n",
      "Epoch 19/1000\n",
      "131/131 [==============================] - 9s 69ms/step - loss: 4.2113 - mse: 0.0732 - mae: 0.2136 - MAEMS: 4.2073 - val_loss: 3.0777 - val_mse: 0.0622 - val_mae: 0.2072 - val_MAEMS: 3.0679\n",
      "Epoch 20/1000\n",
      "131/131 [==============================] - 9s 69ms/step - loss: 4.1944 - mse: 0.0739 - mae: 0.2149 - MAEMS: 4.1911 - val_loss: 3.0118 - val_mse: 0.0715 - val_mae: 0.2222 - val_MAEMS: 3.0175\n",
      "Epoch 21/1000\n",
      "131/131 [==============================] - 9s 69ms/step - loss: 4.1788 - mse: 0.0730 - mae: 0.2134 - MAEMS: 4.1749 - val_loss: 3.1050 - val_mse: 0.0607 - val_mae: 0.2045 - val_MAEMS: 3.0948\n",
      "Epoch 22/1000\n",
      "131/131 [==============================] - 9s 69ms/step - loss: 4.2190 - mse: 0.0727 - mae: 0.2129 - MAEMS: 4.2152 - val_loss: 3.0701 - val_mse: 0.0650 - val_mae: 0.2116 - val_MAEMS: 3.0663\n",
      "Epoch 23/1000\n",
      "131/131 [==============================] - 9s 69ms/step - loss: 4.1726 - mse: 0.0735 - mae: 0.2141 - MAEMS: 4.1688 - val_loss: 3.0548 - val_mse: 0.0616 - val_mae: 0.2064 - val_MAEMS: 3.0460\n",
      "Epoch 24/1000\n",
      "131/131 [==============================] - 9s 69ms/step - loss: 4.1698 - mse: 0.0741 - mae: 0.2149 - MAEMS: 4.1662 - val_loss: 3.0230 - val_mse: 0.0665 - val_mae: 0.2139 - val_MAEMS: 3.0218\n",
      "Epoch 25/1000\n",
      "131/131 [==============================] - 9s 69ms/step - loss: 4.1654 - mse: 0.0734 - mae: 0.2137 - MAEMS: 4.1616 - val_loss: 3.0317 - val_mse: 0.0640 - val_mae: 0.2095 - val_MAEMS: 3.0277\n",
      "Epoch 26/1000\n",
      "131/131 [==============================] - 9s 69ms/step - loss: 4.1480 - mse: 0.0731 - mae: 0.2133 - MAEMS: 4.1440 - val_loss: 3.0896 - val_mse: 0.0587 - val_mae: 0.2013 - val_MAEMS: 3.0791\n",
      "Epoch 27/1000\n",
      "131/131 [==============================] - 9s 69ms/step - loss: 4.1383 - mse: 0.0729 - mae: 0.2130 - MAEMS: 4.1345 - val_loss: 3.0372 - val_mse: 0.0615 - val_mae: 0.2055 - val_MAEMS: 3.0289\n",
      "Epoch 28/1000\n",
      "131/131 [==============================] - 9s 69ms/step - loss: 4.1393 - mse: 0.0733 - mae: 0.2136 - MAEMS: 4.1355 - val_loss: 3.0420 - val_mse: 0.0626 - val_mae: 0.2074 - val_MAEMS: 3.0388\n",
      "Epoch 29/1000\n",
      "131/131 [==============================] - 9s 69ms/step - loss: 4.1658 - mse: 0.0732 - mae: 0.2137 - MAEMS: 4.1622 - val_loss: 2.9971 - val_mse: 0.0668 - val_mae: 0.2145 - val_MAEMS: 2.9996\n",
      "Epoch 30/1000\n",
      "131/131 [==============================] - 9s 69ms/step - loss: 4.1667 - mse: 0.0733 - mae: 0.2137 - MAEMS: 4.1626 - val_loss: 3.0219 - val_mse: 0.0603 - val_mae: 0.2037 - val_MAEMS: 3.0152\n",
      "Epoch 31/1000\n",
      "131/131 [==============================] - 9s 69ms/step - loss: 4.1780 - mse: 0.0740 - mae: 0.2149 - MAEMS: 4.1743 - val_loss: 2.9829 - val_mse: 0.0650 - val_mae: 0.2112 - val_MAEMS: 2.9851\n",
      "Epoch 32/1000\n",
      "131/131 [==============================] - 9s 69ms/step - loss: 4.1500 - mse: 0.0731 - mae: 0.2136 - MAEMS: 4.1459 - val_loss: 3.1138 - val_mse: 0.0555 - val_mae: 0.1956 - val_MAEMS: 3.0989\n",
      "Epoch 33/1000\n",
      "131/131 [==============================] - 9s 69ms/step - loss: 4.1227 - mse: 0.0723 - mae: 0.2122 - MAEMS: 4.1182 - val_loss: 3.3459 - val_mse: 0.0495 - val_mae: 0.1844 - val_MAEMS: 3.3200\n",
      "Epoch 34/1000\n",
      "131/131 [==============================] - 9s 69ms/step - loss: 4.1214 - mse: 0.0726 - mae: 0.2126 - MAEMS: 4.1169 - val_loss: 3.2881 - val_mse: 0.0497 - val_mae: 0.1851 - val_MAEMS: 3.2630\n",
      "Epoch 35/1000\n",
      "131/131 [==============================] - 9s 69ms/step - loss: 4.0951 - mse: 0.0722 - mae: 0.2118 - MAEMS: 4.0909 - val_loss: 3.2046 - val_mse: 0.0541 - val_mae: 0.1926 - val_MAEMS: 3.1860\n",
      "Epoch 36/1000\n",
      "131/131 [==============================] - 9s 69ms/step - loss: 4.1022 - mse: 0.0724 - mae: 0.2124 - MAEMS: 4.0982 - val_loss: 3.0943 - val_mse: 0.0556 - val_mae: 0.1955 - val_MAEMS: 3.0806\n",
      "Epoch 37/1000\n",
      "131/131 [==============================] - 9s 69ms/step - loss: 4.1283 - mse: 0.0735 - mae: 0.2141 - MAEMS: 4.1248 - val_loss: 2.9900 - val_mse: 0.0660 - val_mae: 0.2126 - val_MAEMS: 2.9911\n",
      "Epoch 38/1000\n",
      "131/131 [==============================] - 9s 70ms/step - loss: 4.1254 - mse: 0.0733 - mae: 0.2137 - MAEMS: 4.1213 - val_loss: 3.1052 - val_mse: 0.0551 - val_mae: 0.1955 - val_MAEMS: 3.0902\n",
      "Epoch 39/1000\n",
      "131/131 [==============================] - 9s 70ms/step - loss: 4.0737 - mse: 0.0723 - mae: 0.2120 - MAEMS: 4.0704 - val_loss: 2.9674 - val_mse: 0.0680 - val_mae: 0.2159 - val_MAEMS: 2.9717\n",
      "Epoch 40/1000\n",
      "131/131 [==============================] - 9s 69ms/step - loss: 4.1128 - mse: 0.0737 - mae: 0.2142 - MAEMS: 4.1086 - val_loss: 3.1796 - val_mse: 0.0526 - val_mae: 0.1908 - val_MAEMS: 3.1576\n",
      "Epoch 41/1000\n",
      "131/131 [==============================] - 9s 70ms/step - loss: 4.1226 - mse: 0.0731 - mae: 0.2133 - MAEMS: 4.1194 - val_loss: 2.9986 - val_mse: 0.0697 - val_mae: 0.2187 - val_MAEMS: 3.0032\n",
      "Epoch 42/1000\n",
      "131/131 [==============================] - 9s 70ms/step - loss: 4.1169 - mse: 0.0733 - mae: 0.2137 - MAEMS: 4.1132 - val_loss: 3.0132 - val_mse: 0.0618 - val_mae: 0.2060 - val_MAEMS: 3.0107\n",
      "Epoch 43/1000\n",
      "131/131 [==============================] - 9s 69ms/step - loss: 4.1205 - mse: 0.0731 - mae: 0.2130 - MAEMS: 4.1170 - val_loss: 3.0118 - val_mse: 0.0666 - val_mae: 0.2141 - val_MAEMS: 3.0138\n",
      "Epoch 44/1000\n",
      "131/131 [==============================] - 9s 69ms/step - loss: 4.1021 - mse: 0.0734 - mae: 0.2136 - MAEMS: 4.0979 - val_loss: 3.1873 - val_mse: 0.0535 - val_mae: 0.1918 - val_MAEMS: 3.1668\n",
      "Epoch 45/1000\n",
      "131/131 [==============================] - 9s 69ms/step - loss: 4.1299 - mse: 0.0736 - mae: 0.2140 - MAEMS: 4.1265 - val_loss: 3.0109 - val_mse: 0.0714 - val_mae: 0.2214 - val_MAEMS: 3.0180\n",
      "Epoch 46/1000\n",
      "131/131 [==============================] - 9s 69ms/step - loss: 4.1060 - mse: 0.0737 - mae: 0.2142 - MAEMS: 4.1018 - val_loss: 3.1566 - val_mse: 0.0544 - val_mae: 0.1937 - val_MAEMS: 3.1392\n",
      "Epoch 47/1000\n",
      "131/131 [==============================] - 9s 69ms/step - loss: 4.1351 - mse: 0.0732 - mae: 0.2135 - MAEMS: 4.1315 - val_loss: 2.9955 - val_mse: 0.0657 - val_mae: 0.2124 - val_MAEMS: 2.9980\n",
      "Epoch 48/1000\n",
      "131/131 [==============================] - 9s 69ms/step - loss: 4.1120 - mse: 0.0740 - mae: 0.2145 - MAEMS: 4.1083 - val_loss: 3.0110 - val_mse: 0.0660 - val_mae: 0.2129 - val_MAEMS: 3.0113\n",
      "Epoch 49/1000\n",
      "131/131 [==============================] - 9s 69ms/step - loss: 4.1026 - mse: 0.0739 - mae: 0.2142 - MAEMS: 4.0987 - val_loss: 3.0376 - val_mse: 0.0593 - val_mae: 0.2016 - val_MAEMS: 3.0281\n",
      "Wall time: 7min 26s\n"
     ]
    }
   ],
   "source": [
    "    %%time\n",
    "    hist2 = model2.fit(trX, trY, epochs=epochs, batch_size=b_size, shuffle=False, validation_data=(vaX, vaY), callbacks=[history2, early_stopping])  # , checkpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "45bd2607",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4590"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "bec1dd5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "testPredict2 = model2.predict(teX, batch_size=b_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "090adf8b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error Test Score > MSE ==  0.05777416028290359  MAE ==  0.19821962767480678  MAEMS ==  2.299234600962123\n",
      "Error Test Score > MSE ==  0.07393853312161693  MAE ==  0.2267428881732096  MAEMS ==  2.388160953150741\n"
     ]
    }
   ],
   "source": [
    "tePredict2 = testPredict2.reshape(-1)\n",
    "testY = teY.reshape(-1)\n",
    "print('Error Test Score > MSE == ', npMSE(testY, tePredict), ' MAE == ', npMAE(testY, tePredict), ' MAEMS == ', npMAEMS(testY, tePredict))\n",
    "print('Error Test Score > MSE == ', npMSE(testY, tePredict2), ' MAE == ', npMAE(testY, tePredict2), ' MAEMS == ', npMAEMS(testY, tePredict2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "dd593969",
   "metadata": {},
   "outputs": [],
   "source": [
    "from statsmodels.stats.diagnostic import acorr_ljungbox\n",
    "from scipy.stats import norm\n",
    "\n",
    "def diebold_mariano_test(forecast1, forecast2, actual, opt): \n",
    "    \n",
    "    if opt==0: # MSE\n",
    "        e1 = actual-forecast1\n",
    "        e2 = actual-forecast2\n",
    "        d = e1**2 - e2**2\n",
    "    elif opt==1: # MAE\n",
    "        e1 = abs(actual-forecast1)\n",
    "        e2 = abs(actual-forecast2)\n",
    "        d = e1 - e2\n",
    "    else:\n",
    "        e1 = np.multiply(abs(actual - forecast1), actual**2)\n",
    "        e2 = np.multiply(abs(actual - forecast2), actual**2)\n",
    "        d = e1-e2\n",
    "    \n",
    "    # Mean of the loss differentials\n",
    "    mean_d = np.mean(d)\n",
    "    \n",
    "    # Standard deviation of the loss differentials\n",
    "    std_d = np.std(d, ddof=1)\n",
    "    \n",
    "    # Calculate the test statistic\n",
    "    test_stat = (mean_d / std_d) * np.sqrt(len(d))\n",
    "    \n",
    "    # Calculate the p-value using a two-tailed test\n",
    "    p_value = 2 * (1 - norm.cdf(abs(test_stat)))\n",
    "    \n",
    "    return test_stat, p_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "3b4972ae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((-25.478750720775235, 0.0),\n",
       " (-24.57443541833054, 0.0),\n",
       " (-3.178320313755772, 0.0014813100281130254))"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "diebold_mariano_test(testPredict, testPredict2, teY, 0), diebold_mariano_test(testPredict, testPredict2, teY, 1), diebold_mariano_test(testPredict, testPredict2, teY, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "5f3632c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.savetxt('PatchMixer_prop', testPredict)\n",
    "np.savetxt('PatchMixer_woshuffling', testPredict2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6efc040a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
