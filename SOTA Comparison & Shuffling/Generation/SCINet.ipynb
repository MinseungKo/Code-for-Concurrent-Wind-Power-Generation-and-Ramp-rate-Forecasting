{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f885f287",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "import pandas as pd\n",
    "import codecs\n",
    "import numpy as np\n",
    "import math\n",
    "import csv\n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.metrics import recall_score, precision_score # New\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn import preprocessing\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow.keras.preprocessing\n",
    "#from tensorflow.keras.callbacks import ModelCheckpoint, CSVLogger, EarlyStopping, LearningRateScheduler, ReduceLROnPlateau\n",
    "from tensorflow.keras.models import Sequential, Model\n",
    "from tensorflow.keras.layers import Dense, Input, Flatten, Add, Multiply, Subtract\n",
    "from tensorflow.keras import backend as K\n",
    "from tensorflow.keras.layers import Activation, BatchNormalization\n",
    "# regularizers\n",
    "from tensorflow.keras.layers import Conv1D, Conv2D\n",
    "from tensorflow.keras.layers import MaxPooling1D\n",
    "from tensorflow.keras.layers import concatenate\n",
    "from tensorflow.keras.layers import LSTM, Bidirectional\n",
    "from tensorflow.keras.utils import plot_model\n",
    "from tensorflow.keras.layers import Dropout, SpatialDropout1D\n",
    "from scipy import signal\n",
    "import openpyxl\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "from matplotlib import pylab as plt\n",
    "import matplotlib.dates as mdates\n",
    "import seaborn as sns\n",
    "import sklearn\n",
    "from sklearn.model_selection import train_test_split\n",
    "from numpy.linalg import svd\n",
    "import gc\n",
    "from keijzer import *\n",
    "from tensorflow import keras\n",
    "from keras.models import Model\n",
    "from keras.layers import *\n",
    "from tensorflow.keras.optimizers import Adam,SGD\n",
    "from keras.layers import Dense, Input, Flatten, Add, concatenate, Dropout, Activation, Multiply, Embedding, Layer, Reshape\n",
    "from keras.layers import LSTM, Bidirectional, GlobalMaxPooling1D, GlobalAveragePooling1D  \n",
    "from keras.layers import Conv1D, AveragePooling1D, MaxPooling1D\n",
    "#from keras.ops import convert_to_tensor, convert_to_numpy\n",
    "#from keras.utils import plot_model\n",
    "from keras import activations\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from keras.callbacks import ModelCheckpoint, CSVLogger, EarlyStopping, LearningRateScheduler, ReduceLROnPlateau\n",
    "import math\n",
    "\n",
    "class LossHistory(tensorflow.keras.callbacks.Callback):  # history = LossHistory()\n",
    "    def init(self):  # history.init()\n",
    "        self.losses = []\n",
    "        # self.accs = []\n",
    "        self.val_losses = []\n",
    "        # self.val_accs = []\n",
    "        self.rmses = []\n",
    "        self.mses = []\n",
    "        self.maes = []\n",
    "        self.mapes = []\n",
    "        self.val_rmses = []\n",
    "        self.val_mses = []\n",
    "        self.val_maes = []\n",
    "        self.val_mapes = []\n",
    "\n",
    "    def on_epoch_end(self, batch, logs={}):\n",
    "        self.losses.append(logs.get('loss'))\n",
    "        # self.accs.append(logs.get('acc'))\n",
    "        self.val_losses.append(logs.get('val_loss'))\n",
    "        # self.val_accs.append(logs.get('val_accuracy\n",
    "        self.rmses.append(logs.get('root_mean_squared_error'))\n",
    "        self.mses.append(logs.get('mean_squared_error'))\n",
    "        self.maes.append(logs.get('mean_absolute_error'))\n",
    "        self.mapes.append(logs.get('mean_absolute_percentage_error'))\n",
    "        self.val_rmses.append(logs.get('val_root_mean_squared_error'))\n",
    "        self.val_mses.append(logs.get('val_mean_squared_error'))\n",
    "        self.val_maes.append(logs.get('val_mean_absolute_error'))\n",
    "        self.val_mapes.append(logs.get('val_mean_absolute_percentage_error'))\n",
    "\n",
    "\n",
    "\n",
    "def root_squared_mean_error(y_true, y_pred):\n",
    "    return K.mean((K.abs(y_pred - y_true))*K.square(y_true-K.mean(y_true)))*100\n",
    "\n",
    "def mse_mae(y_true, y_pred):\n",
    "    return K.mean(K.square(y_pred - y_true))+K.mean(K.abs(y_pred - y_true))\n",
    "\n",
    "from keras.layers.advanced_activations import PReLU\n",
    "\n",
    "def mean_absolute_percentage_error(y_true, y_pred):\n",
    "    y_true, y_pred = np.array(y_true), np.array(y_pred)\n",
    "    return np.mean(np.abs((y_true - y_pred) / y_true)) * 100\n",
    "\n",
    "def root_mean_squared_error(y_true, y_pred):\n",
    "        return K.sqrt(K.mean(K.square(y_pred - y_true))) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a3559aec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]\n"
     ]
    }
   ],
   "source": [
    "import scipy as sc\n",
    "import os\n",
    "\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = '0' # 여러개 사용시 '0,1,2' 식으로 하나의 문자열에 입력\n",
    "gpus = tf.config.experimental.list_physical_devices('GPU') # 호스트 러나임에 표시되는 GPU 장치 목록 반환\n",
    "\n",
    "if gpus: # 반환된 GPU 장치 목록이 있다면\n",
    "    try: # 해당 장치에 대한 메모리 증가 활성화 여부 설정\n",
    "        tf.config.experimental.set_memory_growth(gpus[0], True)\n",
    "    except RuntimeError as e: # try문 실패시에 에러문구 출력\n",
    "        print(e)\n",
    "\n",
    "print(tf.config.list_physical_devices('GPU'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "722ca566",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Year</th>\n",
       "      <th>Wind Change</th>\n",
       "      <th>Wind Output</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2020</td>\n",
       "      <td>0.620197</td>\n",
       "      <td>0.644724</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2020</td>\n",
       "      <td>0.544580</td>\n",
       "      <td>0.658617</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2020</td>\n",
       "      <td>0.570751</td>\n",
       "      <td>0.683924</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2020</td>\n",
       "      <td>0.599594</td>\n",
       "      <td>0.721813</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2020</td>\n",
       "      <td>0.495246</td>\n",
       "      <td>0.714187</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35058</th>\n",
       "      <td>2023</td>\n",
       "      <td>0.774643</td>\n",
       "      <td>0.484984</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35059</th>\n",
       "      <td>2023</td>\n",
       "      <td>0.735512</td>\n",
       "      <td>0.582157</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35060</th>\n",
       "      <td>2023</td>\n",
       "      <td>0.601593</td>\n",
       "      <td>0.620917</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35061</th>\n",
       "      <td>2023</td>\n",
       "      <td>0.536583</td>\n",
       "      <td>0.631322</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35062</th>\n",
       "      <td>2023</td>\n",
       "      <td>0.454969</td>\n",
       "      <td>0.606127</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>35063 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Year  Wind Change  Wind Output\n",
       "0      2020     0.620197     0.644724\n",
       "1      2020     0.544580     0.658617\n",
       "2      2020     0.570751     0.683924\n",
       "3      2020     0.599594     0.721813\n",
       "4      2020     0.495246     0.714187\n",
       "...     ...          ...          ...\n",
       "35058  2023     0.774643     0.484984\n",
       "35059  2023     0.735512     0.582157\n",
       "35060  2023     0.601593     0.620917\n",
       "35061  2023     0.536583     0.631322\n",
       "35062  2023     0.454969     0.606127\n",
       "\n",
       "[35063 rows x 3 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_path = 'C:/Users/smartgrid_AI/Desktop/windpower_ramprate/ercot_2020.csv'\n",
    "data_source1 = pd.read_csv(data_path)\n",
    "dat_source1 = pd.DataFrame(data_source1)\n",
    "#dat_source1 = dat_source1.iloc[:-3,:]\n",
    "\n",
    "data_path = 'C:/Users/smartgrid_AI/Desktop/windpower_ramprate/ercot_2021.csv'\n",
    "data_source2 = pd.read_csv(data_path)\n",
    "dat_source2 = pd.DataFrame(data_source2)\n",
    "dat_source2 = dat_source2.iloc[:8761,:9]\n",
    "\n",
    "data_path = 'C:/Users/smartgrid_AI/Desktop/windpower_ramprate/ercot_2022.csv'\n",
    "data_source3 = pd.read_csv(data_path)\n",
    "dat_source3 = pd.DataFrame(data_source3)\n",
    "dat_source3 = dat_source3.iloc[:8760,:9]\n",
    "\n",
    "data_path = 'C:/Users/smartgrid_AI/Desktop/windpower_ramprate/ercot_2023.csv'\n",
    "data_source4 = pd.read_csv(data_path)\n",
    "dat_source4 = pd.DataFrame(data_source4)\n",
    "dat_source4 = dat_source4.iloc[:8760,:9]\n",
    "\n",
    "dat_arr1 = np.array(dat_source1)\n",
    "dat_arr2 = np.array(dat_source2)\n",
    "dat_arr3 = np.array(dat_source3)\n",
    "dat_arr4 = np.array(dat_source4)\n",
    "\n",
    "dat_arr = np.concatenate([dat_arr1, dat_arr2, dat_arr3, dat_arr4],axis=0)\n",
    "dat_arr.shape # 8784, 8761, 8760, 8760\n",
    "\n",
    "dat_source = pd.DataFrame(dat_arr, columns=['Time-Date stamp','Date','ERCOT Load','Total Wind Output','Total Wind Installed','Wind Output, % of Load','Wind Output, % of Installed','1-hr MW change','1-hr % change'])\n",
    "dat = pd.DataFrame()\n",
    "dat['MW % change'] = np.array(dat_source.iloc[1:,3], dtype=float)-np.array(dat_source.iloc[0:-1,3], dtype=float)\n",
    "dat['MW % change'] = np.divide(np.array(dat['MW % change']),np.array(dat_source.iloc[1:,4]))*100\n",
    "dat['Total Wind Output'] = np.divide(np.array(dat_source.iloc[1:,3]), np.array(dat_source.iloc[1:,4]))\n",
    "\n",
    "ramp_ratio = 20\n",
    "load_ratio = 10\n",
    "year_arr = np.concatenate([np.ones(8784)*2020, np.ones(8760)*2021, np.ones(8760)*2022, np.ones(8760)*2023])\n",
    "year_df = pd.DataFrame(year_arr, columns=['Year'], dtype=int)\n",
    "wind_df = pd.concat([year_df, dat], axis=1)\n",
    "wind_df = wind_df.reset_index(drop=True)\n",
    "\n",
    "std_scaler = sklearn.preprocessing.MinMaxScaler()\n",
    "std_scaler_load = sklearn.preprocessing.MinMaxScaler()\n",
    "std_scaler_ramp = sklearn.preprocessing.MinMaxScaler()\n",
    "\n",
    "wind_df[['Total Wind Output']] = std_scaler.fit_transform(wind_df[['Total Wind Output']])\n",
    "wind_df[['MW % change']] = std_scaler_ramp.fit_transform(wind_df[['MW % change']])\n",
    "wind_df = wind_df.iloc[:-1,:]\n",
    "ramp_df = pd.DataFrame(wind_df)\n",
    "ramp_df.columns=['Year', 'Wind Change', 'Wind Output']\n",
    "ramp_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e6c19279",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_dataset(dataset, timesteps, output_timesteps, leadtime):\n",
    "    dataX, dataY = [], []\n",
    "    for i in range(len(dataset) - timesteps -output_timesteps - leadtime - 1):\n",
    "        a = dataset[i:(i + timesteps), :]\n",
    "        dataX.append(a)\n",
    "        dataY.append(dataset[(i + timesteps + leadtime):(i+timesteps+output_timesteps+leadtime), :])\n",
    "    return np.array(dataX), np.array(dataY)\n",
    "\n",
    "def svdadd(X, start, end, b_size):\n",
    "    dec_x = X[start:end, :, :]\n",
    "    U, S, Vh = svd(dec_x.reshape(b_size, -1), full_matrices=True)\n",
    "\n",
    "    high_sig = np.matmul(np.matmul(U[:,:high_ind], np.diag(S[0:high_ind])), Vh[:high_ind,:])\n",
    "    low_sig = X[:dec_num, :, :].reshape(b_size,-1)-high_sig\n",
    "\n",
    "    rec_x = np.zeros((b_size, b_size, high_ind))\n",
    "    \n",
    "    for i in range(high_ind):\n",
    "        rec_x[:,:,i] = np.matmul((U[:,i]*S[i]).reshape(-1,1), Vh[i,:].reshape(1,-1))    \n",
    "    return rec_x, low_sig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0c0c0351",
   "metadata": {},
   "outputs": [],
   "source": [
    "norm_df = np.array(wind_df.iloc[:,2]).reshape(-1,1)\n",
    "timesteps = 24*7\n",
    "output_timesteps = 24\n",
    "leadtime = 6\n",
    "num_features = 1\n",
    "X, Y = create_dataset(norm_df, timesteps, output_timesteps, leadtime)\n",
    "b_size = timesteps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cfdf0661",
   "metadata": {},
   "outputs": [],
   "source": [
    "dec_num = timesteps\n",
    "high_ind = 35\n",
    "\n",
    "addX = np.zeros((X.shape[0], dec_num, high_ind+1))\n",
    "\n",
    "for k in range(X.shape[0]//dec_num):\n",
    "    rec_x, low_sig = svdadd(X, k*dec_num, (k+1)*dec_num, b_size)\n",
    "    addX[k*dec_num:k*dec_num+dec_num,:, :-1] = rec_x\n",
    "    addX[k*dec_num:k*dec_num+dec_num,:, -1] = low_sig\n",
    "    \n",
    "rec_x, low_sig = svdadd(X, X.shape[0]-dec_num, X.shape[0], b_size)\n",
    "addX[X.shape[0]-dec_num:X.shape[0], :, :-1] = rec_x\n",
    "addX[X.shape[0]-dec_num:X.shape[0],:, -1] = low_sig\n",
    "\n",
    "addX_det = addX[:, :, :-1]\n",
    "addX_det = np.sum(addX_det, axis=2)\n",
    "X = np.concatenate([X, addX], axis=2)\n",
    "num_features = X.shape[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f5926fba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((31377, 168, 37), (31377, 24), (3487, 168, 37), (3487, 24))"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trvaX, teX, trvaY, teY = train_test_split(X, Y, test_size=0.1, shuffle=False)\n",
    "\n",
    "idx = np.arange(trvaX.shape[0])\n",
    "np.random.shuffle(idx)\n",
    "strvaX = trvaX[idx]\n",
    "strvaY = trvaY[idx]\n",
    "strvaY = strvaY.reshape(-1, output_timesteps)\n",
    "\n",
    "trvaY = trvaY.reshape(-1, output_timesteps)\n",
    "teY = teY.reshape(-1, output_timesteps)\n",
    "\n",
    "strX, svaX, strY, svaY = train_test_split(strvaX, strvaY, test_size=0.3, shuffle=False)\n",
    "trX, vaX, trY, vaY = train_test_split(trvaX, trvaY, test_size=0.3, shuffle=False)\n",
    "\n",
    "trvaX.shape, trvaY.shape, teX.shape, teY.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0477bbda",
   "metadata": {},
   "outputs": [],
   "source": [
    "def MAEMS(y_true, y_pred):\n",
    "    return K.mean((K.abs(y_pred - y_true))*K.square(y_true))*100"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea25c768",
   "metadata": {},
   "source": [
    "## SCINet - With SVD With Shuffling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "522fc23c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models\n",
    "\n",
    "class Splitting(layers.Layer):\n",
    "    def __init__(self, name=\"Splitting\"):\n",
    "        super(Splitting, self).__init__(name=name)\n",
    "\n",
    "    def call(self, x):\n",
    "        x_even = x[:, ::2, :]\n",
    "        x_odd = x[:, 1::2, :]\n",
    "        return x_even, x_odd\n",
    "class Interactor(layers.Layer):\n",
    "    def __init__(self, in_planes, kernel=5, dropout=0.5, groups=1, hidden_size=1, INN=True, name=\"Interactor\"):\n",
    "        super(Interactor, self).__init__(name=name)\n",
    "        self.modified = INN\n",
    "        padding = 'same' if kernel % 2 == 1 else 'causal'\n",
    "        \n",
    "        self.P = models.Sequential([\n",
    "            layers.Conv1D(int(in_planes * hidden_size), kernel, padding=padding, groups=groups, name=\"P_Conv1\"),\n",
    "            layers.LeakyReLU(alpha=0.01, name=\"P_LeakyReLU\"),\n",
    "            layers.Dropout(dropout, name=\"P_Dropout\"),\n",
    "            layers.Conv1D(in_planes, 3, padding=padding, groups=groups, name=\"P_Conv2\"),\n",
    "            layers.Activation('tanh', name=\"P_Activation\")\n",
    "        ], name=\"P_Block\")\n",
    "        \n",
    "        self.U = models.Sequential([\n",
    "            layers.Conv1D(int(in_planes * hidden_size), kernel, padding=padding, groups=groups, name=\"U_Conv1\"),\n",
    "            layers.LeakyReLU(alpha=0.01, name=\"U_LeakyReLU\"),\n",
    "            layers.Dropout(dropout, name=\"U_Dropout\"),\n",
    "            layers.Conv1D(in_planes, 3, padding=padding, groups=groups, name=\"U_Conv2\"),\n",
    "            layers.Activation('tanh', name=\"U_Activation\")\n",
    "        ], name=\"U_Block\")\n",
    "        \n",
    "        self.phi = models.Sequential([\n",
    "            layers.Conv1D(int(in_planes * hidden_size), kernel, padding=padding, groups=groups, name=\"phi_Conv1\"),\n",
    "            layers.LeakyReLU(alpha=0.01, name=\"phi_LeakyReLU\"),\n",
    "            layers.Dropout(dropout, name=\"phi_Dropout\"),\n",
    "            layers.Conv1D(in_planes, 3, padding=padding, groups=groups, name=\"phi_Conv2\"),\n",
    "            layers.Activation('tanh', name=\"phi_Activation\")\n",
    "        ], name=\"phi_Block\")\n",
    "        \n",
    "        self.psi = models.Sequential([\n",
    "            layers.Conv1D(int(in_planes * hidden_size), kernel, padding=padding, groups=groups, name=\"psi_Conv1\"),\n",
    "            layers.LeakyReLU(alpha=0.01, name=\"psi_LeakyReLU\"),\n",
    "            layers.Dropout(dropout, name=\"psi_Dropout\"),\n",
    "            layers.Conv1D(in_planes, 3, padding=padding, groups=groups, name=\"psi_Conv2\"),\n",
    "            layers.Activation('tanh', name=\"psi_Activation\")\n",
    "        ], name=\"psi_Block\")\n",
    "        \n",
    "        self.split = Splitting()\n",
    "\n",
    "    def call(self, x):\n",
    "        x_even, x_odd = self.split(x)\n",
    "        # Interactor는 각 레이어의 입력 모양이 맞아야 함\n",
    "        d = tf.math.multiply(x_odd, tf.math.exp(self.phi(x_even)))  # x_even의 shape이 (batch_size, 84, in_planes)\n",
    "        c = tf.math.multiply(x_even, tf.math.exp(self.psi(x_odd)))  # x_odd의 shape이 (batch_size, 84, in_planes)\n",
    "        \n",
    "        if self.modified:\n",
    "            x_even_update = c + self.U(d)\n",
    "            x_odd_update = d - self.P(c)\n",
    "        else:\n",
    "            x_even_update = c - self.U(d)\n",
    "            x_odd_update = d + self.P(c)\n",
    "        \n",
    "        return x_even_update, x_odd_update\n",
    "\n",
    "\n",
    "class SCINet_Tree(models.Model):\n",
    "    def __init__(self, in_planes, current_level, kernel_size, dropout, groups, hidden_size, INN, name=\"SCINet_Tree\"):\n",
    "        super(SCINet_Tree, self).__init__(name=name)\n",
    "        self.current_level = current_level\n",
    "        self.interact = Interactor(in_planes, kernel_size, dropout, groups, hidden_size, INN, name=f\"Interactor_Level_{current_level}\")\n",
    "\n",
    "        if current_level > 0:\n",
    "            self.SCINet_Tree_even = SCINet_Tree(in_planes, current_level-1, kernel_size, dropout, groups, hidden_size, INN, name=f\"SCINet_Tree_even_{current_level}\")\n",
    "            self.SCINet_Tree_odd = SCINet_Tree(in_planes, current_level-1, kernel_size, dropout, groups, hidden_size, INN, name=f\"SCINet_Tree_odd_{current_level}\")\n",
    "\n",
    "    def zip_up_the_pants(self, even, odd):\n",
    "        zipped = tf.concat([even[:, i:i+1, :] for i in range(even.shape[1])] +\n",
    "                           [odd[:, i:i+1, :] for i in range(odd.shape[1])], axis=1)\n",
    "        return zipped\n",
    "\n",
    "    def call(self, x):\n",
    "        x_even_update, x_odd_update = self.interact(x)\n",
    "        if self.current_level == 0:\n",
    "            return self.zip_up_the_pants(x_even_update, x_odd_update)\n",
    "        else:\n",
    "            return self.zip_up_the_pants(self.SCINet_Tree_even(x_even_update), self.SCINet_Tree_odd(x_odd_update))\n",
    "\n",
    "\n",
    "\n",
    "class SCINet(models.Model):\n",
    "    def __init__(self, output_len, input_len, input_dim=1, hid_size=1, num_stacks=1, num_levels=3, kernel=5, dropout=0.5, INN=True, name=\"SCINet\"):\n",
    "        super(SCINet, self).__init__(name=name)\n",
    "        self.input_dim = input_dim\n",
    "        self.output_len = output_len\n",
    "        self.input_len = input_len\n",
    "        self.num_stacks = num_stacks\n",
    "\n",
    "        # 각 스택을 정의\n",
    "        self.blocks = [SCINet_Tree(input_dim, num_levels-1, kernel, dropout, groups=1, hidden_size=hid_size, INN=INN, name=f\"SCINet_Tree_Stack_{i}\") for i in range(num_stacks)]\n",
    "\n",
    "        self.projections = [layers.Conv1D(output_len, 1, padding='same', name=f\"Projection_Stack_{i}\") for i in range(num_stacks)]\n",
    "        self.global_pool = layers.GlobalAveragePooling1D()\n",
    "\n",
    "    def call(self, x):\n",
    "        res = x\n",
    "        for i in range(self.num_stacks):\n",
    "            x = self.blocks[i](x)\n",
    "            x = self.projections[i](x) \n",
    "            res = x  \n",
    "        return self.global_pool(x) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6f94988c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"SCINet\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "SCINet_Tree_Stack_0 (SCINet_ multiple                  2222220   \n",
      "_________________________________________________________________\n",
      "Projection_Stack_0 (Conv1D)  multiple                  912       \n",
      "_________________________________________________________________\n",
      "global_average_pooling1d (Gl multiple                  0         \n",
      "=================================================================\n",
      "Total params: 2,223,132\n",
      "Trainable params: 2,223,132\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "output_len = 24        \n",
    "input_len = 168        \n",
    "input_dim = trvaX.shape[-1]         \n",
    "hid_size = 9        \n",
    "num_stacks = 1\n",
    "num_levels = 2\n",
    "kernel_size = 12    \n",
    "dropout = 0.2         \n",
    "INN = True           \n",
    "\n",
    "# 모델 정의\n",
    "with tf.device('/gpu:0'):\n",
    "    model = SCINet(output_len, input_len, input_dim, hid_size, num_stacks, num_levels, kernel_size, dropout, INN)\n",
    "    model.build(input_shape=(None, 168, input_dim))\n",
    "    model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ba896e2f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "13045"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9b9367aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "    model.compile(loss=MAEMS, optimizer='adam', metrics=['mse','mae', MAEMS])\n",
    "    early_stopping =EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)\n",
    "    batch_size = 100\n",
    "    epochs = 1000\n",
    "    history = LossHistory()\n",
    "    history.init()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "cb83a6ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "131/131 [==============================] - 21s 101ms/step - loss: 3.7345 - mse: 0.0973 - mae: 0.2530 - MAEMS: 3.7342 - val_loss: 3.3411 - val_mse: 0.0734 - val_mae: 0.2207 - val_MAEMS: 3.3397\n",
      "Epoch 2/1000\n",
      "131/131 [==============================] - 11s 83ms/step - loss: 3.0928 - mse: 0.0807 - mae: 0.2279 - MAEMS: 3.0928 - val_loss: 2.9786 - val_mse: 0.0664 - val_mae: 0.2069 - val_MAEMS: 2.9759\n",
      "Epoch 3/1000\n",
      "131/131 [==============================] - 11s 83ms/step - loss: 2.7772 - mse: 0.0686 - mae: 0.2069 - MAEMS: 2.7777 - val_loss: 2.6963 - val_mse: 0.0699 - val_mae: 0.2091 - val_MAEMS: 2.6934\n",
      "Epoch 4/1000\n",
      "131/131 [==============================] - 11s 83ms/step - loss: 2.5459 - mse: 0.0597 - mae: 0.1901 - MAEMS: 2.5463 - val_loss: 2.4749 - val_mse: 0.0656 - val_mae: 0.2000 - val_MAEMS: 2.4720\n",
      "Epoch 5/1000\n",
      "131/131 [==============================] - 11s 83ms/step - loss: 2.3020 - mse: 0.0510 - mae: 0.1729 - MAEMS: 2.3020 - val_loss: 2.5163 - val_mse: 0.0691 - val_mae: 0.2060 - val_MAEMS: 2.5127\n",
      "Epoch 6/1000\n",
      "131/131 [==============================] - 11s 82ms/step - loss: 2.1579 - mse: 0.0456 - mae: 0.1612 - MAEMS: 2.1588 - val_loss: 2.1650 - val_mse: 0.0529 - val_mae: 0.1755 - val_MAEMS: 2.1625\n",
      "Epoch 7/1000\n",
      "131/131 [==============================] - 11s 84ms/step - loss: 1.9987 - mse: 0.0404 - mae: 0.1494 - MAEMS: 1.9993 - val_loss: 1.9674 - val_mse: 0.0405 - val_mae: 0.1502 - val_MAEMS: 1.9671\n",
      "Epoch 8/1000\n",
      "131/131 [==============================] - 11s 83ms/step - loss: 1.8537 - mse: 0.0359 - mae: 0.1388 - MAEMS: 1.8539 - val_loss: 2.2814 - val_mse: 0.0275 - val_mae: 0.1270 - val_MAEMS: 2.2812\n",
      "Epoch 9/1000\n",
      "131/131 [==============================] - 11s 83ms/step - loss: 1.7957 - mse: 0.0334 - mae: 0.1330 - MAEMS: 1.7960 - val_loss: 1.8327 - val_mse: 0.0368 - val_mae: 0.1403 - val_MAEMS: 1.8366\n",
      "Epoch 10/1000\n",
      "131/131 [==============================] - 11s 84ms/step - loss: 1.6199 - mse: 0.0293 - mae: 0.1222 - MAEMS: 1.6206 - val_loss: 1.7993 - val_mse: 0.0408 - val_mae: 0.1487 - val_MAEMS: 1.8007\n",
      "Epoch 11/1000\n",
      "131/131 [==============================] - 11s 83ms/step - loss: 1.5816 - mse: 0.0274 - mae: 0.1174 - MAEMS: 1.5820 - val_loss: 1.7087 - val_mse: 0.0370 - val_mae: 0.1403 - val_MAEMS: 1.7169\n",
      "Epoch 12/1000\n",
      "131/131 [==============================] - 11s 83ms/step - loss: 1.4954 - mse: 0.0251 - mae: 0.1114 - MAEMS: 1.4953 - val_loss: 1.5599 - val_mse: 0.0324 - val_mae: 0.1289 - val_MAEMS: 1.5636\n",
      "Epoch 13/1000\n",
      "131/131 [==============================] - 11s 83ms/step - loss: 1.3430 - mse: 0.0223 - mae: 0.1027 - MAEMS: 1.3431 - val_loss: 1.4332 - val_mse: 0.0274 - val_mae: 0.1161 - val_MAEMS: 1.4359\n",
      "Epoch 14/1000\n",
      "131/131 [==============================] - 11s 83ms/step - loss: 1.2802 - mse: 0.0203 - mae: 0.0973 - MAEMS: 1.2804 - val_loss: 1.4835 - val_mse: 0.0282 - val_mae: 0.1193 - val_MAEMS: 1.4880\n",
      "Epoch 15/1000\n",
      "131/131 [==============================] - 11s 82ms/step - loss: 1.2695 - mse: 0.0195 - mae: 0.0951 - MAEMS: 1.2697 - val_loss: 1.5940 - val_mse: 0.0302 - val_mae: 0.1259 - val_MAEMS: 1.5939\n",
      "Epoch 16/1000\n",
      "131/131 [==============================] - 11s 82ms/step - loss: 1.3063 - mse: 0.0192 - mae: 0.0950 - MAEMS: 1.3075 - val_loss: 1.3762 - val_mse: 0.0212 - val_mae: 0.1015 - val_MAEMS: 1.3787\n",
      "Epoch 17/1000\n",
      "131/131 [==============================] - 11s 83ms/step - loss: 1.3633 - mse: 0.0199 - mae: 0.0977 - MAEMS: 1.3633 - val_loss: 1.4210 - val_mse: 0.0170 - val_mae: 0.0912 - val_MAEMS: 1.4250\n",
      "Epoch 18/1000\n",
      "131/131 [==============================] - 11s 83ms/step - loss: 1.3083 - mse: 0.0187 - mae: 0.0941 - MAEMS: 1.3082 - val_loss: 1.3377 - val_mse: 0.0222 - val_mae: 0.1038 - val_MAEMS: 1.3424\n",
      "Epoch 19/1000\n",
      "131/131 [==============================] - 11s 82ms/step - loss: 1.2871 - mse: 0.0181 - mae: 0.0922 - MAEMS: 1.2874 - val_loss: 1.3539 - val_mse: 0.0183 - val_mae: 0.0936 - val_MAEMS: 1.3539\n",
      "Epoch 20/1000\n",
      "131/131 [==============================] - 11s 82ms/step - loss: 1.2546 - mse: 0.0174 - mae: 0.0900 - MAEMS: 1.2547 - val_loss: 1.4190 - val_mse: 0.0186 - val_mae: 0.0951 - val_MAEMS: 1.4172\n",
      "Epoch 21/1000\n",
      "131/131 [==============================] - 11s 82ms/step - loss: 1.2262 - mse: 0.0167 - mae: 0.0878 - MAEMS: 1.2265 - val_loss: 1.2343 - val_mse: 0.0194 - val_mae: 0.0946 - val_MAEMS: 1.2347\n",
      "Epoch 22/1000\n",
      "131/131 [==============================] - 11s 82ms/step - loss: 1.1744 - mse: 0.0157 - mae: 0.0844 - MAEMS: 1.1746 - val_loss: 1.3885 - val_mse: 0.0226 - val_mae: 0.1055 - val_MAEMS: 1.3880\n",
      "Epoch 23/1000\n",
      "131/131 [==============================] - 11s 83ms/step - loss: 1.1386 - mse: 0.0150 - mae: 0.0821 - MAEMS: 1.1388 - val_loss: 1.2017 - val_mse: 0.0167 - val_mae: 0.0877 - val_MAEMS: 1.2042\n",
      "Epoch 24/1000\n",
      "131/131 [==============================] - 11s 83ms/step - loss: 1.1209 - mse: 0.0147 - mae: 0.0810 - MAEMS: 1.1213 - val_loss: 1.4029 - val_mse: 0.0133 - val_mae: 0.0814 - val_MAEMS: 1.4067\n",
      "Epoch 25/1000\n",
      "131/131 [==============================] - 11s 82ms/step - loss: 1.1370 - mse: 0.0146 - mae: 0.0810 - MAEMS: 1.1373 - val_loss: 1.2328 - val_mse: 0.0160 - val_mae: 0.0859 - val_MAEMS: 1.2299\n",
      "Epoch 26/1000\n",
      "131/131 [==============================] - 11s 82ms/step - loss: 1.1482 - mse: 0.0144 - mae: 0.0808 - MAEMS: 1.1483 - val_loss: 1.2035 - val_mse: 0.0186 - val_mae: 0.0925 - val_MAEMS: 1.2041\n",
      "Epoch 27/1000\n",
      "131/131 [==============================] - 11s 82ms/step - loss: 1.1172 - mse: 0.0139 - mae: 0.0790 - MAEMS: 1.1172 - val_loss: 1.0818 - val_mse: 0.0152 - val_mae: 0.0820 - val_MAEMS: 1.0823\n",
      "Epoch 28/1000\n",
      "131/131 [==============================] - 11s 83ms/step - loss: 1.0780 - mse: 0.0134 - mae: 0.0770 - MAEMS: 1.0781 - val_loss: 1.1348 - val_mse: 0.0125 - val_mae: 0.0754 - val_MAEMS: 1.1333\n",
      "Epoch 29/1000\n",
      "131/131 [==============================] - 11s 82ms/step - loss: 1.0635 - mse: 0.0130 - mae: 0.0758 - MAEMS: 1.0634 - val_loss: 1.1772 - val_mse: 0.0120 - val_mae: 0.0744 - val_MAEMS: 1.1770\n",
      "Epoch 30/1000\n",
      "131/131 [==============================] - 11s 82ms/step - loss: 1.0560 - mse: 0.0126 - mae: 0.0745 - MAEMS: 1.0560 - val_loss: 1.0862 - val_mse: 0.0127 - val_mae: 0.0748 - val_MAEMS: 1.0844\n",
      "Epoch 31/1000\n",
      "131/131 [==============================] - 11s 82ms/step - loss: 1.0200 - mse: 0.0121 - mae: 0.0724 - MAEMS: 1.0201 - val_loss: 1.0715 - val_mse: 0.0139 - val_mae: 0.0780 - val_MAEMS: 1.0718\n",
      "Epoch 32/1000\n",
      "131/131 [==============================] - 11s 82ms/step - loss: 0.9885 - mse: 0.0115 - mae: 0.0704 - MAEMS: 0.9885 - val_loss: 1.1200 - val_mse: 0.0142 - val_mae: 0.0794 - val_MAEMS: 1.1194\n",
      "Epoch 33/1000\n",
      "131/131 [==============================] - 11s 82ms/step - loss: 0.9794 - mse: 0.0112 - mae: 0.0694 - MAEMS: 0.9794 - val_loss: 1.0838 - val_mse: 0.0154 - val_mae: 0.0825 - val_MAEMS: 1.0835\n",
      "Epoch 34/1000\n",
      "131/131 [==============================] - 11s 82ms/step - loss: 0.9900 - mse: 0.0112 - mae: 0.0694 - MAEMS: 0.9900 - val_loss: 1.1008 - val_mse: 0.0156 - val_mae: 0.0837 - val_MAEMS: 1.1008\n",
      "Epoch 35/1000\n",
      "131/131 [==============================] - 11s 82ms/step - loss: 1.0674 - mse: 0.0120 - mae: 0.0732 - MAEMS: 1.0676 - val_loss: 1.1250 - val_mse: 0.0124 - val_mae: 0.0750 - val_MAEMS: 1.1228\n",
      "Epoch 36/1000\n",
      "131/131 [==============================] - 11s 84ms/step - loss: 1.0736 - mse: 0.0120 - mae: 0.0735 - MAEMS: 1.0735 - val_loss: 1.1095 - val_mse: 0.0120 - val_mae: 0.0737 - val_MAEMS: 1.1069\n",
      "Epoch 37/1000\n",
      "131/131 [==============================] - 11s 82ms/step - loss: 0.9779 - mse: 0.0110 - mae: 0.0688 - MAEMS: 0.9780 - val_loss: 1.0233 - val_mse: 0.0137 - val_mae: 0.0774 - val_MAEMS: 1.0224\n",
      "Epoch 38/1000\n",
      "131/131 [==============================] - 11s 83ms/step - loss: 0.9298 - mse: 0.0104 - mae: 0.0662 - MAEMS: 0.9299 - val_loss: 1.0423 - val_mse: 0.0140 - val_mae: 0.0787 - val_MAEMS: 1.0415\n",
      "Epoch 39/1000\n",
      "131/131 [==============================] - 11s 83ms/step - loss: 0.9213 - mse: 0.0102 - mae: 0.0654 - MAEMS: 0.9215 - val_loss: 1.0797 - val_mse: 0.0144 - val_mae: 0.0805 - val_MAEMS: 1.0793\n",
      "Epoch 40/1000\n",
      "131/131 [==============================] - 11s 82ms/step - loss: 0.9751 - mse: 0.0106 - mae: 0.0675 - MAEMS: 0.9755 - val_loss: 1.1858 - val_mse: 0.0137 - val_mae: 0.0799 - val_MAEMS: 1.1852\n",
      "Epoch 41/1000\n",
      "131/131 [==============================] - 11s 83ms/step - loss: 1.0349 - mse: 0.0110 - mae: 0.0700 - MAEMS: 1.0352 - val_loss: 1.1448 - val_mse: 0.0116 - val_mae: 0.0731 - val_MAEMS: 1.1438\n",
      "Epoch 42/1000\n",
      "131/131 [==============================] - 11s 83ms/step - loss: 1.0485 - mse: 0.0112 - mae: 0.0708 - MAEMS: 1.0485 - val_loss: 1.2241 - val_mse: 0.0108 - val_mae: 0.0714 - val_MAEMS: 1.2249\n",
      "Epoch 43/1000\n",
      "131/131 [==============================] - 11s 83ms/step - loss: 0.9850 - mse: 0.0105 - mae: 0.0675 - MAEMS: 0.9851 - val_loss: 1.0503 - val_mse: 0.0125 - val_mae: 0.0743 - val_MAEMS: 1.0534\n",
      "Epoch 44/1000\n",
      "131/131 [==============================] - 11s 83ms/step - loss: 0.8975 - mse: 0.0096 - mae: 0.0631 - MAEMS: 0.8975 - val_loss: 0.9622 - val_mse: 0.0119 - val_mae: 0.0712 - val_MAEMS: 0.9631\n",
      "Epoch 45/1000\n",
      "131/131 [==============================] - 11s 83ms/step - loss: 0.8477 - mse: 0.0090 - mae: 0.0606 - MAEMS: 0.8478 - val_loss: 0.9701 - val_mse: 0.0110 - val_mae: 0.0684 - val_MAEMS: 0.9706\n",
      "Epoch 46/1000\n",
      "131/131 [==============================] - 11s 82ms/step - loss: 0.8319 - mse: 0.0087 - mae: 0.0594 - MAEMS: 0.8320 - val_loss: 0.9745 - val_mse: 0.0108 - val_mae: 0.0681 - val_MAEMS: 0.9763\n",
      "Epoch 47/1000\n",
      "131/131 [==============================] - 11s 82ms/step - loss: 0.8289 - mse: 0.0085 - mae: 0.0587 - MAEMS: 0.8289 - val_loss: 0.9579 - val_mse: 0.0110 - val_mae: 0.0682 - val_MAEMS: 0.9598\n",
      "Epoch 48/1000\n",
      "131/131 [==============================] - 11s 83ms/step - loss: 0.8323 - mse: 0.0084 - mae: 0.0585 - MAEMS: 0.8323 - val_loss: 0.9210 - val_mse: 0.0105 - val_mae: 0.0662 - val_MAEMS: 0.9235\n",
      "Epoch 49/1000\n",
      "131/131 [==============================] - 11s 84ms/step - loss: 0.8561 - mse: 0.0085 - mae: 0.0592 - MAEMS: 0.8562 - val_loss: 0.9013 - val_mse: 0.0095 - val_mae: 0.0628 - val_MAEMS: 0.9031\n",
      "Epoch 50/1000\n",
      "131/131 [==============================] - 11s 82ms/step - loss: 0.8920 - mse: 0.0085 - mae: 0.0602 - MAEMS: 0.8921 - val_loss: 0.9404 - val_mse: 0.0108 - val_mae: 0.0676 - val_MAEMS: 0.9397\n",
      "Epoch 51/1000\n",
      "131/131 [==============================] - 11s 83ms/step - loss: 0.8954 - mse: 0.0085 - mae: 0.0601 - MAEMS: 0.8954 - val_loss: 0.9774 - val_mse: 0.0098 - val_mae: 0.0649 - val_MAEMS: 0.9770\n",
      "Epoch 52/1000\n",
      "131/131 [==============================] - 11s 83ms/step - loss: 0.8646 - mse: 0.0082 - mae: 0.0587 - MAEMS: 0.8646 - val_loss: 0.9538 - val_mse: 0.0097 - val_mae: 0.0641 - val_MAEMS: 0.9529\n",
      "Epoch 53/1000\n",
      "131/131 [==============================] - 11s 83ms/step - loss: 0.8430 - mse: 0.0081 - mae: 0.0580 - MAEMS: 0.8432 - val_loss: 0.9264 - val_mse: 0.0101 - val_mae: 0.0656 - val_MAEMS: 0.9245\n",
      "Epoch 54/1000\n",
      "131/131 [==============================] - 11s 84ms/step - loss: 0.8612 - mse: 0.0082 - mae: 0.0586 - MAEMS: 0.8612 - val_loss: 1.0195 - val_mse: 0.0130 - val_mae: 0.0767 - val_MAEMS: 1.0196\n",
      "Epoch 55/1000\n",
      "131/131 [==============================] - 11s 84ms/step - loss: 0.8850 - mse: 0.0084 - mae: 0.0599 - MAEMS: 0.8850 - val_loss: 0.9199 - val_mse: 0.0092 - val_mae: 0.0624 - val_MAEMS: 0.9183\n",
      "Epoch 56/1000\n",
      "131/131 [==============================] - 11s 83ms/step - loss: 0.8520 - mse: 0.0080 - mae: 0.0580 - MAEMS: 0.8520 - val_loss: 0.9207 - val_mse: 0.0110 - val_mae: 0.0683 - val_MAEMS: 0.9214\n",
      "Epoch 57/1000\n",
      "131/131 [==============================] - 11s 83ms/step - loss: 0.8180 - mse: 0.0077 - mae: 0.0561 - MAEMS: 0.8180 - val_loss: 0.9583 - val_mse: 0.0131 - val_mae: 0.0762 - val_MAEMS: 0.9579\n",
      "Epoch 58/1000\n",
      "131/131 [==============================] - 11s 83ms/step - loss: 0.8063 - mse: 0.0075 - mae: 0.0554 - MAEMS: 0.8066 - val_loss: 0.9185 - val_mse: 0.0111 - val_mae: 0.0688 - val_MAEMS: 0.9193\n",
      "Epoch 59/1000\n",
      "131/131 [==============================] - 11s 83ms/step - loss: 0.8336 - mse: 0.0077 - mae: 0.0568 - MAEMS: 0.8343 - val_loss: 1.0438 - val_mse: 0.0079 - val_mae: 0.0601 - val_MAEMS: 1.0460\n",
      "Wall time: 10min 49s\n"
     ]
    }
   ],
   "source": [
    "    %%time\n",
    "    b_size = 168\n",
    "    hist = model.fit(strX, strY, epochs=epochs, batch_size=b_size, shuffle=False, validation_data=(svaX, svaY), callbacks=[history, early_stopping])  # , checkpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "aaf307ad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4594"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d742e8ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "#model3.save('SCINet', save_format='tf')\n",
    "testPredict = model.predict(teX, batch_size=b_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "81159c56",
   "metadata": {},
   "outputs": [],
   "source": [
    "def npMAEMS(y_true, y_pred):\n",
    "    return np.mean((abs(y_pred - y_true))*np.square(y_true))*100\n",
    "def npMAEMD(y_true, y_pred):\n",
    "    return np.mean((abs(y_pred - y_true))*np.square(y_true-np.mean(y_true)))*100\n",
    "def npMSE(y_true, y_pred):\n",
    "    return np.mean(np.square(-y_true+y_pred))\n",
    "def npMAE(y_true, y_pred):\n",
    "    return np.mean(abs(-y_true+y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "988be495",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error Test Score > MSE ==  0.04884789016950677  MAE ==  0.17941999954264826  MAEMS ==  2.7640606336811144\n"
     ]
    }
   ],
   "source": [
    "tePredict = testPredict.reshape(-1)\n",
    "testY = teY.reshape(-1)\n",
    "print('Error Test Score > MSE == ', npMSE(testY, tePredict), ' MAE == ', npMAE(testY, tePredict), ' MAEMS == ', npMAEMS(testY, tePredict))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b6cf7ca",
   "metadata": {},
   "source": [
    "## Without Shuffling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "01521540",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"SCINet\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "SCINet_Tree_Stack_0 (SCINet_ multiple                  2222220   \n",
      "_________________________________________________________________\n",
      "Projection_Stack_0 (Conv1D)  multiple                  912       \n",
      "_________________________________________________________________\n",
      "global_average_pooling1d_1 ( multiple                  0         \n",
      "=================================================================\n",
      "Total params: 2,223,132\n",
      "Trainable params: 2,223,132\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "output_len = 24        \n",
    "input_len = 168        \n",
    "input_dim = trvaX.shape[-1]         \n",
    "hid_size = 9        \n",
    "num_stacks = 1\n",
    "num_levels = 2\n",
    "kernel_size = 12    \n",
    "dropout = 0.2         \n",
    "INN = True           \n",
    "\n",
    "# 모델 정의\n",
    "with tf.device('/gpu:0'):\n",
    "    model2 = SCINet(output_len, input_len, input_dim, hid_size, num_stacks, num_levels, kernel_size, dropout, INN)\n",
    "    model2.build(input_shape=(None, 168, input_dim))\n",
    "    model2.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "065b1b0c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "15524"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f02e5432",
   "metadata": {},
   "outputs": [],
   "source": [
    "    model2.compile(loss=MAEMS, optimizer='adam', metrics=['mse','mae', MAEMS])\n",
    "    early_stopping =EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)\n",
    "    batch_size = 100\n",
    "    epochs = 1000\n",
    "    history2 = LossHistory()\n",
    "    history2.init()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "733a5212",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "131/131 [==============================] - 19s 94ms/step - loss: 4.4023 - mse: 0.1090 - mae: 0.2685 - MAEMS: 4.3991 - val_loss: 3.4804 - val_mse: 0.1319 - val_mae: 0.3039 - val_MAEMS: 3.4961\n",
      "Epoch 2/1000\n",
      "131/131 [==============================] - 11s 84ms/step - loss: 3.7482 - mse: 0.1021 - mae: 0.2611 - MAEMS: 3.7464 - val_loss: 3.4901 - val_mse: 0.1340 - val_mae: 0.3074 - val_MAEMS: 3.5058\n",
      "Epoch 3/1000\n",
      "131/131 [==============================] - 11s 83ms/step - loss: 3.6755 - mse: 0.1009 - mae: 0.2591 - MAEMS: 3.6737 - val_loss: 3.5427 - val_mse: 0.1370 - val_mae: 0.3115 - val_MAEMS: 3.5542\n",
      "Epoch 4/1000\n",
      "131/131 [==============================] - 11s 83ms/step - loss: 3.5945 - mse: 0.0983 - mae: 0.2550 - MAEMS: 3.5922 - val_loss: 3.5181 - val_mse: 0.1332 - val_mae: 0.3062 - val_MAEMS: 3.5230\n",
      "Epoch 5/1000\n",
      "131/131 [==============================] - 11s 83ms/step - loss: 3.5131 - mse: 0.0956 - mae: 0.2505 - MAEMS: 3.5102 - val_loss: 3.4326 - val_mse: 0.1252 - val_mae: 0.2953 - val_MAEMS: 3.4300\n",
      "Epoch 6/1000\n",
      "131/131 [==============================] - 11s 83ms/step - loss: 3.4087 - mse: 0.0921 - mae: 0.2446 - MAEMS: 3.4057 - val_loss: 3.3855 - val_mse: 0.1207 - val_mae: 0.2893 - val_MAEMS: 3.3778\n",
      "Epoch 7/1000\n",
      "131/131 [==============================] - 11s 83ms/step - loss: 3.2850 - mse: 0.0886 - mae: 0.2379 - MAEMS: 3.2819 - val_loss: 3.3412 - val_mse: 0.1139 - val_mae: 0.2799 - val_MAEMS: 3.3311\n",
      "Epoch 8/1000\n",
      "131/131 [==============================] - 11s 83ms/step - loss: 3.1669 - mse: 0.0856 - mae: 0.2320 - MAEMS: 3.1636 - val_loss: 3.2228 - val_mse: 0.0959 - val_mae: 0.2553 - val_MAEMS: 3.2102\n",
      "Epoch 9/1000\n",
      "131/131 [==============================] - 11s 82ms/step - loss: 3.1859 - mse: 0.0862 - mae: 0.2330 - MAEMS: 3.1828 - val_loss: 3.3867 - val_mse: 0.1078 - val_mae: 0.2724 - val_MAEMS: 3.3750\n",
      "Epoch 10/1000\n",
      "131/131 [==============================] - 11s 83ms/step - loss: 3.0616 - mse: 0.0819 - mae: 0.2257 - MAEMS: 3.0592 - val_loss: 3.6723 - val_mse: 0.1285 - val_mae: 0.2998 - val_MAEMS: 3.6603\n",
      "Epoch 11/1000\n",
      "131/131 [==============================] - 11s 83ms/step - loss: 3.0865 - mse: 0.0805 - mae: 0.2235 - MAEMS: 3.0848 - val_loss: 4.5579 - val_mse: 0.1702 - val_mae: 0.3521 - val_MAEMS: 4.5343\n",
      "Epoch 12/1000\n",
      "131/131 [==============================] - 11s 83ms/step - loss: 3.1155 - mse: 0.0808 - mae: 0.2238 - MAEMS: 3.1144 - val_loss: 4.5828 - val_mse: 0.1707 - val_mae: 0.3526 - val_MAEMS: 4.5775\n",
      "Epoch 13/1000\n",
      "131/131 [==============================] - 11s 82ms/step - loss: 2.9993 - mse: 0.0796 - mae: 0.2210 - MAEMS: 2.9976 - val_loss: 4.1076 - val_mse: 0.1498 - val_mae: 0.3284 - val_MAEMS: 4.1049\n",
      "Epoch 14/1000\n",
      "131/131 [==============================] - 11s 82ms/step - loss: 2.9590 - mse: 0.0761 - mae: 0.2161 - MAEMS: 2.9579 - val_loss: 4.7193 - val_mse: 0.1806 - val_mae: 0.3681 - val_MAEMS: 4.7160\n",
      "Epoch 15/1000\n",
      "131/131 [==============================] - 11s 84ms/step - loss: 2.8726 - mse: 0.0731 - mae: 0.2103 - MAEMS: 2.8718 - val_loss: 4.9976 - val_mse: 0.1868 - val_mae: 0.3764 - val_MAEMS: 4.9873\n",
      "Epoch 16/1000\n",
      "131/131 [==============================] - 11s 83ms/step - loss: 2.8361 - mse: 0.0715 - mae: 0.2077 - MAEMS: 2.8340 - val_loss: 4.0087 - val_mse: 0.1449 - val_mae: 0.3236 - val_MAEMS: 3.9932\n",
      "Epoch 17/1000\n",
      "131/131 [==============================] - 11s 83ms/step - loss: 2.8453 - mse: 0.0696 - mae: 0.2050 - MAEMS: 2.8428 - val_loss: 3.7376 - val_mse: 0.1288 - val_mae: 0.3004 - val_MAEMS: 3.7180\n",
      "Epoch 18/1000\n",
      "131/131 [==============================] - 11s 83ms/step - loss: 2.7055 - mse: 0.0675 - mae: 0.2001 - MAEMS: 2.7029 - val_loss: 3.3666 - val_mse: 0.1121 - val_mae: 0.2785 - val_MAEMS: 3.3550\n",
      "Wall time: 3min 24s\n"
     ]
    }
   ],
   "source": [
    "    %%time\n",
    "    hist2 = model2.fit(trX, trY, epochs=epochs, batch_size=b_size, shuffle=False, validation_data=(vaX, vaY), callbacks=[history2, early_stopping])  # , checkpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "7b957a3e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4598"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "9fea3189",
   "metadata": {},
   "outputs": [],
   "source": [
    "testPredict2 = model2.predict(teX, batch_size=b_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "b90bb903",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error Test Score > MSE ==  0.04884789016950677  MAE ==  0.17941999954264826  MAEMS ==  2.7640606336811144\n",
      "Error Test Score > MSE ==  0.10928829504387161  MAE ==  0.27804073018754466  MAEMS ==  2.657115109660811\n"
     ]
    }
   ],
   "source": [
    "tePredict2 = testPredict2.reshape(-1)\n",
    "testY = teY.reshape(-1)\n",
    "print('Error Test Score > MSE == ', npMSE(testY, tePredict), ' MAE == ', npMAE(testY, tePredict), ' MAEMS == ', npMAEMS(testY, tePredict))\n",
    "print('Error Test Score > MSE == ', npMSE(testY, tePredict2), ' MAE == ', npMAE(testY, tePredict2), ' MAEMS == ', npMAEMS(testY, tePredict2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "330748c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from statsmodels.stats.diagnostic import acorr_ljungbox\n",
    "from scipy.stats import norm\n",
    "\n",
    "def diebold_mariano_test(forecast1, forecast2, actual, opt): \n",
    "    \n",
    "    if opt==0: # MSE\n",
    "        e1 = actual-forecast1\n",
    "        e2 = actual-forecast2\n",
    "        d = e1**2 - e2**2\n",
    "    elif opt==1: # MAE\n",
    "        e1 = abs(actual-forecast1)\n",
    "        e2 = abs(actual-forecast2)\n",
    "        d = e1 - e2\n",
    "    else:\n",
    "        e1 = np.multiply(abs(actual - forecast1), actual**2)\n",
    "        e2 = np.multiply(abs(actual - forecast2), actual**2)\n",
    "        d = e1-e2\n",
    "    \n",
    "    # Mean of the loss differentials\n",
    "    mean_d = np.mean(d)\n",
    "    \n",
    "    # Standard deviation of the loss differentials\n",
    "    std_d = np.std(d, ddof=1)\n",
    "    \n",
    "    # Calculate the test statistic\n",
    "    test_stat = (mean_d / std_d) * np.sqrt(len(d))\n",
    "    \n",
    "    # Calculate the p-value using a two-tailed test\n",
    "    p_value = 2 * (1 - norm.cdf(abs(test_stat)))\n",
    "    \n",
    "    return test_stat, p_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "97fd92b3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((-38.08709072810582, 0.0),\n",
       " (-35.99164069439573, 0.0),\n",
       " (1.6499016454883806, 0.09896305413307172))"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "diebold_mariano_test(testPredict, testPredict2, teY, 0), diebold_mariano_test(testPredict, testPredict2, teY, 1), diebold_mariano_test(testPredict, testPredict2, teY, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "ab6860e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.savetxt('SCINet_prop', testPredict)\n",
    "np.savetxt('SCINet_woshuffling', testPredict2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c3b8165",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
