{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b0e41db1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "from time import time\n",
    "import json\n",
    "import logging\n",
    "\n",
    "import tensorflow as tf\n",
    "import keras\n",
    "from keras import layers\n",
    "from keras.models import Model\n",
    "from keras.models import load_model\n",
    "from keras.models import Sequential\n",
    "from keras.callbacks import EarlyStopping, TensorBoard, ModelCheckpoint\n",
    "from keras.callbacks import Callback\n",
    "\n",
    "from sklearn.metrics import r2_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "396ffee0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "import pandas as pd\n",
    "import codecs\n",
    "import numpy as np\n",
    "import math\n",
    "import csv\n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.metrics import recall_score, precision_score # New\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn import preprocessing\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow.keras.preprocessing\n",
    "#from tensorflow.keras.callbacks import ModelCheckpoint, CSVLogger, EarlyStopping, LearningRateScheduler, ReduceLROnPlateau\n",
    "from tensorflow.keras.models import Sequential, Model\n",
    "from tensorflow.keras.layers import Dense, Input, Flatten, Add, Multiply, Subtract\n",
    "from tensorflow.keras import backend as K\n",
    "from tensorflow.keras.layers import Activation, BatchNormalization\n",
    "# regularizers\n",
    "from tensorflow.keras.layers import Conv1D, Conv2D\n",
    "from tensorflow.keras.layers import MaxPooling1D\n",
    "from tensorflow.keras.layers import concatenate\n",
    "from tensorflow.keras.layers import LSTM, Bidirectional\n",
    "from tensorflow.keras.utils import plot_model\n",
    "from tensorflow.keras.layers import Dropout, SpatialDropout1D\n",
    "from scipy import signal\n",
    "import openpyxl\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "from matplotlib import pylab as plt\n",
    "import matplotlib.dates as mdates\n",
    "import seaborn as sns\n",
    "import sklearn\n",
    "from sklearn.model_selection import train_test_split\n",
    "from numpy.linalg import svd\n",
    "import gc\n",
    "from keijzer import *\n",
    "from tensorflow import keras\n",
    "from keras.models import Model\n",
    "from keras.layers import *\n",
    "from tensorflow.keras.optimizers import Adam,SGD\n",
    "from keras.layers import Dense, Input, Flatten, Add, concatenate, Dropout, Activation, Multiply, Embedding, Layer, Reshape\n",
    "from keras.layers import LSTM, Bidirectional, GlobalMaxPooling1D, GlobalAveragePooling1D  \n",
    "from keras.layers import Conv1D, AveragePooling1D, MaxPooling1D\n",
    "#from keras.ops import convert_to_tensor, convert_to_numpy\n",
    "#from keras.utils import plot_model\n",
    "from keras import activations\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from keras.callbacks import ModelCheckpoint, CSVLogger, EarlyStopping, LearningRateScheduler, ReduceLROnPlateau\n",
    "import math\n",
    "\n",
    "class LossHistory(tensorflow.keras.callbacks.Callback):  # history = LossHistory()\n",
    "    def init(self):  # history.init()\n",
    "        self.losses = []\n",
    "        # self.accs = []\n",
    "        self.val_losses = []\n",
    "        # self.val_accs = []\n",
    "        self.rmses = []\n",
    "        self.mses = []\n",
    "        self.maes = []\n",
    "        self.mapes = []\n",
    "        self.val_rmses = []\n",
    "        self.val_mses = []\n",
    "        self.val_maes = []\n",
    "        self.val_mapes = []\n",
    "\n",
    "    def on_epoch_end(self, batch, logs={}):\n",
    "        self.losses.append(logs.get('loss'))\n",
    "        # self.accs.append(logs.get('acc'))\n",
    "        self.val_losses.append(logs.get('val_loss'))\n",
    "        # self.val_accs.append(logs.get('val_accuracy\n",
    "        self.rmses.append(logs.get('root_mean_squared_error'))\n",
    "        self.mses.append(logs.get('mean_squared_error'))\n",
    "        self.maes.append(logs.get('mean_absolute_error'))\n",
    "        self.mapes.append(logs.get('mean_absolute_percentage_error'))\n",
    "        self.val_rmses.append(logs.get('val_root_mean_squared_error'))\n",
    "        self.val_mses.append(logs.get('val_mean_squared_error'))\n",
    "        self.val_maes.append(logs.get('val_mean_absolute_error'))\n",
    "        self.val_mapes.append(logs.get('val_mean_absolute_percentage_error'))\n",
    "\n",
    "\n",
    "\n",
    "def root_squared_mean_error(y_true, y_pred):\n",
    "    return K.mean((K.abs(y_pred - y_true))*K.square(y_true-K.mean(y_true)))*100\n",
    "\n",
    "def mse_mae(y_true, y_pred):\n",
    "    return K.mean(K.square(y_pred - y_true))+K.mean(K.abs(y_pred - y_true))\n",
    "\n",
    "from keras.layers.advanced_activations import PReLU\n",
    "\n",
    "def mean_absolute_percentage_error(y_true, y_pred):\n",
    "    y_true, y_pred = np.array(y_true), np.array(y_pred)\n",
    "    return np.mean(np.abs((y_true - y_pred) / y_true)) * 100\n",
    "\n",
    "def root_mean_squared_error(y_true, y_pred):\n",
    "        return K.sqrt(K.mean(K.square(y_pred - y_true))) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fdd9d408",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]\n"
     ]
    }
   ],
   "source": [
    "import scipy as sc\n",
    "import os\n",
    "\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = '0' # 여러개 사용시 '0,1,2' 식으로 하나의 문자열에 입력\n",
    "gpus = tf.config.experimental.list_physical_devices('GPU') # 호스트 러나임에 표시되는 GPU 장치 목록 반환\n",
    "\n",
    "if gpus: # 반환된 GPU 장치 목록이 있다면\n",
    "    try: # 해당 장치에 대한 메모리 증가 활성화 여부 설정\n",
    "        tf.config.experimental.set_memory_growth(gpus[0], True)\n",
    "    except RuntimeError as e: # try문 실패시에 에러문구 출력\n",
    "        print(e)\n",
    "\n",
    "print(tf.config.list_physical_devices('GPU'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d66b201b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Year</th>\n",
       "      <th>Wind Change</th>\n",
       "      <th>Wind Output</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2020</td>\n",
       "      <td>0.620197</td>\n",
       "      <td>0.644724</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2020</td>\n",
       "      <td>0.544580</td>\n",
       "      <td>0.658617</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2020</td>\n",
       "      <td>0.570751</td>\n",
       "      <td>0.683924</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2020</td>\n",
       "      <td>0.599594</td>\n",
       "      <td>0.721813</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2020</td>\n",
       "      <td>0.495246</td>\n",
       "      <td>0.714187</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35058</th>\n",
       "      <td>2023</td>\n",
       "      <td>0.774643</td>\n",
       "      <td>0.484984</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35059</th>\n",
       "      <td>2023</td>\n",
       "      <td>0.735512</td>\n",
       "      <td>0.582157</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35060</th>\n",
       "      <td>2023</td>\n",
       "      <td>0.601593</td>\n",
       "      <td>0.620917</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35061</th>\n",
       "      <td>2023</td>\n",
       "      <td>0.536583</td>\n",
       "      <td>0.631322</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35062</th>\n",
       "      <td>2023</td>\n",
       "      <td>0.454969</td>\n",
       "      <td>0.606127</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>35063 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Year  Wind Change  Wind Output\n",
       "0      2020     0.620197     0.644724\n",
       "1      2020     0.544580     0.658617\n",
       "2      2020     0.570751     0.683924\n",
       "3      2020     0.599594     0.721813\n",
       "4      2020     0.495246     0.714187\n",
       "...     ...          ...          ...\n",
       "35058  2023     0.774643     0.484984\n",
       "35059  2023     0.735512     0.582157\n",
       "35060  2023     0.601593     0.620917\n",
       "35061  2023     0.536583     0.631322\n",
       "35062  2023     0.454969     0.606127\n",
       "\n",
       "[35063 rows x 3 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_path = 'C:/Users/smartgrid_AI/Desktop/windpower_ramprate/ercot_2020.csv'\n",
    "data_source1 = pd.read_csv(data_path)\n",
    "dat_source1 = pd.DataFrame(data_source1)\n",
    "#dat_source1 = dat_source1.iloc[:-3,:]\n",
    "\n",
    "data_path = 'C:/Users/smartgrid_AI/Desktop/windpower_ramprate/ercot_2021.csv'\n",
    "data_source2 = pd.read_csv(data_path)\n",
    "dat_source2 = pd.DataFrame(data_source2)\n",
    "dat_source2 = dat_source2.iloc[:8761,:9]\n",
    "\n",
    "data_path = 'C:/Users/smartgrid_AI/Desktop/windpower_ramprate/ercot_2022.csv'\n",
    "data_source3 = pd.read_csv(data_path)\n",
    "dat_source3 = pd.DataFrame(data_source3)\n",
    "dat_source3 = dat_source3.iloc[:8760,:9]\n",
    "\n",
    "data_path = 'C:/Users/smartgrid_AI/Desktop/windpower_ramprate/ercot_2023.csv'\n",
    "data_source4 = pd.read_csv(data_path)\n",
    "dat_source4 = pd.DataFrame(data_source4)\n",
    "dat_source4 = dat_source4.iloc[:8760,:9]\n",
    "\n",
    "dat_arr1 = np.array(dat_source1)\n",
    "dat_arr2 = np.array(dat_source2)\n",
    "dat_arr3 = np.array(dat_source3)\n",
    "dat_arr4 = np.array(dat_source4)\n",
    "\n",
    "dat_arr = np.concatenate([dat_arr1, dat_arr2, dat_arr3, dat_arr4],axis=0)\n",
    "dat_arr.shape # 8784, 8761, 8760, 8760\n",
    "\n",
    "dat_source = pd.DataFrame(dat_arr, columns=['Time-Date stamp','Date','ERCOT Load','Total Wind Output','Total Wind Installed','Wind Output, % of Load','Wind Output, % of Installed','1-hr MW change','1-hr % change'])\n",
    "dat = pd.DataFrame()\n",
    "dat['MW % change'] = np.array(dat_source.iloc[1:,3], dtype=float)-np.array(dat_source.iloc[0:-1,3], dtype=float)\n",
    "dat['MW % change'] = np.divide(np.array(dat['MW % change']),np.array(dat_source.iloc[1:,4]))*100\n",
    "dat['Total Wind Output'] = np.divide(np.array(dat_source.iloc[1:,3]), np.array(dat_source.iloc[1:,4]))\n",
    "\n",
    "ramp_ratio = 20\n",
    "load_ratio = 10\n",
    "year_arr = np.concatenate([np.ones(8784)*2020, np.ones(8760)*2021, np.ones(8760)*2022, np.ones(8760)*2023])\n",
    "year_df = pd.DataFrame(year_arr, columns=['Year'], dtype=int)\n",
    "wind_df = pd.concat([year_df, dat], axis=1)\n",
    "wind_df = wind_df.reset_index(drop=True)\n",
    "\n",
    "std_scaler = sklearn.preprocessing.MinMaxScaler()\n",
    "std_scaler_load = sklearn.preprocessing.MinMaxScaler()\n",
    "std_scaler_ramp = sklearn.preprocessing.MinMaxScaler()\n",
    "\n",
    "wind_df[['Total Wind Output']] = std_scaler.fit_transform(wind_df[['Total Wind Output']])\n",
    "wind_df[['MW % change']] = std_scaler_ramp.fit_transform(wind_df[['MW % change']])\n",
    "wind_df = wind_df.iloc[:-1,:]\n",
    "ramp_df = pd.DataFrame(wind_df)\n",
    "ramp_df.columns=['Year', 'Wind Change', 'Wind Output']\n",
    "ramp_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8248d616",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_dataset(dataset, timesteps, output_timesteps, leadtime):\n",
    "    dataX, dataY = [], []\n",
    "    for i in range(len(dataset) - timesteps -output_timesteps - leadtime - 1):\n",
    "        a = dataset[i:(i + timesteps), :]\n",
    "        dataX.append(a)\n",
    "        dataY.append(dataset[(i + timesteps + leadtime):(i+timesteps+output_timesteps+leadtime), :])\n",
    "    return np.array(dataX), np.array(dataY)\n",
    "\n",
    "def svdadd(X, start, end, b_size):\n",
    "    dec_x = X[start:end, :, :]\n",
    "    U, S, Vh = svd(dec_x.reshape(b_size, -1), full_matrices=True)\n",
    "\n",
    "    high_sig = np.matmul(np.matmul(U[:,:high_ind], np.diag(S[0:high_ind])), Vh[:high_ind,:])\n",
    "    low_sig = X[:dec_num, :, :].reshape(b_size,-1)-high_sig\n",
    "\n",
    "    rec_x = np.zeros((b_size, b_size, high_ind))\n",
    "    \n",
    "    for i in range(high_ind):\n",
    "        rec_x[:,:,i] = np.matmul((U[:,i]*S[i]).reshape(-1,1), Vh[i,:].reshape(1,-1))    \n",
    "    return rec_x, low_sig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "702bd01a",
   "metadata": {},
   "outputs": [],
   "source": [
    "norm_df = np.array(wind_df.iloc[:,2]).reshape(-1,1)\n",
    "timesteps = 24*7\n",
    "output_timesteps = 24\n",
    "leadtime = 6\n",
    "num_features = 1\n",
    "X, Y = create_dataset(norm_df, timesteps, output_timesteps, leadtime)\n",
    "b_size = timesteps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e03e5ebe",
   "metadata": {},
   "outputs": [],
   "source": [
    "dec_num = timesteps\n",
    "high_ind = 35\n",
    "\n",
    "addX = np.zeros((X.shape[0], dec_num, high_ind+1))\n",
    "\n",
    "for k in range(X.shape[0]//dec_num):\n",
    "    rec_x, low_sig = svdadd(X, k*dec_num, (k+1)*dec_num, b_size)\n",
    "    addX[k*dec_num:k*dec_num+dec_num,:, :-1] = rec_x\n",
    "    addX[k*dec_num:k*dec_num+dec_num,:, -1] = low_sig\n",
    "    \n",
    "rec_x, low_sig = svdadd(X, X.shape[0]-dec_num, X.shape[0], b_size)\n",
    "addX[X.shape[0]-dec_num:X.shape[0], :, :-1] = rec_x\n",
    "addX[X.shape[0]-dec_num:X.shape[0],:, -1] = low_sig\n",
    "\n",
    "addX_det = addX[:, :, :-1]\n",
    "addX_det = np.sum(addX_det, axis=2)\n",
    "X = np.concatenate([X, addX], axis=2)\n",
    "num_features = X.shape[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "214f028b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((31377, 168, 37), (31377, 24), (3487, 168, 37), (3487, 24))"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trvaX, teX, trvaY, teY = train_test_split(X, Y, test_size=0.1, shuffle=False)\n",
    "\n",
    "idx = np.arange(trvaX.shape[0])\n",
    "np.random.shuffle(idx)\n",
    "strvaX = trvaX[idx]\n",
    "strvaY = trvaY[idx]\n",
    "strvaY = strvaY.reshape(-1, output_timesteps)\n",
    "\n",
    "trvaY = trvaY.reshape(-1, output_timesteps)\n",
    "teY = teY.reshape(-1, output_timesteps)\n",
    "\n",
    "strX, svaX, strY, svaY = train_test_split(strvaX, strvaY, test_size=0.3, shuffle=False)\n",
    "trX, vaX, trY, vaY = train_test_split(trvaX, trvaY, test_size=0.3, shuffle=False)\n",
    "\n",
    "trvaX.shape, trvaY.shape, teX.shape, teY.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6537e85a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def MAEMS(y_true, y_pred):\n",
    "    return K.mean((K.abs(y_pred - y_true))*K.square(y_true))*100"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efc4b987",
   "metadata": {},
   "source": [
    "## Transformer Model - With SVD With Shuffling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "14465f3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_features = trvaX.shape[2]\n",
    "output_timesteps = trvaY.shape[1]\n",
    "transformer_block_num = 10\n",
    "mlp_units = [24*7*5]\n",
    "mlp_dropout = 0.4\n",
    "dropout = 0.25\n",
    "\n",
    "head_size=24\n",
    "num_heads=4\n",
    "ff_dim=4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f54403fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.device('/gpu:0'):\n",
    "    inputs = keras.Input(shape=(timesteps, num_features))\n",
    "    x = inputs\n",
    "    \n",
    "    for _ in range(transformer_block_num):\n",
    "        x = layers.LayerNormalization(epsilon=1e-6)(x)\n",
    "        x = layers.MultiHeadAttention(\n",
    "        key_dim=head_size, num_heads=num_heads, dropout=dropout)(x, x)\n",
    "        x = layers.Dropout(dropout)(x)\n",
    "\n",
    "        res = x + inputs\n",
    "\n",
    "        # Feed Forward Part\n",
    "        x = layers.LayerNormalization(epsilon=1e-6)(res)\n",
    "        x = layers.Conv1D(filters=ff_dim, kernel_size=1, activation=\"relu\")(x)\n",
    "        x = layers.Dropout(dropout)(x)\n",
    "        x = layers.Conv1D(filters=inputs.shape[-1], kernel_size=1)(x)\n",
    "\n",
    "        x = x + res\n",
    "        \n",
    "    x = layers.GlobalAveragePooling1D(data_format=\"channels_first\")(x)\n",
    "    for dim in mlp_units:\n",
    "        x = layers.Dense(dim, activation=\"relu\")(x)\n",
    "        x = layers.Dropout(mlp_dropout)(x)\n",
    "\n",
    "    # output layer\n",
    "    outputs = layers.Dense(output_timesteps)(x)\n",
    "\n",
    "    model = keras.Model(inputs, outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "68c034d2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1943"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "28091499",
   "metadata": {},
   "outputs": [],
   "source": [
    "    model.compile(loss=MAEMS, optimizer='adam', metrics=['mse','mae', MAEMS])\n",
    "    early_stopping =EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)\n",
    "    batch_size = 100\n",
    "    epochs = 1000\n",
    "    history = LossHistory()\n",
    "    history.init()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "adf6bcb9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "131/131 [==============================] - 68s 454ms/step - loss: 4.3652 - mse: 0.1077 - mae: 0.2690 - MAEMS: 4.3637 - val_loss: 3.7831 - val_mse: 0.1336 - val_mae: 0.3033 - val_MAEMS: 3.7794\n",
      "Epoch 2/1000\n",
      "131/131 [==============================] - 56s 432ms/step - loss: 3.8106 - mse: 0.1002 - mae: 0.2602 - MAEMS: 3.8100 - val_loss: 3.8124 - val_mse: 0.1350 - val_mae: 0.3054 - val_MAEMS: 3.8085\n",
      "Epoch 3/1000\n",
      "131/131 [==============================] - 58s 446ms/step - loss: 3.6399 - mse: 0.0961 - mae: 0.2544 - MAEMS: 3.6395 - val_loss: 3.6368 - val_mse: 0.1244 - val_mae: 0.2915 - val_MAEMS: 3.6367\n",
      "Epoch 4/1000\n",
      "131/131 [==============================] - 56s 433ms/step - loss: 3.5862 - mse: 0.0936 - mae: 0.2511 - MAEMS: 3.5856 - val_loss: 3.4875 - val_mse: 0.1070 - val_mae: 0.2691 - val_MAEMS: 3.4907\n",
      "Epoch 5/1000\n",
      "131/131 [==============================] - 56s 433ms/step - loss: 3.5437 - mse: 0.0914 - mae: 0.2481 - MAEMS: 3.5432 - val_loss: 3.3715 - val_mse: 0.0806 - val_mae: 0.2328 - val_MAEMS: 3.3820\n",
      "Epoch 6/1000\n",
      "131/131 [==============================] - 56s 433ms/step - loss: 3.4679 - mse: 0.0878 - mae: 0.2428 - MAEMS: 3.4672 - val_loss: 3.3536 - val_mse: 0.0854 - val_mae: 0.2394 - val_MAEMS: 3.3654\n",
      "Epoch 7/1000\n",
      "131/131 [==============================] - 58s 445ms/step - loss: 3.3902 - mse: 0.0822 - mae: 0.2340 - MAEMS: 3.3895 - val_loss: 3.4154 - val_mse: 0.0793 - val_mae: 0.2317 - val_MAEMS: 3.4269\n",
      "Epoch 8/1000\n",
      "131/131 [==============================] - 56s 433ms/step - loss: 3.3116 - mse: 0.0761 - mae: 0.2241 - MAEMS: 3.3113 - val_loss: 3.4220 - val_mse: 0.0790 - val_mae: 0.2312 - val_MAEMS: 3.4307\n",
      "Epoch 9/1000\n",
      "131/131 [==============================] - 56s 433ms/step - loss: 3.2317 - mse: 0.0719 - mae: 0.2165 - MAEMS: 3.2314 - val_loss: 3.4913 - val_mse: 0.0949 - val_mae: 0.2529 - val_MAEMS: 3.5008\n",
      "Epoch 10/1000\n",
      "131/131 [==============================] - 56s 433ms/step - loss: 3.1751 - mse: 0.0694 - mae: 0.2117 - MAEMS: 3.1744 - val_loss: 3.5195 - val_mse: 0.0923 - val_mae: 0.2495 - val_MAEMS: 3.5290\n",
      "Epoch 11/1000\n",
      "131/131 [==============================] - 58s 431ms/step - loss: 3.1275 - mse: 0.0681 - mae: 0.2088 - MAEMS: 3.1269 - val_loss: 3.6828 - val_mse: 0.0768 - val_mae: 0.2295 - val_MAEMS: 3.6949\n",
      "Epoch 12/1000\n",
      "131/131 [==============================] - 56s 430ms/step - loss: 3.1099 - mse: 0.0672 - mae: 0.2069 - MAEMS: 3.1094 - val_loss: 3.4315 - val_mse: 0.0940 - val_mae: 0.2517 - val_MAEMS: 3.4410\n",
      "Epoch 13/1000\n",
      "131/131 [==============================] - 56s 429ms/step - loss: 3.0870 - mse: 0.0668 - mae: 0.2062 - MAEMS: 3.0866 - val_loss: 3.6001 - val_mse: 0.0856 - val_mae: 0.2412 - val_MAEMS: 3.6106\n",
      "Epoch 14/1000\n",
      "131/131 [==============================] - 58s 429ms/step - loss: 3.0615 - mse: 0.0655 - mae: 0.2038 - MAEMS: 3.0609 - val_loss: 3.6794 - val_mse: 0.0744 - val_mae: 0.2258 - val_MAEMS: 3.6909\n",
      "Epoch 15/1000\n",
      "131/131 [==============================] - 56s 429ms/step - loss: 3.0370 - mse: 0.0649 - mae: 0.2024 - MAEMS: 3.0367 - val_loss: 3.6467 - val_mse: 0.0782 - val_mae: 0.2313 - val_MAEMS: 3.6581\n",
      "Epoch 16/1000\n",
      "131/131 [==============================] - 56s 428ms/step - loss: 3.0140 - mse: 0.0637 - mae: 0.2002 - MAEMS: 3.0136 - val_loss: 3.5067 - val_mse: 0.0854 - val_mae: 0.2406 - val_MAEMS: 3.5172\n",
      "Wall time: 15min 19s\n"
     ]
    }
   ],
   "source": [
    "    %%time\n",
    "    b_size = 168\n",
    "    hist = model.fit(strX, strY, epochs=epochs, batch_size=b_size, shuffle=False, validation_data=(svaX, svaY), callbacks=[history, early_stopping])  # , checkpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ccc88e62",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4590"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d579dea9",
   "metadata": {},
   "outputs": [],
   "source": [
    "testPredict = model.predict(teX, batch_size=b_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "4e148fa6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def npMAEMS(y_true, y_pred):\n",
    "    return np.mean((abs(y_pred - y_true))*np.square(y_true))*100\n",
    "def npMAEMD(y_true, y_pred):\n",
    "    return np.mean((abs(y_pred - y_true))*np.square(y_true-np.mean(y_true)))*100\n",
    "def npMSE(y_true, y_pred):\n",
    "    return np.mean(np.square(-y_true+y_pred))\n",
    "def npMAE(y_true, y_pred):\n",
    "    return np.mean(abs(-y_true+y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "3765359e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error Test Score > MSE ==  0.09739213808941012  MAE ==  0.2634617411885624  MAEMS ==  2.5163133696902658\n"
     ]
    }
   ],
   "source": [
    "tePredict = testPredict.reshape(-1)\n",
    "testY = teY.reshape(-1)\n",
    "print('Error Test Score > MSE == ', npMSE(testY, tePredict), ' MAE == ', npMAE(testY, tePredict), ' MAEMS == ', npMAEMS(testY, tePredict))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a984dc6",
   "metadata": {},
   "source": [
    "## Without Shuffling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "cc114c0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.device('/gpu:0'):\n",
    "    inputs = keras.Input(shape=(timesteps, num_features))\n",
    "    x = inputs\n",
    "    \n",
    "    for _ in range(transformer_block_num):\n",
    "        x = layers.LayerNormalization(epsilon=1e-6)(x)\n",
    "        x = layers.MultiHeadAttention(\n",
    "        key_dim=head_size, num_heads=num_heads, dropout=dropout)(x, x)\n",
    "        x = layers.Dropout(dropout)(x)\n",
    "\n",
    "        res = x + inputs\n",
    "\n",
    "        # Feed Forward Part\n",
    "        x = layers.LayerNormalization(epsilon=1e-6)(res)\n",
    "        x = layers.Conv1D(filters=ff_dim, kernel_size=1, activation=\"relu\")(x)\n",
    "        x = layers.Dropout(dropout)(x)\n",
    "        x = layers.Conv1D(filters=inputs.shape[-1], kernel_size=1)(x)\n",
    "\n",
    "        x = x + res\n",
    "        \n",
    "    x = layers.GlobalAveragePooling1D(data_format=\"channels_first\")(x)\n",
    "    for dim in mlp_units:\n",
    "        x = layers.Dense(dim, activation=\"relu\")(x)\n",
    "        x = layers.Dropout(mlp_dropout)(x)\n",
    "\n",
    "    # output layer\n",
    "    outputs = layers.Dense(output_timesteps)(x)\n",
    "\n",
    "    model2 = keras.Model(inputs, outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "643f9cd7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3633"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "9f488605",
   "metadata": {},
   "outputs": [],
   "source": [
    "    model2.compile(loss=MAEMS, optimizer='adam', metrics=['mse','mae', MAEMS])\n",
    "    early_stopping =EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)\n",
    "    batch_size = 100\n",
    "    epochs = 1000\n",
    "    history2 = LossHistory()\n",
    "    history2.init()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "acde664c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "131/131 [==============================] - 65s 447ms/step - loss: 5.1202 - mse: 0.1108 - mae: 0.2706 - MAEMS: 5.1137 - val_loss: 3.4014 - val_mse: 0.0711 - val_mae: 0.2243 - val_MAEMS: 3.3812\n",
      "Epoch 2/1000\n",
      "131/131 [==============================] - 56s 428ms/step - loss: 4.2829 - mse: 0.1023 - mae: 0.2613 - MAEMS: 4.2782 - val_loss: 3.5019 - val_mse: 0.0645 - val_mae: 0.2146 - val_MAEMS: 3.4762\n",
      "Epoch 3/1000\n",
      "131/131 [==============================] - 56s 428ms/step - loss: 4.1011 - mse: 0.0989 - mae: 0.2571 - MAEMS: 4.0969 - val_loss: 3.3218 - val_mse: 0.0708 - val_mae: 0.2236 - val_MAEMS: 3.3046\n",
      "Epoch 4/1000\n",
      "131/131 [==============================] - 56s 429ms/step - loss: 4.0156 - mse: 0.0973 - mae: 0.2551 - MAEMS: 4.0116 - val_loss: 3.3572 - val_mse: 0.0683 - val_mae: 0.2200 - val_MAEMS: 3.3371\n",
      "Epoch 5/1000\n",
      "131/131 [==============================] - 58s 429ms/step - loss: 3.9566 - mse: 0.0950 - mae: 0.2523 - MAEMS: 3.9529 - val_loss: 3.2550 - val_mse: 0.0737 - val_mae: 0.2278 - val_MAEMS: 3.2408\n",
      "Epoch 6/1000\n",
      "131/131 [==============================] - 56s 429ms/step - loss: 3.9551 - mse: 0.0933 - mae: 0.2503 - MAEMS: 3.9533 - val_loss: 3.1943 - val_mse: 0.1088 - val_mae: 0.2761 - val_MAEMS: 3.2086\n",
      "Epoch 7/1000\n",
      "131/131 [==============================] - 58s 442ms/step - loss: 3.8268 - mse: 0.0922 - mae: 0.2488 - MAEMS: 3.8255 - val_loss: 3.2836 - val_mse: 0.1171 - val_mae: 0.2876 - val_MAEMS: 3.3016\n",
      "Epoch 8/1000\n",
      "131/131 [==============================] - 56s 430ms/step - loss: 3.7497 - mse: 0.0925 - mae: 0.2491 - MAEMS: 3.7477 - val_loss: 3.2496 - val_mse: 0.1118 - val_mae: 0.2803 - val_MAEMS: 3.2604\n",
      "Epoch 9/1000\n",
      "131/131 [==============================] - 58s 442ms/step - loss: 3.6887 - mse: 0.0912 - mae: 0.2476 - MAEMS: 3.6871 - val_loss: 3.2855 - val_mse: 0.1169 - val_mae: 0.2873 - val_MAEMS: 3.2983\n",
      "Epoch 10/1000\n",
      "131/131 [==============================] - 56s 429ms/step - loss: 3.6368 - mse: 0.0880 - mae: 0.2431 - MAEMS: 3.6353 - val_loss: 3.2035 - val_mse: 0.1083 - val_mae: 0.2762 - val_MAEMS: 3.2146\n",
      "Epoch 11/1000\n",
      "131/131 [==============================] - 58s 443ms/step - loss: 3.6074 - mse: 0.0828 - mae: 0.2351 - MAEMS: 3.6061 - val_loss: 3.5098 - val_mse: 0.1255 - val_mae: 0.3007 - val_MAEMS: 3.5276\n",
      "Epoch 12/1000\n",
      "131/131 [==============================] - 56s 428ms/step - loss: 3.6676 - mse: 0.0857 - mae: 0.2400 - MAEMS: 3.6663 - val_loss: 3.5127 - val_mse: 0.1251 - val_mae: 0.3002 - val_MAEMS: 3.5314\n",
      "Epoch 13/1000\n",
      "131/131 [==============================] - 56s 428ms/step - loss: 3.6264 - mse: 0.0865 - mae: 0.2410 - MAEMS: 3.6252 - val_loss: 3.4573 - val_mse: 0.1233 - val_mae: 0.2973 - val_MAEMS: 3.4733\n",
      "Epoch 14/1000\n",
      "131/131 [==============================] - 56s 428ms/step - loss: 3.5774 - mse: 0.0838 - mae: 0.2369 - MAEMS: 3.5764 - val_loss: 3.6738 - val_mse: 0.1324 - val_mae: 0.3118 - val_MAEMS: 3.6961\n",
      "Epoch 15/1000\n",
      "131/131 [==============================] - 56s 427ms/step - loss: 3.6717 - mse: 0.0850 - mae: 0.2391 - MAEMS: 3.6695 - val_loss: 3.2009 - val_mse: 0.1085 - val_mae: 0.2764 - val_MAEMS: 3.2141\n",
      "Epoch 16/1000\n",
      "131/131 [==============================] - 57s 427ms/step - loss: 3.5689 - mse: 0.0834 - mae: 0.2361 - MAEMS: 3.5675 - val_loss: 3.6158 - val_mse: 0.1273 - val_mae: 0.3034 - val_MAEMS: 3.6397\n",
      "Wall time: 15min 13s\n"
     ]
    }
   ],
   "source": [
    "    %%time\n",
    "    hist2 = model2.fit(trX, trY, epochs=epochs, batch_size=b_size, shuffle=False, validation_data=(vaX, vaY), callbacks=[history2, early_stopping])  # , checkpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "234477a7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4598"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "d26e592a",
   "metadata": {},
   "outputs": [],
   "source": [
    "testPredict2 = model2.predict(teX, batch_size=b_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "cc5d0b4e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error Test Score > MSE ==  0.09739213808941012  MAE ==  0.2634617411885624  MAEMS ==  2.5163133696902658\n",
      "Error Test Score > MSE ==  0.12195081157574128  MAE ==  0.2998280573776987  MAEMS ==  2.8297367778583453\n"
     ]
    }
   ],
   "source": [
    "tePredict2 = testPredict2.reshape(-1)\n",
    "testY = teY.reshape(-1)\n",
    "print('Error Test Score > MSE == ', npMSE(testY, tePredict), ' MAE == ', npMAE(testY, tePredict), ' MAEMS == ', npMAEMS(testY, tePredict))\n",
    "print('Error Test Score > MSE == ', npMSE(testY, tePredict2), ' MAE == ', npMAE(testY, tePredict2), ' MAEMS == ', npMAEMS(testY, tePredict2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "2fc6de59",
   "metadata": {},
   "outputs": [],
   "source": [
    "from statsmodels.stats.diagnostic import acorr_ljungbox\n",
    "from scipy.stats import norm\n",
    "\n",
    "def diebold_mariano_test(forecast1, forecast2, actual, opt): \n",
    "    \n",
    "    if opt==0: # MSE\n",
    "        e1 = actual-forecast1\n",
    "        e2 = actual-forecast2\n",
    "        d = e1**2 - e2**2\n",
    "    elif opt==1: # MAE\n",
    "        e1 = abs(actual-forecast1)\n",
    "        e2 = abs(actual-forecast2)\n",
    "        d = e1 - e2\n",
    "    else:\n",
    "        e1 = np.multiply(abs(actual - forecast1), actual**2)\n",
    "        e2 = np.multiply(abs(actual - forecast2), actual**2)\n",
    "        d = e1-e2\n",
    "    \n",
    "    # Mean of the loss differentials\n",
    "    mean_d = np.mean(d)\n",
    "    \n",
    "    # Standard deviation of the loss differentials\n",
    "    std_d = np.std(d, ddof=1)\n",
    "    \n",
    "    # Calculate the test statistic\n",
    "    test_stat = (mean_d / std_d) * np.sqrt(len(d))\n",
    "    \n",
    "    # Calculate the p-value using a two-tailed test\n",
    "    p_value = 2 * (1 - norm.cdf(abs(test_stat)))\n",
    "    \n",
    "    return test_stat, p_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "2930b572",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((-53.351136764194656, 0.0),\n",
       " (-50.501331858243375, 0.0),\n",
       " (-14.199332350949444, 0.0))"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "diebold_mariano_test(testPredict, testPredict2, teY, 0), diebold_mariano_test(testPredict, testPredict2, teY, 1), diebold_mariano_test(testPredict, testPredict2, teY, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "87d1c902",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.savetxt('Transformer_prop', testPredict)\n",
    "np.savetxt('Transformer_woshuffling', testPredict2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f5d0c52",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20ed8478",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
