{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2bbac3cb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "from time import time\n",
    "import json\n",
    "import logging\n",
    "\n",
    "import tensorflow as tf\n",
    "import keras\n",
    "from keras import layers\n",
    "from keras.models import Model\n",
    "from keras.models import load_model\n",
    "from keras.models import Sequential\n",
    "from keras.callbacks import EarlyStopping, TensorBoard, ModelCheckpoint\n",
    "from keras.callbacks import Callback\n",
    "\n",
    "from sklearn.metrics import r2_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "92903a54",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "import pandas as pd\n",
    "import codecs\n",
    "import numpy as np\n",
    "import math\n",
    "import csv\n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.metrics import recall_score, precision_score # New\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn import preprocessing\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow.keras.preprocessing\n",
    "#from tensorflow.keras.callbacks import ModelCheckpoint, CSVLogger, EarlyStopping, LearningRateScheduler, ReduceLROnPlateau\n",
    "from tensorflow.keras.models import Sequential, Model\n",
    "from tensorflow.keras.layers import Dense, Input, Flatten, Add, Multiply, Subtract\n",
    "from tensorflow.keras import backend as K\n",
    "from tensorflow.keras.layers import Activation, BatchNormalization\n",
    "# regularizers\n",
    "from tensorflow.keras.layers import Conv1D, Conv2D\n",
    "from tensorflow.keras.layers import MaxPooling1D\n",
    "from tensorflow.keras.layers import concatenate\n",
    "from tensorflow.keras.layers import LSTM, Bidirectional\n",
    "from tensorflow.keras.utils import plot_model\n",
    "from tensorflow.keras.layers import Dropout, SpatialDropout1D\n",
    "from scipy import signal\n",
    "import openpyxl\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "from matplotlib import pylab as plt\n",
    "import matplotlib.dates as mdates\n",
    "import seaborn as sns\n",
    "import sklearn\n",
    "from sklearn.model_selection import train_test_split\n",
    "from numpy.linalg import svd\n",
    "import gc\n",
    "from keijzer import *\n",
    "from tensorflow import keras\n",
    "from keras.models import Model\n",
    "from keras.layers import *\n",
    "from tensorflow.keras.optimizers import Adam,SGD\n",
    "from keras.layers import Dense, Input, Flatten, Add, concatenate, Dropout, Activation, Multiply, Embedding, Layer, Reshape\n",
    "from keras.layers import LSTM, Bidirectional, GlobalMaxPooling1D, GlobalAveragePooling1D  \n",
    "from keras.layers import Conv1D, AveragePooling1D, MaxPooling1D\n",
    "#from keras.ops import convert_to_tensor, convert_to_numpy\n",
    "#from keras.utils import plot_model\n",
    "from keras import activations\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from keras.callbacks import ModelCheckpoint, CSVLogger, EarlyStopping, LearningRateScheduler, ReduceLROnPlateau\n",
    "import math\n",
    "\n",
    "class LossHistory(tensorflow.keras.callbacks.Callback):  # history = LossHistory()\n",
    "    def init(self):  # history.init()\n",
    "        self.losses = []\n",
    "        # self.accs = []\n",
    "        self.val_losses = []\n",
    "        # self.val_accs = []\n",
    "        self.rmses = []\n",
    "        self.mses = []\n",
    "        self.maes = []\n",
    "        self.mapes = []\n",
    "        self.val_rmses = []\n",
    "        self.val_mses = []\n",
    "        self.val_maes = []\n",
    "        self.val_mapes = []\n",
    "\n",
    "    def on_epoch_end(self, batch, logs={}):\n",
    "        self.losses.append(logs.get('loss'))\n",
    "        # self.accs.append(logs.get('acc'))\n",
    "        self.val_losses.append(logs.get('val_loss'))\n",
    "        # self.val_accs.append(logs.get('val_accuracy\n",
    "        self.rmses.append(logs.get('root_mean_squared_error'))\n",
    "        self.mses.append(logs.get('mean_squared_error'))\n",
    "        self.maes.append(logs.get('mean_absolute_error'))\n",
    "        self.mapes.append(logs.get('mean_absolute_percentage_error'))\n",
    "        self.val_rmses.append(logs.get('val_root_mean_squared_error'))\n",
    "        self.val_mses.append(logs.get('val_mean_squared_error'))\n",
    "        self.val_maes.append(logs.get('val_mean_absolute_error'))\n",
    "        self.val_mapes.append(logs.get('val_mean_absolute_percentage_error'))\n",
    "\n",
    "\n",
    "\n",
    "def root_squared_mean_error(y_true, y_pred):\n",
    "    return K.mean((K.abs(y_pred - y_true))*K.square(y_true-K.mean(y_true)))*100\n",
    "\n",
    "def mse_mae(y_true, y_pred):\n",
    "    return K.mean(K.square(y_pred - y_true))+K.mean(K.abs(y_pred - y_true))\n",
    "\n",
    "from keras.layers.advanced_activations import PReLU\n",
    "\n",
    "def mean_absolute_percentage_error(y_true, y_pred):\n",
    "    y_true, y_pred = np.array(y_true), np.array(y_pred)\n",
    "    return np.mean(np.abs((y_true - y_pred) / y_true)) * 100\n",
    "\n",
    "def root_mean_squared_error(y_true, y_pred):\n",
    "        return K.sqrt(K.mean(K.square(y_pred - y_true))) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "414b8835",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]\n"
     ]
    }
   ],
   "source": [
    "import scipy as sc\n",
    "import os\n",
    "\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = '0' # 여러개 사용시 '0,1,2' 식으로 하나의 문자열에 입력\n",
    "gpus = tf.config.experimental.list_physical_devices('GPU') # 호스트 러나임에 표시되는 GPU 장치 목록 반환\n",
    "\n",
    "if gpus: # 반환된 GPU 장치 목록이 있다면\n",
    "    try: # 해당 장치에 대한 메모리 증가 활성화 여부 설정\n",
    "        tf.config.experimental.set_memory_growth(gpus[0], True)\n",
    "    except RuntimeError as e: # try문 실패시에 에러문구 출력\n",
    "        print(e)\n",
    "\n",
    "print(tf.config.list_physical_devices('GPU'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c09c4735",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Year</th>\n",
       "      <th>Wind Change</th>\n",
       "      <th>Wind Output</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2020</td>\n",
       "      <td>0.620197</td>\n",
       "      <td>0.644724</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2020</td>\n",
       "      <td>0.544580</td>\n",
       "      <td>0.658617</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2020</td>\n",
       "      <td>0.570751</td>\n",
       "      <td>0.683924</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2020</td>\n",
       "      <td>0.599594</td>\n",
       "      <td>0.721813</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2020</td>\n",
       "      <td>0.495246</td>\n",
       "      <td>0.714187</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35058</th>\n",
       "      <td>2023</td>\n",
       "      <td>0.774643</td>\n",
       "      <td>0.484984</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35059</th>\n",
       "      <td>2023</td>\n",
       "      <td>0.735512</td>\n",
       "      <td>0.582157</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35060</th>\n",
       "      <td>2023</td>\n",
       "      <td>0.601593</td>\n",
       "      <td>0.620917</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35061</th>\n",
       "      <td>2023</td>\n",
       "      <td>0.536583</td>\n",
       "      <td>0.631322</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35062</th>\n",
       "      <td>2023</td>\n",
       "      <td>0.454969</td>\n",
       "      <td>0.606127</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>35063 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Year  Wind Change  Wind Output\n",
       "0      2020     0.620197     0.644724\n",
       "1      2020     0.544580     0.658617\n",
       "2      2020     0.570751     0.683924\n",
       "3      2020     0.599594     0.721813\n",
       "4      2020     0.495246     0.714187\n",
       "...     ...          ...          ...\n",
       "35058  2023     0.774643     0.484984\n",
       "35059  2023     0.735512     0.582157\n",
       "35060  2023     0.601593     0.620917\n",
       "35061  2023     0.536583     0.631322\n",
       "35062  2023     0.454969     0.606127\n",
       "\n",
       "[35063 rows x 3 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_path = 'C:/Users/smartgrid_AI/Desktop/windpower_ramprate/ercot_2020.csv'\n",
    "data_source1 = pd.read_csv(data_path)\n",
    "dat_source1 = pd.DataFrame(data_source1)\n",
    "#dat_source1 = dat_source1.iloc[:-3,:]\n",
    "\n",
    "data_path = 'C:/Users/smartgrid_AI/Desktop/windpower_ramprate/ercot_2021.csv'\n",
    "data_source2 = pd.read_csv(data_path)\n",
    "dat_source2 = pd.DataFrame(data_source2)\n",
    "dat_source2 = dat_source2.iloc[:8761,:9]\n",
    "\n",
    "data_path = 'C:/Users/smartgrid_AI/Desktop/windpower_ramprate/ercot_2022.csv'\n",
    "data_source3 = pd.read_csv(data_path)\n",
    "dat_source3 = pd.DataFrame(data_source3)\n",
    "dat_source3 = dat_source3.iloc[:8760,:9]\n",
    "\n",
    "data_path = 'C:/Users/smartgrid_AI/Desktop/windpower_ramprate/ercot_2023.csv'\n",
    "data_source4 = pd.read_csv(data_path)\n",
    "dat_source4 = pd.DataFrame(data_source4)\n",
    "dat_source4 = dat_source4.iloc[:8760,:9]\n",
    "\n",
    "dat_arr1 = np.array(dat_source1)\n",
    "dat_arr2 = np.array(dat_source2)\n",
    "dat_arr3 = np.array(dat_source3)\n",
    "dat_arr4 = np.array(dat_source4)\n",
    "\n",
    "dat_arr = np.concatenate([dat_arr1, dat_arr2, dat_arr3, dat_arr4],axis=0)\n",
    "dat_arr.shape # 8784, 8761, 8760, 8760\n",
    "\n",
    "dat_source = pd.DataFrame(dat_arr, columns=['Time-Date stamp','Date','ERCOT Load','Total Wind Output','Total Wind Installed','Wind Output, % of Load','Wind Output, % of Installed','1-hr MW change','1-hr % change'])\n",
    "dat = pd.DataFrame()\n",
    "dat['MW % change'] = np.array(dat_source.iloc[1:,3], dtype=float)-np.array(dat_source.iloc[0:-1,3], dtype=float)\n",
    "dat['MW % change'] = np.divide(np.array(dat['MW % change']),np.array(dat_source.iloc[1:,4]))*100\n",
    "dat['Total Wind Output'] = np.divide(np.array(dat_source.iloc[1:,3]), np.array(dat_source.iloc[1:,4]))\n",
    "\n",
    "ramp_ratio = 20\n",
    "load_ratio = 10\n",
    "year_arr = np.concatenate([np.ones(8784)*2020, np.ones(8760)*2021, np.ones(8760)*2022, np.ones(8760)*2023])\n",
    "year_df = pd.DataFrame(year_arr, columns=['Year'], dtype=int)\n",
    "wind_df = pd.concat([year_df, dat], axis=1)\n",
    "wind_df = wind_df.reset_index(drop=True)\n",
    "\n",
    "std_scaler = sklearn.preprocessing.MinMaxScaler()\n",
    "std_scaler_load = sklearn.preprocessing.MinMaxScaler()\n",
    "std_scaler_ramp = sklearn.preprocessing.MinMaxScaler()\n",
    "\n",
    "wind_df[['Total Wind Output']] = std_scaler.fit_transform(wind_df[['Total Wind Output']])\n",
    "wind_df[['MW % change']] = std_scaler_ramp.fit_transform(wind_df[['MW % change']])\n",
    "wind_df = wind_df.iloc[:-1,:]\n",
    "ramp_df = pd.DataFrame(wind_df)\n",
    "ramp_df.columns=['Year', 'Wind Change', 'Wind Output']\n",
    "ramp_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2ea86051",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_dataset(dataset, timesteps, output_timesteps, leadtime):\n",
    "    dataX, dataY = [], []\n",
    "    for i in range(len(dataset) - timesteps -output_timesteps - leadtime - 1):\n",
    "        a = dataset[i:(i + timesteps), :]\n",
    "        dataX.append(a)\n",
    "        dataY.append(dataset[(i + timesteps + leadtime):(i+timesteps+output_timesteps+leadtime), :])\n",
    "    return np.array(dataX), np.array(dataY)\n",
    "\n",
    "def svdadd(X, start, end, b_size):\n",
    "    dec_x = X[start:end, :, :]\n",
    "    U, S, Vh = svd(dec_x.reshape(b_size, -1), full_matrices=True)\n",
    "\n",
    "    high_sig = np.matmul(np.matmul(U[:,:high_ind], np.diag(S[0:high_ind])), Vh[:high_ind,:])\n",
    "    low_sig = X[:dec_num, :, :].reshape(b_size,-1)-high_sig\n",
    "\n",
    "    rec_x = np.zeros((b_size, b_size, high_ind))\n",
    "    \n",
    "    for i in range(high_ind):\n",
    "        rec_x[:,:,i] = np.matmul((U[:,i]*S[i]).reshape(-1,1), Vh[i,:].reshape(1,-1))    \n",
    "    return rec_x, low_sig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c665bd2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "norm_df = np.array(wind_df.iloc[:,2]).reshape(-1,1)\n",
    "timesteps = 24*7\n",
    "output_timesteps = 24\n",
    "leadtime = 6\n",
    "num_features = 1\n",
    "X, Y = create_dataset(norm_df, timesteps, output_timesteps, leadtime)\n",
    "b_size = timesteps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e59f7f90",
   "metadata": {},
   "outputs": [],
   "source": [
    "dec_num = timesteps\n",
    "high_ind = 35\n",
    "\n",
    "addX = np.zeros((X.shape[0], dec_num, high_ind+1))\n",
    "\n",
    "for k in range(X.shape[0]//dec_num):\n",
    "    rec_x, low_sig = svdadd(X, k*dec_num, (k+1)*dec_num, b_size)\n",
    "    addX[k*dec_num:k*dec_num+dec_num,:, :-1] = rec_x\n",
    "    addX[k*dec_num:k*dec_num+dec_num,:, -1] = low_sig\n",
    "    \n",
    "rec_x, low_sig = svdadd(X, X.shape[0]-dec_num, X.shape[0], b_size)\n",
    "addX[X.shape[0]-dec_num:X.shape[0], :, :-1] = rec_x\n",
    "addX[X.shape[0]-dec_num:X.shape[0],:, -1] = low_sig\n",
    "\n",
    "addX_det = addX[:, :, :-1]\n",
    "addX_det = np.sum(addX_det, axis=2)\n",
    "X = np.concatenate([X, addX], axis=2)\n",
    "num_features = X.shape[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cad77e6c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((31377, 168, 37), (31377, 24), (3487, 168, 37), (3487, 24))"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trvaX, teX, trvaY, teY = train_test_split(X, Y, test_size=0.1, shuffle=False)\n",
    "\n",
    "idx = np.arange(trvaX.shape[0])\n",
    "np.random.shuffle(idx)\n",
    "strvaX = trvaX[idx]\n",
    "strvaY = trvaY[idx]\n",
    "strvaY = strvaY.reshape(-1, output_timesteps)\n",
    "\n",
    "trvaY = trvaY.reshape(-1, output_timesteps)\n",
    "teY = teY.reshape(-1, output_timesteps)\n",
    "\n",
    "strX, svaX, strY, svaY = train_test_split(strvaX, strvaY, test_size=0.3, shuffle=False)\n",
    "trX, vaX, trY, vaY = train_test_split(trvaX, trvaY, test_size=0.3, shuffle=False)\n",
    "\n",
    "trvaX.shape, trvaY.shape, teX.shape, teY.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d5b33fe9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def MAEMS(y_true, y_pred):\n",
    "    return K.mean((K.abs(y_pred - y_true))*K.square(y_true))*100\n",
    "\n",
    "def MAE(y_true, y_pred):\n",
    "    return K.mean((K.abs(y_pred - y_true)))\n",
    "\n",
    "def MSE(y_true, y_pred):\n",
    "    return K.mean((K.square(y_pred - y_true)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ee2a5fb",
   "metadata": {},
   "source": [
    "## Transformer Model - Without SVD With Shuffling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5a68803d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "class RevIN(tf.keras.layers.Layer):\n",
    "    def __init__(self, num_features, eps=1e-5, affine=True, subtract_last=False):\n",
    "        super(RevIN, self).__init__()\n",
    "        self.num_features = num_features\n",
    "        self.eps = eps\n",
    "        self.affine = affine\n",
    "        self.subtract_last = subtract_last\n",
    "\n",
    "        if self.affine:\n",
    "            self.affine_weight = self.add_weight(shape=(num_features,),\n",
    "                                                 initializer=\"ones\", trainable=True)\n",
    "            self.affine_bias = self.add_weight(shape=(num_features,),\n",
    "                                               initializer=\"zeros\", trainable=True)\n",
    "\n",
    "    def call(self, x, mode):\n",
    "        if mode == 'norm':\n",
    "            x = self._normalize(x)\n",
    "        elif mode == 'denorm':\n",
    "            x = self._denormalize(x)\n",
    "        else:\n",
    "            raise NotImplementedError\n",
    "        return x\n",
    "\n",
    "    def _get_statistics(self, x):\n",
    "        if self.subtract_last:\n",
    "            self.last = tf.expand_dims(x[:, -1, :], axis=1)\n",
    "        else:\n",
    "            self.mean = tf.reduce_mean(x, axis=[1, 2], keepdims=True)\n",
    "        self.stdev = tf.sqrt(tf.math.reduce_variance(x, axis=[1, 2], keepdims=True) + self.eps)\n",
    "\n",
    "    def _normalize(self, x):\n",
    "        self._get_statistics(x)\n",
    "        if self.subtract_last:\n",
    "            x = x - self.last\n",
    "        else:\n",
    "            x = x - self.mean\n",
    "        x = x / self.stdev\n",
    "        if self.affine:\n",
    "            x = x * self.affine_weight + self.affine_bias\n",
    "        return x\n",
    "\n",
    "    def _denormalize(self, x):\n",
    "        if self.affine:\n",
    "            x = (x - self.affine_bias) / (self.affine_weight + self.eps * self.eps)\n",
    "        x = x * self.stdev\n",
    "        if self.subtract_last:\n",
    "            x = x + self.last\n",
    "        else:\n",
    "            x = x + self.mean\n",
    "        return x\n",
    "\n",
    "\n",
    "class Model(tf.keras.Model):\n",
    "    def __init__(self, seq_len, pred_len, numfeatures, d_model, rnn_type, dec_way, seg_len, dropout, channel_id, revin):\n",
    "        super(Model, self).__init__()\n",
    "\n",
    "        self.seq_len = seq_len\n",
    "        self.pred_len = pred_len\n",
    "        self.numfeatures = numfeatures\n",
    "        self.d_model = d_model\n",
    "        self.rnn_type = rnn_type\n",
    "        self.dec_way = dec_way\n",
    "        self.seg_len = seg_len\n",
    "        self.dropout = dropout\n",
    "        self.channel_id = channel_id\n",
    "        self.revin = revin\n",
    "\n",
    "        self.seg_num_x = seq_len // seg_len\n",
    "\n",
    "        self.value_embedding = tf.keras.Sequential([\n",
    "            tf.keras.layers.Dense(d_model, activation='relu')\n",
    "        ])\n",
    "\n",
    "        if rnn_type == 'rnn':\n",
    "            self.rnn = tf.keras.layers.SimpleRNN(d_model, return_sequences=False, return_state=True)\n",
    "        elif rnn_type == 'gru':\n",
    "            self.rnn = tf.keras.layers.GRU(d_model, return_sequences=False, return_state=True)\n",
    "        elif rnn_type == 'lstm':\n",
    "            self.rnn = tf.keras.layers.LSTM(d_model, return_sequences=False, return_state=True)\n",
    "\n",
    "        self.predict = tf.keras.Sequential([\n",
    "            tf.keras.layers.Dropout(dropout),\n",
    "            tf.keras.layers.Dense(seg_len)\n",
    "        ])\n",
    "\n",
    "        if revin:\n",
    "            self.revin_layer = RevIN(numfeatures, affine=False, subtract_last=False)\n",
    "\n",
    "    def call(self, x):\n",
    "        batch_size = tf.shape(x)[0]\n",
    "\n",
    "        if self.revin:\n",
    "            x = self.revin_layer(x, mode='norm')\n",
    "            x = tf.transpose(x, perm=[0, 2, 1])\n",
    "        else:\n",
    "            seq_last = x[:, -1:, :]\n",
    "            x = tf.transpose(x - seq_last, perm=[0, 2, 1])\n",
    "\n",
    "        # Ensure the correct reshaping\n",
    "        x = tf.reshape(x, (-1, self.seg_num_x, self.seg_len))\n",
    "        x = self.value_embedding(x)  # Shape: (batch_size * seg_num_x, seg_len, d_model)\n",
    "\n",
    "        if self.rnn_type == 'lstm':\n",
    "            _, hn, cn = self.rnn(x)\n",
    "        else:\n",
    "            _, hn = self.rnn(x)\n",
    "\n",
    "        if self.dec_way == 'rmf':\n",
    "            y = []\n",
    "            for _ in range(self.pred_len // self.seg_len):\n",
    "                yy = self.predict(hn)\n",
    "                y.append(yy)\n",
    "                yy = self.value_embedding(tf.expand_dims(yy, axis=1))  # Correct input to the RNN\n",
    "                if self.rnn_type == 'lstm':\n",
    "                    _, hn, cn = self.rnn(yy, initial_state=[hn, cn])\n",
    "                else:\n",
    "                    _, hn = self.rnn(yy, initial_state=hn)\n",
    "            y = tf.reshape(tf.stack(y, axis=1), (batch_size, self.numfeatures, self.pred_len))\n",
    "\n",
    "        elif self.dec_way == 'pmf':\n",
    "            y = []\n",
    "            for _ in range(self.pred_len // self.seg_len):\n",
    "                yy = self.predict(hn)\n",
    "                y.append(yy)\n",
    "                yy = self.value_embedding(tf.expand_dims(yy, axis=1))  # Correct input to the RNN\n",
    "                if self.rnn_type == 'lstm':\n",
    "                    _, hn, cn = self.rnn(yy, initial_state=[hn, cn])\n",
    "                else:\n",
    "                    _, hn = self.rnn(yy, initial_state=hn)\n",
    "            y = tf.concat(y, axis=1)\n",
    "            y = tf.reshape(y, (batch_size, self.numfeatures, self.pred_len))\n",
    "\n",
    "        else:\n",
    "            raise NotImplementedError(\"Only 'rmf' and 'pmf' decoding are implemented in this version.\")\n",
    "\n",
    "        if self.revin:\n",
    "            y = self.revin_layer(tf.transpose(y, perm=[0, 2, 1]), mode='denorm')\n",
    "        else:\n",
    "            y = tf.transpose(y, perm=[0, 2, 1]) + seq_last\n",
    "\n",
    "        y = tf.reduce_mean(y, axis=-1)\n",
    "        return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f8c99545",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_features = trvaX.shape[2]\n",
    "output_timesteps = trvaY.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c1958b7d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "sequential (Sequential)      (6216, None, 256)         1792      \n",
      "_________________________________________________________________\n",
      "gru (GRU)                    multiple                  394752    \n",
      "_________________________________________________________________\n",
      "rev_in (RevIN)               multiple                  0         \n",
      "=================================================================\n",
      "Total params: 396,544\n",
      "Trainable params: 396,544\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "class Config:\n",
    "    seq_len = 168\n",
    "    pred_len = 24\n",
    "    numfeatures = num_features\n",
    "    d_model = 256\n",
    "    rnn_type = 'gru'  # 'rnn', 'gru', 'lstm'\n",
    "    dec_way = 'pmf'  # 'rmf'\n",
    "    seg_len = 6\n",
    "    dropout = 0.1\n",
    "    channel_id = False\n",
    "    revin = True\n",
    "\n",
    "configs = Config()\n",
    "\n",
    "input_shape = (168, num_features)\n",
    "batch_size = 168\n",
    "\n",
    "with tf.device('/gpu:0'):\n",
    "    model = Model(\n",
    "        seq_len=configs.seq_len,\n",
    "        pred_len=configs.pred_len,\n",
    "        numfeatures=configs.numfeatures,\n",
    "        d_model=configs.d_model,\n",
    "        rnn_type=configs.rnn_type,\n",
    "        dec_way=configs.dec_way,\n",
    "        seg_len=configs.seg_len,\n",
    "        dropout=configs.dropout,\n",
    "        channel_id=configs.channel_id,\n",
    "        revin=configs.revin)\n",
    "\n",
    "    example_input = tf.random.normal((batch_size, *input_shape))\n",
    "    output = model(example_input)\n",
    "    model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1467e71f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "851"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3266a816",
   "metadata": {},
   "outputs": [],
   "source": [
    "    model.compile(loss=MAEMS, optimizer='adam', metrics=[MSE, MAE, MAEMS])\n",
    "    early_stopping =EarlyStopping(monitor='val_loss', patience=10)\n",
    "    batch_size = 100\n",
    "    epochs = 1000\n",
    "    history = LossHistory()\n",
    "    history.init()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "56203233",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "131/131 [==============================] - 27s 160ms/step - loss: 4.4777 - MSE: 0.1021 - MAE: 0.2598 - MAEMS: 4.4766 - val_loss: 3.6697 - val_MSE: 0.0928 - val_MAE: 0.2482 - val_MAEMS: 3.6852\n",
      "Epoch 2/1000\n",
      "131/131 [==============================] - 20s 149ms/step - loss: 3.7233 - MSE: 0.0934 - MAE: 0.2491 - MAEMS: 3.7237 - val_loss: 3.6494 - val_MSE: 0.0939 - val_MAE: 0.2498 - val_MAEMS: 3.6646\n",
      "Epoch 3/1000\n",
      "131/131 [==============================] - 19s 148ms/step - loss: 3.6963 - MSE: 0.0930 - MAE: 0.2487 - MAEMS: 3.6967 - val_loss: 3.6139 - val_MSE: 0.0901 - val_MAE: 0.2448 - val_MAEMS: 3.6295\n",
      "Epoch 4/1000\n",
      "131/131 [==============================] - 19s 149ms/step - loss: 3.6573 - MSE: 0.0928 - MAE: 0.2486 - MAEMS: 3.6575 - val_loss: 3.5724 - val_MSE: 0.0842 - val_MAE: 0.2374 - val_MAEMS: 3.5878\n",
      "Epoch 5/1000\n",
      "131/131 [==============================] - 20s 150ms/step - loss: 3.6085 - MSE: 0.0930 - MAE: 0.2491 - MAEMS: 3.6087 - val_loss: 3.5804 - val_MSE: 0.1034 - val_MAE: 0.2629 - val_MAEMS: 3.5946\n",
      "Epoch 6/1000\n",
      "131/131 [==============================] - 19s 149ms/step - loss: 3.5796 - MSE: 0.0936 - MAE: 0.2500 - MAEMS: 3.5798 - val_loss: 3.5262 - val_MSE: 0.0866 - val_MAE: 0.2410 - val_MAEMS: 3.5405\n",
      "Epoch 7/1000\n",
      "131/131 [==============================] - 16s 120ms/step - loss: 3.5707 - MSE: 0.0934 - MAE: 0.2497 - MAEMS: 3.5709 - val_loss: 3.5142 - val_MSE: 0.0967 - val_MAE: 0.2542 - val_MAEMS: 3.5279\n",
      "Epoch 8/1000\n",
      "131/131 [==============================] - 13s 98ms/step - loss: 3.5540 - MSE: 0.0937 - MAE: 0.2501 - MAEMS: 3.5541 - val_loss: 3.5000 - val_MSE: 0.0953 - val_MAE: 0.2524 - val_MAEMS: 3.5133\n",
      "Epoch 9/1000\n",
      "131/131 [==============================] - 13s 98ms/step - loss: 3.5445 - MSE: 0.0935 - MAE: 0.2498 - MAEMS: 3.5447 - val_loss: 3.4864 - val_MSE: 0.0942 - val_MAE: 0.2509 - val_MAEMS: 3.4993\n",
      "Epoch 10/1000\n",
      "131/131 [==============================] - 13s 99ms/step - loss: 3.5342 - MSE: 0.0931 - MAE: 0.2493 - MAEMS: 3.5344 - val_loss: 3.4680 - val_MSE: 0.0916 - val_MAE: 0.2475 - val_MAEMS: 3.4806\n",
      "Epoch 11/1000\n",
      "131/131 [==============================] - 13s 99ms/step - loss: 3.5191 - MSE: 0.0925 - MAE: 0.2483 - MAEMS: 3.5192 - val_loss: 3.4544 - val_MSE: 0.0921 - val_MAE: 0.2481 - val_MAEMS: 3.4660\n",
      "Epoch 12/1000\n",
      "131/131 [==============================] - 13s 99ms/step - loss: 3.5044 - MSE: 0.0919 - MAE: 0.2475 - MAEMS: 3.5045 - val_loss: 3.4401 - val_MSE: 0.0902 - val_MAE: 0.2455 - val_MAEMS: 3.4519\n",
      "Epoch 13/1000\n",
      "131/131 [==============================] - 13s 100ms/step - loss: 3.4783 - MSE: 0.0913 - MAE: 0.2466 - MAEMS: 3.4785 - val_loss: 3.4223 - val_MSE: 0.0870 - val_MAE: 0.2411 - val_MAEMS: 3.4357\n",
      "Epoch 14/1000\n",
      "131/131 [==============================] - 13s 99ms/step - loss: 3.4647 - MSE: 0.0906 - MAE: 0.2456 - MAEMS: 3.4648 - val_loss: 3.4080 - val_MSE: 0.0883 - val_MAE: 0.2428 - val_MAEMS: 3.4209\n",
      "Epoch 15/1000\n",
      "131/131 [==============================] - 13s 99ms/step - loss: 3.4445 - MSE: 0.0902 - MAE: 0.2449 - MAEMS: 3.4447 - val_loss: 3.3946 - val_MSE: 0.0882 - val_MAE: 0.2426 - val_MAEMS: 3.4075\n",
      "Epoch 16/1000\n",
      "131/131 [==============================] - 13s 98ms/step - loss: 3.4324 - MSE: 0.0897 - MAE: 0.2440 - MAEMS: 3.4326 - val_loss: 3.3887 - val_MSE: 0.0841 - val_MAE: 0.2368 - val_MAEMS: 3.4010\n",
      "Epoch 17/1000\n",
      "131/131 [==============================] - 13s 98ms/step - loss: 3.4172 - MSE: 0.0889 - MAE: 0.2430 - MAEMS: 3.4173 - val_loss: 3.3712 - val_MSE: 0.0863 - val_MAE: 0.2398 - val_MAEMS: 3.3814\n",
      "Epoch 18/1000\n",
      "131/131 [==============================] - 13s 99ms/step - loss: 3.4033 - MSE: 0.0886 - MAE: 0.2425 - MAEMS: 3.4034 - val_loss: 3.3558 - val_MSE: 0.0869 - val_MAE: 0.2406 - val_MAEMS: 3.3678\n",
      "Epoch 19/1000\n",
      "131/131 [==============================] - 13s 99ms/step - loss: 3.4019 - MSE: 0.0881 - MAE: 0.2417 - MAEMS: 3.4019 - val_loss: 3.3544 - val_MSE: 0.0877 - val_MAE: 0.2417 - val_MAEMS: 3.3657\n",
      "Epoch 20/1000\n",
      "131/131 [==============================] - 13s 98ms/step - loss: 3.3738 - MSE: 0.0876 - MAE: 0.2409 - MAEMS: 3.3739 - val_loss: 3.3590 - val_MSE: 0.0904 - val_MAE: 0.2452 - val_MAEMS: 3.3684\n",
      "Epoch 21/1000\n",
      "131/131 [==============================] - 13s 99ms/step - loss: 3.3725 - MSE: 0.0874 - MAE: 0.2407 - MAEMS: 3.3726 - val_loss: 3.3150 - val_MSE: 0.0859 - val_MAE: 0.2387 - val_MAEMS: 3.3251\n",
      "Epoch 22/1000\n",
      "131/131 [==============================] - 13s 99ms/step - loss: 3.3429 - MSE: 0.0871 - MAE: 0.2401 - MAEMS: 3.3430 - val_loss: 3.3001 - val_MSE: 0.0816 - val_MAE: 0.2327 - val_MAEMS: 3.3092\n",
      "Epoch 23/1000\n",
      "131/131 [==============================] - 13s 99ms/step - loss: 3.3295 - MSE: 0.0865 - MAE: 0.2390 - MAEMS: 3.3297 - val_loss: 3.2922 - val_MSE: 0.0843 - val_MAE: 0.2366 - val_MAEMS: 3.3029\n",
      "Epoch 24/1000\n",
      "131/131 [==============================] - 13s 99ms/step - loss: 3.3255 - MSE: 0.0862 - MAE: 0.2385 - MAEMS: 3.3255 - val_loss: 3.2716 - val_MSE: 0.0821 - val_MAE: 0.2332 - val_MAEMS: 3.2809\n",
      "Epoch 25/1000\n",
      "131/131 [==============================] - 13s 98ms/step - loss: 3.3181 - MSE: 0.0862 - MAE: 0.2385 - MAEMS: 3.3182 - val_loss: 3.2584 - val_MSE: 0.0827 - val_MAE: 0.2339 - val_MAEMS: 3.2682\n",
      "Epoch 26/1000\n",
      "131/131 [==============================] - 13s 99ms/step - loss: 3.2970 - MSE: 0.0856 - MAE: 0.2373 - MAEMS: 3.2970 - val_loss: 3.2612 - val_MSE: 0.0842 - val_MAE: 0.2357 - val_MAEMS: 3.2711\n",
      "Epoch 27/1000\n",
      "131/131 [==============================] - 13s 99ms/step - loss: 3.2808 - MSE: 0.0850 - MAE: 0.2364 - MAEMS: 3.2808 - val_loss: 3.2389 - val_MSE: 0.0855 - val_MAE: 0.2374 - val_MAEMS: 3.2483\n",
      "Epoch 28/1000\n",
      "131/131 [==============================] - 13s 99ms/step - loss: 3.2642 - MSE: 0.0847 - MAE: 0.2359 - MAEMS: 3.2644 - val_loss: 3.2310 - val_MSE: 0.0811 - val_MAE: 0.2311 - val_MAEMS: 3.2405\n",
      "Epoch 29/1000\n",
      "131/131 [==============================] - 13s 99ms/step - loss: 3.2575 - MSE: 0.0848 - MAE: 0.2359 - MAEMS: 3.2577 - val_loss: 3.2931 - val_MSE: 0.0754 - val_MAE: 0.2238 - val_MAEMS: 3.3056\n",
      "Epoch 30/1000\n",
      "131/131 [==============================] - 13s 99ms/step - loss: 3.2561 - MSE: 0.0838 - MAE: 0.2345 - MAEMS: 3.2561 - val_loss: 3.2214 - val_MSE: 0.0786 - val_MAE: 0.2277 - val_MAEMS: 3.2327\n",
      "Epoch 31/1000\n",
      "131/131 [==============================] - 13s 99ms/step - loss: 3.2357 - MSE: 0.0838 - MAE: 0.2344 - MAEMS: 3.2357 - val_loss: 3.1915 - val_MSE: 0.0837 - val_MAE: 0.2346 - val_MAEMS: 3.2011\n",
      "Epoch 32/1000\n",
      "131/131 [==============================] - 13s 99ms/step - loss: 3.2117 - MSE: 0.0833 - MAE: 0.2335 - MAEMS: 3.2117 - val_loss: 3.1793 - val_MSE: 0.0810 - val_MAE: 0.2307 - val_MAEMS: 3.1903\n",
      "Epoch 33/1000\n",
      "131/131 [==============================] - 13s 99ms/step - loss: 3.2133 - MSE: 0.0833 - MAE: 0.2334 - MAEMS: 3.2133 - val_loss: 3.1780 - val_MSE: 0.0802 - val_MAE: 0.2294 - val_MAEMS: 3.1887\n",
      "Epoch 34/1000\n",
      "131/131 [==============================] - 13s 100ms/step - loss: 3.2107 - MSE: 0.0827 - MAE: 0.2325 - MAEMS: 3.2110 - val_loss: 3.1977 - val_MSE: 0.0775 - val_MAE: 0.2255 - val_MAEMS: 3.2093\n",
      "Epoch 35/1000\n",
      "131/131 [==============================] - 13s 100ms/step - loss: 3.2032 - MSE: 0.0823 - MAE: 0.2318 - MAEMS: 3.2033 - val_loss: 3.1713 - val_MSE: 0.0803 - val_MAE: 0.2296 - val_MAEMS: 3.1832\n",
      "Epoch 36/1000\n",
      "131/131 [==============================] - 13s 98ms/step - loss: 3.1646 - MSE: 0.0820 - MAE: 0.2311 - MAEMS: 3.1647 - val_loss: 3.1618 - val_MSE: 0.0785 - val_MAE: 0.2268 - val_MAEMS: 3.1698\n",
      "Epoch 37/1000\n",
      "131/131 [==============================] - 13s 98ms/step - loss: 3.1611 - MSE: 0.0816 - MAE: 0.2305 - MAEMS: 3.1611 - val_loss: 3.1358 - val_MSE: 0.0781 - val_MAE: 0.2259 - val_MAEMS: 3.1470\n",
      "Epoch 38/1000\n",
      "131/131 [==============================] - 13s 100ms/step - loss: 3.1554 - MSE: 0.0810 - MAE: 0.2297 - MAEMS: 3.1553 - val_loss: 3.1108 - val_MSE: 0.0808 - val_MAE: 0.2297 - val_MAEMS: 3.1188\n",
      "Epoch 39/1000\n",
      "131/131 [==============================] - 13s 99ms/step - loss: 3.1334 - MSE: 0.0807 - MAE: 0.2291 - MAEMS: 3.1335 - val_loss: 3.1368 - val_MSE: 0.0799 - val_MAE: 0.2288 - val_MAEMS: 3.1488\n",
      "Epoch 40/1000\n",
      "131/131 [==============================] - 13s 98ms/step - loss: 3.1263 - MSE: 0.0803 - MAE: 0.2284 - MAEMS: 3.1264 - val_loss: 3.1235 - val_MSE: 0.0837 - val_MAE: 0.2338 - val_MAEMS: 3.1344\n",
      "Epoch 41/1000\n",
      "131/131 [==============================] - 13s 99ms/step - loss: 3.1174 - MSE: 0.0806 - MAE: 0.2287 - MAEMS: 3.1175 - val_loss: 3.1349 - val_MSE: 0.0750 - val_MAE: 0.2216 - val_MAEMS: 3.1457\n",
      "Epoch 42/1000\n",
      "131/131 [==============================] - 13s 100ms/step - loss: 3.1132 - MSE: 0.0803 - MAE: 0.2282 - MAEMS: 3.1133 - val_loss: 3.1042 - val_MSE: 0.0780 - val_MAE: 0.2255 - val_MAEMS: 3.1164\n",
      "Epoch 43/1000\n",
      "131/131 [==============================] - 13s 99ms/step - loss: 3.1038 - MSE: 0.0796 - MAE: 0.2272 - MAEMS: 3.1039 - val_loss: 3.1267 - val_MSE: 0.0756 - val_MAE: 0.2223 - val_MAEMS: 3.1378\n",
      "Epoch 44/1000\n",
      "131/131 [==============================] - 13s 98ms/step - loss: 3.1132 - MSE: 0.0803 - MAE: 0.2283 - MAEMS: 3.1131 - val_loss: 3.1248 - val_MSE: 0.0719 - val_MAE: 0.2170 - val_MAEMS: 3.1389\n",
      "Epoch 45/1000\n",
      "131/131 [==============================] - 13s 99ms/step - loss: 3.0962 - MSE: 0.0797 - MAE: 0.2272 - MAEMS: 3.0963 - val_loss: 3.0851 - val_MSE: 0.0770 - val_MAE: 0.2239 - val_MAEMS: 3.0952\n",
      "Epoch 46/1000\n",
      "131/131 [==============================] - 16s 120ms/step - loss: 3.0796 - MSE: 0.0785 - MAE: 0.2254 - MAEMS: 3.0798 - val_loss: 3.1520 - val_MSE: 0.0808 - val_MAE: 0.2296 - val_MAEMS: 3.1602\n",
      "Epoch 47/1000\n",
      "131/131 [==============================] - 18s 141ms/step - loss: 3.0903 - MSE: 0.0793 - MAE: 0.2265 - MAEMS: 3.0904 - val_loss: 3.0655 - val_MSE: 0.0795 - val_MAE: 0.2273 - val_MAEMS: 3.0739\n",
      "Epoch 48/1000\n",
      "131/131 [==============================] - 18s 141ms/step - loss: 3.0799 - MSE: 0.0793 - MAE: 0.2264 - MAEMS: 3.0801 - val_loss: 3.0863 - val_MSE: 0.0800 - val_MAE: 0.2280 - val_MAEMS: 3.0966\n",
      "Epoch 49/1000\n",
      "131/131 [==============================] - 17s 128ms/step - loss: 3.0640 - MSE: 0.0786 - MAE: 0.2253 - MAEMS: 3.0642 - val_loss: 3.1002 - val_MSE: 0.0719 - val_MAE: 0.2167 - val_MAEMS: 3.1127\n",
      "Epoch 50/1000\n",
      "131/131 [==============================] - 31s 236ms/step - loss: 3.0811 - MSE: 0.0784 - MAE: 0.2251 - MAEMS: 3.0811 - val_loss: 3.0697 - val_MSE: 0.0772 - val_MAE: 0.2237 - val_MAEMS: 3.0768\n",
      "Epoch 51/1000\n",
      "131/131 [==============================] - 33s 250ms/step - loss: 3.0329 - MSE: 0.0779 - MAE: 0.2239 - MAEMS: 3.0330 - val_loss: 3.0400 - val_MSE: 0.0720 - val_MAE: 0.2161 - val_MAEMS: 3.0484\n",
      "Epoch 52/1000\n",
      "131/131 [==============================] - 33s 250ms/step - loss: 3.0235 - MSE: 0.0775 - MAE: 0.2233 - MAEMS: 3.0236 - val_loss: 3.0326 - val_MSE: 0.0760 - val_MAE: 0.2219 - val_MAEMS: 3.0412\n",
      "Epoch 53/1000\n",
      "131/131 [==============================] - 33s 249ms/step - loss: 3.0251 - MSE: 0.0775 - MAE: 0.2234 - MAEMS: 3.0253 - val_loss: 3.0772 - val_MSE: 0.0799 - val_MAE: 0.2278 - val_MAEMS: 3.0852\n",
      "Epoch 54/1000\n",
      "131/131 [==============================] - 33s 251ms/step - loss: 3.0482 - MSE: 0.0777 - MAE: 0.2239 - MAEMS: 3.0483 - val_loss: 3.0659 - val_MSE: 0.0687 - val_MAE: 0.2113 - val_MAEMS: 3.0747\n",
      "Epoch 55/1000\n",
      "131/131 [==============================] - 33s 249ms/step - loss: 3.0146 - MSE: 0.0771 - MAE: 0.2227 - MAEMS: 3.0145 - val_loss: 3.0042 - val_MSE: 0.0730 - val_MAE: 0.2172 - val_MAEMS: 3.0113\n",
      "Epoch 56/1000\n",
      "131/131 [==============================] - 33s 250ms/step - loss: 2.9905 - MSE: 0.0764 - MAE: 0.2213 - MAEMS: 2.9905 - val_loss: 3.0041 - val_MSE: 0.0725 - val_MAE: 0.2166 - val_MAEMS: 3.0143\n",
      "Epoch 57/1000\n",
      "131/131 [==============================] - 33s 250ms/step - loss: 3.0094 - MSE: 0.0771 - MAE: 0.2227 - MAEMS: 3.0094 - val_loss: 3.0072 - val_MSE: 0.0715 - val_MAE: 0.2149 - val_MAEMS: 3.0144\n",
      "Epoch 58/1000\n",
      "131/131 [==============================] - 33s 250ms/step - loss: 3.0031 - MSE: 0.0762 - MAE: 0.2211 - MAEMS: 3.0034 - val_loss: 3.0339 - val_MSE: 0.0725 - val_MAE: 0.2168 - val_MAEMS: 3.0440\n",
      "Epoch 59/1000\n",
      "131/131 [==============================] - 33s 250ms/step - loss: 2.9924 - MSE: 0.0759 - MAE: 0.2208 - MAEMS: 2.9923 - val_loss: 2.9736 - val_MSE: 0.0751 - val_MAE: 0.2200 - val_MAEMS: 2.9827\n",
      "Epoch 60/1000\n",
      "131/131 [==============================] - 33s 251ms/step - loss: 2.9782 - MSE: 0.0761 - MAE: 0.2208 - MAEMS: 2.9782 - val_loss: 2.9935 - val_MSE: 0.0710 - val_MAE: 0.2142 - val_MAEMS: 3.0061\n",
      "Epoch 61/1000\n",
      "131/131 [==============================] - 31s 239ms/step - loss: 2.9596 - MSE: 0.0752 - MAE: 0.2193 - MAEMS: 2.9598 - val_loss: 2.9815 - val_MSE: 0.0749 - val_MAE: 0.2194 - val_MAEMS: 2.9908\n",
      "Epoch 62/1000\n",
      "131/131 [==============================] - 33s 238ms/step - loss: 3.0028 - MSE: 0.0762 - MAE: 0.2213 - MAEMS: 3.0029 - val_loss: 3.0137 - val_MSE: 0.0705 - val_MAE: 0.2135 - val_MAEMS: 3.0242\n",
      "Epoch 63/1000\n",
      "131/131 [==============================] - 33s 250ms/step - loss: 2.9686 - MSE: 0.0753 - MAE: 0.2197 - MAEMS: 2.9686 - val_loss: 2.9844 - val_MSE: 0.0698 - val_MAE: 0.2121 - val_MAEMS: 2.9925\n",
      "Epoch 64/1000\n",
      "131/131 [==============================] - 33s 250ms/step - loss: 2.9630 - MSE: 0.0753 - MAE: 0.2195 - MAEMS: 2.9630 - val_loss: 2.9870 - val_MSE: 0.0798 - val_MAE: 0.2267 - val_MAEMS: 2.9947\n",
      "Epoch 65/1000\n",
      "131/131 [==============================] - 33s 250ms/step - loss: 3.0149 - MSE: 0.0756 - MAE: 0.2203 - MAEMS: 3.0150 - val_loss: 2.9972 - val_MSE: 0.0753 - val_MAE: 0.2204 - val_MAEMS: 3.0067\n",
      "Epoch 66/1000\n",
      "131/131 [==============================] - 33s 250ms/step - loss: 2.9810 - MSE: 0.0747 - MAE: 0.2186 - MAEMS: 2.9811 - val_loss: 2.9708 - val_MSE: 0.0751 - val_MAE: 0.2200 - val_MAEMS: 2.9810\n",
      "Epoch 67/1000\n",
      "131/131 [==============================] - 33s 250ms/step - loss: 2.9519 - MSE: 0.0750 - MAE: 0.2190 - MAEMS: 2.9519 - val_loss: 2.9641 - val_MSE: 0.0708 - val_MAE: 0.2134 - val_MAEMS: 2.9716\n",
      "Epoch 68/1000\n",
      "131/131 [==============================] - 33s 251ms/step - loss: 2.9462 - MSE: 0.0746 - MAE: 0.2183 - MAEMS: 2.9462 - val_loss: 2.9420 - val_MSE: 0.0763 - val_MAE: 0.2213 - val_MAEMS: 2.9528\n",
      "Epoch 69/1000\n",
      "131/131 [==============================] - 33s 251ms/step - loss: 2.9425 - MSE: 0.0746 - MAE: 0.2183 - MAEMS: 2.9426 - val_loss: 2.9611 - val_MSE: 0.0708 - val_MAE: 0.2133 - val_MAEMS: 2.9687\n",
      "Epoch 70/1000\n",
      "131/131 [==============================] - 33s 250ms/step - loss: 2.9192 - MSE: 0.0739 - MAE: 0.2170 - MAEMS: 2.9193 - val_loss: 2.9576 - val_MSE: 0.0711 - val_MAE: 0.2138 - val_MAEMS: 2.9689\n",
      "Epoch 71/1000\n",
      "131/131 [==============================] - 33s 250ms/step - loss: 2.8976 - MSE: 0.0736 - MAE: 0.2164 - MAEMS: 2.8976 - val_loss: 2.9065 - val_MSE: 0.0731 - val_MAE: 0.2164 - val_MAEMS: 2.9185\n",
      "Epoch 72/1000\n",
      "131/131 [==============================] - 33s 250ms/step - loss: 2.8818 - MSE: 0.0732 - MAE: 0.2157 - MAEMS: 2.8819 - val_loss: 2.8965 - val_MSE: 0.0736 - val_MAE: 0.2169 - val_MAEMS: 2.9053\n",
      "Epoch 73/1000\n",
      "131/131 [==============================] - 33s 250ms/step - loss: 2.9016 - MSE: 0.0733 - MAE: 0.2161 - MAEMS: 2.9017 - val_loss: 2.9244 - val_MSE: 0.0723 - val_MAE: 0.2153 - val_MAEMS: 2.9321\n",
      "Epoch 74/1000\n",
      "131/131 [==============================] - 33s 250ms/step - loss: 2.8882 - MSE: 0.0732 - MAE: 0.2157 - MAEMS: 2.8882 - val_loss: 2.9200 - val_MSE: 0.0699 - val_MAE: 0.2117 - val_MAEMS: 2.9305\n",
      "Epoch 75/1000\n",
      "131/131 [==============================] - 32s 249ms/step - loss: 2.8917 - MSE: 0.0731 - MAE: 0.2156 - MAEMS: 2.8918 - val_loss: 2.9194 - val_MSE: 0.0734 - val_MAE: 0.2168 - val_MAEMS: 2.9288\n",
      "Epoch 76/1000\n",
      "131/131 [==============================] - 32s 249ms/step - loss: 2.8764 - MSE: 0.0733 - MAE: 0.2156 - MAEMS: 2.8765 - val_loss: 2.9006 - val_MSE: 0.0741 - val_MAE: 0.2176 - val_MAEMS: 2.9096\n",
      "Epoch 77/1000\n",
      "131/131 [==============================] - 32s 249ms/step - loss: 2.9207 - MSE: 0.0736 - MAE: 0.2165 - MAEMS: 2.9207 - val_loss: 2.9002 - val_MSE: 0.0741 - val_MAE: 0.2178 - val_MAEMS: 2.9125\n",
      "Epoch 78/1000\n",
      "131/131 [==============================] - 32s 249ms/step - loss: 2.9197 - MSE: 0.0740 - MAE: 0.2171 - MAEMS: 2.9199 - val_loss: 2.9357 - val_MSE: 0.0743 - val_MAE: 0.2185 - val_MAEMS: 2.9468\n",
      "Epoch 79/1000\n",
      "131/131 [==============================] - 31s 237ms/step - loss: 2.9302 - MSE: 0.0740 - MAE: 0.2172 - MAEMS: 2.9303 - val_loss: 2.9804 - val_MSE: 0.0704 - val_MAE: 0.2128 - val_MAEMS: 2.9898\n",
      "Epoch 80/1000\n",
      "131/131 [==============================] - 32s 249ms/step - loss: 2.9467 - MSE: 0.0740 - MAE: 0.2172 - MAEMS: 2.9469 - val_loss: 2.9861 - val_MSE: 0.0743 - val_MAE: 0.2187 - val_MAEMS: 2.9988\n",
      "Epoch 81/1000\n",
      "131/131 [==============================] - 32s 249ms/step - loss: 2.9338 - MSE: 0.0746 - MAE: 0.2181 - MAEMS: 2.9337 - val_loss: 2.9350 - val_MSE: 0.0727 - val_MAE: 0.2160 - val_MAEMS: 2.9442\n",
      "Epoch 82/1000\n",
      "131/131 [==============================] - 32s 249ms/step - loss: 2.8778 - MSE: 0.0731 - MAE: 0.2154 - MAEMS: 2.8779 - val_loss: 2.8834 - val_MSE: 0.0720 - val_MAE: 0.2146 - val_MAEMS: 2.8929\n",
      "Epoch 83/1000\n",
      "131/131 [==============================] - 32s 249ms/step - loss: 2.8964 - MSE: 0.0733 - MAE: 0.2159 - MAEMS: 2.8965 - val_loss: 2.9082 - val_MSE: 0.0703 - val_MAE: 0.2120 - val_MAEMS: 2.9175\n",
      "Epoch 84/1000\n",
      "131/131 [==============================] - 31s 237ms/step - loss: 2.8728 - MSE: 0.0729 - MAE: 0.2151 - MAEMS: 2.8730 - val_loss: 2.9279 - val_MSE: 0.0756 - val_MAE: 0.2201 - val_MAEMS: 2.9379\n",
      "Epoch 85/1000\n",
      "131/131 [==============================] - 32s 249ms/step - loss: 2.8616 - MSE: 0.0721 - MAE: 0.2138 - MAEMS: 2.8617 - val_loss: 2.9080 - val_MSE: 0.0716 - val_MAE: 0.2140 - val_MAEMS: 2.9150\n",
      "Epoch 86/1000\n",
      "131/131 [==============================] - 32s 249ms/step - loss: 2.8768 - MSE: 0.0725 - MAE: 0.2146 - MAEMS: 2.8769 - val_loss: 2.8978 - val_MSE: 0.0725 - val_MAE: 0.2151 - val_MAEMS: 2.9061\n",
      "Epoch 87/1000\n",
      "131/131 [==============================] - 33s 249ms/step - loss: 2.8709 - MSE: 0.0726 - MAE: 0.2146 - MAEMS: 2.8712 - val_loss: 2.9133 - val_MSE: 0.0697 - val_MAE: 0.2114 - val_MAEMS: 2.9215\n",
      "Epoch 88/1000\n",
      "131/131 [==============================] - 31s 237ms/step - loss: 2.8496 - MSE: 0.0723 - MAE: 0.2139 - MAEMS: 2.8498 - val_loss: 2.8827 - val_MSE: 0.0686 - val_MAE: 0.2092 - val_MAEMS: 2.8920\n",
      "Epoch 89/1000\n",
      "131/131 [==============================] - 32s 237ms/step - loss: 2.8385 - MSE: 0.0719 - MAE: 0.2133 - MAEMS: 2.8386 - val_loss: 2.8583 - val_MSE: 0.0679 - val_MAE: 0.2081 - val_MAEMS: 2.8662\n",
      "Epoch 90/1000\n",
      "131/131 [==============================] - 32s 248ms/step - loss: 2.8352 - MSE: 0.0722 - MAE: 0.2136 - MAEMS: 2.8354 - val_loss: 2.8729 - val_MSE: 0.0701 - val_MAE: 0.2115 - val_MAEMS: 2.8793\n",
      "Epoch 91/1000\n",
      "131/131 [==============================] - 32s 249ms/step - loss: 2.8451 - MSE: 0.0719 - MAE: 0.2133 - MAEMS: 2.8452 - val_loss: 2.8692 - val_MSE: 0.0705 - val_MAE: 0.2122 - val_MAEMS: 2.8777\n",
      "Epoch 92/1000\n",
      "131/131 [==============================] - 33s 249ms/step - loss: 2.8155 - MSE: 0.0713 - MAE: 0.2121 - MAEMS: 2.8158 - val_loss: 2.9219 - val_MSE: 0.0686 - val_MAE: 0.2097 - val_MAEMS: 2.9298\n",
      "Epoch 93/1000\n",
      "131/131 [==============================] - 32s 249ms/step - loss: 2.8877 - MSE: 0.0732 - MAE: 0.2157 - MAEMS: 2.8878 - val_loss: 2.8689 - val_MSE: 0.0721 - val_MAE: 0.2143 - val_MAEMS: 2.8781\n",
      "Epoch 94/1000\n",
      "131/131 [==============================] - 31s 237ms/step - loss: 2.8514 - MSE: 0.0722 - MAE: 0.2138 - MAEMS: 2.8514 - val_loss: 2.8699 - val_MSE: 0.0707 - val_MAE: 0.2125 - val_MAEMS: 2.8838\n",
      "Epoch 95/1000\n",
      "131/131 [==============================] - 32s 249ms/step - loss: 2.8225 - MSE: 0.0713 - MAE: 0.2121 - MAEMS: 2.8226 - val_loss: 2.8389 - val_MSE: 0.0692 - val_MAE: 0.2098 - val_MAEMS: 2.8524\n",
      "Epoch 96/1000\n",
      "131/131 [==============================] - 32s 249ms/step - loss: 2.8420 - MSE: 0.0713 - MAE: 0.2124 - MAEMS: 2.8422 - val_loss: 2.8978 - val_MSE: 0.0721 - val_MAE: 0.2147 - val_MAEMS: 2.9091\n",
      "Epoch 97/1000\n",
      "131/131 [==============================] - 33s 250ms/step - loss: 2.8709 - MSE: 0.0727 - MAE: 0.2146 - MAEMS: 2.8710 - val_loss: 2.8728 - val_MSE: 0.0705 - val_MAE: 0.2121 - val_MAEMS: 2.8818\n",
      "Epoch 98/1000\n",
      "131/131 [==============================] - 33s 250ms/step - loss: 2.8516 - MSE: 0.0720 - MAE: 0.2135 - MAEMS: 2.8517 - val_loss: 2.8678 - val_MSE: 0.0687 - val_MAE: 0.2092 - val_MAEMS: 2.8761\n",
      "Epoch 99/1000\n",
      "131/131 [==============================] - 31s 238ms/step - loss: 2.8486 - MSE: 0.0717 - MAE: 0.2131 - MAEMS: 2.8486 - val_loss: 2.8717 - val_MSE: 0.0698 - val_MAE: 0.2108 - val_MAEMS: 2.8819\n",
      "Epoch 100/1000\n",
      "131/131 [==============================] - 33s 250ms/step - loss: 2.8717 - MSE: 0.0725 - MAE: 0.2145 - MAEMS: 2.8717 - val_loss: 2.9012 - val_MSE: 0.0723 - val_MAE: 0.2148 - val_MAEMS: 2.9098\n",
      "Epoch 101/1000\n",
      "131/131 [==============================] - 33s 250ms/step - loss: 2.8462 - MSE: 0.0720 - MAE: 0.2135 - MAEMS: 2.8462 - val_loss: 2.8554 - val_MSE: 0.0716 - val_MAE: 0.2136 - val_MAEMS: 2.8679\n",
      "Epoch 102/1000\n",
      "131/131 [==============================] - 32s 249ms/step - loss: 2.8320 - MSE: 0.0719 - MAE: 0.2132 - MAEMS: 2.8321 - val_loss: 2.8532 - val_MSE: 0.0713 - val_MAE: 0.2131 - val_MAEMS: 2.8614\n",
      "Epoch 103/1000\n",
      "131/131 [==============================] - 33s 250ms/step - loss: 2.8237 - MSE: 0.0714 - MAE: 0.2125 - MAEMS: 2.8239 - val_loss: 2.9083 - val_MSE: 0.0739 - val_MAE: 0.2176 - val_MAEMS: 2.9207\n",
      "Epoch 104/1000\n",
      "131/131 [==============================] - 32s 249ms/step - loss: 2.8345 - MSE: 0.0711 - MAE: 0.2121 - MAEMS: 2.8345 - val_loss: 2.8594 - val_MSE: 0.0728 - val_MAE: 0.2152 - val_MAEMS: 2.8647\n",
      "Epoch 105/1000\n",
      "131/131 [==============================] - 31s 237ms/step - loss: 2.8363 - MSE: 0.0718 - MAE: 0.2132 - MAEMS: 2.8363 - val_loss: 2.8419 - val_MSE: 0.0714 - val_MAE: 0.2131 - val_MAEMS: 2.8472\n",
      "Wall time: 41min 50s\n"
     ]
    }
   ],
   "source": [
    "    %%time\n",
    "    b_size = 168\n",
    "    hist = model.fit(strX, strY, epochs=epochs, batch_size=b_size, shuffle=False, validation_data=(svaX, svaY), callbacks=[history, early_stopping])  # , checkpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e1845098",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4598"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "8517d01d",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 168\n",
    "num_samples = teX.shape[0]\n",
    "predictions = []\n",
    "\n",
    "for start in range(0, num_samples, batch_size):\n",
    "    end = min(start + batch_size, num_samples)\n",
    "    batch_data = teX[start:end]\n",
    "    batch_predictions = model(batch_data)\n",
    "    predictions.append(batch_predictions)\n",
    "\n",
    "testPredict = np.concatenate(predictions, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "1407b976",
   "metadata": {},
   "outputs": [],
   "source": [
    "def npMAEMS(y_true, y_pred):\n",
    "    return np.mean((abs(y_pred - y_true))*np.square(y_true))*100\n",
    "def npMAEMD(y_true, y_pred):\n",
    "    return np.mean((abs(y_pred - y_true))*np.square(y_true-np.mean(y_true)))*100\n",
    "def npMSE(y_true, y_pred):\n",
    "    return np.mean(np.square(-y_true+y_pred))\n",
    "def npMAE(y_true, y_pred):\n",
    "    return np.mean(abs(-y_true+y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d4638a04",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error Test Score > MSE ==  0.08323841026057144  MAE ==  0.24249344761257993  MAEMS ==  2.5130886863223547\n"
     ]
    }
   ],
   "source": [
    "tePredict = testPredict.reshape(-1)\n",
    "testY = teY.reshape(-1)\n",
    "print('Error Test Score > MSE == ', npMSE(testY, tePredict), ' MAE == ', npMAE(testY, tePredict), ' MAEMS == ', npMAEMS(testY, tePredict))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9cc90fe",
   "metadata": {},
   "source": [
    "## Without Shuffling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "8990fd5e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "sequential_2 (Sequential)    (6216, None, 256)         1792      \n",
      "_________________________________________________________________\n",
      "gru_1 (GRU)                  multiple                  394752    \n",
      "_________________________________________________________________\n",
      "rev_in_1 (RevIN)             multiple                  0         \n",
      "=================================================================\n",
      "Total params: 396,544\n",
      "Trainable params: 396,544\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "class Config:\n",
    "    seq_len = 168\n",
    "    pred_len = 24\n",
    "    numfeatures = num_features\n",
    "    d_model = 256\n",
    "    rnn_type = 'gru'  # 'rnn', 'gru', 'lstm'\n",
    "    dec_way = 'pmf'  # 'rmf' 'pmf'\n",
    "    seg_len = 6\n",
    "    dropout = 0.1\n",
    "    channel_id = False\n",
    "    revin = True\n",
    "\n",
    "configs = Config()\n",
    "\n",
    "input_shape = (168, num_features)\n",
    "batch_size = 168\n",
    "\n",
    "with tf.device('/gpu:0'):\n",
    "    model2 = Model(\n",
    "        seq_len=configs.seq_len,\n",
    "        pred_len=configs.pred_len,\n",
    "        numfeatures=configs.numfeatures,\n",
    "        d_model=configs.d_model,\n",
    "        rnn_type=configs.rnn_type,\n",
    "        dec_way=configs.dec_way,\n",
    "        seg_len=configs.seg_len,\n",
    "        dropout=configs.dropout,\n",
    "        channel_id=configs.channel_id,\n",
    "        revin=configs.revin)\n",
    "\n",
    "    example_input = tf.random.normal((batch_size, *input_shape))\n",
    "    output = model2(example_input)\n",
    "    model2.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "df85eb5e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "783"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "bb0d3f69",
   "metadata": {},
   "outputs": [],
   "source": [
    "    model2.compile(loss=MAEMS, optimizer='adam', metrics=[MSE, MAE, MAEMS])\n",
    "    early_stopping =EarlyStopping(monitor='val_loss', patience=10)\n",
    "    batch_size = 100\n",
    "    epochs = 1000\n",
    "    history2 = LossHistory()\n",
    "    history2.init()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "f7d01832",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "  6/131 [>.............................] - ETA: 10s - loss: 16.0421 - MSE: 0.2111 - MAE: 0.3950 - MAEMS: 16.0421WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0374s vs `on_train_batch_end` time: 0.0474s). Check your callbacks.\n",
      "131/131 [==============================] - 39s 255ms/step - loss: 4.7774 - MSE: 0.1107 - MAE: 0.2700 - MAEMS: 4.7717 - val_loss: 3.2311 - val_MSE: 0.0726 - val_MAE: 0.2215 - val_MAEMS: 3.2147\n",
      "Epoch 2/1000\n",
      "131/131 [==============================] - 32s 249ms/step - loss: 3.9545 - MSE: 0.0980 - MAE: 0.2543 - MAEMS: 3.9507 - val_loss: 3.2036 - val_MSE: 0.0785 - val_MAE: 0.2300 - val_MAEMS: 3.1914\n",
      "Epoch 3/1000\n",
      "131/131 [==============================] - 33s 251ms/step - loss: 3.9432 - MSE: 0.0980 - MAE: 0.2544 - MAEMS: 3.9396 - val_loss: 3.1976 - val_MSE: 0.0799 - val_MAE: 0.2321 - val_MAEMS: 3.1864\n",
      "Epoch 4/1000\n",
      "131/131 [==============================] - 33s 249ms/step - loss: 3.9366 - MSE: 0.0980 - MAE: 0.2544 - MAEMS: 3.9330 - val_loss: 3.1933 - val_MSE: 0.0811 - val_MAE: 0.2338 - val_MAEMS: 3.1828\n",
      "Epoch 5/1000\n",
      "131/131 [==============================] - 32s 249ms/step - loss: 3.9310 - MSE: 0.0982 - MAE: 0.2546 - MAEMS: 3.9274 - val_loss: 3.1897 - val_MSE: 0.0813 - val_MAE: 0.2341 - val_MAEMS: 3.1793\n",
      "Epoch 6/1000\n",
      "131/131 [==============================] - 33s 250ms/step - loss: 3.9258 - MSE: 0.0982 - MAE: 0.2546 - MAEMS: 3.9222 - val_loss: 3.1892 - val_MSE: 0.0803 - val_MAE: 0.2327 - val_MAEMS: 3.1781\n",
      "Epoch 7/1000\n",
      "131/131 [==============================] - 31s 238ms/step - loss: 3.9212 - MSE: 0.0980 - MAE: 0.2544 - MAEMS: 3.9175 - val_loss: 3.1846 - val_MSE: 0.0795 - val_MAE: 0.2315 - val_MAEMS: 3.1729\n",
      "Epoch 8/1000\n",
      "131/131 [==============================] - 33s 250ms/step - loss: 3.9146 - MSE: 0.0978 - MAE: 0.2541 - MAEMS: 3.9109 - val_loss: 3.1816 - val_MSE: 0.0797 - val_MAE: 0.2318 - val_MAEMS: 3.1700\n",
      "Epoch 9/1000\n",
      "131/131 [==============================] - 33s 250ms/step - loss: 3.9101 - MSE: 0.0977 - MAE: 0.2540 - MAEMS: 3.9064 - val_loss: 3.1814 - val_MSE: 0.0782 - val_MAE: 0.2297 - val_MAEMS: 3.1687\n",
      "Epoch 10/1000\n",
      "131/131 [==============================] - 33s 250ms/step - loss: 3.9052 - MSE: 0.0979 - MAE: 0.2543 - MAEMS: 3.9016 - val_loss: 3.1745 - val_MSE: 0.0798 - val_MAE: 0.2320 - val_MAEMS: 3.1630\n",
      "Epoch 11/1000\n",
      "131/131 [==============================] - 33s 249ms/step - loss: 3.8979 - MSE: 0.0977 - MAE: 0.2540 - MAEMS: 3.8942 - val_loss: 3.1815 - val_MSE: 0.0780 - val_MAE: 0.2294 - val_MAEMS: 3.1686\n",
      "Epoch 12/1000\n",
      "131/131 [==============================] - 32s 249ms/step - loss: 3.8911 - MSE: 0.0976 - MAE: 0.2539 - MAEMS: 3.8874 - val_loss: 3.1825 - val_MSE: 0.0772 - val_MAE: 0.2282 - val_MAEMS: 3.1691\n",
      "Epoch 13/1000\n",
      "131/131 [==============================] - 33s 250ms/step - loss: 3.8905 - MSE: 0.0971 - MAE: 0.2532 - MAEMS: 3.8868 - val_loss: 3.1734 - val_MSE: 0.0782 - val_MAE: 0.2298 - val_MAEMS: 3.1609\n",
      "Epoch 14/1000\n",
      "131/131 [==============================] - 31s 238ms/step - loss: 3.8842 - MSE: 0.0974 - MAE: 0.2536 - MAEMS: 3.8806 - val_loss: 3.1659 - val_MSE: 0.0790 - val_MAE: 0.2309 - val_MAEMS: 3.1542\n",
      "Epoch 15/1000\n",
      "131/131 [==============================] - 33s 250ms/step - loss: 3.8745 - MSE: 0.0973 - MAE: 0.2535 - MAEMS: 3.8708 - val_loss: 3.1629 - val_MSE: 0.0788 - val_MAE: 0.2307 - val_MAEMS: 3.1514\n",
      "Epoch 16/1000\n",
      "131/131 [==============================] - 33s 250ms/step - loss: 3.8697 - MSE: 0.0973 - MAE: 0.2534 - MAEMS: 3.8660 - val_loss: 3.1606 - val_MSE: 0.0781 - val_MAE: 0.2296 - val_MAEMS: 3.1488\n",
      "Epoch 17/1000\n",
      "131/131 [==============================] - 33s 250ms/step - loss: 3.8637 - MSE: 0.0971 - MAE: 0.2532 - MAEMS: 3.8600 - val_loss: 3.1561 - val_MSE: 0.0779 - val_MAE: 0.2294 - val_MAEMS: 3.1445\n",
      "Epoch 18/1000\n",
      "131/131 [==============================] - 32s 249ms/step - loss: 3.8566 - MSE: 0.0970 - MAE: 0.2531 - MAEMS: 3.8529 - val_loss: 3.1481 - val_MSE: 0.0767 - val_MAE: 0.2277 - val_MAEMS: 3.1360\n",
      "Epoch 19/1000\n",
      "131/131 [==============================] - 31s 238ms/step - loss: 3.8452 - MSE: 0.0968 - MAE: 0.2528 - MAEMS: 3.8414 - val_loss: 3.1517 - val_MSE: 0.0748 - val_MAE: 0.2250 - val_MAEMS: 3.1386\n",
      "Epoch 20/1000\n",
      "131/131 [==============================] - 33s 238ms/step - loss: 3.8328 - MSE: 0.0966 - MAE: 0.2526 - MAEMS: 3.8289 - val_loss: 3.1582 - val_MSE: 0.0719 - val_MAE: 0.2209 - val_MAEMS: 3.1438\n",
      "Epoch 21/1000\n",
      "131/131 [==============================] - 33s 250ms/step - loss: 3.8264 - MSE: 0.0980 - MAE: 0.2543 - MAEMS: 3.8227 - val_loss: 3.1417 - val_MSE: 0.0738 - val_MAE: 0.2237 - val_MAEMS: 3.1292\n",
      "Epoch 22/1000\n",
      "131/131 [==============================] - 32s 249ms/step - loss: 3.7966 - MSE: 0.0974 - MAE: 0.2535 - MAEMS: 3.7931 - val_loss: 3.1008 - val_MSE: 0.0780 - val_MAE: 0.2302 - val_MAEMS: 3.0940\n",
      "Epoch 23/1000\n",
      "131/131 [==============================] - 32s 249ms/step - loss: 3.7771 - MSE: 0.0975 - MAE: 0.2535 - MAEMS: 3.7736 - val_loss: 3.1119 - val_MSE: 0.0777 - val_MAE: 0.2295 - val_MAEMS: 3.1054\n",
      "Epoch 24/1000\n",
      "131/131 [==============================] - 33s 250ms/step - loss: 3.7814 - MSE: 0.0986 - MAE: 0.2549 - MAEMS: 3.7783 - val_loss: 3.1176 - val_MSE: 0.0861 - val_MAE: 0.2418 - val_MAEMS: 3.1180\n",
      "Epoch 25/1000\n",
      "131/131 [==============================] - 31s 238ms/step - loss: 3.7617 - MSE: 0.0967 - MAE: 0.2528 - MAEMS: 3.7589 - val_loss: 3.1461 - val_MSE: 0.0925 - val_MAE: 0.2514 - val_MAEMS: 3.1519\n",
      "Epoch 26/1000\n",
      "131/131 [==============================] - 32s 237ms/step - loss: 3.7497 - MSE: 0.0972 - MAE: 0.2536 - MAEMS: 3.7471 - val_loss: 3.2095 - val_MSE: 0.0988 - val_MAE: 0.2606 - val_MAEMS: 3.2190\n",
      "Epoch 27/1000\n",
      "131/131 [==============================] - 35s 270ms/step - loss: 3.7368 - MSE: 0.0975 - MAE: 0.2541 - MAEMS: 3.7343 - val_loss: 3.2151 - val_MSE: 0.1006 - val_MAE: 0.2633 - val_MAEMS: 3.2262\n",
      "Epoch 28/1000\n",
      "131/131 [==============================] - 32s 249ms/step - loss: 3.7201 - MSE: 0.0972 - MAE: 0.2538 - MAEMS: 3.7177 - val_loss: 3.2092 - val_MSE: 0.0996 - val_MAE: 0.2619 - val_MAEMS: 3.2206\n",
      "Epoch 29/1000\n",
      "131/131 [==============================] - 33s 250ms/step - loss: 3.7134 - MSE: 0.0970 - MAE: 0.2534 - MAEMS: 3.7110 - val_loss: 3.2179 - val_MSE: 0.1008 - val_MAE: 0.2639 - val_MAEMS: 3.2303\n",
      "Epoch 30/1000\n",
      "131/131 [==============================] - 33s 250ms/step - loss: 3.7032 - MSE: 0.0970 - MAE: 0.2534 - MAEMS: 3.7007 - val_loss: 3.1901 - val_MSE: 0.0985 - val_MAE: 0.2605 - val_MAEMS: 3.2031\n",
      "Epoch 31/1000\n",
      "131/131 [==============================] - 31s 238ms/step - loss: 3.7027 - MSE: 0.0969 - MAE: 0.2532 - MAEMS: 3.7002 - val_loss: 3.2137 - val_MSE: 0.1008 - val_MAE: 0.2639 - val_MAEMS: 3.2277\n",
      "Epoch 32/1000\n",
      "131/131 [==============================] - 32s 237ms/step - loss: 3.6894 - MSE: 0.0968 - MAE: 0.2531 - MAEMS: 3.6870 - val_loss: 3.2113 - val_MSE: 0.1008 - val_MAE: 0.2640 - val_MAEMS: 3.2265\n",
      "Wall time: 17min 24s\n"
     ]
    }
   ],
   "source": [
    "    %%time\n",
    "    hist2 = model2.fit(trX, trY, epochs=epochs, batch_size=b_size, shuffle=False, validation_data=(vaX, vaY), callbacks=[history, early_stopping])  # , checkpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "e07f5abf",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 168\n",
    "num_samples = teX.shape[0]\n",
    "predictions = []\n",
    "\n",
    "for start in range(0, num_samples, batch_size):\n",
    "    end = min(start + batch_size, num_samples)\n",
    "    batch_data = teX[start:end]\n",
    "    batch_predictions = model2(batch_data)\n",
    "    predictions.append(batch_predictions)\n",
    "\n",
    "testPredict2 = np.concatenate(predictions, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "6471b738",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error Test Score > MSE ==  0.08323841026057144  MAE ==  0.24249344761257993  MAEMS ==  2.5130886863223547\n",
      "Error Test Score > MSE ==  0.10898849030283744  MAE ==  0.27897002338274185  MAEMS ==  2.705722980780666\n"
     ]
    }
   ],
   "source": [
    "tePredict2 = testPredict2.reshape(-1)\n",
    "testY = teY.reshape(-1)\n",
    "print('Error Test Score > MSE == ', npMSE(testY, tePredict), ' MAE == ', npMAE(testY, tePredict), ' MAEMS == ', npMAEMS(testY, tePredict))\n",
    "print('Error Test Score > MSE == ', npMSE(testY, tePredict2), ' MAE == ', npMAE(testY, tePredict2), ' MAEMS == ', npMAEMS(testY, tePredict2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "66d7c2d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from statsmodels.stats.diagnostic import acorr_ljungbox\n",
    "from scipy.stats import norm\n",
    "\n",
    "def diebold_mariano_test(forecast1, forecast2, actual, opt): \n",
    "    \n",
    "    if opt==0: # MSE\n",
    "        e1 = actual-forecast1\n",
    "        e2 = actual-forecast2\n",
    "        d = e1**2 - e2**2\n",
    "    elif opt==1: # MAE\n",
    "        e1 = abs(actual-forecast1)\n",
    "        e2 = abs(actual-forecast2)\n",
    "        d = e1 - e2\n",
    "    else:\n",
    "        e1 = np.multiply(abs(actual - forecast1), actual**2)\n",
    "        e2 = np.multiply(abs(actual - forecast2), actual**2)\n",
    "        d = e1-e2\n",
    "    \n",
    "    # Mean of the loss differentials\n",
    "    mean_d = np.mean(d)\n",
    "    \n",
    "    # Standard deviation of the loss differentials\n",
    "    std_d = np.std(d, ddof=1)\n",
    "    \n",
    "    # Calculate the test statistic\n",
    "    test_stat = (mean_d / std_d) * np.sqrt(len(d))\n",
    "    \n",
    "    # Calculate the p-value using a two-tailed test\n",
    "    p_value = 2 * (1 - norm.cdf(abs(test_stat)))\n",
    "    \n",
    "    return test_stat, p_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "bdddd74b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((-42.041603697765304, 0.0),\n",
       " (-40.05180541396674, 0.0),\n",
       " (-8.385805629249582, 0.0))"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "diebold_mariano_test(testPredict, testPredict2, teY, 0), diebold_mariano_test(testPredict, testPredict2, teY, 1), diebold_mariano_test(testPredict, testPredict2, teY, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "cf0189e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.savetxt('SegRNN_prop', testPredict)\n",
    "np.savetxt('SegRNN_woshuffling', testPredict2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ead6cae4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1df48b77",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
