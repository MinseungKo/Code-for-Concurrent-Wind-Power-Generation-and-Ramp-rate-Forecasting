{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5e862085",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "import pandas as pd\n",
    "import codecs\n",
    "import numpy as np\n",
    "import math\n",
    "import csv\n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.metrics import recall_score, precision_score # New\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn import preprocessing\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow.keras.preprocessing\n",
    "#from tensorflow.keras.callbacks import ModelCheckpoint, CSVLogger, EarlyStopping, LearningRateScheduler, ReduceLROnPlateau\n",
    "from tensorflow.keras.models import Sequential, Model\n",
    "from tensorflow.keras.layers import Dense, Input, Flatten, Add, Multiply, Subtract\n",
    "from tensorflow.keras import backend as K\n",
    "from tensorflow.keras.layers import Activation, BatchNormalization\n",
    "# regularizers\n",
    "from tensorflow.keras.layers import Conv1D, Conv2D\n",
    "from tensorflow.keras.layers import MaxPooling1D\n",
    "from tensorflow.keras.layers import concatenate\n",
    "from tensorflow.keras.layers import LSTM, Bidirectional\n",
    "from tensorflow.keras.utils import plot_model\n",
    "from tensorflow.keras.layers import Dropout, SpatialDropout1D\n",
    "from scipy import signal\n",
    "import openpyxl\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "from matplotlib import pylab as plt\n",
    "import matplotlib.dates as mdates\n",
    "import seaborn as sns\n",
    "import sklearn\n",
    "from sklearn.model_selection import train_test_split\n",
    "from numpy.linalg import svd\n",
    "import gc\n",
    "from keijzer import *\n",
    "from tensorflow import keras\n",
    "from keras.models import Model\n",
    "from keras.layers import *\n",
    "from tensorflow.keras.optimizers import Adam,SGD\n",
    "from keras.layers import Dense, Input, Flatten, Add, concatenate, Dropout, Activation, Multiply, Embedding, Layer, Reshape\n",
    "from keras.layers import LSTM, Bidirectional, GlobalMaxPooling1D, GlobalAveragePooling1D  \n",
    "from keras.layers import Conv1D, AveragePooling1D, MaxPooling1D\n",
    "#from keras.ops import convert_to_tensor, convert_to_numpy\n",
    "#from keras.utils import plot_model\n",
    "from keras import activations\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from keras.callbacks import ModelCheckpoint, CSVLogger, EarlyStopping, LearningRateScheduler, ReduceLROnPlateau\n",
    "import math\n",
    "\n",
    "class LossHistory(tensorflow.keras.callbacks.Callback):  # history = LossHistory()\n",
    "    def init(self):  # history.init()\n",
    "        self.losses = []\n",
    "        # self.accs = []\n",
    "        self.val_losses = []\n",
    "        # self.val_accs = []\n",
    "        self.rmses = []\n",
    "        self.mses = []\n",
    "        self.maes = []\n",
    "        self.mapes = []\n",
    "        self.val_rmses = []\n",
    "        self.val_mses = []\n",
    "        self.val_maes = []\n",
    "        self.val_mapes = []\n",
    "\n",
    "    def on_epoch_end(self, batch, logs={}):\n",
    "        self.losses.append(logs.get('loss'))\n",
    "        # self.accs.append(logs.get('acc'))\n",
    "        self.val_losses.append(logs.get('val_loss'))\n",
    "        # self.val_accs.append(logs.get('val_accuracy\n",
    "        self.rmses.append(logs.get('root_mean_squared_error'))\n",
    "        self.mses.append(logs.get('mean_squared_error'))\n",
    "        self.maes.append(logs.get('mean_absolute_error'))\n",
    "        self.mapes.append(logs.get('mean_absolute_percentage_error'))\n",
    "        self.val_rmses.append(logs.get('val_root_mean_squared_error'))\n",
    "        self.val_mses.append(logs.get('val_mean_squared_error'))\n",
    "        self.val_maes.append(logs.get('val_mean_absolute_error'))\n",
    "        self.val_mapes.append(logs.get('val_mean_absolute_percentage_error'))\n",
    "\n",
    "\n",
    "\n",
    "def root_squared_mean_error(y_true, y_pred):\n",
    "    return K.mean((K.abs(y_pred - y_true))*K.square(y_true-K.mean(y_true)))*100\n",
    "\n",
    "def mse_mae(y_true, y_pred):\n",
    "    return K.mean(K.square(y_pred - y_true))+K.mean(K.abs(y_pred - y_true))\n",
    "\n",
    "from keras.layers.advanced_activations import PReLU\n",
    "\n",
    "def mean_absolute_percentage_error(y_true, y_pred):\n",
    "    y_true, y_pred = np.array(y_true), np.array(y_pred)\n",
    "    return np.mean(np.abs((y_true - y_pred) / y_true)) * 100\n",
    "\n",
    "def root_mean_squared_error(y_true, y_pred):\n",
    "        return K.sqrt(K.mean(K.square(y_pred - y_true))) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "afe5dada",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]\n"
     ]
    }
   ],
   "source": [
    "import scipy as sc\n",
    "import os\n",
    "\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = '0' # 여러개 사용시 '0,1,2' 식으로 하나의 문자열에 입력\n",
    "gpus = tf.config.experimental.list_physical_devices('GPU') # 호스트 러나임에 표시되는 GPU 장치 목록 반환\n",
    "\n",
    "if gpus: # 반환된 GPU 장치 목록이 있다면\n",
    "    try: # 해당 장치에 대한 메모리 증가 활성화 여부 설정\n",
    "        tf.config.experimental.set_memory_growth(gpus[0], True)\n",
    "    except RuntimeError as e: # try문 실패시에 에러문구 출력\n",
    "        print(e)\n",
    "\n",
    "print(tf.config.list_physical_devices('GPU'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "69f302e1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Year</th>\n",
       "      <th>Wind Change</th>\n",
       "      <th>Wind Output</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2020</td>\n",
       "      <td>0.620197</td>\n",
       "      <td>0.644724</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2020</td>\n",
       "      <td>0.544580</td>\n",
       "      <td>0.658617</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2020</td>\n",
       "      <td>0.570751</td>\n",
       "      <td>0.683924</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2020</td>\n",
       "      <td>0.599594</td>\n",
       "      <td>0.721813</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2020</td>\n",
       "      <td>0.495246</td>\n",
       "      <td>0.714187</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35058</th>\n",
       "      <td>2023</td>\n",
       "      <td>0.774643</td>\n",
       "      <td>0.484984</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35059</th>\n",
       "      <td>2023</td>\n",
       "      <td>0.735512</td>\n",
       "      <td>0.582157</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35060</th>\n",
       "      <td>2023</td>\n",
       "      <td>0.601593</td>\n",
       "      <td>0.620917</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35061</th>\n",
       "      <td>2023</td>\n",
       "      <td>0.536583</td>\n",
       "      <td>0.631322</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35062</th>\n",
       "      <td>2023</td>\n",
       "      <td>0.454969</td>\n",
       "      <td>0.606127</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>35063 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Year  Wind Change  Wind Output\n",
       "0      2020     0.620197     0.644724\n",
       "1      2020     0.544580     0.658617\n",
       "2      2020     0.570751     0.683924\n",
       "3      2020     0.599594     0.721813\n",
       "4      2020     0.495246     0.714187\n",
       "...     ...          ...          ...\n",
       "35058  2023     0.774643     0.484984\n",
       "35059  2023     0.735512     0.582157\n",
       "35060  2023     0.601593     0.620917\n",
       "35061  2023     0.536583     0.631322\n",
       "35062  2023     0.454969     0.606127\n",
       "\n",
       "[35063 rows x 3 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_path = 'C:/Users/smartgrid_AI/Desktop/windpower_ramprate/ercot_2020.csv'\n",
    "data_source1 = pd.read_csv(data_path)\n",
    "dat_source1 = pd.DataFrame(data_source1)\n",
    "#dat_source1 = dat_source1.iloc[:-3,:]\n",
    "\n",
    "data_path = 'C:/Users/smartgrid_AI/Desktop/windpower_ramprate/ercot_2021.csv'\n",
    "data_source2 = pd.read_csv(data_path)\n",
    "dat_source2 = pd.DataFrame(data_source2)\n",
    "dat_source2 = dat_source2.iloc[:8761,:9]\n",
    "\n",
    "data_path = 'C:/Users/smartgrid_AI/Desktop/windpower_ramprate/ercot_2022.csv'\n",
    "data_source3 = pd.read_csv(data_path)\n",
    "dat_source3 = pd.DataFrame(data_source3)\n",
    "dat_source3 = dat_source3.iloc[:8760,:9]\n",
    "\n",
    "data_path = 'C:/Users/smartgrid_AI/Desktop/windpower_ramprate/ercot_2023.csv'\n",
    "data_source4 = pd.read_csv(data_path)\n",
    "dat_source4 = pd.DataFrame(data_source4)\n",
    "dat_source4 = dat_source4.iloc[:8760,:9]\n",
    "\n",
    "dat_arr1 = np.array(dat_source1)\n",
    "dat_arr2 = np.array(dat_source2)\n",
    "dat_arr3 = np.array(dat_source3)\n",
    "dat_arr4 = np.array(dat_source4)\n",
    "\n",
    "dat_arr = np.concatenate([dat_arr1, dat_arr2, dat_arr3, dat_arr4],axis=0)\n",
    "dat_arr.shape # 8784, 8761, 8760, 8760\n",
    "\n",
    "dat_source = pd.DataFrame(dat_arr, columns=['Time-Date stamp','Date','ERCOT Load','Total Wind Output','Total Wind Installed','Wind Output, % of Load','Wind Output, % of Installed','1-hr MW change','1-hr % change'])\n",
    "dat = pd.DataFrame()\n",
    "dat['MW % change'] = np.array(dat_source.iloc[1:,3], dtype=float)-np.array(dat_source.iloc[0:-1,3], dtype=float)\n",
    "dat['MW % change'] = np.divide(np.array(dat['MW % change']),np.array(dat_source.iloc[1:,4]))*100\n",
    "dat['Total Wind Output'] = np.divide(np.array(dat_source.iloc[1:,3]), np.array(dat_source.iloc[1:,4]))\n",
    "\n",
    "ramp_ratio = 20\n",
    "load_ratio = 10\n",
    "year_arr = np.concatenate([np.ones(8784)*2020, np.ones(8760)*2021, np.ones(8760)*2022, np.ones(8760)*2023])\n",
    "year_df = pd.DataFrame(year_arr, columns=['Year'], dtype=int)\n",
    "wind_df = pd.concat([year_df, dat], axis=1)\n",
    "wind_df = wind_df.reset_index(drop=True)\n",
    "\n",
    "std_scaler = sklearn.preprocessing.MinMaxScaler()\n",
    "std_scaler_load = sklearn.preprocessing.MinMaxScaler()\n",
    "std_scaler_ramp = sklearn.preprocessing.MinMaxScaler()\n",
    "\n",
    "wind_df[['Total Wind Output']] = std_scaler.fit_transform(wind_df[['Total Wind Output']])\n",
    "wind_df[['MW % change']] = std_scaler_ramp.fit_transform(wind_df[['MW % change']])\n",
    "wind_df = wind_df.iloc[:-1,:]\n",
    "ramp_df = pd.DataFrame(wind_df)\n",
    "ramp_df.columns=['Year', 'Wind Change', 'Wind Output']\n",
    "ramp_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d9c9061a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_dataset(dataset, timesteps, output_timesteps, leadtime):\n",
    "    dataX, dataY = [], []\n",
    "    for i in range(len(dataset) - timesteps -output_timesteps - leadtime - 1):\n",
    "        a = dataset[i:(i + timesteps), :]\n",
    "        dataX.append(a)\n",
    "        dataY.append(dataset[(i + timesteps + leadtime):(i+timesteps+output_timesteps+leadtime), :])\n",
    "    return np.array(dataX), np.array(dataY)\n",
    "\n",
    "def svdadd(X, start, end, b_size):\n",
    "    dec_x = X[start:end, :, :]\n",
    "    U, S, Vh = svd(dec_x.reshape(b_size, -1), full_matrices=True)\n",
    "\n",
    "    high_sig = np.matmul(np.matmul(U[:,:high_ind], np.diag(S[0:high_ind])), Vh[:high_ind,:])\n",
    "    low_sig = X[:dec_num, :, :].reshape(b_size,-1)-high_sig\n",
    "\n",
    "    rec_x = np.zeros((b_size, b_size, high_ind))\n",
    "    \n",
    "    for i in range(high_ind):\n",
    "        rec_x[:,:,i] = np.matmul((U[:,i]*S[i]).reshape(-1,1), Vh[i,:].reshape(1,-1))    \n",
    "    return rec_x, low_sig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b69646be",
   "metadata": {},
   "outputs": [],
   "source": [
    "norm_df = np.array(wind_df.iloc[:,1]).reshape(-1,1)\n",
    "timesteps = 24*7\n",
    "output_timesteps = 24\n",
    "leadtime = 6\n",
    "num_features = 1\n",
    "X, Y = create_dataset(norm_df, timesteps, output_timesteps, leadtime)\n",
    "b_size = timesteps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4395eea4",
   "metadata": {},
   "outputs": [],
   "source": [
    "dec_num = timesteps\n",
    "high_ind = 35\n",
    "\n",
    "addX = np.zeros((X.shape[0], dec_num, high_ind+1))\n",
    "\n",
    "for k in range(X.shape[0]//dec_num):\n",
    "    rec_x, low_sig = svdadd(X, k*dec_num, (k+1)*dec_num, b_size)\n",
    "    addX[k*dec_num:k*dec_num+dec_num,:, :-1] = rec_x\n",
    "    addX[k*dec_num:k*dec_num+dec_num,:, -1] = low_sig\n",
    "    \n",
    "rec_x, low_sig = svdadd(X, X.shape[0]-dec_num, X.shape[0], b_size)\n",
    "addX[X.shape[0]-dec_num:X.shape[0], :, :-1] = rec_x\n",
    "addX[X.shape[0]-dec_num:X.shape[0],:, -1] = low_sig\n",
    "\n",
    "addX_det = addX[:, :, :-1]\n",
    "addX_det = np.sum(addX_det, axis=2)\n",
    "X = np.concatenate([X, addX], axis=2)\n",
    "num_features = X.shape[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "af62257d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((31377, 168, 37), (31377, 24), (3487, 168, 37), (3487, 24))"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trvaX, teX, trvaY, teY = train_test_split(X, Y, test_size=0.1, shuffle=False)\n",
    "\n",
    "idx = np.arange(trvaX.shape[0])\n",
    "np.random.shuffle(idx)\n",
    "strvaX = trvaX[idx]\n",
    "strvaY = trvaY[idx]\n",
    "strvaY = strvaY.reshape(-1, output_timesteps)\n",
    "\n",
    "trvaY = trvaY.reshape(-1, output_timesteps)\n",
    "teY = teY.reshape(-1, output_timesteps)\n",
    "\n",
    "strX, svaX, strY, svaY = train_test_split(strvaX, strvaY, test_size=0.3, shuffle=False)\n",
    "trX, vaX, trY, vaY = train_test_split(trvaX, trvaY, test_size=0.3, shuffle=False)\n",
    "\n",
    "trvaX.shape, trvaY.shape, teX.shape, teY.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "dcb7c6ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "def MAEMD(y_true, y_pred):\n",
    "    return K.mean((K.abs(y_pred - y_true))*K.square(y_true-K.mean(y_true)))*100"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb7d8567",
   "metadata": {},
   "source": [
    "## SCINet - With SVD With Shuffling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6a977467",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models\n",
    "\n",
    "class Splitting(layers.Layer):\n",
    "    def __init__(self, name=\"Splitting\"):\n",
    "        super(Splitting, self).__init__(name=name)\n",
    "\n",
    "    def call(self, x):\n",
    "        x_even = x[:, ::2, :]\n",
    "        x_odd = x[:, 1::2, :]\n",
    "        return x_even, x_odd\n",
    "class Interactor(layers.Layer):\n",
    "    def __init__(self, in_planes, kernel=5, dropout=0.5, groups=1, hidden_size=1, INN=True, name=\"Interactor\"):\n",
    "        super(Interactor, self).__init__(name=name)\n",
    "        self.modified = INN\n",
    "        padding = 'same' if kernel % 2 == 1 else 'causal'\n",
    "        \n",
    "        self.P = models.Sequential([\n",
    "            layers.Conv1D(int(in_planes * hidden_size), kernel, padding=padding, groups=groups, name=\"P_Conv1\"),\n",
    "            layers.LeakyReLU(alpha=0.01, name=\"P_LeakyReLU\"),\n",
    "            layers.Dropout(dropout, name=\"P_Dropout\"),\n",
    "            layers.Conv1D(in_planes, 3, padding=padding, groups=groups, name=\"P_Conv2\"),\n",
    "            layers.Activation('tanh', name=\"P_Activation\")\n",
    "        ], name=\"P_Block\")\n",
    "        \n",
    "        self.U = models.Sequential([\n",
    "            layers.Conv1D(int(in_planes * hidden_size), kernel, padding=padding, groups=groups, name=\"U_Conv1\"),\n",
    "            layers.LeakyReLU(alpha=0.01, name=\"U_LeakyReLU\"),\n",
    "            layers.Dropout(dropout, name=\"U_Dropout\"),\n",
    "            layers.Conv1D(in_planes, 3, padding=padding, groups=groups, name=\"U_Conv2\"),\n",
    "            layers.Activation('tanh', name=\"U_Activation\")\n",
    "        ], name=\"U_Block\")\n",
    "        \n",
    "        self.phi = models.Sequential([\n",
    "            layers.Conv1D(int(in_planes * hidden_size), kernel, padding=padding, groups=groups, name=\"phi_Conv1\"),\n",
    "            layers.LeakyReLU(alpha=0.01, name=\"phi_LeakyReLU\"),\n",
    "            layers.Dropout(dropout, name=\"phi_Dropout\"),\n",
    "            layers.Conv1D(in_planes, 3, padding=padding, groups=groups, name=\"phi_Conv2\"),\n",
    "            layers.Activation('tanh', name=\"phi_Activation\")\n",
    "        ], name=\"phi_Block\")\n",
    "        \n",
    "        self.psi = models.Sequential([\n",
    "            layers.Conv1D(int(in_planes * hidden_size), kernel, padding=padding, groups=groups, name=\"psi_Conv1\"),\n",
    "            layers.LeakyReLU(alpha=0.01, name=\"psi_LeakyReLU\"),\n",
    "            layers.Dropout(dropout, name=\"psi_Dropout\"),\n",
    "            layers.Conv1D(in_planes, 3, padding=padding, groups=groups, name=\"psi_Conv2\"),\n",
    "            layers.Activation('tanh', name=\"psi_Activation\")\n",
    "        ], name=\"psi_Block\")\n",
    "        \n",
    "        self.split = Splitting()\n",
    "\n",
    "    def call(self, x):\n",
    "        x_even, x_odd = self.split(x)\n",
    "        # Interactor는 각 레이어의 입력 모양이 맞아야 함\n",
    "        d = tf.math.multiply(x_odd, tf.math.exp(self.phi(x_even)))  # x_even의 shape이 (batch_size, 84, in_planes)\n",
    "        c = tf.math.multiply(x_even, tf.math.exp(self.psi(x_odd)))  # x_odd의 shape이 (batch_size, 84, in_planes)\n",
    "        \n",
    "        if self.modified:\n",
    "            x_even_update = c + self.U(d)\n",
    "            x_odd_update = d - self.P(c)\n",
    "        else:\n",
    "            x_even_update = c - self.U(d)\n",
    "            x_odd_update = d + self.P(c)\n",
    "        \n",
    "        return x_even_update, x_odd_update\n",
    "\n",
    "\n",
    "class SCINet_Tree(models.Model):\n",
    "    def __init__(self, in_planes, current_level, kernel_size, dropout, groups, hidden_size, INN, name=\"SCINet_Tree\"):\n",
    "        super(SCINet_Tree, self).__init__(name=name)\n",
    "        self.current_level = current_level\n",
    "        self.interact = Interactor(in_planes, kernel_size, dropout, groups, hidden_size, INN, name=f\"Interactor_Level_{current_level}\")\n",
    "\n",
    "        if current_level > 0:\n",
    "            self.SCINet_Tree_even = SCINet_Tree(in_planes, current_level-1, kernel_size, dropout, groups, hidden_size, INN, name=f\"SCINet_Tree_even_{current_level}\")\n",
    "            self.SCINet_Tree_odd = SCINet_Tree(in_planes, current_level-1, kernel_size, dropout, groups, hidden_size, INN, name=f\"SCINet_Tree_odd_{current_level}\")\n",
    "\n",
    "    def zip_up_the_pants(self, even, odd):\n",
    "        zipped = tf.concat([even[:, i:i+1, :] for i in range(even.shape[1])] +\n",
    "                           [odd[:, i:i+1, :] for i in range(odd.shape[1])], axis=1)\n",
    "        return zipped\n",
    "\n",
    "    def call(self, x):\n",
    "        x_even_update, x_odd_update = self.interact(x)\n",
    "        if self.current_level == 0:\n",
    "            return self.zip_up_the_pants(x_even_update, x_odd_update)\n",
    "        else:\n",
    "            return self.zip_up_the_pants(self.SCINet_Tree_even(x_even_update), self.SCINet_Tree_odd(x_odd_update))\n",
    "\n",
    "\n",
    "\n",
    "class SCINet(models.Model):\n",
    "    def __init__(self, output_len, input_len, input_dim=1, hid_size=1, num_stacks=1, num_levels=3, kernel=5, dropout=0.5, INN=True, name=\"SCINet\"):\n",
    "        super(SCINet, self).__init__(name=name)\n",
    "        self.input_dim = input_dim\n",
    "        self.output_len = output_len\n",
    "        self.input_len = input_len\n",
    "        self.num_stacks = num_stacks\n",
    "\n",
    "        # 각 스택을 정의\n",
    "        self.blocks = [SCINet_Tree(input_dim, num_levels-1, kernel, dropout, groups=1, hidden_size=hid_size, INN=INN, name=f\"SCINet_Tree_Stack_{i}\") for i in range(num_stacks)]\n",
    "\n",
    "        self.projections = [layers.Conv1D(output_len, 1, padding='same', name=f\"Projection_Stack_{i}\") for i in range(num_stacks)]\n",
    "        self.global_pool = layers.GlobalAveragePooling1D()\n",
    "\n",
    "    def call(self, x):\n",
    "        res = x\n",
    "        for i in range(self.num_stacks):\n",
    "            x = self.blocks[i](x)\n",
    "            x = self.projections[i](x) \n",
    "            res = x  \n",
    "        return self.global_pool(x) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "87b355fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"SCINet\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "SCINet_Tree_Stack_0 (SCINet_ multiple                  2222220   \n",
      "_________________________________________________________________\n",
      "Projection_Stack_0 (Conv1D)  multiple                  912       \n",
      "_________________________________________________________________\n",
      "global_average_pooling1d (Gl multiple                  0         \n",
      "=================================================================\n",
      "Total params: 2,223,132\n",
      "Trainable params: 2,223,132\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "output_len = 24        \n",
    "input_len = 168        \n",
    "input_dim = trvaX.shape[-1]         \n",
    "hid_size = 9        \n",
    "num_stacks = 1\n",
    "num_levels = 2\n",
    "kernel_size = 12    \n",
    "dropout = 0.2         \n",
    "INN = True           \n",
    "\n",
    "# 모델 정의\n",
    "with tf.device('/gpu:0'):\n",
    "    model = SCINet(output_len, input_len, input_dim, hid_size, num_stacks, num_levels, kernel_size, dropout, INN)\n",
    "    model.build(input_shape=(None, 168, input_dim))\n",
    "    model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2b6571b0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "13045"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4e40434d",
   "metadata": {},
   "outputs": [],
   "source": [
    "    model.compile(loss=MAEMD, optimizer='adam', metrics=['mse','mae', MAEMD])\n",
    "    early_stopping =EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)\n",
    "    batch_size = 100\n",
    "    epochs = 1000\n",
    "    history = LossHistory()\n",
    "    history.init()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2a6c7bc1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "131/131 [==============================] - 67s 430ms/step - loss: 0.1973 - mse: 0.0218 - mae: 0.1081 - MAEMD: 0.1972 - val_loss: 0.1714 - val_mse: 0.0180 - val_mae: 0.1060 - val_MAEMD: 0.1700\n",
      "Epoch 2/1000\n",
      "131/131 [==============================] - 171s 1s/step - loss: 0.1467 - mse: 0.0172 - mae: 0.1043 - MAEMD: 0.1466 - val_loss: 0.1407 - val_mse: 0.0168 - val_mae: 0.1037 - val_MAEMD: 0.1397\n",
      "Epoch 3/1000\n",
      "131/131 [==============================] - 170s 1s/step - loss: 0.1334 - mse: 0.0172 - mae: 0.1050 - MAEMD: 0.1334 - val_loss: 0.1336 - val_mse: 0.0175 - val_mae: 0.1057 - val_MAEMD: 0.1328\n",
      "Epoch 4/1000\n",
      "131/131 [==============================] - 167s 1s/step - loss: 0.1239 - mse: 0.0170 - mae: 0.1041 - MAEMD: 0.1239 - val_loss: 0.1311 - val_mse: 0.0178 - val_mae: 0.1064 - val_MAEMD: 0.1305\n",
      "Epoch 5/1000\n",
      "131/131 [==============================] - 170s 1s/step - loss: 0.1169 - mse: 0.0167 - mae: 0.1031 - MAEMD: 0.1169 - val_loss: 0.1267 - val_mse: 0.0174 - val_mae: 0.1050 - val_MAEMD: 0.1259\n",
      "Epoch 6/1000\n",
      "131/131 [==============================] - 164s 1s/step - loss: 0.1094 - mse: 0.0162 - mae: 0.1012 - MAEMD: 0.1094 - val_loss: 0.1222 - val_mse: 0.0162 - val_mae: 0.1014 - val_MAEMD: 0.1214\n",
      "Epoch 7/1000\n",
      "131/131 [==============================] - 166s 1s/step - loss: 0.1053 - mse: 0.0159 - mae: 0.1005 - MAEMD: 0.1053 - val_loss: 0.1185 - val_mse: 0.0163 - val_mae: 0.1018 - val_MAEMD: 0.1179\n",
      "Epoch 8/1000\n",
      "131/131 [==============================] - 167s 1s/step - loss: 0.1012 - mse: 0.0157 - mae: 0.0996 - MAEMD: 0.1012 - val_loss: 0.1152 - val_mse: 0.0154 - val_mae: 0.0987 - val_MAEMD: 0.1145\n",
      "Epoch 9/1000\n",
      "131/131 [==============================] - 169s 1s/step - loss: 0.0978 - mse: 0.0154 - mae: 0.0985 - MAEMD: 0.0978 - val_loss: 0.1155 - val_mse: 0.0156 - val_mae: 0.0996 - val_MAEMD: 0.1147\n",
      "Epoch 10/1000\n",
      "131/131 [==============================] - 166s 1s/step - loss: 0.0949 - mse: 0.0151 - mae: 0.0978 - MAEMD: 0.0949 - val_loss: 0.1167 - val_mse: 0.0159 - val_mae: 0.1005 - val_MAEMD: 0.1159\n",
      "Epoch 11/1000\n",
      "131/131 [==============================] - 165s 1s/step - loss: 0.0933 - mse: 0.0150 - mae: 0.0973 - MAEMD: 0.0933 - val_loss: 0.1117 - val_mse: 0.0143 - val_mae: 0.0954 - val_MAEMD: 0.1110\n",
      "Epoch 12/1000\n",
      "131/131 [==============================] - 160s 1s/step - loss: 0.0918 - mse: 0.0148 - mae: 0.0969 - MAEMD: 0.0918 - val_loss: 0.1206 - val_mse: 0.0177 - val_mae: 0.1067 - val_MAEMD: 0.1197\n",
      "Epoch 13/1000\n",
      "131/131 [==============================] - 166s 1s/step - loss: 0.0892 - mse: 0.0146 - mae: 0.0960 - MAEMD: 0.0891 - val_loss: 0.1147 - val_mse: 0.0159 - val_mae: 0.1009 - val_MAEMD: 0.1140\n",
      "Epoch 14/1000\n",
      "131/131 [==============================] - 154s 1s/step - loss: 0.0853 - mse: 0.0141 - mae: 0.0940 - MAEMD: 0.0853 - val_loss: 0.1086 - val_mse: 0.0146 - val_mae: 0.0961 - val_MAEMD: 0.1078\n",
      "Epoch 15/1000\n",
      "131/131 [==============================] - 104s 791ms/step - loss: 0.0827 - mse: 0.0138 - mae: 0.0929 - MAEMD: 0.0826 - val_loss: 0.1111 - val_mse: 0.0161 - val_mae: 0.1007 - val_MAEMD: 0.1102\n",
      "Epoch 16/1000\n",
      "131/131 [==============================] - 107s 814ms/step - loss: 0.0829 - mse: 0.0139 - mae: 0.0932 - MAEMD: 0.0829 - val_loss: 0.1063 - val_mse: 0.0147 - val_mae: 0.0969 - val_MAEMD: 0.1056\n",
      "Epoch 17/1000\n",
      "131/131 [==============================] - 106s 811ms/step - loss: 0.0800 - mse: 0.0135 - mae: 0.0918 - MAEMD: 0.0800 - val_loss: 0.1101 - val_mse: 0.0149 - val_mae: 0.0974 - val_MAEMD: 0.1093\n",
      "Epoch 18/1000\n",
      "131/131 [==============================] - 105s 799ms/step - loss: 0.0799 - mse: 0.0135 - mae: 0.0917 - MAEMD: 0.0798 - val_loss: 0.1086 - val_mse: 0.0152 - val_mae: 0.0986 - val_MAEMD: 0.1078\n",
      "Epoch 19/1000\n",
      "131/131 [==============================] - 103s 789ms/step - loss: 0.0772 - mse: 0.0132 - mae: 0.0907 - MAEMD: 0.0772 - val_loss: 0.1052 - val_mse: 0.0145 - val_mae: 0.0961 - val_MAEMD: 0.1045\n",
      "Epoch 20/1000\n",
      "131/131 [==============================] - 107s 818ms/step - loss: 0.0764 - mse: 0.0131 - mae: 0.0903 - MAEMD: 0.0764 - val_loss: 0.1049 - val_mse: 0.0154 - val_mae: 0.0990 - val_MAEMD: 0.1042\n",
      "Epoch 21/1000\n",
      "131/131 [==============================] - 106s 809ms/step - loss: 0.0751 - mse: 0.0129 - mae: 0.0894 - MAEMD: 0.0751 - val_loss: 0.1057 - val_mse: 0.0158 - val_mae: 0.1004 - val_MAEMD: 0.1050\n",
      "Epoch 22/1000\n",
      "131/131 [==============================] - 109s 830ms/step - loss: 0.0749 - mse: 0.0128 - mae: 0.0889 - MAEMD: 0.0748 - val_loss: 0.1050 - val_mse: 0.0144 - val_mae: 0.0959 - val_MAEMD: 0.1042\n",
      "Epoch 23/1000\n",
      "131/131 [==============================] - 100s 767ms/step - loss: 0.0751 - mse: 0.0127 - mae: 0.0888 - MAEMD: 0.0751 - val_loss: 0.1053 - val_mse: 0.0131 - val_mae: 0.0910 - val_MAEMD: 0.1046\n",
      "Epoch 24/1000\n",
      "131/131 [==============================] - 103s 786ms/step - loss: 0.0732 - mse: 0.0125 - mae: 0.0880 - MAEMD: 0.0732 - val_loss: 0.1083 - val_mse: 0.0142 - val_mae: 0.0951 - val_MAEMD: 0.1077\n",
      "Epoch 25/1000\n",
      "131/131 [==============================] - 108s 819ms/step - loss: 0.0719 - mse: 0.0122 - mae: 0.0870 - MAEMD: 0.0718 - val_loss: 0.1072 - val_mse: 0.0137 - val_mae: 0.0932 - val_MAEMD: 0.1066\n",
      "Epoch 26/1000\n",
      "131/131 [==============================] - 111s 841ms/step - loss: 0.0697 - mse: 0.0119 - mae: 0.0857 - MAEMD: 0.0697 - val_loss: 0.1050 - val_mse: 0.0139 - val_mae: 0.0938 - val_MAEMD: 0.1043\n",
      "Epoch 27/1000\n",
      "131/131 [==============================] - 109s 829ms/step - loss: 0.0680 - mse: 0.0117 - mae: 0.0846 - MAEMD: 0.0680 - val_loss: 0.1049 - val_mse: 0.0130 - val_mae: 0.0907 - val_MAEMD: 0.1040\n",
      "Epoch 28/1000\n",
      "131/131 [==============================] - 109s 833ms/step - loss: 0.0666 - mse: 0.0115 - mae: 0.0839 - MAEMD: 0.0666 - val_loss: 0.1058 - val_mse: 0.0138 - val_mae: 0.0935 - val_MAEMD: 0.1050\n",
      "Epoch 29/1000\n",
      "131/131 [==============================] - 163s 1s/step - loss: 0.0664 - mse: 0.0114 - mae: 0.0837 - MAEMD: 0.0664 - val_loss: 0.1082 - val_mse: 0.0143 - val_mae: 0.0949 - val_MAEMD: 0.1074\n",
      "Epoch 30/1000\n",
      "131/131 [==============================] - 167s 1s/step - loss: 0.0668 - mse: 0.0114 - mae: 0.0836 - MAEMD: 0.0667 - val_loss: 0.1039 - val_mse: 0.0133 - val_mae: 0.0917 - val_MAEMD: 0.1031\n",
      "Epoch 31/1000\n",
      "131/131 [==============================] - 164s 1s/step - loss: 0.0659 - mse: 0.0112 - mae: 0.0830 - MAEMD: 0.0659 - val_loss: 0.1045 - val_mse: 0.0135 - val_mae: 0.0924 - val_MAEMD: 0.1037\n",
      "Epoch 32/1000\n",
      "131/131 [==============================] - 161s 1s/step - loss: 0.0646 - mse: 0.0111 - mae: 0.0824 - MAEMD: 0.0646 - val_loss: 0.1028 - val_mse: 0.0133 - val_mae: 0.0917 - val_MAEMD: 0.1020\n",
      "Epoch 33/1000\n",
      "131/131 [==============================] - 168s 1s/step - loss: 0.0631 - mse: 0.0109 - mae: 0.0814 - MAEMD: 0.0631 - val_loss: 0.1023 - val_mse: 0.0124 - val_mae: 0.0885 - val_MAEMD: 0.1015\n",
      "Epoch 34/1000\n",
      "131/131 [==============================] - 100s 758ms/step - loss: 0.0635 - mse: 0.0109 - mae: 0.0816 - MAEMD: 0.0635 - val_loss: 0.1056 - val_mse: 0.0124 - val_mae: 0.0885 - val_MAEMD: 0.1047\n",
      "Epoch 35/1000\n",
      "131/131 [==============================] - 11s 84ms/step - loss: 0.0630 - mse: 0.0107 - mae: 0.0811 - MAEMD: 0.0630 - val_loss: 0.1083 - val_mse: 0.0133 - val_mae: 0.0920 - val_MAEMD: 0.1074\n",
      "Epoch 36/1000\n",
      "131/131 [==============================] - 11s 84ms/step - loss: 0.0633 - mse: 0.0108 - mae: 0.0812 - MAEMD: 0.0633 - val_loss: 0.1097 - val_mse: 0.0134 - val_mae: 0.0925 - val_MAEMD: 0.1090\n",
      "Epoch 37/1000\n",
      "131/131 [==============================] - 11s 84ms/step - loss: 0.0623 - mse: 0.0106 - mae: 0.0802 - MAEMD: 0.0623 - val_loss: 0.1042 - val_mse: 0.0125 - val_mae: 0.0892 - val_MAEMD: 0.1035\n",
      "Epoch 38/1000\n",
      "131/131 [==============================] - 11s 84ms/step - loss: 0.0616 - mse: 0.0105 - mae: 0.0801 - MAEMD: 0.0616 - val_loss: 0.1049 - val_mse: 0.0125 - val_mae: 0.0889 - val_MAEMD: 0.1041\n",
      "Epoch 39/1000\n",
      "131/131 [==============================] - 11s 83ms/step - loss: 0.0622 - mse: 0.0105 - mae: 0.0800 - MAEMD: 0.0622 - val_loss: 0.1065 - val_mse: 0.0136 - val_mae: 0.0929 - val_MAEMD: 0.1057\n",
      "Epoch 40/1000\n",
      "131/131 [==============================] - 12s 88ms/step - loss: 0.0615 - mse: 0.0104 - mae: 0.0795 - MAEMD: 0.0615 - val_loss: 0.1038 - val_mse: 0.0136 - val_mae: 0.0930 - val_MAEMD: 0.1029\n",
      "Epoch 41/1000\n",
      "131/131 [==============================] - 11s 84ms/step - loss: 0.0598 - mse: 0.0101 - mae: 0.0784 - MAEMD: 0.0598 - val_loss: 0.1044 - val_mse: 0.0134 - val_mae: 0.0922 - val_MAEMD: 0.1035\n",
      "Epoch 42/1000\n",
      "131/131 [==============================] - 11s 83ms/step - loss: 0.0586 - mse: 0.0099 - mae: 0.0776 - MAEMD: 0.0586 - val_loss: 0.1031 - val_mse: 0.0127 - val_mae: 0.0896 - val_MAEMD: 0.1023\n",
      "Epoch 43/1000\n",
      "131/131 [==============================] - 11s 83ms/step - loss: 0.0583 - mse: 0.0100 - mae: 0.0778 - MAEMD: 0.0582 - val_loss: 0.1031 - val_mse: 0.0117 - val_mae: 0.0858 - val_MAEMD: 0.1023\n",
      "Wall time: 1h 18min 52s\n"
     ]
    }
   ],
   "source": [
    "    %%time\n",
    "    b_size = 168\n",
    "    hist = model.fit(strX, strY, epochs=epochs, batch_size=b_size, shuffle=False, validation_data=(svaX, svaY), callbacks=[history, early_stopping])  # , checkpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "92d0d675",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4594"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "887014b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#model3.save('SCINet', save_format='tf')\n",
    "testPredict = model.predict(teX, batch_size=b_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b5d16520",
   "metadata": {},
   "outputs": [],
   "source": [
    "def npMAEMS(y_true, y_pred):\n",
    "    return np.mean((abs(y_pred - y_true))*np.square(y_true))*100\n",
    "def npMAEMD(y_true, y_pred):\n",
    "    return np.mean((abs(y_pred - y_true))*np.square(y_true-np.mean(y_true)))*100\n",
    "def npMSE(y_true, y_pred):\n",
    "    return np.mean(np.square(-y_true+y_pred))\n",
    "def npMAE(y_true, y_pred):\n",
    "    return np.mean(abs(-y_true+y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "8ecb2c53",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error Test Score > MSE ==  0.01443934840045931  MAE ==  0.09536675228445723  MAEMD ==  0.1150927807923784\n"
     ]
    }
   ],
   "source": [
    "tePredict = testPredict.reshape(-1)\n",
    "testY = teY.reshape(-1)\n",
    "print('Error Test Score > MSE == ', npMSE(testY, tePredict), ' MAE == ', npMAE(testY, tePredict), ' MAEMD == ', npMAEMD(testY, tePredict))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cab3f7b",
   "metadata": {},
   "source": [
    "## Without Shuffling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "4d47f1b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"SCINet\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "SCINet_Tree_Stack_0 (SCINet_ multiple                  2222220   \n",
      "_________________________________________________________________\n",
      "Projection_Stack_0 (Conv1D)  multiple                  912       \n",
      "_________________________________________________________________\n",
      "global_average_pooling1d_1 ( multiple                  0         \n",
      "=================================================================\n",
      "Total params: 2,223,132\n",
      "Trainable params: 2,223,132\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "output_len = 24        \n",
    "input_len = 168        \n",
    "input_dim = trvaX.shape[-1]         \n",
    "hid_size = 9        \n",
    "num_stacks = 1\n",
    "num_levels = 2\n",
    "kernel_size = 12    \n",
    "dropout = 0.2         \n",
    "INN = True           \n",
    "\n",
    "# 모델 정의\n",
    "with tf.device('/gpu:0'):\n",
    "    model2 = SCINet(output_len, input_len, input_dim, hid_size, num_stacks, num_levels, kernel_size, dropout, INN)\n",
    "    model2.build(input_shape=(None, 168, input_dim))\n",
    "    model2.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "069974ef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "15524"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "841dbe50",
   "metadata": {},
   "outputs": [],
   "source": [
    "    model2.compile(loss=MAEMD, optimizer='adam', metrics=['mse','mae', MAEMD])\n",
    "    early_stopping =EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)\n",
    "    batch_size = 100\n",
    "    epochs = 1000\n",
    "    history2 = LossHistory()\n",
    "    history2.init()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "33b75009",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "131/131 [==============================] - 19s 94ms/step - loss: 0.2170 - mse: 0.0218 - mae: 0.1072 - MAEMD: 0.2168 - val_loss: 0.1346 - val_mse: 0.0119 - val_mae: 0.0854 - val_MAEMD: 0.1355\n",
      "Epoch 2/1000\n",
      "131/131 [==============================] - 11s 83ms/step - loss: 0.1721 - mse: 0.0189 - mae: 0.1086 - MAEMD: 0.1720 - val_loss: 0.1154 - val_mse: 0.0139 - val_mae: 0.0949 - val_MAEMD: 0.1168\n",
      "Epoch 3/1000\n",
      "131/131 [==============================] - 11s 83ms/step - loss: 0.1597 - mse: 0.0189 - mae: 0.1097 - MAEMD: 0.1596 - val_loss: 0.1126 - val_mse: 0.0142 - val_mae: 0.0961 - val_MAEMD: 0.1138\n",
      "Epoch 4/1000\n",
      "131/131 [==============================] - 11s 82ms/step - loss: 0.1543 - mse: 0.0191 - mae: 0.1102 - MAEMD: 0.1542 - val_loss: 0.1113 - val_mse: 0.0141 - val_mae: 0.0957 - val_MAEMD: 0.1128\n",
      "Epoch 5/1000\n",
      "131/131 [==============================] - 11s 82ms/step - loss: 0.1510 - mse: 0.0194 - mae: 0.1112 - MAEMD: 0.1508 - val_loss: 0.1133 - val_mse: 0.0147 - val_mae: 0.0970 - val_MAEMD: 0.1150\n",
      "Epoch 6/1000\n",
      "131/131 [==============================] - 11s 82ms/step - loss: 0.1494 - mse: 0.0197 - mae: 0.1123 - MAEMD: 0.1493 - val_loss: 0.1147 - val_mse: 0.0166 - val_mae: 0.1042 - val_MAEMD: 0.1162\n",
      "Epoch 7/1000\n",
      "131/131 [==============================] - 11s 83ms/step - loss: 0.1439 - mse: 0.0192 - mae: 0.1106 - MAEMD: 0.1437 - val_loss: 0.1218 - val_mse: 0.0192 - val_mae: 0.1121 - val_MAEMD: 0.1235\n",
      "Epoch 8/1000\n",
      "131/131 [==============================] - 11s 83ms/step - loss: 0.1408 - mse: 0.0193 - mae: 0.1109 - MAEMD: 0.1406 - val_loss: 0.1163 - val_mse: 0.0169 - val_mae: 0.1044 - val_MAEMD: 0.1178\n",
      "Epoch 9/1000\n",
      "131/131 [==============================] - 11s 83ms/step - loss: 0.1393 - mse: 0.0194 - mae: 0.1113 - MAEMD: 0.1391 - val_loss: 0.1123 - val_mse: 0.0153 - val_mae: 0.0996 - val_MAEMD: 0.1138\n",
      "Epoch 10/1000\n",
      "131/131 [==============================] - 11s 83ms/step - loss: 0.1354 - mse: 0.0191 - mae: 0.1107 - MAEMD: 0.1353 - val_loss: 0.1128 - val_mse: 0.0156 - val_mae: 0.1000 - val_MAEMD: 0.1142\n",
      "Epoch 11/1000\n",
      "131/131 [==============================] - 11s 83ms/step - loss: 0.1324 - mse: 0.0191 - mae: 0.1106 - MAEMD: 0.1323 - val_loss: 0.1216 - val_mse: 0.0186 - val_mae: 0.1095 - val_MAEMD: 0.1222\n",
      "Epoch 12/1000\n",
      "131/131 [==============================] - 11s 83ms/step - loss: 0.1299 - mse: 0.0189 - mae: 0.1101 - MAEMD: 0.1298 - val_loss: 0.1263 - val_mse: 0.0209 - val_mae: 0.1169 - val_MAEMD: 0.1270\n",
      "Epoch 13/1000\n",
      "131/131 [==============================] - 11s 83ms/step - loss: 0.1278 - mse: 0.0188 - mae: 0.1099 - MAEMD: 0.1278 - val_loss: 0.1230 - val_mse: 0.0205 - val_mae: 0.1158 - val_MAEMD: 0.1237\n",
      "Epoch 14/1000\n",
      "131/131 [==============================] - 11s 83ms/step - loss: 0.1228 - mse: 0.0186 - mae: 0.1090 - MAEMD: 0.1228 - val_loss: 0.1271 - val_mse: 0.0213 - val_mae: 0.1182 - val_MAEMD: 0.1275\n",
      "Wall time: 2min 40s\n"
     ]
    }
   ],
   "source": [
    "    %%time\n",
    "    hist2 = model2.fit(trX, trY, epochs=epochs, batch_size=b_size, shuffle=False, validation_data=(vaX, vaY), callbacks=[history2, early_stopping])  # , checkpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "12601326",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4598"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "c27f00e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "testPredict2 = model2.predict(teX, batch_size=b_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "93895477",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error Test Score > MSE ==  0.01443934840045931  MAE ==  0.09536675228445723  MAEMD ==  0.1150927807923784\n",
      "Error Test Score > MSE ==  0.014802573874587506  MAE ==  0.09728650984682821  MAEMD ==  0.11644914118638079\n"
     ]
    }
   ],
   "source": [
    "tePredict2 = testPredict2.reshape(-1)\n",
    "testY = teY.reshape(-1)\n",
    "print('Error Test Score > MSE == ', npMSE(testY, tePredict), ' MAE == ', npMAE(testY, tePredict), ' MAEMD == ', npMAEMD(testY, tePredict))\n",
    "print('Error Test Score > MSE == ', npMSE(testY, tePredict2), ' MAE == ', npMAE(testY, tePredict2), ' MAEMD == ', npMAEMD(testY, tePredict2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "e0863500",
   "metadata": {},
   "outputs": [],
   "source": [
    "from statsmodels.stats.diagnostic import acorr_ljungbox\n",
    "from scipy.stats import norm\n",
    "\n",
    "def diebold_mariano_test(forecast1, forecast2, actual, opt): \n",
    "    \n",
    "    if opt==0: # MSE\n",
    "        e1 = actual-forecast1\n",
    "        e2 = actual-forecast2\n",
    "        d = e1**2 - e2**2\n",
    "    elif opt==1: # MAE\n",
    "        e1 = abs(actual-forecast1)\n",
    "        e2 = abs(actual-forecast2)\n",
    "        d = e1 - e2\n",
    "    else:\n",
    "        e1 = np.multiply(abs(actual - forecast1), np.square(actual-np.mean(actual)))\n",
    "        e2 = np.multiply(abs(actual - forecast2), np.square(actual-np.mean(actual)))\n",
    "        d = e1-e2\n",
    "    \n",
    "    # Mean of the loss differentials\n",
    "    mean_d = np.mean(d)\n",
    "    \n",
    "    # Standard deviation of the loss differentials\n",
    "    std_d = np.std(d, ddof=1)\n",
    "    \n",
    "    # Calculate the test statistic\n",
    "    test_stat = (mean_d / std_d) * np.sqrt(len(d))\n",
    "    \n",
    "    # Calculate the p-value using a two-tailed test\n",
    "    p_value = 2 * (1 - norm.cdf(abs(test_stat)))\n",
    "    \n",
    "    return test_stat, p_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "c3be2df8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((-1.0729893639576775, 0.28327588828736294),\n",
       " (-1.5345959351827765, 0.12488311175325251),\n",
       " (-0.49070806166286923, 0.6236329438340948))"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "diebold_mariano_test(testPredict, testPredict2, teY, 0), diebold_mariano_test(testPredict, testPredict2, teY, 1), diebold_mariano_test(testPredict, testPredict2, teY, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a95a6ce3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
