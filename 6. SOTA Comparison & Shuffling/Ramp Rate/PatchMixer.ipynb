{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "19dfdf02",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "import pandas as pd\n",
    "import codecs\n",
    "import numpy as np\n",
    "import math\n",
    "import csv\n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.metrics import recall_score, precision_score # New\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn import preprocessing\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow.keras.preprocessing\n",
    "#from tensorflow.keras.callbacks import ModelCheckpoint, CSVLogger, EarlyStopping, LearningRateScheduler, ReduceLROnPlateau\n",
    "from tensorflow.keras.models import Sequential, Model\n",
    "from tensorflow.keras.layers import Dense, Input, Flatten, Add, Multiply, Subtract\n",
    "from tensorflow.keras import backend as K\n",
    "from tensorflow.keras.layers import Activation, BatchNormalization\n",
    "# regularizers\n",
    "from tensorflow.keras.layers import Conv1D, Conv2D\n",
    "from tensorflow.keras.layers import MaxPooling1D\n",
    "from tensorflow.keras.layers import concatenate\n",
    "from tensorflow.keras.layers import LSTM, Bidirectional\n",
    "from tensorflow.keras.utils import plot_model\n",
    "from tensorflow.keras.layers import Dropout, SpatialDropout1D\n",
    "from scipy import signal\n",
    "import openpyxl\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "from matplotlib import pylab as plt\n",
    "import matplotlib.dates as mdates\n",
    "import seaborn as sns\n",
    "import sklearn\n",
    "from sklearn.model_selection import train_test_split\n",
    "from numpy.linalg import svd\n",
    "import gc\n",
    "from keijzer import *\n",
    "from tensorflow import keras\n",
    "from keras.models import Model\n",
    "from keras.layers import *\n",
    "from tensorflow.keras.optimizers import Adam,SGD\n",
    "from keras.layers import Dense, Input, Flatten, Add, concatenate, Dropout, Activation, Multiply, Embedding, Layer, Reshape\n",
    "from keras.layers import LSTM, Bidirectional, GlobalMaxPooling1D, GlobalAveragePooling1D  \n",
    "from keras.layers import Conv1D, AveragePooling1D, MaxPooling1D\n",
    "#from keras.ops import convert_to_tensor, convert_to_numpy\n",
    "#from keras.utils import plot_model\n",
    "from keras import activations\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from keras.callbacks import ModelCheckpoint, CSVLogger, EarlyStopping, LearningRateScheduler, ReduceLROnPlateau\n",
    "import math\n",
    "\n",
    "class LossHistory(tensorflow.keras.callbacks.Callback):  # history = LossHistory()\n",
    "    def init(self):  # history.init()\n",
    "        self.losses = []\n",
    "        # self.accs = []\n",
    "        self.val_losses = []\n",
    "        # self.val_accs = []\n",
    "        self.rmses = []\n",
    "        self.mses = []\n",
    "        self.maes = []\n",
    "        self.mapes = []\n",
    "        self.val_rmses = []\n",
    "        self.val_mses = []\n",
    "        self.val_maes = []\n",
    "        self.val_mapes = []\n",
    "\n",
    "    def on_epoch_end(self, batch, logs={}):\n",
    "        self.losses.append(logs.get('loss'))\n",
    "        # self.accs.append(logs.get('acc'))\n",
    "        self.val_losses.append(logs.get('val_loss'))\n",
    "        # self.val_accs.append(logs.get('val_accuracy\n",
    "        self.rmses.append(logs.get('root_mean_squared_error'))\n",
    "        self.mses.append(logs.get('mean_squared_error'))\n",
    "        self.maes.append(logs.get('mean_absolute_error'))\n",
    "        self.mapes.append(logs.get('mean_absolute_percentage_error'))\n",
    "        self.val_rmses.append(logs.get('val_root_mean_squared_error'))\n",
    "        self.val_mses.append(logs.get('val_mean_squared_error'))\n",
    "        self.val_maes.append(logs.get('val_mean_absolute_error'))\n",
    "        self.val_mapes.append(logs.get('val_mean_absolute_percentage_error'))\n",
    "\n",
    "\n",
    "\n",
    "def root_squared_mean_error(y_true, y_pred):\n",
    "    return K.mean((K.abs(y_pred - y_true))*K.square(y_true-K.mean(y_true)))*100\n",
    "\n",
    "def mse_mae(y_true, y_pred):\n",
    "    return K.mean(K.square(y_pred - y_true))+K.mean(K.abs(y_pred - y_true))\n",
    "\n",
    "from keras.layers.advanced_activations import PReLU\n",
    "\n",
    "def mean_absolute_percentage_error(y_true, y_pred):\n",
    "    y_true, y_pred = np.array(y_true), np.array(y_pred)\n",
    "    return np.mean(np.abs((y_true - y_pred) / y_true)) * 100\n",
    "\n",
    "def root_mean_squared_error(y_true, y_pred):\n",
    "        return K.sqrt(K.mean(K.square(y_pred - y_true))) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "44218208",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]\n"
     ]
    }
   ],
   "source": [
    "import scipy as sc\n",
    "import os\n",
    "\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = '0' # 여러개 사용시 '0,1,2' 식으로 하나의 문자열에 입력\n",
    "gpus = tf.config.experimental.list_physical_devices('GPU') # 호스트 러나임에 표시되는 GPU 장치 목록 반환\n",
    "\n",
    "if gpus: # 반환된 GPU 장치 목록이 있다면\n",
    "    try: # 해당 장치에 대한 메모리 증가 활성화 여부 설정\n",
    "        tf.config.experimental.set_memory_growth(gpus[0], True)\n",
    "    except RuntimeError as e: # try문 실패시에 에러문구 출력\n",
    "        print(e)\n",
    "\n",
    "print(tf.config.list_physical_devices('GPU'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f6d301dd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Year</th>\n",
       "      <th>Wind Change</th>\n",
       "      <th>Wind Output</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2020</td>\n",
       "      <td>0.620197</td>\n",
       "      <td>0.644724</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2020</td>\n",
       "      <td>0.544580</td>\n",
       "      <td>0.658617</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2020</td>\n",
       "      <td>0.570751</td>\n",
       "      <td>0.683924</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2020</td>\n",
       "      <td>0.599594</td>\n",
       "      <td>0.721813</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2020</td>\n",
       "      <td>0.495246</td>\n",
       "      <td>0.714187</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35058</th>\n",
       "      <td>2023</td>\n",
       "      <td>0.774643</td>\n",
       "      <td>0.484984</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35059</th>\n",
       "      <td>2023</td>\n",
       "      <td>0.735512</td>\n",
       "      <td>0.582157</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35060</th>\n",
       "      <td>2023</td>\n",
       "      <td>0.601593</td>\n",
       "      <td>0.620917</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35061</th>\n",
       "      <td>2023</td>\n",
       "      <td>0.536583</td>\n",
       "      <td>0.631322</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35062</th>\n",
       "      <td>2023</td>\n",
       "      <td>0.454969</td>\n",
       "      <td>0.606127</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>35063 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Year  Wind Change  Wind Output\n",
       "0      2020     0.620197     0.644724\n",
       "1      2020     0.544580     0.658617\n",
       "2      2020     0.570751     0.683924\n",
       "3      2020     0.599594     0.721813\n",
       "4      2020     0.495246     0.714187\n",
       "...     ...          ...          ...\n",
       "35058  2023     0.774643     0.484984\n",
       "35059  2023     0.735512     0.582157\n",
       "35060  2023     0.601593     0.620917\n",
       "35061  2023     0.536583     0.631322\n",
       "35062  2023     0.454969     0.606127\n",
       "\n",
       "[35063 rows x 3 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_path = 'C:/Users/smartgrid_AI/Desktop/windpower_ramprate/ercot_2020.csv'\n",
    "data_source1 = pd.read_csv(data_path)\n",
    "dat_source1 = pd.DataFrame(data_source1)\n",
    "#dat_source1 = dat_source1.iloc[:-3,:]\n",
    "\n",
    "data_path = 'C:/Users/smartgrid_AI/Desktop/windpower_ramprate/ercot_2021.csv'\n",
    "data_source2 = pd.read_csv(data_path)\n",
    "dat_source2 = pd.DataFrame(data_source2)\n",
    "dat_source2 = dat_source2.iloc[:8761,:9]\n",
    "\n",
    "data_path = 'C:/Users/smartgrid_AI/Desktop/windpower_ramprate/ercot_2022.csv'\n",
    "data_source3 = pd.read_csv(data_path)\n",
    "dat_source3 = pd.DataFrame(data_source3)\n",
    "dat_source3 = dat_source3.iloc[:8760,:9]\n",
    "\n",
    "data_path = 'C:/Users/smartgrid_AI/Desktop/windpower_ramprate/ercot_2023.csv'\n",
    "data_source4 = pd.read_csv(data_path)\n",
    "dat_source4 = pd.DataFrame(data_source4)\n",
    "dat_source4 = dat_source4.iloc[:8760,:9]\n",
    "\n",
    "dat_arr1 = np.array(dat_source1)\n",
    "dat_arr2 = np.array(dat_source2)\n",
    "dat_arr3 = np.array(dat_source3)\n",
    "dat_arr4 = np.array(dat_source4)\n",
    "\n",
    "dat_arr = np.concatenate([dat_arr1, dat_arr2, dat_arr3, dat_arr4],axis=0)\n",
    "dat_arr.shape # 8784, 8761, 8760, 8760\n",
    "\n",
    "dat_source = pd.DataFrame(dat_arr, columns=['Time-Date stamp','Date','ERCOT Load','Total Wind Output','Total Wind Installed','Wind Output, % of Load','Wind Output, % of Installed','1-hr MW change','1-hr % change'])\n",
    "dat = pd.DataFrame()\n",
    "dat['MW % change'] = np.array(dat_source.iloc[1:,3], dtype=float)-np.array(dat_source.iloc[0:-1,3], dtype=float)\n",
    "dat['MW % change'] = np.divide(np.array(dat['MW % change']),np.array(dat_source.iloc[1:,4]))*100\n",
    "dat['Total Wind Output'] = np.divide(np.array(dat_source.iloc[1:,3]), np.array(dat_source.iloc[1:,4]))\n",
    "\n",
    "ramp_ratio = 20\n",
    "load_ratio = 10\n",
    "year_arr = np.concatenate([np.ones(8784)*2020, np.ones(8760)*2021, np.ones(8760)*2022, np.ones(8760)*2023])\n",
    "year_df = pd.DataFrame(year_arr, columns=['Year'], dtype=int)\n",
    "wind_df = pd.concat([year_df, dat], axis=1)\n",
    "wind_df = wind_df.reset_index(drop=True)\n",
    "\n",
    "std_scaler = sklearn.preprocessing.MinMaxScaler()\n",
    "std_scaler_load = sklearn.preprocessing.MinMaxScaler()\n",
    "std_scaler_ramp = sklearn.preprocessing.MinMaxScaler()\n",
    "\n",
    "wind_df[['Total Wind Output']] = std_scaler.fit_transform(wind_df[['Total Wind Output']])\n",
    "wind_df[['MW % change']] = std_scaler_ramp.fit_transform(wind_df[['MW % change']])\n",
    "wind_df = wind_df.iloc[:-1,:]\n",
    "ramp_df = pd.DataFrame(wind_df)\n",
    "ramp_df.columns=['Year', 'Wind Change', 'Wind Output']\n",
    "ramp_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6b796ae9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_dataset(dataset, timesteps, output_timesteps, leadtime):\n",
    "    dataX, dataY = [], []\n",
    "    for i in range(len(dataset) - timesteps -output_timesteps - leadtime - 1):\n",
    "        a = dataset[i:(i + timesteps), :]\n",
    "        dataX.append(a)\n",
    "        dataY.append(dataset[(i + timesteps + leadtime):(i+timesteps+output_timesteps+leadtime), :])\n",
    "    return np.array(dataX), np.array(dataY)\n",
    "\n",
    "def svdadd(X, start, end, b_size):\n",
    "    dec_x = X[start:end, :, :]\n",
    "    U, S, Vh = svd(dec_x.reshape(b_size, -1), full_matrices=True)\n",
    "\n",
    "    high_sig = np.matmul(np.matmul(U[:,:high_ind], np.diag(S[0:high_ind])), Vh[:high_ind,:])\n",
    "    low_sig = X[:dec_num, :, :].reshape(b_size,-1)-high_sig\n",
    "\n",
    "    rec_x = np.zeros((b_size, b_size, high_ind))\n",
    "    \n",
    "    for i in range(high_ind):\n",
    "        rec_x[:,:,i] = np.matmul((U[:,i]*S[i]).reshape(-1,1), Vh[i,:].reshape(1,-1))    \n",
    "    return rec_x, low_sig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "97cecb29",
   "metadata": {},
   "outputs": [],
   "source": [
    "norm_df = np.array(wind_df.iloc[:,1]).reshape(-1,1)\n",
    "timesteps = 24*7\n",
    "output_timesteps = 24\n",
    "leadtime = 6\n",
    "num_features = 1\n",
    "X, Y = create_dataset(norm_df, timesteps, output_timesteps, leadtime)\n",
    "b_size = timesteps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2a055f60",
   "metadata": {},
   "outputs": [],
   "source": [
    "dec_num = timesteps\n",
    "high_ind = 35\n",
    "\n",
    "addX = np.zeros((X.shape[0], dec_num, high_ind+1))\n",
    "\n",
    "for k in range(X.shape[0]//dec_num):\n",
    "    rec_x, low_sig = svdadd(X, k*dec_num, (k+1)*dec_num, b_size)\n",
    "    addX[k*dec_num:k*dec_num+dec_num,:, :-1] = rec_x\n",
    "    addX[k*dec_num:k*dec_num+dec_num,:, -1] = low_sig\n",
    "    \n",
    "rec_x, low_sig = svdadd(X, X.shape[0]-dec_num, X.shape[0], b_size)\n",
    "addX[X.shape[0]-dec_num:X.shape[0], :, :-1] = rec_x\n",
    "addX[X.shape[0]-dec_num:X.shape[0],:, -1] = low_sig\n",
    "\n",
    "addX_det = addX[:, :, :-1]\n",
    "addX_det = np.sum(addX_det, axis=2)\n",
    "X = np.concatenate([X, addX], axis=2)\n",
    "num_features = X.shape[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a52dd6eb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((31377, 168, 37), (31377, 24), (3487, 168, 37), (3487, 24))"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trvaX, teX, trvaY, teY = train_test_split(X, Y, test_size=0.1, shuffle=False)\n",
    "\n",
    "idx = np.arange(trvaX.shape[0])\n",
    "np.random.shuffle(idx)\n",
    "strvaX = trvaX[idx]\n",
    "strvaY = trvaY[idx]\n",
    "strvaY = strvaY.reshape(-1, output_timesteps)\n",
    "\n",
    "trvaY = trvaY.reshape(-1, output_timesteps)\n",
    "teY = teY.reshape(-1, output_timesteps)\n",
    "\n",
    "strX, svaX, strY, svaY = train_test_split(strvaX, strvaY, test_size=0.3, shuffle=False)\n",
    "trX, vaX, trY, vaY = train_test_split(trvaX, trvaY, test_size=0.3, shuffle=False)\n",
    "\n",
    "trvaX.shape, trvaY.shape, teX.shape, teY.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9515d133",
   "metadata": {},
   "outputs": [],
   "source": [
    "def MAEMD(y_true, y_pred):\n",
    "    return K.mean((K.abs(y_pred - y_true))*K.square(y_true-K.mean(y_true)))*100"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92787b1a",
   "metadata": {},
   "source": [
    "## PatchMixer - With SVD With Shuffling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "568f8a64",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "import numpy as np\n",
    "\n",
    "# PatchMixerLayer definition\n",
    "class PatchMixerLayer(keras.layers.Layer):\n",
    "    def __init__(self, dim, a, kernel_size=8):\n",
    "        super(PatchMixerLayer, self).__init__()\n",
    "        self.resnet = keras.Sequential([\n",
    "            layers.Conv1D(dim, kernel_size, groups=dim, padding=\"same\"),\n",
    "            layers.Activation(\"gelu\"),\n",
    "            layers.BatchNormalization()\n",
    "        ])\n",
    "        self.conv_1x1 = keras.Sequential([\n",
    "            layers.Conv1D(a, 1),\n",
    "            layers.Activation(\"gelu\"),\n",
    "            layers.BatchNormalization()\n",
    "        ])\n",
    "    \n",
    "    def call(self, x):\n",
    "        x = x + self.resnet(x)\n",
    "        x = self.conv_1x1(x)\n",
    "        return x\n",
    "\n",
    "# RevIN implementation\n",
    "class RevIN(layers.Layer):\n",
    "    def __init__(self, num_features, eps=1e-5, affine=True, subtract_last=False):\n",
    "        super(RevIN, self).__init__()\n",
    "        self.num_features = num_features\n",
    "        self.eps = eps\n",
    "        self.affine = affine\n",
    "        self.subtract_last = subtract_last\n",
    "        if self.affine:\n",
    "            self.affine_weight = self.add_weight(shape=(num_features,), initializer=\"ones\", trainable=True)\n",
    "            self.affine_bias = self.add_weight(shape=(num_features,), initializer=\"zeros\", trainable=True)\n",
    "    \n",
    "    def call(self, x, mode):\n",
    "        if mode == \"norm\":\n",
    "            return self._normalize(x)\n",
    "        elif mode == \"denorm\":\n",
    "            return self._denormalize(x)\n",
    "        else:\n",
    "            raise NotImplementedError\n",
    "\n",
    "    def _normalize(self, x):\n",
    "        mean = tf.reduce_mean(x, axis=(1, 2), keepdims=True)\n",
    "        stdev = tf.math.sqrt(tf.reduce_variance(x, axis=(1, 2), keepdims=True) + self.eps)\n",
    "        if self.subtract_last:\n",
    "            last = tf.expand_dims(x[:, -1, :], axis=1)\n",
    "            x = (x - last) / stdev\n",
    "        else:\n",
    "            x = (x - mean) / stdev\n",
    "        if self.affine:\n",
    "            x = x * self.affine_weight + self.affine_bias\n",
    "        return x\n",
    "\n",
    "    def _denormalize(self, x):\n",
    "        if self.affine:\n",
    "            x = (x - self.affine_bias) / self.affine_weight\n",
    "        stdev = tf.math.sqrt(tf.reduce_variance(x, axis=(1, 2), keepdims=True) + self.eps)\n",
    "        mean = tf.reduce_mean(x, axis=(1, 2), keepdims=True)\n",
    "        x = x * stdev + mean\n",
    "        return x\n",
    "\n",
    "# Main PatchMixer model definition\n",
    "class PatchMixerModel(keras.Model):\n",
    "    def __init__(self, input_shape, patch_size, stride, d_model, depth, kernel_size, forecasting, head_dropout):\n",
    "        super(PatchMixerModel, self).__init__()\n",
    "        self.lookback = input_shape[1]\n",
    "        self.patch_size = patch_size\n",
    "        self.stride = stride\n",
    "        self.patch_num = (self.lookback - self.patch_size) // self.stride + 1\n",
    "        self.d_model = d_model\n",
    "        self.depth = depth\n",
    "        self.kernel_size = kernel_size\n",
    "        self.forecasting = forecasting\n",
    "        self.head_dropout = head_dropout\n",
    "\n",
    "        self.patch_mixer_blocks = [PatchMixerLayer(self.patch_num, self.patch_num, kernel_size) for _ in range(depth)]\n",
    "        self.W_P = layers.Dense(d_model)\n",
    "        \n",
    "        self.head0 = keras.Sequential([\n",
    "            layers.Flatten(),\n",
    "            layers.Dense(forecasting),\n",
    "            layers.Dropout(head_dropout)\n",
    "        ])\n",
    "        self.head1 = keras.Sequential([\n",
    "            layers.Flatten(),\n",
    "            layers.Dense(forecasting * 2, activation=\"gelu\"),\n",
    "            layers.Dropout(head_dropout),\n",
    "            layers.Dense(forecasting),\n",
    "            layers.Dropout(head_dropout)\n",
    "        ])\n",
    "    \n",
    "    def call(self, x):\n",
    "        batch_size = tf.shape(x)[0]\n",
    "        x = tf.transpose(x, perm=[0, 2, 1])\n",
    "        x_padded = tf.image.extract_patches(\n",
    "            images=tf.expand_dims(x, axis=-1),\n",
    "            sizes=[1, self.patch_size, 1, 1],\n",
    "            strides=[1, self.stride, 1, 1],\n",
    "            rates=[1, 1, 1, 1],\n",
    "            padding=\"VALID\"\n",
    "        )\n",
    "        #print(x_padded.shape)\n",
    "        x = self.W_P(x_padded)\n",
    "        x = tf.reshape(x, (batch_size, -1, self.d_model))\n",
    "        u = self.head0(x)\n",
    "        #print(x.shape, (self.lookback - self.patch_size),self.stride, self.patch_num)\n",
    "        for block in self.patch_mixer_blocks:\n",
    "            x = block(x)\n",
    "        x = self.head1(x)\n",
    "        return u + x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "1f990a1d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"patch_mixer_model_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "patch_mixer_layer_8 (PatchMi multiple                  1683      \n",
      "_________________________________________________________________\n",
      "patch_mixer_layer_9 (PatchMi multiple                  1683      \n",
      "_________________________________________________________________\n",
      "patch_mixer_layer_10 (PatchM multiple                  1683      \n",
      "_________________________________________________________________\n",
      "patch_mixer_layer_11 (PatchM multiple                  1683      \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              multiple                  297       \n",
      "_________________________________________________________________\n",
      "sequential_28 (Sequential)   (168, 24)                 798360    \n",
      "_________________________________________________________________\n",
      "sequential_29 (Sequential)   (168, 24)                 1597896   \n",
      "=================================================================\n",
      "Total params: 2,403,285\n",
      "Trainable params: 2,402,757\n",
      "Non-trainable params: 528\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "input_shape = (None, 168, 37)  # Example input shape\n",
    "\n",
    "with tf.device('/gpu:0'):\n",
    "    model = PatchMixerModel(\n",
    "        input_shape=input_shape,\n",
    "        patch_size=8,\n",
    "        stride=5,\n",
    "        d_model=33,\n",
    "        depth=4,\n",
    "        kernel_size=8,\n",
    "        forecasting=24,\n",
    "        head_dropout=0.1)\n",
    "    model.build(input_shape=(168, 168, 37))\n",
    "    model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "3ebbf798",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6246"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "757cf39b",
   "metadata": {},
   "outputs": [],
   "source": [
    "    model.compile(loss=MAEMD, optimizer='adam', metrics=['mse','mae', MAEMD])\n",
    "    early_stopping =EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)\n",
    "    batch_size = 168\n",
    "    epochs = 1000\n",
    "    history = LossHistory()\n",
    "    history.init()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "a125ea7b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "  6/131 [>.............................] - ETA: 19s - loss: 0.7767 - mse: 1.0228 - mae: 0.7231 - MAEMD: 0.7767 ETA: 21s - loss: 0.9708 - mse: 1.4377 - mae: 0.9040 - MAEMD: 0.WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0671s vs `on_train_batch_end` time: 0.0946s). Check your callbacks.\n",
      "131/131 [==============================] - 27s 185ms/step - loss: 0.2283 - mse: 0.0949 - mae: 0.1889 - MAEMD: 0.2282 - val_loss: 0.1459 - val_mse: 0.0175 - val_mae: 0.1046 - val_MAEMD: 0.1470\n",
      "Epoch 2/1000\n",
      "131/131 [==============================] - 24s 182ms/step - loss: 0.1725 - mse: 0.0420 - mae: 0.1467 - MAEMD: 0.1724 - val_loss: 0.1496 - val_mse: 0.0196 - val_mae: 0.1115 - val_MAEMD: 0.1516\n",
      "Epoch 3/1000\n",
      "131/131 [==============================] - 24s 183ms/step - loss: 0.1610 - mse: 0.0375 - mae: 0.1401 - MAEMD: 0.1610 - val_loss: 0.1528 - val_mse: 0.0210 - val_mae: 0.1154 - val_MAEMD: 0.1543\n",
      "Epoch 4/1000\n",
      "131/131 [==============================] - 24s 183ms/step - loss: 0.1511 - mse: 0.0344 - mae: 0.1341 - MAEMD: 0.1511 - val_loss: 0.1393 - val_mse: 0.0167 - val_mae: 0.1016 - val_MAEMD: 0.1408\n",
      "Epoch 5/1000\n",
      "131/131 [==============================] - 24s 181ms/step - loss: 0.1454 - mse: 0.0327 - mae: 0.1316 - MAEMD: 0.1453 - val_loss: 0.1389 - val_mse: 0.0167 - val_mae: 0.1018 - val_MAEMD: 0.1402\n",
      "Epoch 6/1000\n",
      "131/131 [==============================] - 24s 181ms/step - loss: 0.1408 - mse: 0.0318 - mae: 0.1305 - MAEMD: 0.1408 - val_loss: 0.1376 - val_mse: 0.0165 - val_mae: 0.1008 - val_MAEMD: 0.1390\n",
      "Epoch 7/1000\n",
      "131/131 [==============================] - 24s 182ms/step - loss: 0.1382 - mse: 0.0310 - mae: 0.1296 - MAEMD: 0.1381 - val_loss: 0.1354 - val_mse: 0.0161 - val_mae: 0.0990 - val_MAEMD: 0.1365\n",
      "Epoch 8/1000\n",
      "131/131 [==============================] - 24s 184ms/step - loss: 0.1375 - mse: 0.0308 - mae: 0.1297 - MAEMD: 0.1374 - val_loss: 0.1361 - val_mse: 0.0162 - val_mae: 0.0994 - val_MAEMD: 0.1374\n",
      "Epoch 9/1000\n",
      "131/131 [==============================] - 24s 184ms/step - loss: 0.1352 - mse: 0.0303 - mae: 0.1292 - MAEMD: 0.1352 - val_loss: 0.1378 - val_mse: 0.0171 - val_mae: 0.1026 - val_MAEMD: 0.1390\n",
      "Epoch 10/1000\n",
      "131/131 [==============================] - 24s 182ms/step - loss: 0.1342 - mse: 0.0300 - mae: 0.1290 - MAEMD: 0.1341 - val_loss: 0.1350 - val_mse: 0.0163 - val_mae: 0.0997 - val_MAEMD: 0.1362\n",
      "Epoch 11/1000\n",
      "131/131 [==============================] - 24s 183ms/step - loss: 0.1334 - mse: 0.0298 - mae: 0.1289 - MAEMD: 0.1333 - val_loss: 0.1343 - val_mse: 0.0163 - val_mae: 0.0998 - val_MAEMD: 0.1356\n",
      "Epoch 12/1000\n",
      "131/131 [==============================] - 24s 183ms/step - loss: 0.1323 - mse: 0.0296 - mae: 0.1288 - MAEMD: 0.1323 - val_loss: 0.1368 - val_mse: 0.0167 - val_mae: 0.1011 - val_MAEMD: 0.1381\n",
      "Epoch 13/1000\n",
      "131/131 [==============================] - 24s 182ms/step - loss: 0.1311 - mse: 0.0295 - mae: 0.1287 - MAEMD: 0.1310 - val_loss: 0.1378 - val_mse: 0.0174 - val_mae: 0.1034 - val_MAEMD: 0.1390\n",
      "Epoch 14/1000\n",
      "131/131 [==============================] - 24s 182ms/step - loss: 0.1308 - mse: 0.0295 - mae: 0.1288 - MAEMD: 0.1307 - val_loss: 0.1374 - val_mse: 0.0172 - val_mae: 0.1025 - val_MAEMD: 0.1386\n",
      "Epoch 15/1000\n",
      "131/131 [==============================] - 24s 182ms/step - loss: 0.1303 - mse: 0.0294 - mae: 0.1287 - MAEMD: 0.1303 - val_loss: 0.1364 - val_mse: 0.0171 - val_mae: 0.1023 - val_MAEMD: 0.1376\n",
      "Epoch 16/1000\n",
      "131/131 [==============================] - 24s 183ms/step - loss: 0.1297 - mse: 0.0294 - mae: 0.1288 - MAEMD: 0.1297 - val_loss: 0.1352 - val_mse: 0.0169 - val_mae: 0.1017 - val_MAEMD: 0.1364\n",
      "Epoch 17/1000\n",
      "131/131 [==============================] - 24s 184ms/step - loss: 0.1290 - mse: 0.0294 - mae: 0.1288 - MAEMD: 0.1290 - val_loss: 0.1358 - val_mse: 0.0171 - val_mae: 0.1021 - val_MAEMD: 0.1369\n",
      "Epoch 18/1000\n",
      "131/131 [==============================] - 24s 184ms/step - loss: 0.1286 - mse: 0.0294 - mae: 0.1288 - MAEMD: 0.1285 - val_loss: 0.1356 - val_mse: 0.0167 - val_mae: 0.1009 - val_MAEMD: 0.1367\n",
      "Epoch 19/1000\n",
      "131/131 [==============================] - 24s 182ms/step - loss: 0.1284 - mse: 0.0293 - mae: 0.1288 - MAEMD: 0.1283 - val_loss: 0.1372 - val_mse: 0.0175 - val_mae: 0.1036 - val_MAEMD: 0.1382\n",
      "Epoch 20/1000\n",
      "131/131 [==============================] - 24s 182ms/step - loss: 0.1278 - mse: 0.0294 - mae: 0.1290 - MAEMD: 0.1278 - val_loss: 0.1381 - val_mse: 0.0179 - val_mae: 0.1049 - val_MAEMD: 0.1391\n",
      "Epoch 21/1000\n",
      "131/131 [==============================] - 24s 183ms/step - loss: 0.1280 - mse: 0.0295 - mae: 0.1292 - MAEMD: 0.1279 - val_loss: 0.1392 - val_mse: 0.0182 - val_mae: 0.1058 - val_MAEMD: 0.1402\n",
      "Wall time: 8min 26s\n"
     ]
    }
   ],
   "source": [
    "    %%time\n",
    "    b_size = 168\n",
    "    hist = model.fit(strX, strY, epochs=epochs, batch_size=b_size, shuffle=False, validation_data=(svaX, svaY), callbacks=[history, early_stopping])  # , checkpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "fe5f6206",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "189554"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "dc992469",
   "metadata": {},
   "outputs": [],
   "source": [
    "#model3.save('SCINet', save_format='tf')\n",
    "testPredict = model.predict(teX, batch_size=b_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "62b61b78",
   "metadata": {},
   "outputs": [],
   "source": [
    "def npMAEMS(y_true, y_pred):\n",
    "    return np.mean((abs(y_pred - y_true))*np.square(y_true))*100\n",
    "def npMAEMD(y_true, y_pred):\n",
    "    return np.mean((abs(y_pred - y_true))*np.square(y_true-np.mean(y_true)))*100\n",
    "def npMSE(y_true, y_pred):\n",
    "    return np.mean(np.square(-y_true+y_pred))\n",
    "def npMAE(y_true, y_pred):\n",
    "    return np.mean(abs(-y_true+y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "93e464a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error Test Score > MSE ==  0.015372308671441997  MAE ==  0.09759434327142198  MAEMD ==  0.1141773134758004\n"
     ]
    }
   ],
   "source": [
    "tePredict = testPredict.reshape(-1)\n",
    "testY = teY.reshape(-1)\n",
    "print('Error Test Score > MSE == ', npMSE(testY, tePredict), ' MAE == ', npMAE(testY, tePredict), ' MAEMD == ', npMAEMD(testY, tePredict))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bafcf1f",
   "metadata": {},
   "source": [
    "## Without Shuffling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "44529f25",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"patch_mixer_model_3\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "patch_mixer_layer_12 (PatchM multiple                  1683      \n",
      "_________________________________________________________________\n",
      "patch_mixer_layer_13 (PatchM multiple                  1683      \n",
      "_________________________________________________________________\n",
      "patch_mixer_layer_14 (PatchM multiple                  1683      \n",
      "_________________________________________________________________\n",
      "patch_mixer_layer_15 (PatchM multiple                  1683      \n",
      "_________________________________________________________________\n",
      "dense_12 (Dense)             multiple                  297       \n",
      "_________________________________________________________________\n",
      "sequential_38 (Sequential)   (168, 24)                 798360    \n",
      "_________________________________________________________________\n",
      "sequential_39 (Sequential)   (168, 24)                 1597896   \n",
      "=================================================================\n",
      "Total params: 2,403,285\n",
      "Trainable params: 2,402,757\n",
      "Non-trainable params: 528\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "input_shape = (None, 168, 37)  # Example input shape\n",
    "\n",
    "with tf.device('/gpu:0'):\n",
    "    model2 = PatchMixerModel(\n",
    "        input_shape=input_shape,\n",
    "        patch_size=8,\n",
    "        stride=5,\n",
    "        d_model=33,\n",
    "        depth=4,\n",
    "        kernel_size=8,\n",
    "        forecasting=24,\n",
    "        head_dropout=0.1)\n",
    "    model2.build(input_shape=(168, 168, 37))\n",
    "    model2.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "bc211dee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6246"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "826d0c0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "    model2.compile(loss=MAEMD, optimizer='adam', metrics=['mse','mae', MAEMD])\n",
    "    early_stopping2 =EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)\n",
    "    batch_size = 168\n",
    "    epochs = 1000\n",
    "    history2 = LossHistory()\n",
    "    history2.init()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "32e36a70",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "  6/131 [>.............................] - ETA: 45s - loss: 0.1730 - mse: 0.0352 - mae: 0.1456 - MAEMD: 0.1730WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0295s vs `on_train_batch_end` time: 0.2809s). Check your callbacks.\n",
      "131/131 [==============================] - 24s 167ms/step - loss: 0.1452 - mse: 0.0314 - mae: 0.1342 - MAEMD: 0.1451 - val_loss: 0.1211 - val_mse: 0.0167 - val_mae: 0.1014 - val_MAEMD: 0.1225\n",
      "Epoch 2/1000\n",
      "131/131 [==============================] - 21s 164ms/step - loss: 0.1452 - mse: 0.0315 - mae: 0.1341 - MAEMD: 0.1452 - val_loss: 21.4141 - val_mse: 903.2235 - val_mae: 23.6605 - val_MAEMD: 21.6723\n",
      "Epoch 3/1000\n",
      "131/131 [==============================] - 21s 153ms/step - loss: 0.1439 - mse: 0.0326 - mae: 0.1335 - MAEMD: 0.1438 - val_loss: 2.6596 - val_mse: 14.7181 - val_mae: 2.8725 - val_MAEMD: 2.7123\n",
      "Epoch 4/1000\n",
      "131/131 [==============================] - 21s 164ms/step - loss: 0.1423 - mse: 0.0305 - mae: 0.1324 - MAEMD: 0.1422 - val_loss: 0.1235 - val_mse: 0.0182 - val_mae: 0.1061 - val_MAEMD: 0.1250\n",
      "Epoch 5/1000\n",
      "131/131 [==============================] - 21s 164ms/step - loss: 0.1413 - mse: 0.0305 - mae: 0.1323 - MAEMD: 0.1412 - val_loss: 0.1222 - val_mse: 0.0178 - val_mae: 0.1047 - val_MAEMD: 0.1235\n",
      "Epoch 6/1000\n",
      "131/131 [==============================] - 21s 164ms/step - loss: 0.1412 - mse: 0.0305 - mae: 0.1324 - MAEMD: 0.1411 - val_loss: 0.1224 - val_mse: 0.0179 - val_mae: 0.1051 - val_MAEMD: 0.1237\n",
      "Epoch 7/1000\n",
      "131/131 [==============================] - 21s 164ms/step - loss: 0.1400 - mse: 0.0305 - mae: 0.1323 - MAEMD: 0.1400 - val_loss: 0.1227 - val_mse: 0.0179 - val_mae: 0.1051 - val_MAEMD: 0.1242\n",
      "Epoch 8/1000\n",
      "131/131 [==============================] - 21s 164ms/step - loss: 0.1389 - mse: 0.0304 - mae: 0.1321 - MAEMD: 0.1388 - val_loss: 0.1221 - val_mse: 0.0177 - val_mae: 0.1045 - val_MAEMD: 0.1234\n",
      "Epoch 9/1000\n",
      "131/131 [==============================] - 22s 165ms/step - loss: 0.1392 - mse: 0.0304 - mae: 0.1320 - MAEMD: 0.1391 - val_loss: 0.1236 - val_mse: 0.0182 - val_mae: 0.1062 - val_MAEMD: 0.1249\n",
      "Epoch 10/1000\n",
      "131/131 [==============================] - 21s 164ms/step - loss: 0.1378 - mse: 0.0304 - mae: 0.1319 - MAEMD: 0.1377 - val_loss: 0.1230 - val_mse: 0.0182 - val_mae: 0.1059 - val_MAEMD: 0.1243\n",
      "Epoch 11/1000\n",
      "131/131 [==============================] - 21s 164ms/step - loss: 0.1373 - mse: 0.0304 - mae: 0.1319 - MAEMD: 0.1373 - val_loss: 0.1238 - val_mse: 0.0184 - val_mae: 0.1065 - val_MAEMD: 0.1252\n",
      "Wall time: 3min 58s\n"
     ]
    }
   ],
   "source": [
    "    %%time\n",
    "    hist2 = model2.fit(trX, trY, epochs=epochs, batch_size=b_size, shuffle=False, validation_data=(vaX, vaY), callbacks=[history2, early_stopping2])  # , checkpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "e2d102ac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "714"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "b8768f4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "testPredict2 = model2.predict(teX, batch_size=b_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "0a1d4b93",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error Test Score > MSE ==  0.015372308671441997  MAE ==  0.09759434327142198  MAEMD ==  0.1141773134758004\n",
      "Error Test Score > MSE ==  0.01731172370530455  MAE ==  0.104071741798158  MAEMD ==  0.12051458036421082\n"
     ]
    }
   ],
   "source": [
    "tePredict2 = testPredict2.reshape(-1)\n",
    "testY = teY.reshape(-1)\n",
    "print('Error Test Score > MSE == ', npMSE(testY, tePredict), ' MAE == ', npMAE(testY, tePredict), ' MAEMD == ', npMAEMD(testY, tePredict))\n",
    "print('Error Test Score > MSE == ', npMSE(testY, tePredict2), ' MAE == ', npMAE(testY, tePredict2), ' MAEMD == ', npMAEMD(testY, tePredict2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "bca7a546",
   "metadata": {},
   "outputs": [],
   "source": [
    "from statsmodels.stats.diagnostic import acorr_ljungbox\n",
    "from scipy.stats import norm\n",
    "\n",
    "def diebold_mariano_test(forecast1, forecast2, actual, opt): \n",
    "    \n",
    "    if opt==0: # MSE\n",
    "        e1 = actual-forecast1\n",
    "        e2 = actual-forecast2\n",
    "        d = e1**2 - e2**2\n",
    "    elif opt==1: # MAE\n",
    "        e1 = abs(actual-forecast1)\n",
    "        e2 = abs(actual-forecast2)\n",
    "        d = e1 - e2\n",
    "    else:\n",
    "        e1 = np.multiply(abs(actual - forecast1), np.square(actual-np.mean(actual)))\n",
    "        e2 = np.multiply(abs(actual - forecast2), np.square(actual-np.mean(actual)))\n",
    "        d = e1-e2\n",
    "    \n",
    "    # Mean of the loss differentials\n",
    "    mean_d = np.mean(d)\n",
    "    \n",
    "    # Standard deviation of the loss differentials\n",
    "    std_d = np.std(d, ddof=1)\n",
    "    \n",
    "    # Calculate the test statistic\n",
    "    test_stat = (mean_d / std_d) * np.sqrt(len(d))\n",
    "    \n",
    "    # Calculate the p-value using a two-tailed test\n",
    "    p_value = 2 * (1 - norm.cdf(abs(test_stat)))\n",
    "    \n",
    "    return test_stat, p_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "a68a9d0b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((-6.022194600501482, 1.7206782665368792e-09),\n",
       " (-5.873473391046085, 4.267575626215603e-09),\n",
       " (-2.876314077657889, 0.004023491454638872))"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "diebold_mariano_test(testPredict, testPredict2, teY, 0), diebold_mariano_test(testPredict, testPredict2, teY, 1), diebold_mariano_test(testPredict, testPredict2, teY, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "e6b4dd66",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.savetxt('PatchMixer_prop', testPredict)\n",
    "np.savetxt('PatchMixer_woshuffling', testPredict2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc2bd990",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
