{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "13931864",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "from time import time\n",
    "import json\n",
    "import logging\n",
    "\n",
    "import tensorflow as tf\n",
    "import keras\n",
    "from keras import layers\n",
    "from keras.models import Model\n",
    "from keras.models import load_model\n",
    "from keras.models import Sequential\n",
    "from keras.callbacks import EarlyStopping, TensorBoard, ModelCheckpoint\n",
    "from keras.callbacks import Callback\n",
    "\n",
    "from sklearn.metrics import r2_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "da211a5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "import pandas as pd\n",
    "import codecs\n",
    "import numpy as np\n",
    "import math\n",
    "import csv\n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.metrics import recall_score, precision_score # New\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn import preprocessing\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow.keras.preprocessing\n",
    "#from tensorflow.keras.callbacks import ModelCheckpoint, CSVLogger, EarlyStopping, LearningRateScheduler, ReduceLROnPlateau\n",
    "from tensorflow.keras.models import Sequential, Model\n",
    "from tensorflow.keras.layers import Dense, Input, Flatten, Add, Multiply, Subtract\n",
    "from tensorflow.keras import backend as K\n",
    "from tensorflow.keras.layers import Activation, BatchNormalization\n",
    "# regularizers\n",
    "from tensorflow.keras.layers import Conv1D, Conv2D\n",
    "from tensorflow.keras.layers import MaxPooling1D\n",
    "from tensorflow.keras.layers import concatenate\n",
    "from tensorflow.keras.layers import LSTM, Bidirectional\n",
    "from tensorflow.keras.utils import plot_model\n",
    "from tensorflow.keras.layers import Dropout, SpatialDropout1D\n",
    "from scipy import signal\n",
    "import openpyxl\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "from matplotlib import pylab as plt\n",
    "import matplotlib.dates as mdates\n",
    "import seaborn as sns\n",
    "import sklearn\n",
    "from sklearn.model_selection import train_test_split\n",
    "from numpy.linalg import svd\n",
    "import gc\n",
    "from keijzer import *\n",
    "from tensorflow import keras\n",
    "from keras.models import Model\n",
    "from keras.layers import *\n",
    "from tensorflow.keras.optimizers import Adam,SGD\n",
    "from keras.layers import Dense, Input, Flatten, Add, concatenate, Dropout, Activation, Multiply, Embedding, Layer, Reshape\n",
    "from keras.layers import LSTM, Bidirectional, GlobalMaxPooling1D, GlobalAveragePooling1D  \n",
    "from keras.layers import Conv1D, AveragePooling1D, MaxPooling1D\n",
    "#from keras.ops import convert_to_tensor, convert_to_numpy\n",
    "#from keras.utils import plot_model\n",
    "from keras import activations\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from keras.callbacks import ModelCheckpoint, CSVLogger, EarlyStopping, LearningRateScheduler, ReduceLROnPlateau\n",
    "import math\n",
    "\n",
    "class LossHistory(tensorflow.keras.callbacks.Callback):  # history = LossHistory()\n",
    "    def init(self):  # history.init()\n",
    "        self.losses = []\n",
    "        # self.accs = []\n",
    "        self.val_losses = []\n",
    "        # self.val_accs = []\n",
    "        self.rmses = []\n",
    "        self.mses = []\n",
    "        self.maes = []\n",
    "        self.mapes = []\n",
    "        self.val_rmses = []\n",
    "        self.val_mses = []\n",
    "        self.val_maes = []\n",
    "        self.val_mapes = []\n",
    "\n",
    "    def on_epoch_end(self, batch, logs={}):\n",
    "        self.losses.append(logs.get('loss'))\n",
    "        # self.accs.append(logs.get('acc'))\n",
    "        self.val_losses.append(logs.get('val_loss'))\n",
    "        # self.val_accs.append(logs.get('val_accuracy\n",
    "        self.rmses.append(logs.get('root_mean_squared_error'))\n",
    "        self.mses.append(logs.get('mean_squared_error'))\n",
    "        self.maes.append(logs.get('mean_absolute_error'))\n",
    "        self.mapes.append(logs.get('mean_absolute_percentage_error'))\n",
    "        self.val_rmses.append(logs.get('val_root_mean_squared_error'))\n",
    "        self.val_mses.append(logs.get('val_mean_squared_error'))\n",
    "        self.val_maes.append(logs.get('val_mean_absolute_error'))\n",
    "        self.val_mapes.append(logs.get('val_mean_absolute_percentage_error'))\n",
    "\n",
    "\n",
    "\n",
    "def root_squared_mean_error(y_true, y_pred):\n",
    "    return K.mean((K.abs(y_pred - y_true))*K.square(y_true-K.mean(y_true)))*100\n",
    "\n",
    "def mse_mae(y_true, y_pred):\n",
    "    return K.mean(K.square(y_pred - y_true))+K.mean(K.abs(y_pred - y_true))\n",
    "\n",
    "from keras.layers.advanced_activations import PReLU\n",
    "\n",
    "def mean_absolute_percentage_error(y_true, y_pred):\n",
    "    y_true, y_pred = np.array(y_true), np.array(y_pred)\n",
    "    return np.mean(np.abs((y_true - y_pred) / y_true)) * 100\n",
    "\n",
    "def root_mean_squared_error(y_true, y_pred):\n",
    "        return K.sqrt(K.mean(K.square(y_pred - y_true))) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1c443aa1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]\n"
     ]
    }
   ],
   "source": [
    "import scipy as sc\n",
    "import os\n",
    "\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = '0' # 여러개 사용시 '0,1,2' 식으로 하나의 문자열에 입력\n",
    "gpus = tf.config.experimental.list_physical_devices('GPU') # 호스트 러나임에 표시되는 GPU 장치 목록 반환\n",
    "\n",
    "if gpus: # 반환된 GPU 장치 목록이 있다면\n",
    "    try: # 해당 장치에 대한 메모리 증가 활성화 여부 설정\n",
    "        tf.config.experimental.set_memory_growth(gpus[0], True)\n",
    "    except RuntimeError as e: # try문 실패시에 에러문구 출력\n",
    "        print(e)\n",
    "\n",
    "print(tf.config.list_physical_devices('GPU'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "110a8681",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Year</th>\n",
       "      <th>Wind Change</th>\n",
       "      <th>Wind Output</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2020</td>\n",
       "      <td>0.620197</td>\n",
       "      <td>0.644724</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2020</td>\n",
       "      <td>0.544580</td>\n",
       "      <td>0.658617</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2020</td>\n",
       "      <td>0.570751</td>\n",
       "      <td>0.683924</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2020</td>\n",
       "      <td>0.599594</td>\n",
       "      <td>0.721813</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2020</td>\n",
       "      <td>0.495246</td>\n",
       "      <td>0.714187</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35058</th>\n",
       "      <td>2023</td>\n",
       "      <td>0.774643</td>\n",
       "      <td>0.484984</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35059</th>\n",
       "      <td>2023</td>\n",
       "      <td>0.735512</td>\n",
       "      <td>0.582157</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35060</th>\n",
       "      <td>2023</td>\n",
       "      <td>0.601593</td>\n",
       "      <td>0.620917</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35061</th>\n",
       "      <td>2023</td>\n",
       "      <td>0.536583</td>\n",
       "      <td>0.631322</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35062</th>\n",
       "      <td>2023</td>\n",
       "      <td>0.454969</td>\n",
       "      <td>0.606127</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>35063 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Year  Wind Change  Wind Output\n",
       "0      2020     0.620197     0.644724\n",
       "1      2020     0.544580     0.658617\n",
       "2      2020     0.570751     0.683924\n",
       "3      2020     0.599594     0.721813\n",
       "4      2020     0.495246     0.714187\n",
       "...     ...          ...          ...\n",
       "35058  2023     0.774643     0.484984\n",
       "35059  2023     0.735512     0.582157\n",
       "35060  2023     0.601593     0.620917\n",
       "35061  2023     0.536583     0.631322\n",
       "35062  2023     0.454969     0.606127\n",
       "\n",
       "[35063 rows x 3 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_path = 'C:/Users/smartgrid_AI/Desktop/windpower_ramprate/ercot_2020.csv'\n",
    "data_source1 = pd.read_csv(data_path)\n",
    "dat_source1 = pd.DataFrame(data_source1)\n",
    "#dat_source1 = dat_source1.iloc[:-3,:]\n",
    "\n",
    "data_path = 'C:/Users/smartgrid_AI/Desktop/windpower_ramprate/ercot_2021.csv'\n",
    "data_source2 = pd.read_csv(data_path)\n",
    "dat_source2 = pd.DataFrame(data_source2)\n",
    "dat_source2 = dat_source2.iloc[:8761,:9]\n",
    "\n",
    "data_path = 'C:/Users/smartgrid_AI/Desktop/windpower_ramprate/ercot_2022.csv'\n",
    "data_source3 = pd.read_csv(data_path)\n",
    "dat_source3 = pd.DataFrame(data_source3)\n",
    "dat_source3 = dat_source3.iloc[:8760,:9]\n",
    "\n",
    "data_path = 'C:/Users/smartgrid_AI/Desktop/windpower_ramprate/ercot_2023.csv'\n",
    "data_source4 = pd.read_csv(data_path)\n",
    "dat_source4 = pd.DataFrame(data_source4)\n",
    "dat_source4 = dat_source4.iloc[:8760,:9]\n",
    "\n",
    "dat_arr1 = np.array(dat_source1)\n",
    "dat_arr2 = np.array(dat_source2)\n",
    "dat_arr3 = np.array(dat_source3)\n",
    "dat_arr4 = np.array(dat_source4)\n",
    "\n",
    "dat_arr = np.concatenate([dat_arr1, dat_arr2, dat_arr3, dat_arr4],axis=0)\n",
    "dat_arr.shape # 8784, 8761, 8760, 8760\n",
    "\n",
    "dat_source = pd.DataFrame(dat_arr, columns=['Time-Date stamp','Date','ERCOT Load','Total Wind Output','Total Wind Installed','Wind Output, % of Load','Wind Output, % of Installed','1-hr MW change','1-hr % change'])\n",
    "dat = pd.DataFrame()\n",
    "dat['MW % change'] = np.array(dat_source.iloc[1:,3], dtype=float)-np.array(dat_source.iloc[0:-1,3], dtype=float)\n",
    "dat['MW % change'] = np.divide(np.array(dat['MW % change']),np.array(dat_source.iloc[1:,4]))*100\n",
    "dat['Total Wind Output'] = np.divide(np.array(dat_source.iloc[1:,3]), np.array(dat_source.iloc[1:,4]))\n",
    "\n",
    "ramp_ratio = 20\n",
    "load_ratio = 10\n",
    "year_arr = np.concatenate([np.ones(8784)*2020, np.ones(8760)*2021, np.ones(8760)*2022, np.ones(8760)*2023])\n",
    "year_df = pd.DataFrame(year_arr, columns=['Year'], dtype=int)\n",
    "wind_df = pd.concat([year_df, dat], axis=1)\n",
    "wind_df = wind_df.reset_index(drop=True)\n",
    "\n",
    "std_scaler = sklearn.preprocessing.MinMaxScaler()\n",
    "std_scaler_load = sklearn.preprocessing.MinMaxScaler()\n",
    "std_scaler_ramp = sklearn.preprocessing.MinMaxScaler()\n",
    "\n",
    "wind_df[['Total Wind Output']] = std_scaler.fit_transform(wind_df[['Total Wind Output']])\n",
    "wind_df[['MW % change']] = std_scaler_ramp.fit_transform(wind_df[['MW % change']])\n",
    "wind_df = wind_df.iloc[:-1,:]\n",
    "ramp_df = pd.DataFrame(wind_df)\n",
    "ramp_df.columns=['Year', 'Wind Change', 'Wind Output']\n",
    "ramp_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a5454ab8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_dataset(dataset, timesteps, output_timesteps, leadtime):\n",
    "    dataX, dataY = [], []\n",
    "    for i in range(len(dataset) - timesteps -output_timesteps - leadtime - 1):\n",
    "        a = dataset[i:(i + timesteps), :]\n",
    "        dataX.append(a)\n",
    "        dataY.append(dataset[(i + timesteps + leadtime):(i+timesteps+output_timesteps+leadtime), :])\n",
    "    return np.array(dataX), np.array(dataY)\n",
    "\n",
    "def svdadd(X, start, end, b_size):\n",
    "    dec_x = X[start:end, :, :]\n",
    "    U, S, Vh = svd(dec_x.reshape(b_size, -1), full_matrices=True)\n",
    "\n",
    "    high_sig = np.matmul(np.matmul(U[:,:high_ind], np.diag(S[0:high_ind])), Vh[:high_ind,:])\n",
    "    low_sig = X[:dec_num, :, :].reshape(b_size,-1)-high_sig\n",
    "\n",
    "    rec_x = np.zeros((b_size, b_size, high_ind))\n",
    "    \n",
    "    for i in range(high_ind):\n",
    "        rec_x[:,:,i] = np.matmul((U[:,i]*S[i]).reshape(-1,1), Vh[i,:].reshape(1,-1))    \n",
    "    return rec_x, low_sig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7b71b0ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "norm_df = np.array(wind_df.iloc[:,1]).reshape(-1,1)\n",
    "timesteps = 24*7\n",
    "output_timesteps = 24\n",
    "leadtime = 6\n",
    "num_features = 1\n",
    "X, Y = create_dataset(norm_df, timesteps, output_timesteps, leadtime)\n",
    "b_size = timesteps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "24ef2dac",
   "metadata": {},
   "outputs": [],
   "source": [
    "dec_num = timesteps\n",
    "high_ind = 35\n",
    "\n",
    "addX = np.zeros((X.shape[0], dec_num, high_ind+1))\n",
    "\n",
    "for k in range(X.shape[0]//dec_num):\n",
    "    rec_x, low_sig = svdadd(X, k*dec_num, (k+1)*dec_num, b_size)\n",
    "    addX[k*dec_num:k*dec_num+dec_num,:, :-1] = rec_x\n",
    "    addX[k*dec_num:k*dec_num+dec_num,:, -1] = low_sig\n",
    "    \n",
    "rec_x, low_sig = svdadd(X, X.shape[0]-dec_num, X.shape[0], b_size)\n",
    "addX[X.shape[0]-dec_num:X.shape[0], :, :-1] = rec_x\n",
    "addX[X.shape[0]-dec_num:X.shape[0],:, -1] = low_sig\n",
    "\n",
    "addX_det = addX[:, :, :-1]\n",
    "addX_det = np.sum(addX_det, axis=2)\n",
    "X = np.concatenate([X, addX], axis=2)\n",
    "num_features = X.shape[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "720a74fe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((31377, 168, 37), (31377, 24), (3487, 168, 37), (3487, 24))"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trvaX, teX, trvaY, teY = train_test_split(X, Y, test_size=0.1, shuffle=False)\n",
    "\n",
    "idx = np.arange(trvaX.shape[0])\n",
    "np.random.shuffle(idx)\n",
    "strvaX = trvaX[idx]\n",
    "strvaY = trvaY[idx]\n",
    "strvaY = strvaY.reshape(-1, output_timesteps)\n",
    "\n",
    "trvaY = trvaY.reshape(-1, output_timesteps)\n",
    "teY = teY.reshape(-1, output_timesteps)\n",
    "\n",
    "strX, svaX, strY, svaY = train_test_split(strvaX, strvaY, test_size=0.3, shuffle=False)\n",
    "trX, vaX, trY, vaY = train_test_split(trvaX, trvaY, test_size=0.3, shuffle=False)\n",
    "\n",
    "trvaX.shape, trvaY.shape, teX.shape, teY.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1fc22e6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def MAEMS(y_true, y_pred):\n",
    "    return K.mean((K.abs(y_pred - y_true))*K.square(y_true))*100\n",
    "\n",
    "def MAEMD(y_true, y_pred):\n",
    "    return K.mean((K.abs(y_pred - y_true))*K.square(y_true-K.mean(y_true)))*100\n",
    "\n",
    "def MAE(y_true, y_pred):\n",
    "    return K.mean((K.abs(y_pred - y_true)))\n",
    "\n",
    "def MSE(y_true, y_pred):\n",
    "    return K.mean((K.square(y_pred - y_true)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "685dcb3c",
   "metadata": {},
   "source": [
    "## Transformer Model - Without SVD With Shuffling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "46278d62",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "class RevIN(tf.keras.layers.Layer):\n",
    "    def __init__(self, num_features, eps=1e-5, affine=True, subtract_last=False):\n",
    "        super(RevIN, self).__init__()\n",
    "        self.num_features = num_features\n",
    "        self.eps = eps\n",
    "        self.affine = affine\n",
    "        self.subtract_last = subtract_last\n",
    "\n",
    "        if self.affine:\n",
    "            self.affine_weight = self.add_weight(shape=(num_features,),\n",
    "                                                 initializer=\"ones\", trainable=True)\n",
    "            self.affine_bias = self.add_weight(shape=(num_features,),\n",
    "                                               initializer=\"zeros\", trainable=True)\n",
    "\n",
    "    def call(self, x, mode):\n",
    "        if mode == 'norm':\n",
    "            x = self._normalize(x)\n",
    "        elif mode == 'denorm':\n",
    "            x = self._denormalize(x)\n",
    "        else:\n",
    "            raise NotImplementedError\n",
    "        return x\n",
    "\n",
    "    def _get_statistics(self, x):\n",
    "        if self.subtract_last:\n",
    "            self.last = tf.expand_dims(x[:, -1, :], axis=1)\n",
    "        else:\n",
    "            self.mean = tf.reduce_mean(x, axis=[1, 2], keepdims=True)\n",
    "        self.stdev = tf.sqrt(tf.math.reduce_variance(x, axis=[1, 2], keepdims=True) + self.eps)\n",
    "\n",
    "    def _normalize(self, x):\n",
    "        self._get_statistics(x)\n",
    "        if self.subtract_last:\n",
    "            x = x - self.last\n",
    "        else:\n",
    "            x = x - self.mean\n",
    "        x = x / self.stdev\n",
    "        if self.affine:\n",
    "            x = x * self.affine_weight + self.affine_bias\n",
    "        return x\n",
    "\n",
    "    def _denormalize(self, x):\n",
    "        if self.affine:\n",
    "            x = (x - self.affine_bias) / (self.affine_weight + self.eps * self.eps)\n",
    "        x = x * self.stdev\n",
    "        if self.subtract_last:\n",
    "            x = x + self.last\n",
    "        else:\n",
    "            x = x + self.mean\n",
    "        return x\n",
    "\n",
    "\n",
    "class Model(tf.keras.Model):\n",
    "    def __init__(self, seq_len, pred_len, numfeatures, d_model, rnn_type, dec_way, seg_len, dropout, channel_id, revin):\n",
    "        super(Model, self).__init__()\n",
    "\n",
    "        self.seq_len = seq_len\n",
    "        self.pred_len = pred_len\n",
    "        self.numfeatures = numfeatures\n",
    "        self.d_model = d_model\n",
    "        self.rnn_type = rnn_type\n",
    "        self.dec_way = dec_way\n",
    "        self.seg_len = seg_len\n",
    "        self.dropout = dropout\n",
    "        self.channel_id = channel_id\n",
    "        self.revin = revin\n",
    "\n",
    "        self.seg_num_x = seq_len // seg_len\n",
    "\n",
    "        self.value_embedding = tf.keras.Sequential([\n",
    "            tf.keras.layers.Dense(d_model, activation='relu')\n",
    "        ])\n",
    "\n",
    "        if rnn_type == 'rnn':\n",
    "            self.rnn = tf.keras.layers.SimpleRNN(d_model, return_sequences=False, return_state=True)\n",
    "        elif rnn_type == 'gru':\n",
    "            self.rnn = tf.keras.layers.GRU(d_model, return_sequences=False, return_state=True)\n",
    "        elif rnn_type == 'lstm':\n",
    "            self.rnn = tf.keras.layers.LSTM(d_model, return_sequences=False, return_state=True)\n",
    "\n",
    "        self.predict = tf.keras.Sequential([\n",
    "            tf.keras.layers.Dropout(dropout),\n",
    "            tf.keras.layers.Dense(seg_len)\n",
    "        ])\n",
    "\n",
    "        if revin:\n",
    "            self.revin_layer = RevIN(numfeatures, affine=False, subtract_last=False)\n",
    "\n",
    "    def call(self, x):\n",
    "        batch_size = tf.shape(x)[0]\n",
    "\n",
    "        if self.revin:\n",
    "            x = self.revin_layer(x, mode='norm')\n",
    "            x = tf.transpose(x, perm=[0, 2, 1])\n",
    "        else:\n",
    "            seq_last = x[:, -1:, :]\n",
    "            x = tf.transpose(x - seq_last, perm=[0, 2, 1])\n",
    "\n",
    "        # Ensure the correct reshaping\n",
    "        x = tf.reshape(x, (-1, self.seg_num_x, self.seg_len))\n",
    "        x = self.value_embedding(x)  # Shape: (batch_size * seg_num_x, seg_len, d_model)\n",
    "\n",
    "        if self.rnn_type == 'lstm':\n",
    "            _, hn, cn = self.rnn(x)\n",
    "        else:\n",
    "            _, hn = self.rnn(x)\n",
    "\n",
    "        if self.dec_way == 'rmf':\n",
    "            y = []\n",
    "            for _ in range(self.pred_len // self.seg_len):\n",
    "                yy = self.predict(hn)\n",
    "                y.append(yy)\n",
    "                yy = self.value_embedding(tf.expand_dims(yy, axis=1))  # Correct input to the RNN\n",
    "                if self.rnn_type == 'lstm':\n",
    "                    _, hn, cn = self.rnn(yy, initial_state=[hn, cn])\n",
    "                else:\n",
    "                    _, hn = self.rnn(yy, initial_state=hn)\n",
    "            y = tf.reshape(tf.stack(y, axis=1), (batch_size, self.numfeatures, self.pred_len))\n",
    "\n",
    "        elif self.dec_way == 'pmf':\n",
    "            y = []\n",
    "            for _ in range(self.pred_len // self.seg_len):\n",
    "                yy = self.predict(hn)\n",
    "                y.append(yy)\n",
    "                yy = self.value_embedding(tf.expand_dims(yy, axis=1))  # Correct input to the RNN\n",
    "                if self.rnn_type == 'lstm':\n",
    "                    _, hn, cn = self.rnn(yy, initial_state=[hn, cn])\n",
    "                else:\n",
    "                    _, hn = self.rnn(yy, initial_state=hn)\n",
    "            y = tf.concat(y, axis=1)\n",
    "            y = tf.reshape(y, (batch_size, self.numfeatures, self.pred_len))\n",
    "\n",
    "        else:\n",
    "            raise NotImplementedError(\"Only 'rmf' and 'pmf' decoding are implemented in this version.\")\n",
    "\n",
    "        if self.revin:\n",
    "            y = self.revin_layer(tf.transpose(y, perm=[0, 2, 1]), mode='denorm')\n",
    "        else:\n",
    "            y = tf.transpose(y, perm=[0, 2, 1]) + seq_last\n",
    "\n",
    "        y = tf.reduce_mean(y, axis=-1)\n",
    "        return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a4aa7961",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_features = trvaX.shape[2]\n",
    "output_timesteps = trvaY.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9b92054d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "sequential (Sequential)      (6216, None, 256)         1792      \n",
      "_________________________________________________________________\n",
      "gru (GRU)                    multiple                  394752    \n",
      "_________________________________________________________________\n",
      "rev_in (RevIN)               multiple                  0         \n",
      "=================================================================\n",
      "Total params: 396,544\n",
      "Trainable params: 396,544\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "class Config:\n",
    "    seq_len = 168\n",
    "    pred_len = 24\n",
    "    numfeatures = num_features\n",
    "    d_model = 256\n",
    "    rnn_type = 'gru'  # 'rnn', 'gru', 'lstm'\n",
    "    dec_way = 'pmf'  # 'rmf'\n",
    "    seg_len = 6\n",
    "    dropout = 0.1\n",
    "    channel_id = False\n",
    "    revin = True\n",
    "\n",
    "configs = Config()\n",
    "\n",
    "input_shape = (168, num_features)\n",
    "batch_size = 168\n",
    "\n",
    "with tf.device('/gpu:0'):\n",
    "    model = Model(\n",
    "        seq_len=configs.seq_len,\n",
    "        pred_len=configs.pred_len,\n",
    "        numfeatures=configs.numfeatures,\n",
    "        d_model=configs.d_model,\n",
    "        rnn_type=configs.rnn_type,\n",
    "        dec_way=configs.dec_way,\n",
    "        seg_len=configs.seg_len,\n",
    "        dropout=configs.dropout,\n",
    "        channel_id=configs.channel_id,\n",
    "        revin=configs.revin)\n",
    "\n",
    "    example_input = tf.random.normal((batch_size, *input_shape))\n",
    "    output = model(example_input)\n",
    "    model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5e2b1894",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "851"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6aac8a93",
   "metadata": {},
   "outputs": [],
   "source": [
    "    model.compile(loss=MAEMD, optimizer='adam', metrics=[MSE, MAE, MAEMD])\n",
    "    early_stopping =EarlyStopping(monitor='val_loss', patience=10)\n",
    "    batch_size = 168\n",
    "    epochs = 1000\n",
    "    history = LossHistory()\n",
    "    history.init()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "71295b32",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "131/131 [==============================] - 20s 108ms/step - loss: 0.2108 - MSE: 0.0254 - MAE: 0.1148 - MAEMD: 0.2108 - val_loss: 0.1946 - val_MSE: 0.0132 - val_MAE: 0.0903 - val_MAEMD: 0.1938\n",
      "Epoch 2/1000\n",
      "131/131 [==============================] - 13s 97ms/step - loss: 0.1936 - MSE: 0.0134 - MAE: 0.0912 - MAEMD: 0.1936 - val_loss: 0.1945 - val_MSE: 0.0132 - val_MAE: 0.0905 - val_MAEMD: 0.1938\n",
      "Epoch 3/1000\n",
      "131/131 [==============================] - 13s 98ms/step - loss: 0.1935 - MSE: 0.0134 - MAE: 0.0913 - MAEMD: 0.1935 - val_loss: 0.1945 - val_MSE: 0.0132 - val_MAE: 0.0905 - val_MAEMD: 0.1938\n",
      "Epoch 4/1000\n",
      "131/131 [==============================] - 13s 98ms/step - loss: 0.1935 - MSE: 0.0134 - MAE: 0.0914 - MAEMD: 0.1935 - val_loss: 0.1945 - val_MSE: 0.0133 - val_MAE: 0.0908 - val_MAEMD: 0.1937\n",
      "Epoch 5/1000\n",
      "131/131 [==============================] - 13s 98ms/step - loss: 0.1935 - MSE: 0.0135 - MAE: 0.0916 - MAEMD: 0.1935 - val_loss: 0.1945 - val_MSE: 0.0133 - val_MAE: 0.0909 - val_MAEMD: 0.1937\n",
      "Epoch 6/1000\n",
      "131/131 [==============================] - 13s 99ms/step - loss: 0.1935 - MSE: 0.0135 - MAE: 0.0915 - MAEMD: 0.1935 - val_loss: 0.1944 - val_MSE: 0.0133 - val_MAE: 0.0909 - val_MAEMD: 0.1937\n",
      "Epoch 7/1000\n",
      "131/131 [==============================] - 13s 99ms/step - loss: 0.1935 - MSE: 0.0135 - MAE: 0.0916 - MAEMD: 0.1935 - val_loss: 0.1944 - val_MSE: 0.0133 - val_MAE: 0.0908 - val_MAEMD: 0.1937\n",
      "Epoch 8/1000\n",
      "131/131 [==============================] - 13s 99ms/step - loss: 0.1934 - MSE: 0.0135 - MAE: 0.0916 - MAEMD: 0.1935 - val_loss: 0.1944 - val_MSE: 0.0133 - val_MAE: 0.0909 - val_MAEMD: 0.1937\n",
      "Epoch 9/1000\n",
      "131/131 [==============================] - 13s 99ms/step - loss: 0.1934 - MSE: 0.0135 - MAE: 0.0917 - MAEMD: 0.1934 - val_loss: 0.1944 - val_MSE: 0.0132 - val_MAE: 0.0906 - val_MAEMD: 0.1937\n",
      "Epoch 10/1000\n",
      "131/131 [==============================] - 13s 99ms/step - loss: 0.1934 - MSE: 0.0135 - MAE: 0.0917 - MAEMD: 0.1934 - val_loss: 0.1943 - val_MSE: 0.0132 - val_MAE: 0.0905 - val_MAEMD: 0.1936\n",
      "Epoch 11/1000\n",
      "131/131 [==============================] - 13s 100ms/step - loss: 0.1933 - MSE: 0.0135 - MAE: 0.0917 - MAEMD: 0.1934 - val_loss: 0.1943 - val_MSE: 0.0133 - val_MAE: 0.0908 - val_MAEMD: 0.1936\n",
      "Epoch 12/1000\n",
      "131/131 [==============================] - 13s 98ms/step - loss: 0.1933 - MSE: 0.0135 - MAE: 0.0915 - MAEMD: 0.1933 - val_loss: 0.1942 - val_MSE: 0.0133 - val_MAE: 0.0909 - val_MAEMD: 0.1935\n",
      "Epoch 13/1000\n",
      "131/131 [==============================] - 13s 98ms/step - loss: 0.1932 - MSE: 0.0134 - MAE: 0.0915 - MAEMD: 0.1932 - val_loss: 0.1941 - val_MSE: 0.0134 - val_MAE: 0.0913 - val_MAEMD: 0.1934\n",
      "Epoch 14/1000\n",
      "131/131 [==============================] - 13s 98ms/step - loss: 0.1931 - MSE: 0.0134 - MAE: 0.0914 - MAEMD: 0.1932 - val_loss: 0.1940 - val_MSE: 0.0132 - val_MAE: 0.0907 - val_MAEMD: 0.1933\n",
      "Epoch 15/1000\n",
      "131/131 [==============================] - 13s 98ms/step - loss: 0.1930 - MSE: 0.0134 - MAE: 0.0913 - MAEMD: 0.1930 - val_loss: 0.1939 - val_MSE: 0.0132 - val_MAE: 0.0905 - val_MAEMD: 0.1931\n",
      "Epoch 16/1000\n",
      "131/131 [==============================] - 13s 98ms/step - loss: 0.1929 - MSE: 0.0134 - MAE: 0.0911 - MAEMD: 0.1929 - val_loss: 0.1937 - val_MSE: 0.0133 - val_MAE: 0.0910 - val_MAEMD: 0.1930\n",
      "Epoch 17/1000\n",
      "131/131 [==============================] - 13s 98ms/step - loss: 0.1926 - MSE: 0.0133 - MAE: 0.0908 - MAEMD: 0.1926 - val_loss: 0.1934 - val_MSE: 0.0130 - val_MAE: 0.0895 - val_MAEMD: 0.1927\n",
      "Epoch 18/1000\n",
      "131/131 [==============================] - 13s 98ms/step - loss: 0.1924 - MSE: 0.0132 - MAE: 0.0904 - MAEMD: 0.1924 - val_loss: 0.1932 - val_MSE: 0.0129 - val_MAE: 0.0891 - val_MAEMD: 0.1925\n",
      "Epoch 19/1000\n",
      "131/131 [==============================] - 13s 98ms/step - loss: 0.1922 - MSE: 0.0131 - MAE: 0.0898 - MAEMD: 0.1922 - val_loss: 0.1934 - val_MSE: 0.0128 - val_MAE: 0.0886 - val_MAEMD: 0.1927\n",
      "Epoch 20/1000\n",
      "131/131 [==============================] - 13s 98ms/step - loss: 0.1917 - MSE: 0.0130 - MAE: 0.0895 - MAEMD: 0.1917 - val_loss: 0.1924 - val_MSE: 0.0132 - val_MAE: 0.0903 - val_MAEMD: 0.1917\n",
      "Epoch 21/1000\n",
      "131/131 [==============================] - 13s 98ms/step - loss: 0.1911 - MSE: 0.0129 - MAE: 0.0889 - MAEMD: 0.1911 - val_loss: 0.1921 - val_MSE: 0.0126 - val_MAE: 0.0874 - val_MAEMD: 0.1915\n",
      "Epoch 22/1000\n",
      "131/131 [==============================] - 13s 98ms/step - loss: 0.1906 - MSE: 0.0129 - MAE: 0.0888 - MAEMD: 0.1906 - val_loss: 0.1917 - val_MSE: 0.0118 - val_MAE: 0.0840 - val_MAEMD: 0.1909\n",
      "Epoch 23/1000\n",
      "131/131 [==============================] - 13s 98ms/step - loss: 0.1898 - MSE: 0.0128 - MAE: 0.0882 - MAEMD: 0.1898 - val_loss: 0.1905 - val_MSE: 0.0120 - val_MAE: 0.0850 - val_MAEMD: 0.1899\n",
      "Epoch 24/1000\n",
      "131/131 [==============================] - 13s 98ms/step - loss: 0.1900 - MSE: 0.0129 - MAE: 0.0885 - MAEMD: 0.1900 - val_loss: 0.1907 - val_MSE: 0.0122 - val_MAE: 0.0858 - val_MAEMD: 0.1901\n",
      "Epoch 25/1000\n",
      "131/131 [==============================] - 13s 98ms/step - loss: 0.1885 - MSE: 0.0126 - MAE: 0.0874 - MAEMD: 0.1885 - val_loss: 0.1890 - val_MSE: 0.0120 - val_MAE: 0.0847 - val_MAEMD: 0.1884\n",
      "Epoch 26/1000\n",
      "131/131 [==============================] - 13s 98ms/step - loss: 0.1876 - MSE: 0.0126 - MAE: 0.0876 - MAEMD: 0.1876 - val_loss: 0.1883 - val_MSE: 0.0118 - val_MAE: 0.0842 - val_MAEMD: 0.1876\n",
      "Epoch 27/1000\n",
      "131/131 [==============================] - 13s 98ms/step - loss: 0.1861 - MSE: 0.0125 - MAE: 0.0869 - MAEMD: 0.1861 - val_loss: 0.1859 - val_MSE: 0.0118 - val_MAE: 0.0842 - val_MAEMD: 0.1852\n",
      "Epoch 28/1000\n",
      "131/131 [==============================] - 13s 99ms/step - loss: 0.1836 - MSE: 0.0122 - MAE: 0.0860 - MAEMD: 0.1836 - val_loss: 0.1842 - val_MSE: 0.0120 - val_MAE: 0.0853 - val_MAEMD: 0.1836\n",
      "Epoch 29/1000\n",
      "131/131 [==============================] - 13s 98ms/step - loss: 0.1816 - MSE: 0.0120 - MAE: 0.0852 - MAEMD: 0.1816 - val_loss: 0.1818 - val_MSE: 0.0118 - val_MAE: 0.0843 - val_MAEMD: 0.1812\n",
      "Epoch 30/1000\n",
      "131/131 [==============================] - 13s 98ms/step - loss: 0.1842 - MSE: 0.0130 - MAE: 0.0879 - MAEMD: 0.1842 - val_loss: 0.1826 - val_MSE: 0.0119 - val_MAE: 0.0851 - val_MAEMD: 0.1819\n",
      "Epoch 31/1000\n",
      "131/131 [==============================] - 13s 98ms/step - loss: 0.1804 - MSE: 0.0116 - MAE: 0.0834 - MAEMD: 0.1804 - val_loss: 0.1806 - val_MSE: 0.0112 - val_MAE: 0.0818 - val_MAEMD: 0.1799\n",
      "Epoch 32/1000\n",
      "131/131 [==============================] - 13s 98ms/step - loss: 0.1785 - MSE: 0.0116 - MAE: 0.0832 - MAEMD: 0.1786 - val_loss: 0.1793 - val_MSE: 0.0112 - val_MAE: 0.0818 - val_MAEMD: 0.1786\n",
      "Epoch 33/1000\n",
      "131/131 [==============================] - 13s 98ms/step - loss: 0.1767 - MSE: 0.0113 - MAE: 0.0823 - MAEMD: 0.1768 - val_loss: 0.1772 - val_MSE: 0.0110 - val_MAE: 0.0812 - val_MAEMD: 0.1764\n",
      "Epoch 34/1000\n",
      "131/131 [==============================] - 13s 99ms/step - loss: 0.1750 - MSE: 0.0112 - MAE: 0.0818 - MAEMD: 0.1750 - val_loss: 0.1765 - val_MSE: 0.0111 - val_MAE: 0.0814 - val_MAEMD: 0.1758\n",
      "Epoch 35/1000\n",
      "131/131 [==============================] - 13s 98ms/step - loss: 0.1738 - MSE: 0.0112 - MAE: 0.0819 - MAEMD: 0.1738 - val_loss: 0.1751 - val_MSE: 0.0105 - val_MAE: 0.0784 - val_MAEMD: 0.1744\n",
      "Epoch 36/1000\n",
      "131/131 [==============================] - 13s 99ms/step - loss: 0.1723 - MSE: 0.0109 - MAE: 0.0807 - MAEMD: 0.1723 - val_loss: 0.1732 - val_MSE: 0.0106 - val_MAE: 0.0792 - val_MAEMD: 0.1726\n",
      "Epoch 37/1000\n",
      "131/131 [==============================] - 13s 99ms/step - loss: 0.1701 - MSE: 0.0108 - MAE: 0.0802 - MAEMD: 0.1701 - val_loss: 0.1702 - val_MSE: 0.0108 - val_MAE: 0.0804 - val_MAEMD: 0.1695\n",
      "Epoch 38/1000\n",
      "131/131 [==============================] - 13s 99ms/step - loss: 0.1675 - MSE: 0.0106 - MAE: 0.0793 - MAEMD: 0.1675 - val_loss: 0.1681 - val_MSE: 0.0102 - val_MAE: 0.0775 - val_MAEMD: 0.1675\n",
      "Epoch 39/1000\n",
      "131/131 [==============================] - 13s 99ms/step - loss: 0.1657 - MSE: 0.0106 - MAE: 0.0798 - MAEMD: 0.1657 - val_loss: 0.1677 - val_MSE: 0.0108 - val_MAE: 0.0801 - val_MAEMD: 0.1672\n",
      "Epoch 40/1000\n",
      "131/131 [==============================] - 13s 100ms/step - loss: 0.1643 - MSE: 0.0104 - MAE: 0.0785 - MAEMD: 0.1643 - val_loss: 0.1653 - val_MSE: 0.0105 - val_MAE: 0.0792 - val_MAEMD: 0.1647\n",
      "Epoch 41/1000\n",
      "131/131 [==============================] - 13s 99ms/step - loss: 0.1627 - MSE: 0.0104 - MAE: 0.0786 - MAEMD: 0.1627 - val_loss: 0.1643 - val_MSE: 0.0103 - val_MAE: 0.0780 - val_MAEMD: 0.1637\n",
      "Epoch 42/1000\n",
      "131/131 [==============================] - 13s 99ms/step - loss: 0.1636 - MSE: 0.0104 - MAE: 0.0786 - MAEMD: 0.1636 - val_loss: 0.1632 - val_MSE: 0.0100 - val_MAE: 0.0767 - val_MAEMD: 0.1626\n",
      "Epoch 43/1000\n",
      "131/131 [==============================] - 13s 99ms/step - loss: 0.1616 - MSE: 0.0104 - MAE: 0.0787 - MAEMD: 0.1616 - val_loss: 0.1627 - val_MSE: 0.0102 - val_MAE: 0.0775 - val_MAEMD: 0.1621\n",
      "Epoch 44/1000\n",
      "131/131 [==============================] - 13s 99ms/step - loss: 0.1611 - MSE: 0.0103 - MAE: 0.0785 - MAEMD: 0.1612 - val_loss: 0.1631 - val_MSE: 0.0103 - val_MAE: 0.0784 - val_MAEMD: 0.1623\n",
      "Epoch 45/1000\n",
      "131/131 [==============================] - 13s 99ms/step - loss: 0.1606 - MSE: 0.0103 - MAE: 0.0784 - MAEMD: 0.1606 - val_loss: 0.1614 - val_MSE: 0.0099 - val_MAE: 0.0764 - val_MAEMD: 0.1608\n",
      "Epoch 46/1000\n",
      "131/131 [==============================] - 13s 99ms/step - loss: 0.1587 - MSE: 0.0102 - MAE: 0.0780 - MAEMD: 0.1587 - val_loss: 0.1599 - val_MSE: 0.0104 - val_MAE: 0.0788 - val_MAEMD: 0.1594\n",
      "Epoch 47/1000\n",
      "131/131 [==============================] - 13s 99ms/step - loss: 0.1576 - MSE: 0.0101 - MAE: 0.0779 - MAEMD: 0.1576 - val_loss: 0.1595 - val_MSE: 0.0103 - val_MAE: 0.0779 - val_MAEMD: 0.1588\n",
      "Epoch 48/1000\n",
      "131/131 [==============================] - 13s 99ms/step - loss: 0.1568 - MSE: 0.0101 - MAE: 0.0779 - MAEMD: 0.1568 - val_loss: 0.1585 - val_MSE: 0.0099 - val_MAE: 0.0763 - val_MAEMD: 0.1580\n",
      "Epoch 49/1000\n",
      "131/131 [==============================] - 13s 99ms/step - loss: 0.1557 - MSE: 0.0101 - MAE: 0.0778 - MAEMD: 0.1557 - val_loss: 0.1576 - val_MSE: 0.0099 - val_MAE: 0.0766 - val_MAEMD: 0.1571\n",
      "Epoch 50/1000\n",
      "131/131 [==============================] - 13s 100ms/step - loss: 0.1559 - MSE: 0.0102 - MAE: 0.0780 - MAEMD: 0.1559 - val_loss: 0.1575 - val_MSE: 0.0100 - val_MAE: 0.0769 - val_MAEMD: 0.1569\n",
      "Epoch 51/1000\n",
      "131/131 [==============================] - 13s 100ms/step - loss: 0.1549 - MSE: 0.0102 - MAE: 0.0783 - MAEMD: 0.1549 - val_loss: 0.1576 - val_MSE: 0.0101 - val_MAE: 0.0777 - val_MAEMD: 0.1570\n",
      "Epoch 52/1000\n",
      "131/131 [==============================] - 13s 99ms/step - loss: 0.1547 - MSE: 0.0102 - MAE: 0.0784 - MAEMD: 0.1548 - val_loss: 0.1591 - val_MSE: 0.0103 - val_MAE: 0.0783 - val_MAEMD: 0.1586\n",
      "Epoch 53/1000\n",
      "131/131 [==============================] - 13s 99ms/step - loss: 0.1560 - MSE: 0.0103 - MAE: 0.0785 - MAEMD: 0.1560 - val_loss: 0.1573 - val_MSE: 0.0101 - val_MAE: 0.0776 - val_MAEMD: 0.1568\n",
      "Epoch 54/1000\n",
      "131/131 [==============================] - 13s 99ms/step - loss: 0.1548 - MSE: 0.0102 - MAE: 0.0781 - MAEMD: 0.1548 - val_loss: 0.1562 - val_MSE: 0.0100 - val_MAE: 0.0770 - val_MAEMD: 0.1557\n",
      "Epoch 55/1000\n",
      "131/131 [==============================] - 13s 99ms/step - loss: 0.1536 - MSE: 0.0101 - MAE: 0.0779 - MAEMD: 0.1536 - val_loss: 0.1556 - val_MSE: 0.0100 - val_MAE: 0.0770 - val_MAEMD: 0.1550\n",
      "Epoch 56/1000\n",
      "131/131 [==============================] - 13s 99ms/step - loss: 0.1533 - MSE: 0.0102 - MAE: 0.0782 - MAEMD: 0.1534 - val_loss: 0.1550 - val_MSE: 0.0101 - val_MAE: 0.0777 - val_MAEMD: 0.1545\n",
      "Epoch 57/1000\n",
      "131/131 [==============================] - 13s 99ms/step - loss: 0.1543 - MSE: 0.0104 - MAE: 0.0791 - MAEMD: 0.1543 - val_loss: 0.1556 - val_MSE: 0.0100 - val_MAE: 0.0773 - val_MAEMD: 0.1551\n",
      "Epoch 58/1000\n",
      "131/131 [==============================] - 13s 99ms/step - loss: 0.1537 - MSE: 0.0102 - MAE: 0.0781 - MAEMD: 0.1537 - val_loss: 0.1556 - val_MSE: 0.0102 - val_MAE: 0.0782 - val_MAEMD: 0.1550\n",
      "Epoch 59/1000\n",
      "131/131 [==============================] - 13s 99ms/step - loss: 0.1530 - MSE: 0.0103 - MAE: 0.0787 - MAEMD: 0.1530 - val_loss: 0.1553 - val_MSE: 0.0103 - val_MAE: 0.0784 - val_MAEMD: 0.1548\n",
      "Epoch 60/1000\n",
      "131/131 [==============================] - 13s 99ms/step - loss: 0.1524 - MSE: 0.0101 - MAE: 0.0781 - MAEMD: 0.1524 - val_loss: 0.1551 - val_MSE: 0.0099 - val_MAE: 0.0766 - val_MAEMD: 0.1545\n",
      "Epoch 61/1000\n",
      "131/131 [==============================] - 13s 99ms/step - loss: 0.1518 - MSE: 0.0101 - MAE: 0.0777 - MAEMD: 0.1518 - val_loss: 0.1555 - val_MSE: 0.0105 - val_MAE: 0.0791 - val_MAEMD: 0.1549\n",
      "Epoch 62/1000\n",
      "131/131 [==============================] - 13s 100ms/step - loss: 0.1536 - MSE: 0.0106 - MAE: 0.0799 - MAEMD: 0.1536 - val_loss: 0.1545 - val_MSE: 0.0101 - val_MAE: 0.0779 - val_MAEMD: 0.1540\n",
      "Epoch 63/1000\n",
      "131/131 [==============================] - 13s 99ms/step - loss: 0.1515 - MSE: 0.0101 - MAE: 0.0781 - MAEMD: 0.1515 - val_loss: 0.1572 - val_MSE: 0.0101 - val_MAE: 0.0776 - val_MAEMD: 0.1566\n",
      "Epoch 64/1000\n",
      "131/131 [==============================] - 13s 99ms/step - loss: 0.1530 - MSE: 0.0103 - MAE: 0.0787 - MAEMD: 0.1530 - val_loss: 0.1557 - val_MSE: 0.0104 - val_MAE: 0.0792 - val_MAEMD: 0.1552\n",
      "Epoch 65/1000\n",
      "131/131 [==============================] - 13s 99ms/step - loss: 0.1554 - MSE: 0.0104 - MAE: 0.0789 - MAEMD: 0.1554 - val_loss: 0.1559 - val_MSE: 0.0101 - val_MAE: 0.0775 - val_MAEMD: 0.1554\n",
      "Epoch 66/1000\n",
      "131/131 [==============================] - 13s 99ms/step - loss: 0.1531 - MSE: 0.0101 - MAE: 0.0778 - MAEMD: 0.1531 - val_loss: 0.1560 - val_MSE: 0.0099 - val_MAE: 0.0768 - val_MAEMD: 0.1554\n",
      "Epoch 67/1000\n",
      "131/131 [==============================] - 13s 100ms/step - loss: 0.1524 - MSE: 0.0102 - MAE: 0.0784 - MAEMD: 0.1525 - val_loss: 0.1544 - val_MSE: 0.0102 - val_MAE: 0.0780 - val_MAEMD: 0.1537\n",
      "Epoch 68/1000\n",
      "131/131 [==============================] - 13s 99ms/step - loss: 0.1511 - MSE: 0.0101 - MAE: 0.0778 - MAEMD: 0.1511 - val_loss: 0.1531 - val_MSE: 0.0099 - val_MAE: 0.0766 - val_MAEMD: 0.1526\n",
      "Epoch 69/1000\n",
      "131/131 [==============================] - 13s 99ms/step - loss: 0.1509 - MSE: 0.0102 - MAE: 0.0782 - MAEMD: 0.1509 - val_loss: 0.1539 - val_MSE: 0.0101 - val_MAE: 0.0776 - val_MAEMD: 0.1533\n",
      "Epoch 70/1000\n",
      "131/131 [==============================] - 13s 99ms/step - loss: 0.1506 - MSE: 0.0102 - MAE: 0.0783 - MAEMD: 0.1506 - val_loss: 0.1540 - val_MSE: 0.0104 - val_MAE: 0.0791 - val_MAEMD: 0.1534\n",
      "Epoch 71/1000\n",
      "131/131 [==============================] - 13s 99ms/step - loss: 0.1518 - MSE: 0.0102 - MAE: 0.0785 - MAEMD: 0.1518 - val_loss: 0.1543 - val_MSE: 0.0104 - val_MAE: 0.0789 - val_MAEMD: 0.1537\n",
      "Epoch 72/1000\n",
      "131/131 [==============================] - 13s 99ms/step - loss: 0.1517 - MSE: 0.0102 - MAE: 0.0785 - MAEMD: 0.1517 - val_loss: 0.1540 - val_MSE: 0.0102 - val_MAE: 0.0781 - val_MAEMD: 0.1534\n",
      "Epoch 73/1000\n",
      "131/131 [==============================] - 13s 99ms/step - loss: 0.1546 - MSE: 0.0107 - MAE: 0.0805 - MAEMD: 0.1546 - val_loss: 0.1548 - val_MSE: 0.0101 - val_MAE: 0.0773 - val_MAEMD: 0.1542\n",
      "Epoch 74/1000\n",
      "131/131 [==============================] - 13s 99ms/step - loss: 0.1510 - MSE: 0.0099 - MAE: 0.0772 - MAEMD: 0.1510 - val_loss: 0.1544 - val_MSE: 0.0104 - val_MAE: 0.0789 - val_MAEMD: 0.1539\n",
      "Epoch 75/1000\n",
      "131/131 [==============================] - 13s 99ms/step - loss: 0.1509 - MSE: 0.0101 - MAE: 0.0780 - MAEMD: 0.1509 - val_loss: 0.1528 - val_MSE: 0.0101 - val_MAE: 0.0776 - val_MAEMD: 0.1524\n",
      "Epoch 76/1000\n",
      "131/131 [==============================] - 13s 99ms/step - loss: 0.1497 - MSE: 0.0101 - MAE: 0.0778 - MAEMD: 0.1497 - val_loss: 0.1530 - val_MSE: 0.0106 - val_MAE: 0.0795 - val_MAEMD: 0.1525\n",
      "Epoch 77/1000\n",
      "131/131 [==============================] - 13s 100ms/step - loss: 0.1500 - MSE: 0.0103 - MAE: 0.0789 - MAEMD: 0.1500 - val_loss: 0.1530 - val_MSE: 0.0103 - val_MAE: 0.0785 - val_MAEMD: 0.1525\n",
      "Epoch 78/1000\n",
      "131/131 [==============================] - 13s 99ms/step - loss: 0.1516 - MSE: 0.0104 - MAE: 0.0792 - MAEMD: 0.1516 - val_loss: 0.1525 - val_MSE: 0.0103 - val_MAE: 0.0785 - val_MAEMD: 0.1520\n",
      "Epoch 79/1000\n",
      "131/131 [==============================] - 13s 100ms/step - loss: 0.1497 - MSE: 0.0102 - MAE: 0.0784 - MAEMD: 0.1497 - val_loss: 0.1519 - val_MSE: 0.0102 - val_MAE: 0.0782 - val_MAEMD: 0.1514\n",
      "Epoch 80/1000\n",
      "131/131 [==============================] - 13s 100ms/step - loss: 0.1497 - MSE: 0.0102 - MAE: 0.0785 - MAEMD: 0.1497 - val_loss: 0.1529 - val_MSE: 0.0103 - val_MAE: 0.0786 - val_MAEMD: 0.1524\n",
      "Epoch 81/1000\n",
      "131/131 [==============================] - 13s 99ms/step - loss: 0.1510 - MSE: 0.0103 - MAE: 0.0786 - MAEMD: 0.1510 - val_loss: 0.1522 - val_MSE: 0.0099 - val_MAE: 0.0769 - val_MAEMD: 0.1516\n",
      "Epoch 82/1000\n",
      "131/131 [==============================] - 13s 99ms/step - loss: 0.1507 - MSE: 0.0101 - MAE: 0.0781 - MAEMD: 0.1507 - val_loss: 0.1532 - val_MSE: 0.0103 - val_MAE: 0.0785 - val_MAEMD: 0.1528\n",
      "Epoch 83/1000\n",
      "131/131 [==============================] - 13s 99ms/step - loss: 0.1499 - MSE: 0.0102 - MAE: 0.0784 - MAEMD: 0.1499 - val_loss: 0.1523 - val_MSE: 0.0103 - val_MAE: 0.0784 - val_MAEMD: 0.1518\n",
      "Epoch 84/1000\n",
      "131/131 [==============================] - 13s 99ms/step - loss: 0.1500 - MSE: 0.0103 - MAE: 0.0787 - MAEMD: 0.1500 - val_loss: 0.1523 - val_MSE: 0.0100 - val_MAE: 0.0773 - val_MAEMD: 0.1518\n",
      "Epoch 85/1000\n",
      "131/131 [==============================] - 13s 99ms/step - loss: 0.1516 - MSE: 0.0101 - MAE: 0.0781 - MAEMD: 0.1516 - val_loss: 0.1543 - val_MSE: 0.0102 - val_MAE: 0.0782 - val_MAEMD: 0.1537\n",
      "Epoch 86/1000\n",
      "131/131 [==============================] - 13s 99ms/step - loss: 0.1501 - MSE: 0.0102 - MAE: 0.0783 - MAEMD: 0.1501 - val_loss: 0.1523 - val_MSE: 0.0104 - val_MAE: 0.0787 - val_MAEMD: 0.1519\n",
      "Epoch 87/1000\n",
      "131/131 [==============================] - 13s 101ms/step - loss: 0.1493 - MSE: 0.0102 - MAE: 0.0785 - MAEMD: 0.1493 - val_loss: 0.1549 - val_MSE: 0.0115 - val_MAE: 0.0835 - val_MAEMD: 0.1545\n",
      "Epoch 88/1000\n",
      "131/131 [==============================] - 13s 100ms/step - loss: 0.1494 - MSE: 0.0103 - MAE: 0.0791 - MAEMD: 0.1494 - val_loss: 0.1524 - val_MSE: 0.0102 - val_MAE: 0.0784 - val_MAEMD: 0.1519\n",
      "Epoch 89/1000\n",
      "131/131 [==============================] - 13s 100ms/step - loss: 0.1492 - MSE: 0.0103 - MAE: 0.0790 - MAEMD: 0.1493 - val_loss: 0.1528 - val_MSE: 0.0104 - val_MAE: 0.0791 - val_MAEMD: 0.1523\n",
      "Wall time: 19min 19s\n"
     ]
    }
   ],
   "source": [
    "    %%time\n",
    "    b_size = 168\n",
    "    hist = model.fit(strX, strY, epochs=epochs, batch_size=b_size, shuffle=False, validation_data=(svaX, svaY), callbacks=[history, early_stopping])  # , checkpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "460f7c92",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4598"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a67f0e36",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 168\n",
    "num_samples = teX.shape[0]\n",
    "predictions = []\n",
    "\n",
    "for start in range(0, num_samples, batch_size):\n",
    "    end = min(start + batch_size, num_samples)\n",
    "    batch_data = teX[start:end]\n",
    "    batch_predictions = model(batch_data)\n",
    "    predictions.append(batch_predictions)\n",
    "\n",
    "testPredict = np.concatenate(predictions, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "2eff0156",
   "metadata": {},
   "outputs": [],
   "source": [
    "def npMAEMS(y_true, y_pred):\n",
    "    return np.mean((abs(y_pred - y_true))*np.square(y_true))*100\n",
    "def npMAEMD(y_true, y_pred):\n",
    "    return np.mean((abs(y_pred - y_true))*np.square(y_true-np.mean(y_true)))*100\n",
    "def npMSE(y_true, y_pred):\n",
    "    return np.mean(np.square(-y_true+y_pred))\n",
    "def npMAE(y_true, y_pred):\n",
    "    return np.mean(abs(-y_true+y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "4dfa2cb8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error Test Score > MSE ==  0.008885226329186419  MAE ==  0.0736185291558078  MAEMD ==  0.11927962335983838\n"
     ]
    }
   ],
   "source": [
    "tePredict = testPredict.reshape(-1)\n",
    "testY = teY.reshape(-1)\n",
    "print('Error Test Score > MSE == ', npMSE(testY, tePredict), ' MAE == ', npMAE(testY, tePredict), ' MAEMD == ', npMAEMD(testY, tePredict))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2870520f",
   "metadata": {},
   "source": [
    "## Without Shuffling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "a05c6cca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "sequential_2 (Sequential)    (6216, None, 256)         1792      \n",
      "_________________________________________________________________\n",
      "gru_1 (GRU)                  multiple                  394752    \n",
      "_________________________________________________________________\n",
      "rev_in_1 (RevIN)             multiple                  0         \n",
      "=================================================================\n",
      "Total params: 396,544\n",
      "Trainable params: 396,544\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "class Config:\n",
    "    seq_len = 168\n",
    "    pred_len = 24\n",
    "    numfeatures = num_features\n",
    "    d_model = 256\n",
    "    rnn_type = 'gru'  # 'rnn', 'gru', 'lstm'\n",
    "    dec_way = 'pmf'  # 'rmf' 'pmf'\n",
    "    seg_len = 6\n",
    "    dropout = 0.1\n",
    "    channel_id = False\n",
    "    revin = True\n",
    "\n",
    "configs = Config()\n",
    "\n",
    "input_shape = (168, num_features)\n",
    "batch_size = 168\n",
    "\n",
    "with tf.device('/gpu:0'):\n",
    "    model2 = Model(\n",
    "        seq_len=configs.seq_len,\n",
    "        pred_len=configs.pred_len,\n",
    "        numfeatures=configs.numfeatures,\n",
    "        d_model=configs.d_model,\n",
    "        rnn_type=configs.rnn_type,\n",
    "        dec_way=configs.dec_way,\n",
    "        seg_len=configs.seg_len,\n",
    "        dropout=configs.dropout,\n",
    "        channel_id=configs.channel_id,\n",
    "        revin=configs.revin)\n",
    "\n",
    "    example_input = tf.random.normal((batch_size, *input_shape))\n",
    "    output = model2(example_input)\n",
    "    model2.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "56b1971b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "783"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "43d6412b",
   "metadata": {},
   "outputs": [],
   "source": [
    "    model2.compile(loss=MAEMD, optimizer='adam', metrics=[MSE, MAE, MAEMD])\n",
    "    early_stopping =EarlyStopping(monitor='val_loss', patience=10)\n",
    "    batch_size = 168\n",
    "    epochs = 1000\n",
    "    history2 = LossHistory()\n",
    "    history2.init()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "2744142f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "  6/131 [>.............................] - ETA: 11s - loss: 0.2140 - MSE: 0.0136 - MAE: 0.0915 - MAEMD: 0.2140WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0357s vs `on_train_batch_end` time: 0.0546s). Check your callbacks.\n",
      "131/131 [==============================] - 13s 101ms/step - loss: 0.1609 - MSE: 0.0114 - MAE: 0.0835 - MAEMD: 0.1608 - val_loss: 0.1209 - val_MSE: 0.0097 - val_MAE: 0.0765 - val_MAEMD: 0.1217\n",
      "Epoch 2/1000\n",
      "131/131 [==============================] - 13s 99ms/step - loss: 0.1595 - MSE: 0.0111 - MAE: 0.0819 - MAEMD: 0.1594 - val_loss: 0.1188 - val_MSE: 0.0095 - val_MAE: 0.0757 - val_MAEMD: 0.1199\n",
      "Epoch 3/1000\n",
      "131/131 [==============================] - 13s 99ms/step - loss: 0.1578 - MSE: 0.0110 - MAE: 0.0816 - MAEMD: 0.1576 - val_loss: 0.1190 - val_MSE: 0.0096 - val_MAE: 0.0762 - val_MAEMD: 0.1200\n",
      "Epoch 4/1000\n",
      "131/131 [==============================] - 13s 99ms/step - loss: 0.1569 - MSE: 0.0109 - MAE: 0.0814 - MAEMD: 0.1568 - val_loss: 0.1210 - val_MSE: 0.0106 - val_MAE: 0.0806 - val_MAEMD: 0.1218\n",
      "Epoch 5/1000\n",
      "131/131 [==============================] - 13s 100ms/step - loss: 0.1582 - MSE: 0.0112 - MAE: 0.0825 - MAEMD: 0.1581 - val_loss: 0.1189 - val_MSE: 0.0097 - val_MAE: 0.0766 - val_MAEMD: 0.1200\n",
      "Epoch 6/1000\n",
      "131/131 [==============================] - 13s 99ms/step - loss: 0.1576 - MSE: 0.0110 - MAE: 0.0819 - MAEMD: 0.1575 - val_loss: 0.1197 - val_MSE: 0.0097 - val_MAE: 0.0768 - val_MAEMD: 0.1205\n",
      "Epoch 7/1000\n",
      "131/131 [==============================] - 13s 100ms/step - loss: 0.1574 - MSE: 0.0111 - MAE: 0.0820 - MAEMD: 0.1573 - val_loss: 0.1189 - val_MSE: 0.0099 - val_MAE: 0.0774 - val_MAEMD: 0.1198\n",
      "Epoch 8/1000\n",
      "131/131 [==============================] - 13s 100ms/step - loss: 0.1564 - MSE: 0.0109 - MAE: 0.0814 - MAEMD: 0.1563 - val_loss: 0.1186 - val_MSE: 0.0096 - val_MAE: 0.0760 - val_MAEMD: 0.1195\n",
      "Epoch 9/1000\n",
      "131/131 [==============================] - 13s 100ms/step - loss: 0.1562 - MSE: 0.0111 - MAE: 0.0821 - MAEMD: 0.1561 - val_loss: 0.1188 - val_MSE: 0.0097 - val_MAE: 0.0764 - val_MAEMD: 0.1197\n",
      "Epoch 10/1000\n",
      "131/131 [==============================] - 13s 100ms/step - loss: 0.1568 - MSE: 0.0111 - MAE: 0.0819 - MAEMD: 0.1567 - val_loss: 0.1188 - val_MSE: 0.0097 - val_MAE: 0.0766 - val_MAEMD: 0.1195\n",
      "Epoch 11/1000\n",
      "131/131 [==============================] - 13s 100ms/step - loss: 0.1566 - MSE: 0.0109 - MAE: 0.0812 - MAEMD: 0.1565 - val_loss: 0.1183 - val_MSE: 0.0095 - val_MAE: 0.0758 - val_MAEMD: 0.1192\n",
      "Epoch 12/1000\n",
      "131/131 [==============================] - 13s 99ms/step - loss: 0.1574 - MSE: 0.0109 - MAE: 0.0812 - MAEMD: 0.1573 - val_loss: 0.1184 - val_MSE: 0.0096 - val_MAE: 0.0760 - val_MAEMD: 0.1194\n",
      "Epoch 13/1000\n",
      "131/131 [==============================] - 13s 99ms/step - loss: 0.1567 - MSE: 0.0109 - MAE: 0.0811 - MAEMD: 0.1566 - val_loss: 0.1192 - val_MSE: 0.0102 - val_MAE: 0.0785 - val_MAEMD: 0.1201\n",
      "Epoch 14/1000\n",
      "131/131 [==============================] - 13s 99ms/step - loss: 0.1562 - MSE: 0.0110 - MAE: 0.0817 - MAEMD: 0.1561 - val_loss: 0.1187 - val_MSE: 0.0098 - val_MAE: 0.0768 - val_MAEMD: 0.1197\n",
      "Epoch 15/1000\n",
      "131/131 [==============================] - 13s 99ms/step - loss: 0.1581 - MSE: 0.0111 - MAE: 0.0819 - MAEMD: 0.1579 - val_loss: 0.1197 - val_MSE: 0.0100 - val_MAE: 0.0778 - val_MAEMD: 0.1206\n",
      "Epoch 16/1000\n",
      "131/131 [==============================] - 13s 99ms/step - loss: 0.1570 - MSE: 0.0108 - MAE: 0.0808 - MAEMD: 0.1568 - val_loss: 0.1187 - val_MSE: 0.0099 - val_MAE: 0.0772 - val_MAEMD: 0.1196\n",
      "Epoch 17/1000\n",
      "131/131 [==============================] - 13s 99ms/step - loss: 0.1570 - MSE: 0.0110 - MAE: 0.0814 - MAEMD: 0.1569 - val_loss: 0.1190 - val_MSE: 0.0097 - val_MAE: 0.0768 - val_MAEMD: 0.1200\n",
      "Epoch 18/1000\n",
      "131/131 [==============================] - 13s 99ms/step - loss: 0.1557 - MSE: 0.0108 - MAE: 0.0808 - MAEMD: 0.1556 - val_loss: 0.1185 - val_MSE: 0.0097 - val_MAE: 0.0764 - val_MAEMD: 0.1195\n",
      "Epoch 19/1000\n",
      "131/131 [==============================] - 13s 99ms/step - loss: 0.1552 - MSE: 0.0107 - MAE: 0.0806 - MAEMD: 0.1550 - val_loss: 0.1179 - val_MSE: 0.0096 - val_MAE: 0.0760 - val_MAEMD: 0.1188\n",
      "Epoch 20/1000\n",
      "131/131 [==============================] - 13s 99ms/step - loss: 0.1546 - MSE: 0.0108 - MAE: 0.0809 - MAEMD: 0.1545 - val_loss: 0.1186 - val_MSE: 0.0098 - val_MAE: 0.0769 - val_MAEMD: 0.1196\n",
      "Epoch 21/1000\n",
      "131/131 [==============================] - 13s 99ms/step - loss: 0.1550 - MSE: 0.0109 - MAE: 0.0815 - MAEMD: 0.1549 - val_loss: 0.1193 - val_MSE: 0.0104 - val_MAE: 0.0794 - val_MAEMD: 0.1205\n",
      "Epoch 22/1000\n",
      "131/131 [==============================] - 13s 99ms/step - loss: 0.1554 - MSE: 0.0111 - MAE: 0.0819 - MAEMD: 0.1552 - val_loss: 0.1186 - val_MSE: 0.0099 - val_MAE: 0.0773 - val_MAEMD: 0.1194\n",
      "Epoch 23/1000\n",
      "131/131 [==============================] - 13s 99ms/step - loss: 0.1552 - MSE: 0.0109 - MAE: 0.0813 - MAEMD: 0.1551 - val_loss: 0.1192 - val_MSE: 0.0095 - val_MAE: 0.0757 - val_MAEMD: 0.1200\n",
      "Epoch 24/1000\n",
      "131/131 [==============================] - 13s 99ms/step - loss: 0.1576 - MSE: 0.0111 - MAE: 0.0821 - MAEMD: 0.1575 - val_loss: 0.1199 - val_MSE: 0.0097 - val_MAE: 0.0765 - val_MAEMD: 0.1207\n",
      "Epoch 25/1000\n",
      "131/131 [==============================] - 13s 99ms/step - loss: 0.1573 - MSE: 0.0109 - MAE: 0.0814 - MAEMD: 0.1572 - val_loss: 0.1187 - val_MSE: 0.0096 - val_MAE: 0.0763 - val_MAEMD: 0.1196\n",
      "Epoch 26/1000\n",
      "131/131 [==============================] - 13s 99ms/step - loss: 0.1572 - MSE: 0.0111 - MAE: 0.0819 - MAEMD: 0.1571 - val_loss: 0.1185 - val_MSE: 0.0097 - val_MAE: 0.0768 - val_MAEMD: 0.1194\n",
      "Epoch 27/1000\n",
      "131/131 [==============================] - 13s 99ms/step - loss: 0.1565 - MSE: 0.0109 - MAE: 0.0813 - MAEMD: 0.1564 - val_loss: 0.1185 - val_MSE: 0.0098 - val_MAE: 0.0772 - val_MAEMD: 0.1194\n",
      "Epoch 28/1000\n",
      "131/131 [==============================] - 13s 99ms/step - loss: 0.1546 - MSE: 0.0109 - MAE: 0.0815 - MAEMD: 0.1545 - val_loss: 0.1180 - val_MSE: 0.0097 - val_MAE: 0.0767 - val_MAEMD: 0.1189\n",
      "Epoch 29/1000\n",
      "131/131 [==============================] - 13s 100ms/step - loss: 0.1545 - MSE: 0.0109 - MAE: 0.0812 - MAEMD: 0.1544 - val_loss: 0.1178 - val_MSE: 0.0097 - val_MAE: 0.0766 - val_MAEMD: 0.1187\n",
      "Epoch 30/1000\n",
      "131/131 [==============================] - 13s 99ms/step - loss: 0.1551 - MSE: 0.0110 - MAE: 0.0820 - MAEMD: 0.1550 - val_loss: 0.1190 - val_MSE: 0.0101 - val_MAE: 0.0781 - val_MAEMD: 0.1198\n",
      "Epoch 31/1000\n",
      "131/131 [==============================] - 13s 99ms/step - loss: 0.1552 - MSE: 0.0109 - MAE: 0.0813 - MAEMD: 0.1550 - val_loss: 0.1185 - val_MSE: 0.0098 - val_MAE: 0.0770 - val_MAEMD: 0.1194\n",
      "Epoch 32/1000\n",
      "131/131 [==============================] - 13s 99ms/step - loss: 0.1544 - MSE: 0.0110 - MAE: 0.0819 - MAEMD: 0.1543 - val_loss: 0.1188 - val_MSE: 0.0100 - val_MAE: 0.0780 - val_MAEMD: 0.1197\n",
      "Epoch 33/1000\n",
      "131/131 [==============================] - 13s 99ms/step - loss: 0.1543 - MSE: 0.0109 - MAE: 0.0815 - MAEMD: 0.1542 - val_loss: 0.1180 - val_MSE: 0.0098 - val_MAE: 0.0770 - val_MAEMD: 0.1189\n",
      "Epoch 34/1000\n",
      "131/131 [==============================] - 13s 99ms/step - loss: 0.1555 - MSE: 0.0112 - MAE: 0.0827 - MAEMD: 0.1554 - val_loss: 0.1203 - val_MSE: 0.0102 - val_MAE: 0.0786 - val_MAEMD: 0.1212\n",
      "Epoch 35/1000\n",
      "131/131 [==============================] - 13s 99ms/step - loss: 0.1561 - MSE: 0.0109 - MAE: 0.0813 - MAEMD: 0.1560 - val_loss: 0.1175 - val_MSE: 0.0095 - val_MAE: 0.0759 - val_MAEMD: 0.1185\n",
      "Epoch 36/1000\n",
      "131/131 [==============================] - 13s 99ms/step - loss: 0.1583 - MSE: 0.0111 - MAE: 0.0821 - MAEMD: 0.1582 - val_loss: 0.1186 - val_MSE: 0.0096 - val_MAE: 0.0767 - val_MAEMD: 0.1195\n",
      "Epoch 37/1000\n",
      "131/131 [==============================] - 13s 99ms/step - loss: 0.1563 - MSE: 0.0108 - MAE: 0.0810 - MAEMD: 0.1561 - val_loss: 0.1197 - val_MSE: 0.0105 - val_MAE: 0.0796 - val_MAEMD: 0.1207\n",
      "Epoch 38/1000\n",
      "131/131 [==============================] - 13s 99ms/step - loss: 0.1586 - MSE: 0.0115 - MAE: 0.0834 - MAEMD: 0.1585 - val_loss: 0.1189 - val_MSE: 0.0098 - val_MAE: 0.0768 - val_MAEMD: 0.1200\n",
      "Epoch 39/1000\n",
      "131/131 [==============================] - 13s 100ms/step - loss: 0.1593 - MSE: 0.0111 - MAE: 0.0821 - MAEMD: 0.1591 - val_loss: 0.1199 - val_MSE: 0.0101 - val_MAE: 0.0782 - val_MAEMD: 0.1208\n",
      "Epoch 40/1000\n",
      "131/131 [==============================] - 13s 100ms/step - loss: 0.1571 - MSE: 0.0110 - MAE: 0.0818 - MAEMD: 0.1570 - val_loss: 0.1192 - val_MSE: 0.0098 - val_MAE: 0.0769 - val_MAEMD: 0.1201\n",
      "Epoch 41/1000\n",
      "131/131 [==============================] - 13s 99ms/step - loss: 0.1559 - MSE: 0.0109 - MAE: 0.0813 - MAEMD: 0.1558 - val_loss: 0.1190 - val_MSE: 0.0101 - val_MAE: 0.0779 - val_MAEMD: 0.1200\n",
      "Epoch 42/1000\n",
      "131/131 [==============================] - 13s 99ms/step - loss: 0.1562 - MSE: 0.0109 - MAE: 0.0815 - MAEMD: 0.1561 - val_loss: 0.1199 - val_MSE: 0.0105 - val_MAE: 0.0798 - val_MAEMD: 0.1210\n",
      "Epoch 43/1000\n",
      "131/131 [==============================] - 13s 99ms/step - loss: 0.1569 - MSE: 0.0111 - MAE: 0.0819 - MAEMD: 0.1568 - val_loss: 0.1187 - val_MSE: 0.0098 - val_MAE: 0.0770 - val_MAEMD: 0.1197\n",
      "Epoch 44/1000\n",
      "131/131 [==============================] - 13s 99ms/step - loss: 0.1620 - MSE: 0.0117 - MAE: 0.0846 - MAEMD: 0.1619 - val_loss: 0.1241 - val_MSE: 0.0112 - val_MAE: 0.0827 - val_MAEMD: 0.1248\n",
      "Epoch 45/1000\n",
      "131/131 [==============================] - 13s 99ms/step - loss: 0.1609 - MSE: 0.0113 - MAE: 0.0827 - MAEMD: 0.1608 - val_loss: 0.1219 - val_MSE: 0.0102 - val_MAE: 0.0789 - val_MAEMD: 0.1226\n",
      "Wall time: 9min 46s\n"
     ]
    }
   ],
   "source": [
    "    %%time\n",
    "    hist2 = model2.fit(trX, trY, epochs=epochs, batch_size=b_size, shuffle=False, validation_data=(vaX, vaY), callbacks=[history, early_stopping])  # , checkpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "ede9d76d",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 168\n",
    "num_samples = teX.shape[0]\n",
    "predictions = []\n",
    "\n",
    "for start in range(0, num_samples, batch_size):\n",
    "    end = min(start + batch_size, num_samples)\n",
    "    batch_data = teX[start:end]\n",
    "    batch_predictions = model2(batch_data)\n",
    "    predictions.append(batch_predictions)\n",
    "\n",
    "testPredict2 = np.concatenate(predictions, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "850e222c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error Test Score > MSE ==  0.008885226329186419  MAE ==  0.0736185291558078  MAEMD ==  0.11927962335983838\n",
      "Error Test Score > MSE ==  0.009699703896932784  MAE ==  0.07682190871086765  MAEMD ==  0.11885777303556062\n"
     ]
    }
   ],
   "source": [
    "tePredict2 = testPredict2.reshape(-1)\n",
    "testY = teY.reshape(-1)\n",
    "print('Error Test Score > MSE == ', npMSE(testY, tePredict), ' MAE == ', npMAE(testY, tePredict), ' MAEMD == ', npMAEMD(testY, tePredict))\n",
    "print('Error Test Score > MSE == ', npMSE(testY, tePredict2), ' MAE == ', npMAE(testY, tePredict2), ' MAEMD == ', npMAEMD(testY, tePredict2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "341d7239",
   "metadata": {},
   "outputs": [],
   "source": [
    "from statsmodels.stats.diagnostic import acorr_ljungbox\n",
    "from scipy.stats import norm\n",
    "\n",
    "def diebold_mariano_test(forecast1, forecast2, actual, opt): \n",
    "    \n",
    "    if opt==0: # MSE\n",
    "        e1 = actual-forecast1\n",
    "        e2 = actual-forecast2\n",
    "        d = e1**2 - e2**2\n",
    "    elif opt==1: # MAE\n",
    "        e1 = abs(actual-forecast1)\n",
    "        e2 = abs(actual-forecast2)\n",
    "        d = e1 - e2\n",
    "    else:\n",
    "        e1 = np.multiply(abs(actual - forecast1), np.square(actual-np.mean(actual)))\n",
    "        e2 = np.multiply(abs(actual - forecast2), np.square(actual-np.mean(actual)))\n",
    "        d = e1-e2\n",
    "    \n",
    "    # Mean of the loss differentials\n",
    "    mean_d = np.mean(d)\n",
    "    \n",
    "    # Standard deviation of the loss differentials\n",
    "    std_d = np.std(d, ddof=1)\n",
    "    \n",
    "    # Calculate the test statistic\n",
    "    test_stat = (mean_d / std_d) * np.sqrt(len(d))\n",
    "    \n",
    "    # Calculate the p-value using a two-tailed test\n",
    "    p_value = 2 * (1 - norm.cdf(abs(test_stat)))\n",
    "    \n",
    "    return test_stat, p_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "e9f19646",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((-4.183368136956967, 2.8722171614425918e-05),\n",
       " (-3.6769065353933432, 0.00023607948947623747),\n",
       " (0.2237501826284071, 0.8229516956256258))"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "diebold_mariano_test(testPredict, testPredict2, teY, 0), diebold_mariano_test(testPredict, testPredict2, teY, 1), diebold_mariano_test(testPredict, testPredict2, teY, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7a02d5c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
