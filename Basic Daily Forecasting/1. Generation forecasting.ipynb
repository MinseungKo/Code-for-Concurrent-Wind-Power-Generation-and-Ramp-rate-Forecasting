{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cebc8a3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "import pandas as pd\n",
    "import codecs\n",
    "import numpy as np\n",
    "import math\n",
    "import csv\n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.metrics import recall_score, precision_score # New\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn import preprocessing\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow.keras.preprocessing\n",
    "#from tensorflow.keras.callbacks import ModelCheckpoint, CSVLogger, EarlyStopping, LearningRateScheduler, ReduceLROnPlateau\n",
    "from tensorflow.keras.models import Sequential, Model\n",
    "from tensorflow.keras.layers import Dense, Input, Flatten, Add, Multiply, Subtract\n",
    "from tensorflow.keras import backend as K\n",
    "from tensorflow.keras.layers import Activation, BatchNormalization\n",
    "# regularizers\n",
    "from tensorflow.keras.layers import Conv1D, Conv2D\n",
    "from tensorflow.keras.layers import MaxPooling1D\n",
    "from tensorflow.keras.layers import concatenate\n",
    "from tensorflow.keras.layers import LSTM, Bidirectional\n",
    "from tensorflow.keras.utils import plot_model\n",
    "from tensorflow.keras.layers import Dropout, SpatialDropout1D\n",
    "from scipy import signal\n",
    "import openpyxl\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "from matplotlib import pylab as plt\n",
    "import matplotlib.dates as mdates\n",
    "import seaborn as sns\n",
    "import sklearn\n",
    "from sklearn.model_selection import train_test_split\n",
    "from numpy.linalg import svd\n",
    "import gc\n",
    "from keijzer import *\n",
    "from tensorflow import keras\n",
    "from keras.models import Model\n",
    "from keras.layers import *\n",
    "from tensorflow.keras.optimizers import Adam,SGD\n",
    "from keras.layers import Dense, Input, Flatten, Add, concatenate, Dropout, Activation, Multiply, Embedding, Layer, Reshape\n",
    "from keras.layers import LSTM, Bidirectional, GlobalMaxPooling1D, GlobalAveragePooling1D  \n",
    "from keras.layers import Conv1D, AveragePooling1D, MaxPooling1D\n",
    "#from keras.ops import convert_to_tensor, convert_to_numpy\n",
    "#from keras.utils import plot_model\n",
    "from keras import activations\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from keras.callbacks import ModelCheckpoint, CSVLogger, EarlyStopping, LearningRateScheduler, ReduceLROnPlateau\n",
    "import math\n",
    "\n",
    "class LossHistory(tensorflow.keras.callbacks.Callback):  # history = LossHistory()\n",
    "    def init(self):  # history.init()\n",
    "        self.losses = []\n",
    "        # self.accs = []\n",
    "        self.val_losses = []\n",
    "        # self.val_accs = []\n",
    "        self.rmses = []\n",
    "        self.mses = []\n",
    "        self.maes = []\n",
    "        self.mapes = []\n",
    "        self.val_rmses = []\n",
    "        self.val_mses = []\n",
    "        self.val_maes = []\n",
    "        self.val_mapes = []\n",
    "\n",
    "    def on_epoch_end(self, batch, logs={}):\n",
    "        self.losses.append(logs.get('loss'))\n",
    "        # self.accs.append(logs.get('acc'))\n",
    "        self.val_losses.append(logs.get('val_loss'))\n",
    "        # self.val_accs.append(logs.get('val_accuracy\n",
    "        self.rmses.append(logs.get('root_mean_squared_error'))\n",
    "        self.mses.append(logs.get('mean_squared_error'))\n",
    "        self.maes.append(logs.get('mean_absolute_error'))\n",
    "        self.mapes.append(logs.get('mean_absolute_percentage_error'))\n",
    "        self.val_rmses.append(logs.get('val_root_mean_squared_error'))\n",
    "        self.val_mses.append(logs.get('val_mean_squared_error'))\n",
    "        self.val_maes.append(logs.get('val_mean_absolute_error'))\n",
    "        self.val_mapes.append(logs.get('val_mean_absolute_percentage_error'))\n",
    "\n",
    "\n",
    "\n",
    "def root_squared_mean_error(y_true, y_pred):\n",
    "    return K.mean((K.abs(y_pred - y_true))*K.square(y_true-K.mean(y_true)))*100\n",
    "\n",
    "def mse_mae(y_true, y_pred):\n",
    "    return K.mean(K.square(y_pred - y_true))+K.mean(K.abs(y_pred - y_true))\n",
    "\n",
    "from keras.layers.advanced_activations import PReLU\n",
    "\n",
    "def mean_absolute_percentage_error(y_true, y_pred):\n",
    "    y_true, y_pred = np.array(y_true), np.array(y_pred)\n",
    "    return np.mean(np.abs((y_true - y_pred) / y_true)) * 100\n",
    "\n",
    "def root_mean_squared_error(y_true, y_pred):\n",
    "        return K.sqrt(K.mean(K.square(y_pred - y_true))) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2dc6dbb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy as sc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0cc17ef9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = '0' # 여러개 사용시 '0,1,2' 식으로 하나의 문자열에 입력\n",
    "gpus = tf.config.experimental.list_physical_devices('GPU') # 호스트 러나임에 표시되는 GPU 장치 목록 반환\n",
    "\n",
    "if gpus: # 반환된 GPU 장치 목록이 있다면\n",
    "    try: # 해당 장치에 대한 메모리 증가 활성화 여부 설정\n",
    "        tf.config.experimental.set_memory_growth(gpus[0], True)\n",
    "    except RuntimeError as e: # try문 실패시에 에러문구 출력\n",
    "        print(e)\n",
    "\n",
    "print(tf.config.list_physical_devices('GPU'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97f9d41e",
   "metadata": {},
   "source": [
    "## Import Data & Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d2b2598f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Time-Date stamp</th>\n",
       "      <th>Date</th>\n",
       "      <th>ERCOT Load</th>\n",
       "      <th>Total Wind Output</th>\n",
       "      <th>Total Wind Installed</th>\n",
       "      <th>Wind Output, % of Load</th>\n",
       "      <th>Wind Output, % of Installed</th>\n",
       "      <th>1-hr MW change</th>\n",
       "      <th>1-hr % change</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>01-01-2020 00:00:00</td>\n",
       "      <td>Jan-01</td>\n",
       "      <td>36823</td>\n",
       "      <td>12335</td>\n",
       "      <td>27040</td>\n",
       "      <td>33.5</td>\n",
       "      <td>45.617</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>01-01-2020 01:00:00</td>\n",
       "      <td>Jan-01</td>\n",
       "      <td>36511</td>\n",
       "      <td>13300</td>\n",
       "      <td>27040</td>\n",
       "      <td>36.4</td>\n",
       "      <td>49.187</td>\n",
       "      <td>965.4</td>\n",
       "      <td>7.826</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>01-01-2020 02:00:00</td>\n",
       "      <td>Jan-01</td>\n",
       "      <td>36022</td>\n",
       "      <td>13586</td>\n",
       "      <td>27040</td>\n",
       "      <td>37.7</td>\n",
       "      <td>50.245</td>\n",
       "      <td>286.2</td>\n",
       "      <td>2.152</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>01-01-2020 03:00:00</td>\n",
       "      <td>Jan-01</td>\n",
       "      <td>35790</td>\n",
       "      <td>14107</td>\n",
       "      <td>27040</td>\n",
       "      <td>39.4</td>\n",
       "      <td>52.171</td>\n",
       "      <td>520.9</td>\n",
       "      <td>3.834</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>01-01-2020 04:00:00</td>\n",
       "      <td>Jan-01</td>\n",
       "      <td>35642</td>\n",
       "      <td>14887</td>\n",
       "      <td>27040</td>\n",
       "      <td>41.8</td>\n",
       "      <td>55.055</td>\n",
       "      <td>779.6</td>\n",
       "      <td>5.527</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35060</th>\n",
       "      <td>12-31-2023 20:00:00</td>\n",
       "      <td>Dec-31</td>\n",
       "      <td>44887</td>\n",
       "      <td>17161</td>\n",
       "      <td>38631</td>\n",
       "      <td>38.23</td>\n",
       "      <td>44.42</td>\n",
       "      <td>2858</td>\n",
       "      <td>19.99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35061</th>\n",
       "      <td>12-31-2023 21:00:00</td>\n",
       "      <td>Dec-31</td>\n",
       "      <td>44013</td>\n",
       "      <td>18301</td>\n",
       "      <td>38631</td>\n",
       "      <td>41.58</td>\n",
       "      <td>47.37</td>\n",
       "      <td>1139</td>\n",
       "      <td>6.64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35062</th>\n",
       "      <td>12-31-2023 22:00:00</td>\n",
       "      <td>Dec-31</td>\n",
       "      <td>43280</td>\n",
       "      <td>18607</td>\n",
       "      <td>38631</td>\n",
       "      <td>42.99</td>\n",
       "      <td>48.17</td>\n",
       "      <td>307</td>\n",
       "      <td>1.67</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35063</th>\n",
       "      <td>12-31-2023 23:00:00</td>\n",
       "      <td>Dec-31</td>\n",
       "      <td>42319</td>\n",
       "      <td>17866</td>\n",
       "      <td>38631</td>\n",
       "      <td>42.22</td>\n",
       "      <td>46.25</td>\n",
       "      <td>-741</td>\n",
       "      <td>-3.98</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35064</th>\n",
       "      <td>01-01-2024 00:00:00</td>\n",
       "      <td>Jan-01</td>\n",
       "      <td>41682</td>\n",
       "      <td>15869</td>\n",
       "      <td>38631</td>\n",
       "      <td>38.07</td>\n",
       "      <td>41.08</td>\n",
       "      <td>-1996</td>\n",
       "      <td>-11.17</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>35065 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           Time-Date stamp    Date ERCOT Load Total Wind Output  \\\n",
       "0      01-01-2020 00:00:00  Jan-01      36823             12335   \n",
       "1      01-01-2020 01:00:00  Jan-01      36511             13300   \n",
       "2      01-01-2020 02:00:00  Jan-01      36022             13586   \n",
       "3      01-01-2020 03:00:00  Jan-01      35790             14107   \n",
       "4      01-01-2020 04:00:00  Jan-01      35642             14887   \n",
       "...                    ...     ...        ...               ...   \n",
       "35060  12-31-2023 20:00:00  Dec-31      44887             17161   \n",
       "35061  12-31-2023 21:00:00  Dec-31      44013             18301   \n",
       "35062  12-31-2023 22:00:00  Dec-31      43280             18607   \n",
       "35063  12-31-2023 23:00:00  Dec-31      42319             17866   \n",
       "35064  01-01-2024 00:00:00  Jan-01      41682             15869   \n",
       "\n",
       "      Total Wind Installed Wind Output, % of Load Wind Output, % of Installed  \\\n",
       "0                    27040                   33.5                      45.617   \n",
       "1                    27040                   36.4                      49.187   \n",
       "2                    27040                   37.7                      50.245   \n",
       "3                    27040                   39.4                      52.171   \n",
       "4                    27040                   41.8                      55.055   \n",
       "...                    ...                    ...                         ...   \n",
       "35060                38631                  38.23                       44.42   \n",
       "35061                38631                  41.58                       47.37   \n",
       "35062                38631                  42.99                       48.17   \n",
       "35063                38631                  42.22                       46.25   \n",
       "35064                38631                  38.07                       41.08   \n",
       "\n",
       "      1-hr MW change 1-hr % change  \n",
       "0                NaN           NaN  \n",
       "1              965.4         7.826  \n",
       "2              286.2         2.152  \n",
       "3              520.9         3.834  \n",
       "4              779.6         5.527  \n",
       "...              ...           ...  \n",
       "35060           2858         19.99  \n",
       "35061           1139          6.64  \n",
       "35062            307          1.67  \n",
       "35063           -741         -3.98  \n",
       "35064          -1996        -11.17  \n",
       "\n",
       "[35065 rows x 9 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_path = 'C:/Users/smartgrid_AI/Desktop/windpower_ramprate/ercot_2020.csv'\n",
    "data_source1 = pd.read_csv(data_path)\n",
    "dat_source1 = pd.DataFrame(data_source1)\n",
    "#dat_source1 = dat_source1.iloc[:-3,:]\n",
    "\n",
    "data_path = 'C:/Users/smartgrid_AI/Desktop/windpower_ramprate/ercot_2021.csv'\n",
    "data_source2 = pd.read_csv(data_path)\n",
    "dat_source2 = pd.DataFrame(data_source2)\n",
    "dat_source2 = dat_source2.iloc[:8761,:9]\n",
    "\n",
    "data_path = 'C:/Users/smartgrid_AI/Desktop/windpower_ramprate/ercot_2022.csv'\n",
    "data_source3 = pd.read_csv(data_path)\n",
    "dat_source3 = pd.DataFrame(data_source3)\n",
    "dat_source3 = dat_source3.iloc[:8760,:9]\n",
    "\n",
    "data_path = 'C:/Users/smartgrid_AI/Desktop/windpower_ramprate/ercot_2023.csv'\n",
    "data_source4 = pd.read_csv(data_path)\n",
    "dat_source4 = pd.DataFrame(data_source4)\n",
    "dat_source4 = dat_source4.iloc[:8760,:9]\n",
    "\n",
    "dat_arr1 = np.array(dat_source1)\n",
    "dat_arr2 = np.array(dat_source2)\n",
    "dat_arr3 = np.array(dat_source3)\n",
    "dat_arr4 = np.array(dat_source4)\n",
    "\n",
    "dat_arr = np.concatenate([dat_arr1, dat_arr2, dat_arr3, dat_arr4],axis=0)\n",
    "dat_arr.shape # 8784, 8761, 8760, 8760\n",
    "\n",
    "dat_source = pd.DataFrame(dat_arr, columns=['Time-Date stamp','Date','ERCOT Load','Total Wind Output','Total Wind Installed','Wind Output, % of Load','Wind Output, % of Installed','1-hr MW change','1-hr % change'])\n",
    "dat_source"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "624b4624",
   "metadata": {},
   "source": [
    "### Dividing by Installed Capacity & Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e2a5f4d4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MW % change</th>\n",
       "      <th>Total Wind Output</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3.56879</td>\n",
       "      <td>0.491864</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.05769</td>\n",
       "      <td>0.502441</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.92678</td>\n",
       "      <td>0.521709</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2.88462</td>\n",
       "      <td>0.550555</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.580621</td>\n",
       "      <td>0.544749</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35059</th>\n",
       "      <td>7.3982</td>\n",
       "      <td>0.444229</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35060</th>\n",
       "      <td>2.951</td>\n",
       "      <td>0.473739</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35061</th>\n",
       "      <td>0.79211</td>\n",
       "      <td>0.48166</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35062</th>\n",
       "      <td>-1.91815</td>\n",
       "      <td>0.462478</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35063</th>\n",
       "      <td>-5.16942</td>\n",
       "      <td>0.410784</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>35064 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      MW % change Total Wind Output\n",
       "0         3.56879          0.491864\n",
       "1         1.05769          0.502441\n",
       "2         1.92678          0.521709\n",
       "3         2.88462          0.550555\n",
       "4       -0.580621          0.544749\n",
       "...           ...               ...\n",
       "35059      7.3982          0.444229\n",
       "35060       2.951          0.473739\n",
       "35061     0.79211           0.48166\n",
       "35062    -1.91815          0.462478\n",
       "35063    -5.16942          0.410784\n",
       "\n",
       "[35064 rows x 2 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dat = pd.DataFrame()\n",
    "dat['MW % change'] = np.array(dat_source.iloc[1:,3], dtype=float)-np.array(dat_source.iloc[0:-1,3], dtype=float)\n",
    "dat['MW % change'] = np.divide(np.array(dat['MW % change']),np.array(dat_source.iloc[1:,4]))*100\n",
    "dat['Total Wind Output'] = np.divide(np.array(dat_source.iloc[1:,3]), np.array(dat_source.iloc[1:,4]))\n",
    "\n",
    "dat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c9d17db4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Year</th>\n",
       "      <th>MW % change</th>\n",
       "      <th>Total Wind Output</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2020</td>\n",
       "      <td>3.56879</td>\n",
       "      <td>0.491864</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2020</td>\n",
       "      <td>1.05769</td>\n",
       "      <td>0.502441</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2020</td>\n",
       "      <td>1.92678</td>\n",
       "      <td>0.521709</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2020</td>\n",
       "      <td>2.88462</td>\n",
       "      <td>0.550555</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2020</td>\n",
       "      <td>-0.580621</td>\n",
       "      <td>0.544749</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35059</th>\n",
       "      <td>2023</td>\n",
       "      <td>7.3982</td>\n",
       "      <td>0.444229</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35060</th>\n",
       "      <td>2023</td>\n",
       "      <td>2.951</td>\n",
       "      <td>0.473739</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35061</th>\n",
       "      <td>2023</td>\n",
       "      <td>0.79211</td>\n",
       "      <td>0.48166</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35062</th>\n",
       "      <td>2023</td>\n",
       "      <td>-1.91815</td>\n",
       "      <td>0.462478</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35063</th>\n",
       "      <td>2023</td>\n",
       "      <td>-5.16942</td>\n",
       "      <td>0.410784</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>35064 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Year MW % change Total Wind Output\n",
       "0      2020     3.56879          0.491864\n",
       "1      2020     1.05769          0.502441\n",
       "2      2020     1.92678          0.521709\n",
       "3      2020     2.88462          0.550555\n",
       "4      2020   -0.580621          0.544749\n",
       "...     ...         ...               ...\n",
       "35059  2023      7.3982          0.444229\n",
       "35060  2023       2.951          0.473739\n",
       "35061  2023     0.79211           0.48166\n",
       "35062  2023    -1.91815          0.462478\n",
       "35063  2023    -5.16942          0.410784\n",
       "\n",
       "[35064 rows x 3 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ramp_ratio = 20\n",
    "load_ratio = 10\n",
    "year_arr = np.concatenate([np.ones(8784)*2020, np.ones(8760)*2021, np.ones(8760)*2022, np.ones(8760)*2023])\n",
    "year_df = pd.DataFrame(year_arr, columns=['Year'], dtype=int)\n",
    "wind_df = pd.concat([year_df, dat], axis=1)\n",
    "wind_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "13b61950",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Year</th>\n",
       "      <th>MW % change</th>\n",
       "      <th>Total Wind Output</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2020</td>\n",
       "      <td>0.620197</td>\n",
       "      <td>0.644724</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2020</td>\n",
       "      <td>0.544580</td>\n",
       "      <td>0.658617</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2020</td>\n",
       "      <td>0.570751</td>\n",
       "      <td>0.683924</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2020</td>\n",
       "      <td>0.599594</td>\n",
       "      <td>0.721813</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2020</td>\n",
       "      <td>0.495246</td>\n",
       "      <td>0.714187</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35058</th>\n",
       "      <td>2023</td>\n",
       "      <td>0.774643</td>\n",
       "      <td>0.484984</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35059</th>\n",
       "      <td>2023</td>\n",
       "      <td>0.735512</td>\n",
       "      <td>0.582157</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35060</th>\n",
       "      <td>2023</td>\n",
       "      <td>0.601593</td>\n",
       "      <td>0.620917</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35061</th>\n",
       "      <td>2023</td>\n",
       "      <td>0.536583</td>\n",
       "      <td>0.631322</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35062</th>\n",
       "      <td>2023</td>\n",
       "      <td>0.454969</td>\n",
       "      <td>0.606127</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>35063 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Year  MW % change  Total Wind Output\n",
       "0      2020     0.620197           0.644724\n",
       "1      2020     0.544580           0.658617\n",
       "2      2020     0.570751           0.683924\n",
       "3      2020     0.599594           0.721813\n",
       "4      2020     0.495246           0.714187\n",
       "...     ...          ...                ...\n",
       "35058  2023     0.774643           0.484984\n",
       "35059  2023     0.735512           0.582157\n",
       "35060  2023     0.601593           0.620917\n",
       "35061  2023     0.536583           0.631322\n",
       "35062  2023     0.454969           0.606127\n",
       "\n",
       "[35063 rows x 3 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wind_df = wind_df.reset_index(drop=True)\n",
    "\n",
    "std_scaler = sklearn.preprocessing.MinMaxScaler()\n",
    "std_scaler_load = sklearn.preprocessing.MinMaxScaler()\n",
    "std_scaler_ramp = sklearn.preprocessing.MinMaxScaler()\n",
    "\n",
    "wind_df[['Total Wind Output']] = std_scaler.fit_transform(wind_df[['Total Wind Output']])\n",
    "wind_df[['MW % change']] = std_scaler_ramp.fit_transform(wind_df[['MW % change']])\n",
    "wind_df = wind_df.iloc[:-1,:]\n",
    "wind_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b6723e6d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Year</th>\n",
       "      <th>Wind Change</th>\n",
       "      <th>Wind Output</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2020</td>\n",
       "      <td>0.620197</td>\n",
       "      <td>0.644724</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2020</td>\n",
       "      <td>0.544580</td>\n",
       "      <td>0.658617</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2020</td>\n",
       "      <td>0.570751</td>\n",
       "      <td>0.683924</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2020</td>\n",
       "      <td>0.599594</td>\n",
       "      <td>0.721813</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2020</td>\n",
       "      <td>0.495246</td>\n",
       "      <td>0.714187</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35058</th>\n",
       "      <td>2023</td>\n",
       "      <td>0.774643</td>\n",
       "      <td>0.484984</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35059</th>\n",
       "      <td>2023</td>\n",
       "      <td>0.735512</td>\n",
       "      <td>0.582157</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35060</th>\n",
       "      <td>2023</td>\n",
       "      <td>0.601593</td>\n",
       "      <td>0.620917</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35061</th>\n",
       "      <td>2023</td>\n",
       "      <td>0.536583</td>\n",
       "      <td>0.631322</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35062</th>\n",
       "      <td>2023</td>\n",
       "      <td>0.454969</td>\n",
       "      <td>0.606127</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>35063 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Year  Wind Change  Wind Output\n",
       "0      2020     0.620197     0.644724\n",
       "1      2020     0.544580     0.658617\n",
       "2      2020     0.570751     0.683924\n",
       "3      2020     0.599594     0.721813\n",
       "4      2020     0.495246     0.714187\n",
       "...     ...          ...          ...\n",
       "35058  2023     0.774643     0.484984\n",
       "35059  2023     0.735512     0.582157\n",
       "35060  2023     0.601593     0.620917\n",
       "35061  2023     0.536583     0.631322\n",
       "35062  2023     0.454969     0.606127\n",
       "\n",
       "[35063 rows x 3 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ramp_df = pd.DataFrame(wind_df)\n",
    "ramp_df.columns=['Year', 'Wind Change', 'Wind Output']\n",
    "ramp_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35640ed2",
   "metadata": {},
   "source": [
    "## Wind Generation Forecasting"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "492b31d9",
   "metadata": {},
   "source": [
    "### SVD-based Feature Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "39c82272",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_dataset(dataset, timesteps, output_timesteps, leadtime):\n",
    "    dataX, dataY = [], []\n",
    "    for i in range(len(dataset) - timesteps -output_timesteps - leadtime - 1):\n",
    "        a = dataset[i:(i + timesteps), :]\n",
    "        dataX.append(a)\n",
    "        dataY.append(dataset[(i + timesteps + leadtime):(i+timesteps+output_timesteps+leadtime), :])\n",
    "    return np.array(dataX), np.array(dataY)\n",
    "\n",
    "def svdadd(X, start, end, b_size):\n",
    "    dec_x = X[start:end, :, :]\n",
    "    U, S, Vh = svd(dec_x.reshape(b_size, -1), full_matrices=True)\n",
    "\n",
    "    high_sig = np.matmul(np.matmul(U[:,:high_ind], np.diag(S[0:high_ind])), Vh[:high_ind,:])\n",
    "    low_sig = X[:dec_num, :, :].reshape(b_size,-1)-high_sig\n",
    "\n",
    "    rec_x = np.zeros((b_size, b_size, high_ind))\n",
    "    \n",
    "    for i in range(high_ind):\n",
    "        rec_x[:,:,i] = np.matmul((U[:,i]*S[i]).reshape(-1,1), Vh[i,:].reshape(1,-1))    \n",
    "    return rec_x, low_sig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f443730a",
   "metadata": {},
   "outputs": [],
   "source": [
    "norm_df = np.array(wind_df.iloc[:,2]).reshape(-1,1)\n",
    "timesteps = 24*7\n",
    "output_timesteps = 24\n",
    "leadtime = 6\n",
    "num_features = 1\n",
    "X, Y = create_dataset(norm_df, timesteps, output_timesteps, leadtime)\n",
    "b_size = timesteps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "78b561c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "dec_num = timesteps\n",
    "high_ind = 35\n",
    "\n",
    "addX = np.zeros((X.shape[0], dec_num, high_ind+1))\n",
    "\n",
    "for k in range(X.shape[0]//dec_num):\n",
    "    rec_x, low_sig = svdadd(X, k*dec_num, (k+1)*dec_num, b_size)\n",
    "    addX[k*dec_num:k*dec_num+dec_num,:, :-1] = rec_x\n",
    "    addX[k*dec_num:k*dec_num+dec_num,:, -1] = low_sig\n",
    "    \n",
    "rec_x, low_sig = svdadd(X, X.shape[0]-dec_num, X.shape[0], b_size)\n",
    "addX[X.shape[0]-dec_num:X.shape[0], :, :-1] = rec_x\n",
    "addX[X.shape[0]-dec_num:X.shape[0],:, -1] = low_sig\n",
    "\n",
    "addX_det = addX[:, :, :-1]\n",
    "addX_det = np.sum(addX_det, axis=2)\n",
    "X = np.concatenate([X, addX], axis=2)\n",
    "num_features = X.shape[2]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b36567a",
   "metadata": {},
   "source": [
    "### Training/Test Set Division & Shuffled Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b24472a5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((31377, 168, 37), (31377, 24), (3487, 168, 37), (3487, 24))"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trvaX, teX, trvaY, teY = train_test_split(X, Y, test_size=0.1, shuffle=False)\n",
    "\n",
    "idx = np.arange(trvaX.shape[0])\n",
    "np.random.shuffle(idx)\n",
    "strvaX = trvaX[idx]\n",
    "strvaY = trvaY[idx]\n",
    "strvaY = strvaY.reshape(-1, output_timesteps)\n",
    "\n",
    "trvaY = trvaY.reshape(-1, output_timesteps)\n",
    "teY = teY.reshape(-1, output_timesteps)\n",
    "\n",
    "strX, svaX, strY, svaY = train_test_split(strvaX, strvaY, test_size=0.3, shuffle=False)\n",
    "trX, vaX, trY, vaY = train_test_split(trvaX, trvaY, test_size=0.3, shuffle=False)\n",
    "\n",
    "trvaX.shape, trvaY.shape, teX.shape, teY.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd2a2c2f",
   "metadata": {},
   "source": [
    "## Wind Generation Forecasting Basic Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "98420bb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def MAEMS(y_true, y_pred):\n",
    "    return K.mean((K.abs(y_pred - y_true))*K.square(y_true))*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "68701bca",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers.advanced_activations import PReLU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "833abe4f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            [(None, 168, 37)]    0                                            \n",
      "__________________________________________________________________________________________________\n",
      "permute (Permute)               (None, 37, 168)      0           input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, 37, 168)      28392       permute[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 37, 168)      28392       permute[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "multiply (Multiply)             (None, 37, 168)      0           dense[0][0]                      \n",
      "                                                                 dense_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "attention_vec (Permute)         (None, 168, 37)      0           multiply[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "multiply_1 (Multiply)           (None, 168, 37)      0           input_1[0][0]                    \n",
      "                                                                 attention_vec[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv1d (Conv1D)                 (None, 168, 256)     9728        multiply_1[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation (Activation)         (None, 168, 256)     0           conv1d[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "activation_1 (Activation)       (None, 168, 256)     0           conv1d[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "multiply_2 (Multiply)           (None, 168, 256)     0           activation[0][0]                 \n",
      "                                                                 activation_1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_1 (Conv1D)               (None, 168, 37)      18981       multiply_2[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_2 (Activation)       (None, 168, 37)      0           conv1d_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_3 (Activation)       (None, 168, 37)      0           conv1d_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "multiply_3 (Multiply)           (None, 168, 37)      0           activation_2[0][0]               \n",
      "                                                                 activation_3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "add (Add)                       (None, 168, 37)      0           input_1[0][0]                    \n",
      "                                                                 multiply_3[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "subtract (Subtract)             (None, 168, 37)      0           input_1[0][0]                    \n",
      "                                                                 multiply_3[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_2 (Conv1D)               (None, 168, 256)     9728        add[0][0]                        \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_4 (Conv1D)               (None, 168, 256)     9728        subtract[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_4 (Activation)       (None, 168, 256)     0           conv1d_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_5 (Activation)       (None, 168, 256)     0           conv1d_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_8 (Activation)       (None, 168, 256)     0           conv1d_4[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_9 (Activation)       (None, 168, 256)     0           conv1d_4[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "multiply_4 (Multiply)           (None, 168, 256)     0           activation_4[0][0]               \n",
      "                                                                 activation_5[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "multiply_6 (Multiply)           (None, 168, 256)     0           activation_8[0][0]               \n",
      "                                                                 activation_9[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_3 (Conv1D)               (None, 168, 37)      18981       multiply_4[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_5 (Conv1D)               (None, 168, 37)      18981       multiply_6[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_6 (Activation)       (None, 168, 37)      0           conv1d_3[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_7 (Activation)       (None, 168, 37)      0           conv1d_3[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_10 (Activation)      (None, 168, 37)      0           conv1d_5[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_11 (Activation)      (None, 168, 37)      0           conv1d_5[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "multiply_5 (Multiply)           (None, 168, 37)      0           activation_6[0][0]               \n",
      "                                                                 activation_7[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "multiply_7 (Multiply)           (None, 168, 37)      0           activation_10[0][0]              \n",
      "                                                                 activation_11[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "add_1 (Add)                     (None, 168, 37)      0           add[0][0]                        \n",
      "                                                                 multiply_5[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "subtract_1 (Subtract)           (None, 168, 37)      0           subtract[0][0]                   \n",
      "                                                                 multiply_7[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "concatenate (Concatenate)       (None, 168, 148)     0           add_1[0][0]                      \n",
      "                                                                 subtract_1[0][0]                 \n",
      "                                                                 add[0][0]                        \n",
      "                                                                 subtract[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_6 (Conv1D)               (None, 168, 256)     38144       concatenate[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_8 (Conv1D)               (None, 168, 256)     38144       concatenate[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "activation_12 (Activation)      (None, 168, 256)     0           conv1d_6[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_13 (Activation)      (None, 168, 256)     0           conv1d_6[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_16 (Activation)      (None, 168, 256)     0           conv1d_8[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_17 (Activation)      (None, 168, 256)     0           conv1d_8[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "multiply_8 (Multiply)           (None, 168, 256)     0           activation_12[0][0]              \n",
      "                                                                 activation_13[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "multiply_10 (Multiply)          (None, 168, 256)     0           activation_16[0][0]              \n",
      "                                                                 activation_17[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_7 (Conv1D)               (None, 168, 37)      18981       multiply_8[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_9 (Conv1D)               (None, 168, 37)      18981       multiply_10[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "activation_14 (Activation)      (None, 168, 37)      0           conv1d_7[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_15 (Activation)      (None, 168, 37)      0           conv1d_7[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_18 (Activation)      (None, 168, 37)      0           conv1d_9[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_19 (Activation)      (None, 168, 37)      0           conv1d_9[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "multiply_9 (Multiply)           (None, 168, 37)      0           activation_14[0][0]              \n",
      "                                                                 activation_15[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "multiply_11 (Multiply)          (None, 168, 37)      0           activation_18[0][0]              \n",
      "                                                                 activation_19[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "add_2 (Add)                     (None, 168, 37)      0           add_1[0][0]                      \n",
      "                                                                 multiply_9[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "subtract_2 (Subtract)           (None, 168, 37)      0           subtract_1[0][0]                 \n",
      "                                                                 multiply_11[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, 168, 222)     0           add_2[0][0]                      \n",
      "                                                                 subtract_2[0][0]                 \n",
      "                                                                 concatenate[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_10 (Conv1D)              (None, 168, 256)     57088       concatenate_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_12 (Conv1D)              (None, 168, 256)     57088       concatenate_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_20 (Activation)      (None, 168, 256)     0           conv1d_10[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_21 (Activation)      (None, 168, 256)     0           conv1d_10[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_24 (Activation)      (None, 168, 256)     0           conv1d_12[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_25 (Activation)      (None, 168, 256)     0           conv1d_12[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "multiply_12 (Multiply)          (None, 168, 256)     0           activation_20[0][0]              \n",
      "                                                                 activation_21[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "multiply_14 (Multiply)          (None, 168, 256)     0           activation_24[0][0]              \n",
      "                                                                 activation_25[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_11 (Conv1D)              (None, 168, 37)      18981       multiply_12[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_13 (Conv1D)              (None, 168, 37)      18981       multiply_14[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "activation_22 (Activation)      (None, 168, 37)      0           conv1d_11[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_23 (Activation)      (None, 168, 37)      0           conv1d_11[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_26 (Activation)      (None, 168, 37)      0           conv1d_13[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_27 (Activation)      (None, 168, 37)      0           conv1d_13[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "multiply_13 (Multiply)          (None, 168, 37)      0           activation_22[0][0]              \n",
      "                                                                 activation_23[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "multiply_15 (Multiply)          (None, 168, 37)      0           activation_26[0][0]              \n",
      "                                                                 activation_27[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "add_3 (Add)                     (None, 168, 37)      0           add_2[0][0]                      \n",
      "                                                                 multiply_13[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "subtract_3 (Subtract)           (None, 168, 37)      0           subtract_1[0][0]                 \n",
      "                                                                 multiply_15[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_2 (Concatenate)     (None, 168, 296)     0           add_3[0][0]                      \n",
      "                                                                 subtract_3[0][0]                 \n",
      "                                                                 concatenate_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_14 (Conv1D)              (None, 168, 256)     76032       concatenate_2[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_16 (Conv1D)              (None, 168, 256)     76032       concatenate_2[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_28 (Activation)      (None, 168, 256)     0           conv1d_14[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_29 (Activation)      (None, 168, 256)     0           conv1d_14[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_32 (Activation)      (None, 168, 256)     0           conv1d_16[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_33 (Activation)      (None, 168, 256)     0           conv1d_16[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "multiply_16 (Multiply)          (None, 168, 256)     0           activation_28[0][0]              \n",
      "                                                                 activation_29[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "multiply_18 (Multiply)          (None, 168, 256)     0           activation_32[0][0]              \n",
      "                                                                 activation_33[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_15 (Conv1D)              (None, 168, 37)      18981       multiply_16[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_17 (Conv1D)              (None, 168, 37)      18981       multiply_18[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "activation_30 (Activation)      (None, 168, 37)      0           conv1d_15[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_31 (Activation)      (None, 168, 37)      0           conv1d_15[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_34 (Activation)      (None, 168, 37)      0           conv1d_17[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_35 (Activation)      (None, 168, 37)      0           conv1d_17[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "multiply_17 (Multiply)          (None, 168, 37)      0           activation_30[0][0]              \n",
      "                                                                 activation_31[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "multiply_19 (Multiply)          (None, 168, 37)      0           activation_34[0][0]              \n",
      "                                                                 activation_35[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "add_4 (Add)                     (None, 168, 37)      0           add_3[0][0]                      \n",
      "                                                                 multiply_17[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "subtract_4 (Subtract)           (None, 168, 37)      0           subtract_3[0][0]                 \n",
      "                                                                 multiply_19[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_3 (Concatenate)     (None, 168, 370)     0           add_4[0][0]                      \n",
      "                                                                 subtract_4[0][0]                 \n",
      "                                                                 concatenate_2[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_4 (Concatenate)     (None, 168, 74)      0           add_4[0][0]                      \n",
      "                                                                 subtract_4[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_5 (Concatenate)     (None, 168, 1110)    0           concatenate[0][0]                \n",
      "                                                                 concatenate_1[0][0]              \n",
      "                                                                 concatenate_2[0][0]              \n",
      "                                                                 concatenate_3[0][0]              \n",
      "                                                                 concatenate_4[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_22 (Conv1D)              (None, 168, 720)     920880      concatenate_5[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout (Dropout)               (None, 168, 720)     0           conv1d_22[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_23 (Conv1D)              (None, 168, 360)     320040      dropout[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)             (None, 168, 360)     0           conv1d_23[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling1d (Globa (None, 360)          0           dropout_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_2 (Dense)                 (None, 24)           8664        global_average_pooling1d[0][0]   \n",
      "==================================================================================================\n",
      "Total params: 1,848,909\n",
      "Trainable params: 1,848,909\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "num_features = trvaX.shape[2]\n",
    "output_timesteps = trvaY.shape[1]\n",
    "\n",
    "with tf.device('/gpu:0'):\n",
    "    alpha=1.0\n",
    "    gamma=1.2\n",
    "    beta = 1\n",
    "    hfilters = 256\n",
    "    hkernel_size1 = 1\n",
    "    hkernel_size2 = 2\n",
    "    \n",
    "    visible1 = Input(shape=(timesteps, num_features))\n",
    "   \n",
    "    ## Attention Block\n",
    "    per1 = Permute((2,1))(visible1)\n",
    "    den1a = Dense(timesteps, activation='tanh')(per1)\n",
    "    den1b = Dense(timesteps, activation='sigmoid')(per1)\n",
    "    den1 = Multiply()([den1a, den1b])\n",
    "    per2 = Permute((2,1), name='attention_vec')(den1)\n",
    "    mul1 = Multiply()([visible1, per2])\n",
    "    \n",
    "    ## Series PN DCCNN Blocks 1 ~ 6\n",
    "    d1 = Conv1D(filters=round(hfilters*alpha), kernel_size=round(hkernel_size1*beta), padding='causal', dilation_rate=1)(mul1)\n",
    "    d1a = Activation(activations.tanh)(d1)\n",
    "    d1b = Activation(activations.sigmoid)(d1)\n",
    "    d1 = Multiply()([d1a, d1b])\n",
    "    \n",
    "    d1 = Conv1D(filters=num_features, kernel_size=round(hkernel_size2*beta), padding='causal', dilation_rate=2)(d1)\n",
    "    d1a = Activation(activations.tanh)(d1)\n",
    "    d1b = Activation(activations.sigmoid)(d1)\n",
    "    d1 = Multiply()([d1a, d1b])\n",
    "    \n",
    "    res01a = Add()([visible1, d1])   # (100, 25) (100, 25)\n",
    "    res01b = Subtract()([visible1, d1])\n",
    "\n",
    "    d1 = Conv1D(filters=round(hfilters*alpha), kernel_size=round(hkernel_size1*beta), padding='causal', dilation_rate=2)(res01a)\n",
    "    d1a = Activation(activations.tanh)(d1)\n",
    "    d1b = Activation(activations.sigmoid)(d1)\n",
    "    d1 = Multiply()([d1a, d1b])\n",
    "    \n",
    "    d1 = Conv1D(filters=num_features, kernel_size=round(hkernel_size2*beta), padding='causal', dilation_rate=4)(d1)    \n",
    "    d1a = Activation(activations.tanh)(d1)\n",
    "    d1b = Activation(activations.sigmoid)(d1)\n",
    "    \n",
    "    d1 = Multiply()([d1a, d1b])\n",
    "    res02a = Add()([res01a, d1])   # (100, 25) (100, 25)\n",
    "    \n",
    "    d2 = Conv1D(filters=round(hfilters*alpha), kernel_size=round(hkernel_size1*beta), padding='causal', dilation_rate=2)(res01b) \n",
    "    d2a = Activation(activations.tanh)(d2)\n",
    "    d2b = Activation(activations.sigmoid)(d2)\n",
    "    d2 = Multiply()([d2a, d2b])\n",
    "    \n",
    "    d2 = Conv1D(filters=num_features, kernel_size=round(hkernel_size2*beta), padding='causal', dilation_rate=4)(d2) \n",
    "    d2a = Activation(activations.tanh)(d2)\n",
    "    d2b = Activation(activations.sigmoid)(d2)\n",
    "    d2 = Multiply()([d2a, d2b])\n",
    "    \n",
    "    res02b = Subtract()([res01b, d2])   # (100, 25) (100, 25) \n",
    "    res02 = Concatenate()([res02a, res02b, res01a, res01b])\n",
    "    \n",
    "    d1 = Conv1D(filters=round(hfilters*alpha), kernel_size=round(hkernel_size1*beta), padding='causal', dilation_rate=4)(res02)\n",
    "    d1a = Activation(activations.tanh)(d1)\n",
    "    d1b = Activation(activations.sigmoid)(d1)\n",
    "    d1 = Multiply()([d1a, d1b])\n",
    "    \n",
    "    d1 = Conv1D(filters=num_features, kernel_size=round(hkernel_size2*beta), padding='causal', dilation_rate=8)(d1)    \n",
    "    d1a = Activation(activations.tanh)(d1)\n",
    "    d1b = Activation(activations.sigmoid)(d1)\n",
    "    d1 = Multiply()([d1a, d1b])\n",
    "    \n",
    "    res03a = Add()([res02a, d1])   # (100, 25) (100, 25)\n",
    "    \n",
    "    d2 = Conv1D(filters=round(hfilters*alpha), kernel_size=round(hkernel_size1*beta), padding='causal', dilation_rate=4)(res02) \n",
    "    d2a = Activation(activations.tanh)(d2)\n",
    "    d2b = Activation(activations.sigmoid)(d2)\n",
    "    d2 = Multiply()([d2a, d2b])\n",
    "    \n",
    "    d2 = Conv1D(filters=num_features, kernel_size=round(hkernel_size2*beta), padding='causal', dilation_rate=8)(d2) \n",
    "    d2a = Activation(activations.tanh)(d2)\n",
    "    d2b = Activation(activations.sigmoid)(d2)\n",
    "    d2 = Multiply()([d2a, d2b])\n",
    "    \n",
    "    res03b = Subtract()([res02b, d2])   # (100, 25) (100, 25)\n",
    "    res03 = Concatenate()([res03a, res03b, res02])\n",
    "    \n",
    "    d1 = Conv1D(filters=round(hfilters*alpha), kernel_size=round(hkernel_size1*beta), padding='causal', dilation_rate=8)(res03)\n",
    "    d1a = Activation(activations.tanh)(d1)\n",
    "    d1b = Activation(activations.sigmoid)(d1)\n",
    "    d1 = Multiply()([d1a, d1b])\n",
    "    d1 = Conv1D(filters=num_features, kernel_size=round(hkernel_size2*beta), padding='causal', dilation_rate=4)(d1)    \n",
    "    d1a = Activation(activations.tanh)(d1)\n",
    "    d1b = Activation(activations.sigmoid)(d1)\n",
    "    d1 = Multiply()([d1a, d1b])\n",
    "    res04a = Add()([res03a, d1])   # (100, 25) (100, 25)\n",
    "    \n",
    "    d2 = Conv1D(filters=round(hfilters*alpha), kernel_size=round(hkernel_size1*beta), padding='causal', dilation_rate=8)(res03) \n",
    "    d2a = Activation(activations.tanh)(d2)\n",
    "    d2b = Activation(activations.sigmoid)(d2)\n",
    "    d2 = Multiply()([d2a, d2b])\n",
    "    \n",
    "    d2 = Conv1D(filters=num_features, kernel_size=round(hkernel_size2*beta), padding='causal', dilation_rate=4)(d2) \n",
    "    d2a = Activation(activations.tanh)(d2)\n",
    "    d2b = Activation(activations.sigmoid)(d2)\n",
    "    d2 = Multiply()([d2a, d2b])\n",
    "    \n",
    "    res04b = Subtract()([res02b, d2])   # (100, 25) (100, 25)\n",
    "    res04 = Concatenate()([res04a, res04b, res03])\n",
    "    \n",
    "    d1 = Conv1D(filters=round(hfilters*alpha), kernel_size=round(hkernel_size1*beta), padding='causal', dilation_rate=4)(res04)\n",
    "    d1a = Activation(activations.tanh)(d1)\n",
    "    d1b = Activation(activations.sigmoid)(d1)\n",
    "    d1 = Multiply()([d1a, d1b])\n",
    "    \n",
    "    d1 = Conv1D(filters=num_features, kernel_size=round(hkernel_size2*beta), padding='causal', dilation_rate=2)(d1)    \n",
    "    d1a = Activation(activations.tanh)(d1)\n",
    "    d1b = Activation(activations.sigmoid)(d1)\n",
    "    d1 = Multiply()([d1a, d1b])\n",
    "    \n",
    "    res05a = Add()([res04a, d1])   # (100, 25) (100, 25)\n",
    "    \n",
    "    d2 = Conv1D(filters=round(hfilters*alpha), kernel_size=round(hkernel_size1*beta), padding='causal', dilation_rate=4)(res04) \n",
    "    d2a = Activation(activations.tanh)(d2)\n",
    "    d2b = Activation(activations.sigmoid)(d2)\n",
    "    d2 = Multiply()([d2a, d2b])\n",
    "    \n",
    "    d2 = Conv1D(filters=num_features, kernel_size=round(hkernel_size2*beta), padding='causal', dilation_rate=2)(d2) \n",
    "    d2a = Activation(activations.tanh)(d2)\n",
    "    d2b = Activation(activations.sigmoid)(d2)\n",
    "    d2 = Multiply()([d2a, d2b])\n",
    "    \n",
    "    res05b = Subtract()([res04b, d2])   # (100, 25) (100, 25)\n",
    "    res05 = Concatenate()([res05a, res05b, res04])\n",
    "    \n",
    "    d1 = Conv1D(filters=round(hfilters*alpha), kernel_size=round(hkernel_size1*beta), padding='causal', dilation_rate=2)(res05)\n",
    "    d1a = Activation(activations.tanh)(d1)\n",
    "    d1b = Activation(activations.sigmoid)(d1)\n",
    "    d1 = Multiply()([d1a, d1b])\n",
    "    \n",
    "    d1 = Conv1D(filters=num_features, kernel_size=round(hkernel_size2*beta), padding='causal', dilation_rate=1)(d1)    \n",
    "    d1a = Activation(activations.tanh)(d1)\n",
    "    d1b = Activation(activations.sigmoid)(d1)\n",
    "    d1 = Multiply()([d1a, d1b])\n",
    "\n",
    "    res06a = Add()([res05a, d1])   # (100, 25) (100, 25)\n",
    "    \n",
    "    d2 = Conv1D(filters=round(hfilters*alpha), kernel_size=round(hkernel_size1*beta), padding='causal', dilation_rate=2)(res05) \n",
    "    d2a = Activation(activations.tanh)(d2)\n",
    "    d2b = Activation(activations.sigmoid)(d2)\n",
    "    d2 = Multiply()([d2a, d2b])\n",
    "    d2 = Conv1D(filters=num_features, kernel_size=round(hkernel_size2*beta), padding='causal', dilation_rate=1)(d2) \n",
    "    d2a = Activation(activations.tanh)(d2)\n",
    "    d2b = Activation(activations.sigmoid)(d2)\n",
    "    d2 = Multiply()([d2a, d2b])\n",
    "\n",
    "    res06b = Subtract()([res05b, d2])   # (100, 25) (100, 25)\n",
    "    res06 = Concatenate()([res05a, res05b])\n",
    "    \n",
    "    res10 = Concatenate()([res02, res03, res04, res05, res06])   # \n",
    "    \n",
    "    #print('res10 :', res10.shap)  # (None, 24, 11) \n",
    "    \n",
    "    ## Output Block\n",
    "    out = Conv1D(720, 1, padding='same', activation=PReLU())(res10)   # 256, 11X10=110\n",
    "    out = Dropout(0.2)(out)   #SpatialDropout1D\n",
    "    \n",
    "    out = Conv1D(360, 1, padding='same', activation=PReLU())(out) # 512,  110X5=550\n",
    "    out = Dropout(0.2)(out)\n",
    "    \n",
    "    out = GlobalAveragePooling1D()(out) # pool_size=2, strides=1\n",
    "    \n",
    "    out = Dense(24)(out) \n",
    "    model = Model(inputs=[visible1], outputs=[out])\n",
    "    \n",
    "    print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d3d01d6d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1371"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "3542ddfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "    model.compile(loss=MAEMS, optimizer='adam', metrics=['mse','mae', MAEMS])\n",
    "    early_stopping =EarlyStopping(monitor='val_loss', patience=10)\n",
    "    batch_size = 168\n",
    "    epochs = 1000\n",
    "    #root_squared_mean_error\n",
    "    history = LossHistory()\n",
    "    history.init()\n",
    "    \n",
    "    #hist = model.fit(trX, trY, epochs=epochs, batch_size=batch_size, shuffle=False, validation_data=(vaX, vaY), callbacks=[history, early_stopping])  # , checkpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "7650d39f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "131/131 [==============================] - 23s 149ms/step - loss: 3.6657 - mse: 0.0917 - mae: 0.2465 - MAEMS: 3.6645 - val_loss: 3.2811 - val_mse: 0.0657 - val_mae: 0.2090 - val_MAEMS: 3.3050\n",
      "Epoch 2/1000\n",
      "131/131 [==============================] - 18s 134ms/step - loss: 3.1323 - mse: 0.0723 - mae: 0.2175 - MAEMS: 3.1319 - val_loss: 3.0993 - val_mse: 0.0558 - val_mae: 0.1915 - val_MAEMS: 3.1233\n",
      "Epoch 3/1000\n",
      "131/131 [==============================] - 50s 381ms/step - loss: 2.9461 - mse: 0.0625 - mae: 0.1999 - MAEMS: 2.9458 - val_loss: 3.0214 - val_mse: 0.0478 - val_mae: 0.1756 - val_MAEMS: 3.0430\n",
      "Epoch 4/1000\n",
      "131/131 [==============================] - 122s 935ms/step - loss: 2.7985 - mse: 0.0576 - mae: 0.1898 - MAEMS: 2.7981 - val_loss: 2.7550 - val_mse: 0.0560 - val_mae: 0.1866 - val_MAEMS: 2.7625\n",
      "Epoch 5/1000\n",
      "131/131 [==============================] - 123s 940ms/step - loss: 2.7354 - mse: 0.0550 - mae: 0.1843 - MAEMS: 2.7350 - val_loss: 2.8899 - val_mse: 0.0410 - val_mae: 0.1609 - val_MAEMS: 2.9062\n",
      "Epoch 6/1000\n",
      "131/131 [==============================] - 123s 943ms/step - loss: 2.5855 - mse: 0.0512 - mae: 0.1761 - MAEMS: 2.5853 - val_loss: 2.6450 - val_mse: 0.0411 - val_mae: 0.1586 - val_MAEMS: 2.6593\n",
      "Epoch 7/1000\n",
      "131/131 [==============================] - 122s 930ms/step - loss: 2.5638 - mse: 0.0496 - mae: 0.1728 - MAEMS: 2.5633 - val_loss: 2.6560 - val_mse: 0.0384 - val_mae: 0.1532 - val_MAEMS: 2.6744\n",
      "Epoch 8/1000\n",
      "131/131 [==============================] - 39s 297ms/step - loss: 2.3937 - mse: 0.0461 - mae: 0.1645 - MAEMS: 2.3933 - val_loss: 2.6308 - val_mse: 0.0341 - val_mae: 0.1441 - val_MAEMS: 2.6508\n",
      "Epoch 9/1000\n",
      "131/131 [==============================] - 18s 135ms/step - loss: 2.2269 - mse: 0.0421 - mae: 0.1556 - MAEMS: 2.2264 - val_loss: 2.1941 - val_mse: 0.0385 - val_mae: 0.1475 - val_MAEMS: 2.2102\n",
      "Epoch 10/1000\n",
      "131/131 [==============================] - 18s 135ms/step - loss: 2.1051 - mse: 0.0388 - mae: 0.1480 - MAEMS: 2.1048 - val_loss: 2.0824 - val_mse: 0.0381 - val_mae: 0.1459 - val_MAEMS: 2.0997\n",
      "Epoch 11/1000\n",
      "131/131 [==============================] - 18s 135ms/step - loss: 2.0231 - mse: 0.0364 - mae: 0.1423 - MAEMS: 2.0229 - val_loss: 1.9812 - val_mse: 0.0353 - val_mae: 0.1390 - val_MAEMS: 1.9963\n",
      "Epoch 12/1000\n",
      "131/131 [==============================] - 18s 136ms/step - loss: 1.9226 - mse: 0.0341 - mae: 0.1365 - MAEMS: 1.9224 - val_loss: 2.0055 - val_mse: 0.0290 - val_mae: 0.1266 - val_MAEMS: 2.0203\n",
      "Epoch 13/1000\n",
      "131/131 [==============================] - 18s 136ms/step - loss: 1.8931 - mse: 0.0327 - mae: 0.1332 - MAEMS: 1.8927 - val_loss: 1.9749 - val_mse: 0.0278 - val_mae: 0.1232 - val_MAEMS: 1.9848\n",
      "Epoch 14/1000\n",
      "131/131 [==============================] - 18s 135ms/step - loss: 1.8326 - mse: 0.0311 - mae: 0.1293 - MAEMS: 1.8324 - val_loss: 2.4405 - val_mse: 0.0232 - val_mae: 0.1186 - val_MAEMS: 2.4521\n",
      "Epoch 15/1000\n",
      "131/131 [==============================] - 18s 135ms/step - loss: 1.7325 - mse: 0.0291 - mae: 0.1238 - MAEMS: 1.7323 - val_loss: 2.2399 - val_mse: 0.0220 - val_mae: 0.1130 - val_MAEMS: 2.2511\n",
      "Epoch 16/1000\n",
      "131/131 [==============================] - 18s 135ms/step - loss: 1.7209 - mse: 0.0281 - mae: 0.1216 - MAEMS: 1.7209 - val_loss: 1.7415 - val_mse: 0.0280 - val_mae: 0.1216 - val_MAEMS: 1.7533\n",
      "Epoch 17/1000\n",
      "131/131 [==============================] - 18s 135ms/step - loss: 1.6764 - mse: 0.0270 - mae: 0.1187 - MAEMS: 1.6764 - val_loss: 2.1101 - val_mse: 0.0210 - val_mae: 0.1093 - val_MAEMS: 2.1275\n",
      "Epoch 18/1000\n",
      "131/131 [==============================] - 18s 135ms/step - loss: 1.6293 - mse: 0.0261 - mae: 0.1162 - MAEMS: 1.6291 - val_loss: 2.2245 - val_mse: 0.0195 - val_mae: 0.1070 - val_MAEMS: 2.2419\n",
      "Epoch 19/1000\n",
      "131/131 [==============================] - 18s 135ms/step - loss: 1.6253 - mse: 0.0253 - mae: 0.1143 - MAEMS: 1.6250 - val_loss: 1.8679 - val_mse: 0.0209 - val_mae: 0.1062 - val_MAEMS: 1.8839\n",
      "Epoch 20/1000\n",
      "131/131 [==============================] - 18s 135ms/step - loss: 1.5407 - mse: 0.0240 - mae: 0.1102 - MAEMS: 1.5405 - val_loss: 1.8017 - val_mse: 0.0203 - val_mae: 0.1046 - val_MAEMS: 1.8146\n",
      "Epoch 21/1000\n",
      "131/131 [==============================] - 18s 135ms/step - loss: 1.4837 - mse: 0.0229 - mae: 0.1069 - MAEMS: 1.4837 - val_loss: 1.5803 - val_mse: 0.0215 - val_mae: 0.1048 - val_MAEMS: 1.5851\n",
      "Epoch 22/1000\n",
      "131/131 [==============================] - 18s 135ms/step - loss: 1.5321 - mse: 0.0229 - mae: 0.1078 - MAEMS: 1.5317 - val_loss: 1.5261 - val_mse: 0.0242 - val_mae: 0.1104 - val_MAEMS: 1.5395\n",
      "Epoch 23/1000\n",
      "131/131 [==============================] - 18s 135ms/step - loss: 1.5080 - mse: 0.0223 - mae: 0.1059 - MAEMS: 1.5080 - val_loss: 1.8782 - val_mse: 0.0179 - val_mae: 0.0992 - val_MAEMS: 1.9039\n",
      "Epoch 24/1000\n",
      "131/131 [==============================] - 18s 135ms/step - loss: 1.3880 - mse: 0.0207 - mae: 0.1006 - MAEMS: 1.3879 - val_loss: 1.4775 - val_mse: 0.0198 - val_mae: 0.0992 - val_MAEMS: 1.4953\n",
      "Epoch 25/1000\n",
      "131/131 [==============================] - 18s 135ms/step - loss: 1.3242 - mse: 0.0195 - mae: 0.0967 - MAEMS: 1.3241 - val_loss: 1.5614 - val_mse: 0.0175 - val_mae: 0.0943 - val_MAEMS: 1.5798\n",
      "Epoch 26/1000\n",
      "131/131 [==============================] - 18s 135ms/step - loss: 1.2974 - mse: 0.0187 - mae: 0.0945 - MAEMS: 1.2974 - val_loss: 1.4755 - val_mse: 0.0166 - val_mae: 0.0911 - val_MAEMS: 1.4790\n",
      "Epoch 27/1000\n",
      "131/131 [==============================] - 18s 135ms/step - loss: 1.3104 - mse: 0.0185 - mae: 0.0940 - MAEMS: 1.3102 - val_loss: 1.8170 - val_mse: 0.0152 - val_mae: 0.0916 - val_MAEMS: 1.8275\n",
      "Epoch 28/1000\n",
      "131/131 [==============================] - 18s 135ms/step - loss: 1.2810 - mse: 0.0179 - mae: 0.0921 - MAEMS: 1.2808 - val_loss: 1.5710 - val_mse: 0.0160 - val_mae: 0.0907 - val_MAEMS: 1.5822\n",
      "Epoch 29/1000\n",
      "131/131 [==============================] - 18s 136ms/step - loss: 1.2665 - mse: 0.0173 - mae: 0.0904 - MAEMS: 1.2664 - val_loss: 1.5690 - val_mse: 0.0147 - val_mae: 0.0872 - val_MAEMS: 1.5758\n",
      "Epoch 30/1000\n",
      "131/131 [==============================] - 18s 136ms/step - loss: 1.2419 - mse: 0.0168 - mae: 0.0889 - MAEMS: 1.2420 - val_loss: 1.3510 - val_mse: 0.0160 - val_mae: 0.0878 - val_MAEMS: 1.3605\n",
      "Epoch 31/1000\n",
      "131/131 [==============================] - 18s 135ms/step - loss: 1.2383 - mse: 0.0166 - mae: 0.0882 - MAEMS: 1.2382 - val_loss: 1.3671 - val_mse: 0.0156 - val_mae: 0.0869 - val_MAEMS: 1.3771\n",
      "Epoch 32/1000\n",
      "131/131 [==============================] - 18s 135ms/step - loss: 1.2461 - mse: 0.0164 - mae: 0.0879 - MAEMS: 1.2463 - val_loss: 1.7346 - val_mse: 0.0149 - val_mae: 0.0899 - val_MAEMS: 1.7421\n",
      "Epoch 33/1000\n",
      "131/131 [==============================] - 18s 135ms/step - loss: 1.2775 - mse: 0.0164 - mae: 0.0886 - MAEMS: 1.2772 - val_loss: 1.5352 - val_mse: 0.0148 - val_mae: 0.0871 - val_MAEMS: 1.5527\n",
      "Epoch 34/1000\n",
      "131/131 [==============================] - 18s 136ms/step - loss: 1.2519 - mse: 0.0160 - mae: 0.0871 - MAEMS: 1.2518 - val_loss: 1.4396 - val_mse: 0.0144 - val_mae: 0.0847 - val_MAEMS: 1.4529\n",
      "Epoch 35/1000\n",
      "131/131 [==============================] - 18s 135ms/step - loss: 1.2728 - mse: 0.0161 - mae: 0.0877 - MAEMS: 1.2726 - val_loss: 1.9700 - val_mse: 0.0138 - val_mae: 0.0896 - val_MAEMS: 1.9899\n",
      "Epoch 36/1000\n",
      "131/131 [==============================] - 18s 135ms/step - loss: 1.2494 - mse: 0.0158 - mae: 0.0865 - MAEMS: 1.2491 - val_loss: 1.7163 - val_mse: 0.0131 - val_mae: 0.0846 - val_MAEMS: 1.7302\n",
      "Epoch 37/1000\n",
      "131/131 [==============================] - 18s 136ms/step - loss: 1.1922 - mse: 0.0151 - mae: 0.0839 - MAEMS: 1.1920 - val_loss: 1.5238 - val_mse: 0.0130 - val_mae: 0.0819 - val_MAEMS: 1.5344\n",
      "Epoch 38/1000\n",
      "131/131 [==============================] - 18s 135ms/step - loss: 1.1455 - mse: 0.0145 - mae: 0.0814 - MAEMS: 1.1455 - val_loss: 1.4587 - val_mse: 0.0128 - val_mae: 0.0804 - val_MAEMS: 1.4659\n",
      "Epoch 39/1000\n",
      "131/131 [==============================] - 18s 135ms/step - loss: 1.1251 - mse: 0.0140 - mae: 0.0797 - MAEMS: 1.1250 - val_loss: 1.4129 - val_mse: 0.0131 - val_mae: 0.0808 - val_MAEMS: 1.4238\n",
      "Epoch 40/1000\n",
      "131/131 [==============================] - 18s 135ms/step - loss: 1.1038 - mse: 0.0136 - mae: 0.0784 - MAEMS: 1.1038 - val_loss: 1.3211 - val_mse: 0.0132 - val_mae: 0.0799 - val_MAEMS: 1.3266\n",
      "Epoch 41/1000\n",
      "131/131 [==============================] - 18s 135ms/step - loss: 1.0903 - mse: 0.0133 - mae: 0.0772 - MAEMS: 1.0902 - val_loss: 1.2423 - val_mse: 0.0129 - val_mae: 0.0778 - val_MAEMS: 1.2539\n",
      "Epoch 42/1000\n",
      "131/131 [==============================] - 18s 135ms/step - loss: 1.1027 - mse: 0.0132 - mae: 0.0772 - MAEMS: 1.1026 - val_loss: 1.2351 - val_mse: 0.0132 - val_mae: 0.0786 - val_MAEMS: 1.2413\n",
      "Epoch 43/1000\n",
      "131/131 [==============================] - 18s 135ms/step - loss: 1.0888 - mse: 0.0129 - mae: 0.0764 - MAEMS: 1.0886 - val_loss: 1.2948 - val_mse: 0.0128 - val_mae: 0.0786 - val_MAEMS: 1.3040\n",
      "Epoch 44/1000\n",
      "131/131 [==============================] - 18s 135ms/step - loss: 1.0950 - mse: 0.0128 - mae: 0.0760 - MAEMS: 1.0949 - val_loss: 1.4175 - val_mse: 0.0119 - val_mae: 0.0773 - val_MAEMS: 1.4285\n",
      "Epoch 45/1000\n",
      "131/131 [==============================] - 18s 136ms/step - loss: 1.0760 - mse: 0.0125 - mae: 0.0749 - MAEMS: 1.0759 - val_loss: 1.1670 - val_mse: 0.0140 - val_mae: 0.0807 - val_MAEMS: 1.1733\n",
      "Epoch 46/1000\n",
      "131/131 [==============================] - 18s 135ms/step - loss: 1.0999 - mse: 0.0125 - mae: 0.0755 - MAEMS: 1.0999 - val_loss: 1.3137 - val_mse: 0.0124 - val_mae: 0.0777 - val_MAEMS: 1.3208\n",
      "Epoch 47/1000\n",
      "131/131 [==============================] - 18s 135ms/step - loss: 1.1448 - mse: 0.0129 - mae: 0.0773 - MAEMS: 1.1446 - val_loss: 1.5921 - val_mse: 0.0115 - val_mae: 0.0785 - val_MAEMS: 1.5995\n",
      "Epoch 48/1000\n",
      "131/131 [==============================] - 18s 135ms/step - loss: 1.1881 - mse: 0.0132 - mae: 0.0788 - MAEMS: 1.1878 - val_loss: 1.7695 - val_mse: 0.0114 - val_mae: 0.0804 - val_MAEMS: 1.7730\n",
      "Epoch 49/1000\n",
      "131/131 [==============================] - 18s 135ms/step - loss: 1.1351 - mse: 0.0127 - mae: 0.0763 - MAEMS: 1.1354 - val_loss: 1.2884 - val_mse: 0.0130 - val_mae: 0.0792 - val_MAEMS: 1.2906\n",
      "Epoch 50/1000\n",
      "131/131 [==============================] - 18s 135ms/step - loss: 1.0543 - mse: 0.0121 - mae: 0.0734 - MAEMS: 1.0544 - val_loss: 1.2122 - val_mse: 0.0121 - val_mae: 0.0752 - val_MAEMS: 1.2088\n",
      "Epoch 51/1000\n",
      "131/131 [==============================] - 18s 135ms/step - loss: 1.0390 - mse: 0.0117 - mae: 0.0720 - MAEMS: 1.0388 - val_loss: 1.1838 - val_mse: 0.0112 - val_mae: 0.0720 - val_MAEMS: 1.1848\n",
      "Epoch 52/1000\n",
      "131/131 [==============================] - 18s 135ms/step - loss: 1.0370 - mse: 0.0115 - mae: 0.0714 - MAEMS: 1.0369 - val_loss: 1.2048 - val_mse: 0.0110 - val_mae: 0.0717 - val_MAEMS: 1.2124\n",
      "Epoch 53/1000\n",
      "131/131 [==============================] - 18s 136ms/step - loss: 1.0796 - mse: 0.0118 - mae: 0.0729 - MAEMS: 1.0795 - val_loss: 1.2882 - val_mse: 0.0115 - val_mae: 0.0746 - val_MAEMS: 1.2902\n",
      "Epoch 54/1000\n",
      "131/131 [==============================] - 18s 136ms/step - loss: 1.0409 - mse: 0.0114 - mae: 0.0710 - MAEMS: 1.0409 - val_loss: 1.1866 - val_mse: 0.0118 - val_mae: 0.0742 - val_MAEMS: 1.1880\n",
      "Epoch 55/1000\n",
      "131/131 [==============================] - 18s 136ms/step - loss: 1.0651 - mse: 0.0115 - mae: 0.0719 - MAEMS: 1.0652 - val_loss: 1.1815 - val_mse: 0.0120 - val_mae: 0.0748 - val_MAEMS: 1.1865\n",
      "Wall time: 24min 13s\n"
     ]
    }
   ],
   "source": [
    "    %%time\n",
    "    b_size = 168\n",
    "    hist = model.fit(strX, strY, epochs=epochs, batch_size=b_size, shuffle=False, validation_data=(svaX, svaY), callbacks=[history, early_stopping])  # , checkpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b7f1b311",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4601"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2fb2f74",
   "metadata": {},
   "source": [
    "## Saving Results & Figures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "6ac4ce67",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_history = hist.history['loss']\n",
    "valloss_history = hist.history['val_loss']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "59befe3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#np.savetxt('losshistory.txt',(loss_history,valloss_history))\n",
    "model.save('Basic Model Final_lead.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "41845b2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "layer_name = 'attention_vec'\n",
    "intermediate_layer_model = Model(inputs=model.input,\n",
    "                                 outputs=model.get_layer(layer_name).output)\n",
    "intermediate_output = intermediate_layer_model.predict(strvaX)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "4d8648bc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(168, 37)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "avg_int_output = np.mean(intermediate_output, axis=0)\n",
    "avg_int_output.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "affe7bd7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x432 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.set_theme(style=\"white\")\n",
    "f, ax = plt.subplots(figsize=(12, 6))\n",
    "\n",
    "# Generate a custom diverging colormap\n",
    "cmap = sns.diverging_palette(230, 20, as_cmap=True)\n",
    "\n",
    "# Draw the heatmap with the mask and correct aspect ratio\n",
    "sns.heatmap(np.transpose(abs(avg_int_output)), cmap=\"rocket\")\n",
    "lx = ax.set_xticklabels([])\n",
    "ly = ax.set_yticklabels([])\n",
    "cax = ax.figure.axes[-1]\n",
    "cax.tick_params(labelsize=14)\n",
    "\n",
    "f.savefig('attention_output_lead.png', dpi=1000, bbox_inches=\"tight\")\n",
    "#f.savefig('attention_output.eps', dpi=1000, bbox_inches=\"tight\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8834937",
   "metadata": {},
   "source": [
    "## Basic Model Test Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "08af5c4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#with tf.device('/gpu:0'):\n",
    "#    model = keras.models.load_model('Basic Model Final_lead.h5', custom_objects={'MAEMS': MAEMS})\n",
    "#    gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "ee3ac5c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 168\n",
    "testPredict = model.predict(teX, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "6804180a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def npMAEMS(y_true, y_pred):\n",
    "    return np.mean((abs(y_pred - y_true))*np.square(y_true))*100\n",
    "def npMAEMD(y_true, y_pred):\n",
    "    return np.mean((abs(y_pred - y_true))*np.square(y_true-np.mean(y_true)))*100\n",
    "def npMSE(y_true, y_pred):\n",
    "    return np.mean(np.square(-y_true+y_pred))\n",
    "def npMAE(y_true, y_pred):\n",
    "    return np.mean(abs(-y_true+y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "8ab1c0d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error Test Score > MSE ==  0.032836721856768156  MAE ==  0.14583632600714025  MAEMS ==  2.3040104722921315\n"
     ]
    }
   ],
   "source": [
    "tePredict = testPredict.reshape(-1)\n",
    "testY = teY.reshape(-1)\n",
    "print('Error Test Score > MSE == ', npMSE(testY, tePredict), ' MAE == ', npMAE(testY, tePredict), ' MAEMS == ', npMAEMS(testY, tePredict))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "114cd81b",
   "metadata": {},
   "source": [
    "## Wind Generation FFEL Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "af5aff2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainPredict = model.predict(trX, batch_size=batch_size)\n",
    "validPredict = model.predict(vaX, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "7ae0d617",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(31377, 24)\n",
      "(31377, 24)\n"
     ]
    }
   ],
   "source": [
    "e_tr = trainPredict - trY\n",
    "e_va = validPredict - vaY\n",
    "errors = np.vstack([e_tr, e_va])\n",
    "prediction = np.vstack([trainPredict, validPredict])\n",
    "print(errors.shape)\n",
    "print(prediction.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "58cd7947",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Normalized Wind</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.644724</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.658617</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.683924</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.721813</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.714187</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Normalized Wind\n",
       "0         0.644724\n",
       "1         0.658617\n",
       "2         0.683924\n",
       "3         0.721813\n",
       "4         0.714187"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "norm_df2 = pd.DataFrame(norm_df).iloc[:prediction.shape[0], :]\n",
    "norm_df2.columns = ['Normalized Wind']\n",
    "norm_df2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "4e77aad3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Prediction1</th>\n",
       "      <th>Prediction2</th>\n",
       "      <th>Prediction3</th>\n",
       "      <th>Prediction4</th>\n",
       "      <th>Prediction5</th>\n",
       "      <th>Prediction6</th>\n",
       "      <th>Prediction7</th>\n",
       "      <th>Prediction8</th>\n",
       "      <th>Prediction9</th>\n",
       "      <th>Prediction10</th>\n",
       "      <th>...</th>\n",
       "      <th>Prediction15</th>\n",
       "      <th>Prediction16</th>\n",
       "      <th>Prediction17</th>\n",
       "      <th>Prediction18</th>\n",
       "      <th>Prediction19</th>\n",
       "      <th>Prediction20</th>\n",
       "      <th>Prediction21</th>\n",
       "      <th>Prediction22</th>\n",
       "      <th>Prediction23</th>\n",
       "      <th>Prediction24</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.793821</td>\n",
       "      <td>0.778579</td>\n",
       "      <td>0.782684</td>\n",
       "      <td>0.784334</td>\n",
       "      <td>0.817920</td>\n",
       "      <td>0.830460</td>\n",
       "      <td>0.840056</td>\n",
       "      <td>0.855320</td>\n",
       "      <td>0.861071</td>\n",
       "      <td>0.873940</td>\n",
       "      <td>...</td>\n",
       "      <td>0.908312</td>\n",
       "      <td>0.907830</td>\n",
       "      <td>0.908041</td>\n",
       "      <td>0.881006</td>\n",
       "      <td>0.868179</td>\n",
       "      <td>0.851028</td>\n",
       "      <td>0.821287</td>\n",
       "      <td>0.844090</td>\n",
       "      <td>0.800233</td>\n",
       "      <td>0.798682</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.798684</td>\n",
       "      <td>0.780725</td>\n",
       "      <td>0.787723</td>\n",
       "      <td>0.791635</td>\n",
       "      <td>0.821870</td>\n",
       "      <td>0.838346</td>\n",
       "      <td>0.849698</td>\n",
       "      <td>0.871606</td>\n",
       "      <td>0.880321</td>\n",
       "      <td>0.900321</td>\n",
       "      <td>...</td>\n",
       "      <td>0.913722</td>\n",
       "      <td>0.898772</td>\n",
       "      <td>0.894679</td>\n",
       "      <td>0.870234</td>\n",
       "      <td>0.866915</td>\n",
       "      <td>0.855369</td>\n",
       "      <td>0.829599</td>\n",
       "      <td>0.856451</td>\n",
       "      <td>0.804558</td>\n",
       "      <td>0.796497</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.792277</td>\n",
       "      <td>0.779091</td>\n",
       "      <td>0.787298</td>\n",
       "      <td>0.792744</td>\n",
       "      <td>0.814910</td>\n",
       "      <td>0.836805</td>\n",
       "      <td>0.848949</td>\n",
       "      <td>0.878115</td>\n",
       "      <td>0.887301</td>\n",
       "      <td>0.916255</td>\n",
       "      <td>...</td>\n",
       "      <td>0.893018</td>\n",
       "      <td>0.865211</td>\n",
       "      <td>0.857892</td>\n",
       "      <td>0.842288</td>\n",
       "      <td>0.840946</td>\n",
       "      <td>0.834689</td>\n",
       "      <td>0.812496</td>\n",
       "      <td>0.839531</td>\n",
       "      <td>0.781006</td>\n",
       "      <td>0.766646</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.790341</td>\n",
       "      <td>0.778690</td>\n",
       "      <td>0.785007</td>\n",
       "      <td>0.795453</td>\n",
       "      <td>0.804934</td>\n",
       "      <td>0.831996</td>\n",
       "      <td>0.848054</td>\n",
       "      <td>0.879172</td>\n",
       "      <td>0.890917</td>\n",
       "      <td>0.919082</td>\n",
       "      <td>...</td>\n",
       "      <td>0.853824</td>\n",
       "      <td>0.827578</td>\n",
       "      <td>0.820380</td>\n",
       "      <td>0.813830</td>\n",
       "      <td>0.812230</td>\n",
       "      <td>0.809177</td>\n",
       "      <td>0.778603</td>\n",
       "      <td>0.792650</td>\n",
       "      <td>0.721316</td>\n",
       "      <td>0.693880</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.799934</td>\n",
       "      <td>0.785896</td>\n",
       "      <td>0.788972</td>\n",
       "      <td>0.799467</td>\n",
       "      <td>0.801704</td>\n",
       "      <td>0.826851</td>\n",
       "      <td>0.842497</td>\n",
       "      <td>0.865963</td>\n",
       "      <td>0.877197</td>\n",
       "      <td>0.897679</td>\n",
       "      <td>...</td>\n",
       "      <td>0.813313</td>\n",
       "      <td>0.790871</td>\n",
       "      <td>0.789246</td>\n",
       "      <td>0.790217</td>\n",
       "      <td>0.785676</td>\n",
       "      <td>0.776286</td>\n",
       "      <td>0.733072</td>\n",
       "      <td>0.728464</td>\n",
       "      <td>0.648988</td>\n",
       "      <td>0.609956</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31372</th>\n",
       "      <td>0.335937</td>\n",
       "      <td>0.295604</td>\n",
       "      <td>0.268762</td>\n",
       "      <td>0.260960</td>\n",
       "      <td>0.260939</td>\n",
       "      <td>0.286097</td>\n",
       "      <td>0.309418</td>\n",
       "      <td>0.357131</td>\n",
       "      <td>0.409120</td>\n",
       "      <td>0.484241</td>\n",
       "      <td>...</td>\n",
       "      <td>0.600980</td>\n",
       "      <td>0.573294</td>\n",
       "      <td>0.536914</td>\n",
       "      <td>0.498859</td>\n",
       "      <td>0.480851</td>\n",
       "      <td>0.476224</td>\n",
       "      <td>0.475530</td>\n",
       "      <td>0.474575</td>\n",
       "      <td>0.474752</td>\n",
       "      <td>0.485602</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31373</th>\n",
       "      <td>0.269700</td>\n",
       "      <td>0.241362</td>\n",
       "      <td>0.232971</td>\n",
       "      <td>0.242347</td>\n",
       "      <td>0.264628</td>\n",
       "      <td>0.310137</td>\n",
       "      <td>0.355011</td>\n",
       "      <td>0.416972</td>\n",
       "      <td>0.472364</td>\n",
       "      <td>0.543151</td>\n",
       "      <td>...</td>\n",
       "      <td>0.579099</td>\n",
       "      <td>0.547673</td>\n",
       "      <td>0.510561</td>\n",
       "      <td>0.479762</td>\n",
       "      <td>0.476961</td>\n",
       "      <td>0.480232</td>\n",
       "      <td>0.484655</td>\n",
       "      <td>0.485688</td>\n",
       "      <td>0.488608</td>\n",
       "      <td>0.494176</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31374</th>\n",
       "      <td>0.243936</td>\n",
       "      <td>0.230544</td>\n",
       "      <td>0.241394</td>\n",
       "      <td>0.263679</td>\n",
       "      <td>0.300760</td>\n",
       "      <td>0.358665</td>\n",
       "      <td>0.412359</td>\n",
       "      <td>0.483278</td>\n",
       "      <td>0.536601</td>\n",
       "      <td>0.593467</td>\n",
       "      <td>...</td>\n",
       "      <td>0.554984</td>\n",
       "      <td>0.527390</td>\n",
       "      <td>0.494480</td>\n",
       "      <td>0.473757</td>\n",
       "      <td>0.486200</td>\n",
       "      <td>0.495560</td>\n",
       "      <td>0.497707</td>\n",
       "      <td>0.494697</td>\n",
       "      <td>0.491825</td>\n",
       "      <td>0.488511</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31375</th>\n",
       "      <td>0.266681</td>\n",
       "      <td>0.257581</td>\n",
       "      <td>0.278581</td>\n",
       "      <td>0.309854</td>\n",
       "      <td>0.349956</td>\n",
       "      <td>0.410589</td>\n",
       "      <td>0.468383</td>\n",
       "      <td>0.535940</td>\n",
       "      <td>0.585311</td>\n",
       "      <td>0.622202</td>\n",
       "      <td>...</td>\n",
       "      <td>0.531289</td>\n",
       "      <td>0.512522</td>\n",
       "      <td>0.487871</td>\n",
       "      <td>0.474088</td>\n",
       "      <td>0.496884</td>\n",
       "      <td>0.503206</td>\n",
       "      <td>0.498403</td>\n",
       "      <td>0.485239</td>\n",
       "      <td>0.469274</td>\n",
       "      <td>0.458805</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31376</th>\n",
       "      <td>0.306942</td>\n",
       "      <td>0.301389</td>\n",
       "      <td>0.324901</td>\n",
       "      <td>0.359564</td>\n",
       "      <td>0.398696</td>\n",
       "      <td>0.452871</td>\n",
       "      <td>0.510605</td>\n",
       "      <td>0.572032</td>\n",
       "      <td>0.609277</td>\n",
       "      <td>0.629383</td>\n",
       "      <td>...</td>\n",
       "      <td>0.520691</td>\n",
       "      <td>0.510231</td>\n",
       "      <td>0.491918</td>\n",
       "      <td>0.481215</td>\n",
       "      <td>0.507771</td>\n",
       "      <td>0.507166</td>\n",
       "      <td>0.490685</td>\n",
       "      <td>0.464368</td>\n",
       "      <td>0.437051</td>\n",
       "      <td>0.417580</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>31377 rows × 24 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Prediction1  Prediction2  Prediction3  Prediction4  Prediction5  \\\n",
       "0         0.793821     0.778579     0.782684     0.784334     0.817920   \n",
       "1         0.798684     0.780725     0.787723     0.791635     0.821870   \n",
       "2         0.792277     0.779091     0.787298     0.792744     0.814910   \n",
       "3         0.790341     0.778690     0.785007     0.795453     0.804934   \n",
       "4         0.799934     0.785896     0.788972     0.799467     0.801704   \n",
       "...            ...          ...          ...          ...          ...   \n",
       "31372     0.335937     0.295604     0.268762     0.260960     0.260939   \n",
       "31373     0.269700     0.241362     0.232971     0.242347     0.264628   \n",
       "31374     0.243936     0.230544     0.241394     0.263679     0.300760   \n",
       "31375     0.266681     0.257581     0.278581     0.309854     0.349956   \n",
       "31376     0.306942     0.301389     0.324901     0.359564     0.398696   \n",
       "\n",
       "       Prediction6  Prediction7  Prediction8  Prediction9  Prediction10  ...  \\\n",
       "0         0.830460     0.840056     0.855320     0.861071      0.873940  ...   \n",
       "1         0.838346     0.849698     0.871606     0.880321      0.900321  ...   \n",
       "2         0.836805     0.848949     0.878115     0.887301      0.916255  ...   \n",
       "3         0.831996     0.848054     0.879172     0.890917      0.919082  ...   \n",
       "4         0.826851     0.842497     0.865963     0.877197      0.897679  ...   \n",
       "...            ...          ...          ...          ...           ...  ...   \n",
       "31372     0.286097     0.309418     0.357131     0.409120      0.484241  ...   \n",
       "31373     0.310137     0.355011     0.416972     0.472364      0.543151  ...   \n",
       "31374     0.358665     0.412359     0.483278     0.536601      0.593467  ...   \n",
       "31375     0.410589     0.468383     0.535940     0.585311      0.622202  ...   \n",
       "31376     0.452871     0.510605     0.572032     0.609277      0.629383  ...   \n",
       "\n",
       "       Prediction15  Prediction16  Prediction17  Prediction18  Prediction19  \\\n",
       "0          0.908312      0.907830      0.908041      0.881006      0.868179   \n",
       "1          0.913722      0.898772      0.894679      0.870234      0.866915   \n",
       "2          0.893018      0.865211      0.857892      0.842288      0.840946   \n",
       "3          0.853824      0.827578      0.820380      0.813830      0.812230   \n",
       "4          0.813313      0.790871      0.789246      0.790217      0.785676   \n",
       "...             ...           ...           ...           ...           ...   \n",
       "31372      0.600980      0.573294      0.536914      0.498859      0.480851   \n",
       "31373      0.579099      0.547673      0.510561      0.479762      0.476961   \n",
       "31374      0.554984      0.527390      0.494480      0.473757      0.486200   \n",
       "31375      0.531289      0.512522      0.487871      0.474088      0.496884   \n",
       "31376      0.520691      0.510231      0.491918      0.481215      0.507771   \n",
       "\n",
       "       Prediction20  Prediction21  Prediction22  Prediction23  Prediction24  \n",
       "0          0.851028      0.821287      0.844090      0.800233      0.798682  \n",
       "1          0.855369      0.829599      0.856451      0.804558      0.796497  \n",
       "2          0.834689      0.812496      0.839531      0.781006      0.766646  \n",
       "3          0.809177      0.778603      0.792650      0.721316      0.693880  \n",
       "4          0.776286      0.733072      0.728464      0.648988      0.609956  \n",
       "...             ...           ...           ...           ...           ...  \n",
       "31372      0.476224      0.475530      0.474575      0.474752      0.485602  \n",
       "31373      0.480232      0.484655      0.485688      0.488608      0.494176  \n",
       "31374      0.495560      0.497707      0.494697      0.491825      0.488511  \n",
       "31375      0.503206      0.498403      0.485239      0.469274      0.458805  \n",
       "31376      0.507166      0.490685      0.464368      0.437051      0.417580  \n",
       "\n",
       "[31377 rows x 24 columns]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Prindex = ['Prediction1', 'Prediction2','Prediction3','Prediction4','Prediction5','Prediction6','Prediction7','Prediction8','Prediction9','Prediction10','Prediction11','Prediction12','Prediction13', 'Prediction14','Prediction15','Prediction16','Prediction17','Prediction18','Prediction19','Prediction20','Prediction21','Prediction22','Prediction23','Prediction24']\n",
    "Erindex = ['Error1', 'Error2','Error3','Error4','Error5','Error6','Error7','Error8','Error9','Error10','Error11','Error12','Error13', 'Error14','Error15','Error16','Error17','Error18','Error19','Error20','Error21','Error22','Error23','Error24']\n",
    "\n",
    "pr_df = pd.DataFrame(prediction, columns=Prindex)\n",
    "pr_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "fd66fcef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Error1</th>\n",
       "      <th>Error2</th>\n",
       "      <th>Error3</th>\n",
       "      <th>Error4</th>\n",
       "      <th>Error5</th>\n",
       "      <th>Error6</th>\n",
       "      <th>Error7</th>\n",
       "      <th>Error8</th>\n",
       "      <th>Error9</th>\n",
       "      <th>Error10</th>\n",
       "      <th>...</th>\n",
       "      <th>Error15</th>\n",
       "      <th>Error16</th>\n",
       "      <th>Error17</th>\n",
       "      <th>Error18</th>\n",
       "      <th>Error19</th>\n",
       "      <th>Error20</th>\n",
       "      <th>Error21</th>\n",
       "      <th>Error22</th>\n",
       "      <th>Error23</th>\n",
       "      <th>Error24</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.013825</td>\n",
       "      <td>-0.051313</td>\n",
       "      <td>0.006273</td>\n",
       "      <td>-0.000967</td>\n",
       "      <td>-0.050201</td>\n",
       "      <td>-0.030375</td>\n",
       "      <td>-0.020147</td>\n",
       "      <td>-0.011830</td>\n",
       "      <td>-0.012685</td>\n",
       "      <td>-0.014778</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.046370</td>\n",
       "      <td>-0.059384</td>\n",
       "      <td>-0.030708</td>\n",
       "      <td>0.002553</td>\n",
       "      <td>0.006360</td>\n",
       "      <td>0.010906</td>\n",
       "      <td>-0.006251</td>\n",
       "      <td>0.033813</td>\n",
       "      <td>0.013871</td>\n",
       "      <td>-0.062462</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.031208</td>\n",
       "      <td>0.004314</td>\n",
       "      <td>0.002422</td>\n",
       "      <td>-0.076487</td>\n",
       "      <td>-0.038965</td>\n",
       "      <td>-0.021858</td>\n",
       "      <td>-0.017452</td>\n",
       "      <td>-0.002150</td>\n",
       "      <td>-0.008396</td>\n",
       "      <td>0.007815</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.053492</td>\n",
       "      <td>-0.039978</td>\n",
       "      <td>0.016226</td>\n",
       "      <td>0.008415</td>\n",
       "      <td>0.026793</td>\n",
       "      <td>0.027830</td>\n",
       "      <td>0.019322</td>\n",
       "      <td>0.070088</td>\n",
       "      <td>-0.056586</td>\n",
       "      <td>-0.021784</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.015865</td>\n",
       "      <td>-0.006209</td>\n",
       "      <td>-0.080823</td>\n",
       "      <td>-0.068091</td>\n",
       "      <td>-0.045294</td>\n",
       "      <td>-0.030344</td>\n",
       "      <td>-0.024807</td>\n",
       "      <td>-0.010602</td>\n",
       "      <td>-0.005205</td>\n",
       "      <td>0.011411</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.045731</td>\n",
       "      <td>-0.013242</td>\n",
       "      <td>-0.003927</td>\n",
       "      <td>0.002166</td>\n",
       "      <td>0.013408</td>\n",
       "      <td>0.024412</td>\n",
       "      <td>0.026133</td>\n",
       "      <td>-0.021612</td>\n",
       "      <td>-0.037275</td>\n",
       "      <td>-0.004287</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.005040</td>\n",
       "      <td>-0.089431</td>\n",
       "      <td>-0.075828</td>\n",
       "      <td>-0.064751</td>\n",
       "      <td>-0.062215</td>\n",
       "      <td>-0.041760</td>\n",
       "      <td>-0.040663</td>\n",
       "      <td>-0.013334</td>\n",
       "      <td>-0.013927</td>\n",
       "      <td>-0.014081</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.024629</td>\n",
       "      <td>-0.034241</td>\n",
       "      <td>-0.019743</td>\n",
       "      <td>-0.013708</td>\n",
       "      <td>0.001953</td>\n",
       "      <td>0.022814</td>\n",
       "      <td>-0.082541</td>\n",
       "      <td>-0.025631</td>\n",
       "      <td>-0.049618</td>\n",
       "      <td>0.010504</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.068187</td>\n",
       "      <td>-0.074939</td>\n",
       "      <td>-0.071231</td>\n",
       "      <td>-0.067683</td>\n",
       "      <td>-0.072052</td>\n",
       "      <td>-0.061866</td>\n",
       "      <td>-0.050009</td>\n",
       "      <td>-0.038881</td>\n",
       "      <td>-0.055966</td>\n",
       "      <td>-0.039468</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.048506</td>\n",
       "      <td>-0.049251</td>\n",
       "      <td>-0.038292</td>\n",
       "      <td>-0.020060</td>\n",
       "      <td>-0.000687</td>\n",
       "      <td>-0.084857</td>\n",
       "      <td>-0.085209</td>\n",
       "      <td>-0.042470</td>\n",
       "      <td>-0.034387</td>\n",
       "      <td>0.012258</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31372</th>\n",
       "      <td>-0.035311</td>\n",
       "      <td>-0.019690</td>\n",
       "      <td>0.005447</td>\n",
       "      <td>0.014170</td>\n",
       "      <td>0.007525</td>\n",
       "      <td>0.013334</td>\n",
       "      <td>-0.013755</td>\n",
       "      <td>-0.025169</td>\n",
       "      <td>-0.036838</td>\n",
       "      <td>-0.030326</td>\n",
       "      <td>...</td>\n",
       "      <td>0.157322</td>\n",
       "      <td>0.163418</td>\n",
       "      <td>0.041975</td>\n",
       "      <td>-0.028258</td>\n",
       "      <td>-0.016669</td>\n",
       "      <td>-0.016345</td>\n",
       "      <td>-0.033250</td>\n",
       "      <td>-0.001330</td>\n",
       "      <td>0.010003</td>\n",
       "      <td>0.090508</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31373</th>\n",
       "      <td>-0.045595</td>\n",
       "      <td>-0.021953</td>\n",
       "      <td>-0.013819</td>\n",
       "      <td>-0.011067</td>\n",
       "      <td>-0.008134</td>\n",
       "      <td>-0.013037</td>\n",
       "      <td>-0.027289</td>\n",
       "      <td>-0.028986</td>\n",
       "      <td>-0.042203</td>\n",
       "      <td>-0.045499</td>\n",
       "      <td>...</td>\n",
       "      <td>0.169223</td>\n",
       "      <td>0.052733</td>\n",
       "      <td>-0.016557</td>\n",
       "      <td>-0.017758</td>\n",
       "      <td>-0.015608</td>\n",
       "      <td>-0.028548</td>\n",
       "      <td>0.008750</td>\n",
       "      <td>0.020938</td>\n",
       "      <td>0.093514</td>\n",
       "      <td>0.178777</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31374</th>\n",
       "      <td>-0.019379</td>\n",
       "      <td>-0.016246</td>\n",
       "      <td>-0.012020</td>\n",
       "      <td>-0.009084</td>\n",
       "      <td>-0.022413</td>\n",
       "      <td>-0.023635</td>\n",
       "      <td>-0.033600</td>\n",
       "      <td>-0.031289</td>\n",
       "      <td>-0.052048</td>\n",
       "      <td>-0.035099</td>\n",
       "      <td>...</td>\n",
       "      <td>0.060044</td>\n",
       "      <td>0.000273</td>\n",
       "      <td>-0.003040</td>\n",
       "      <td>-0.018813</td>\n",
       "      <td>-0.022580</td>\n",
       "      <td>0.019655</td>\n",
       "      <td>0.032958</td>\n",
       "      <td>0.099603</td>\n",
       "      <td>0.176425</td>\n",
       "      <td>0.230216</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31375</th>\n",
       "      <td>0.019891</td>\n",
       "      <td>0.004167</td>\n",
       "      <td>0.005818</td>\n",
       "      <td>-0.013320</td>\n",
       "      <td>-0.032344</td>\n",
       "      <td>-0.035370</td>\n",
       "      <td>-0.046184</td>\n",
       "      <td>-0.052710</td>\n",
       "      <td>-0.043256</td>\n",
       "      <td>0.007824</td>\n",
       "      <td>...</td>\n",
       "      <td>0.004171</td>\n",
       "      <td>0.015002</td>\n",
       "      <td>-0.004699</td>\n",
       "      <td>-0.034692</td>\n",
       "      <td>0.020979</td>\n",
       "      <td>0.038457</td>\n",
       "      <td>0.103309</td>\n",
       "      <td>0.169840</td>\n",
       "      <td>0.210980</td>\n",
       "      <td>0.232827</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31376</th>\n",
       "      <td>0.053528</td>\n",
       "      <td>0.028626</td>\n",
       "      <td>0.001727</td>\n",
       "      <td>-0.022736</td>\n",
       "      <td>-0.047263</td>\n",
       "      <td>-0.061697</td>\n",
       "      <td>-0.078044</td>\n",
       "      <td>-0.056535</td>\n",
       "      <td>-0.005101</td>\n",
       "      <td>0.089994</td>\n",
       "      <td>...</td>\n",
       "      <td>0.023171</td>\n",
       "      <td>0.017661</td>\n",
       "      <td>-0.016863</td>\n",
       "      <td>0.005310</td>\n",
       "      <td>0.043021</td>\n",
       "      <td>0.112072</td>\n",
       "      <td>0.175286</td>\n",
       "      <td>0.206074</td>\n",
       "      <td>0.211074</td>\n",
       "      <td>0.178181</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>31377 rows × 24 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         Error1    Error2    Error3    Error4    Error5    Error6    Error7  \\\n",
       "0     -0.013825 -0.051313  0.006273 -0.000967 -0.050201 -0.030375 -0.020147   \n",
       "1     -0.031208  0.004314  0.002422 -0.076487 -0.038965 -0.021858 -0.017452   \n",
       "2      0.015865 -0.006209 -0.080823 -0.068091 -0.045294 -0.030344 -0.024807   \n",
       "3      0.005040 -0.089431 -0.075828 -0.064751 -0.062215 -0.041760 -0.040663   \n",
       "4     -0.068187 -0.074939 -0.071231 -0.067683 -0.072052 -0.061866 -0.050009   \n",
       "...         ...       ...       ...       ...       ...       ...       ...   \n",
       "31372 -0.035311 -0.019690  0.005447  0.014170  0.007525  0.013334 -0.013755   \n",
       "31373 -0.045595 -0.021953 -0.013819 -0.011067 -0.008134 -0.013037 -0.027289   \n",
       "31374 -0.019379 -0.016246 -0.012020 -0.009084 -0.022413 -0.023635 -0.033600   \n",
       "31375  0.019891  0.004167  0.005818 -0.013320 -0.032344 -0.035370 -0.046184   \n",
       "31376  0.053528  0.028626  0.001727 -0.022736 -0.047263 -0.061697 -0.078044   \n",
       "\n",
       "         Error8    Error9   Error10  ...   Error15   Error16   Error17  \\\n",
       "0     -0.011830 -0.012685 -0.014778  ... -0.046370 -0.059384 -0.030708   \n",
       "1     -0.002150 -0.008396  0.007815  ... -0.053492 -0.039978  0.016226   \n",
       "2     -0.010602 -0.005205  0.011411  ... -0.045731 -0.013242 -0.003927   \n",
       "3     -0.013334 -0.013927 -0.014081  ... -0.024629 -0.034241 -0.019743   \n",
       "4     -0.038881 -0.055966 -0.039468  ... -0.048506 -0.049251 -0.038292   \n",
       "...         ...       ...       ...  ...       ...       ...       ...   \n",
       "31372 -0.025169 -0.036838 -0.030326  ...  0.157322  0.163418  0.041975   \n",
       "31373 -0.028986 -0.042203 -0.045499  ...  0.169223  0.052733 -0.016557   \n",
       "31374 -0.031289 -0.052048 -0.035099  ...  0.060044  0.000273 -0.003040   \n",
       "31375 -0.052710 -0.043256  0.007824  ...  0.004171  0.015002 -0.004699   \n",
       "31376 -0.056535 -0.005101  0.089994  ...  0.023171  0.017661 -0.016863   \n",
       "\n",
       "        Error18   Error19   Error20   Error21   Error22   Error23   Error24  \n",
       "0      0.002553  0.006360  0.010906 -0.006251  0.033813  0.013871 -0.062462  \n",
       "1      0.008415  0.026793  0.027830  0.019322  0.070088 -0.056586 -0.021784  \n",
       "2      0.002166  0.013408  0.024412  0.026133 -0.021612 -0.037275 -0.004287  \n",
       "3     -0.013708  0.001953  0.022814 -0.082541 -0.025631 -0.049618  0.010504  \n",
       "4     -0.020060 -0.000687 -0.084857 -0.085209 -0.042470 -0.034387  0.012258  \n",
       "...         ...       ...       ...       ...       ...       ...       ...  \n",
       "31372 -0.028258 -0.016669 -0.016345 -0.033250 -0.001330  0.010003  0.090508  \n",
       "31373 -0.017758 -0.015608 -0.028548  0.008750  0.020938  0.093514  0.178777  \n",
       "31374 -0.018813 -0.022580  0.019655  0.032958  0.099603  0.176425  0.230216  \n",
       "31375 -0.034692  0.020979  0.038457  0.103309  0.169840  0.210980  0.232827  \n",
       "31376  0.005310  0.043021  0.112072  0.175286  0.206074  0.211074  0.178181  \n",
       "\n",
       "[31377 rows x 24 columns]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "er_df = pd.DataFrame(errors, columns=Erindex)\n",
    "er_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "be56db85",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Normalized Wind</th>\n",
       "      <th>Prediction1</th>\n",
       "      <th>Prediction2</th>\n",
       "      <th>Prediction3</th>\n",
       "      <th>Prediction4</th>\n",
       "      <th>Prediction5</th>\n",
       "      <th>Prediction6</th>\n",
       "      <th>Prediction7</th>\n",
       "      <th>Prediction8</th>\n",
       "      <th>Prediction9</th>\n",
       "      <th>...</th>\n",
       "      <th>Error15</th>\n",
       "      <th>Error16</th>\n",
       "      <th>Error17</th>\n",
       "      <th>Error18</th>\n",
       "      <th>Error19</th>\n",
       "      <th>Error20</th>\n",
       "      <th>Error21</th>\n",
       "      <th>Error22</th>\n",
       "      <th>Error23</th>\n",
       "      <th>Error24</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.644724</td>\n",
       "      <td>0.793821</td>\n",
       "      <td>0.778579</td>\n",
       "      <td>0.782684</td>\n",
       "      <td>0.784334</td>\n",
       "      <td>0.817920</td>\n",
       "      <td>0.830460</td>\n",
       "      <td>0.840056</td>\n",
       "      <td>0.855320</td>\n",
       "      <td>0.861071</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.046370</td>\n",
       "      <td>-0.059384</td>\n",
       "      <td>-0.030708</td>\n",
       "      <td>0.002553</td>\n",
       "      <td>0.006360</td>\n",
       "      <td>0.010906</td>\n",
       "      <td>-0.006251</td>\n",
       "      <td>0.033813</td>\n",
       "      <td>0.013871</td>\n",
       "      <td>-0.062462</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.658617</td>\n",
       "      <td>0.798684</td>\n",
       "      <td>0.780725</td>\n",
       "      <td>0.787723</td>\n",
       "      <td>0.791635</td>\n",
       "      <td>0.821870</td>\n",
       "      <td>0.838346</td>\n",
       "      <td>0.849698</td>\n",
       "      <td>0.871606</td>\n",
       "      <td>0.880321</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.053492</td>\n",
       "      <td>-0.039978</td>\n",
       "      <td>0.016226</td>\n",
       "      <td>0.008415</td>\n",
       "      <td>0.026793</td>\n",
       "      <td>0.027830</td>\n",
       "      <td>0.019322</td>\n",
       "      <td>0.070088</td>\n",
       "      <td>-0.056586</td>\n",
       "      <td>-0.021784</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.683924</td>\n",
       "      <td>0.792277</td>\n",
       "      <td>0.779091</td>\n",
       "      <td>0.787298</td>\n",
       "      <td>0.792744</td>\n",
       "      <td>0.814910</td>\n",
       "      <td>0.836805</td>\n",
       "      <td>0.848949</td>\n",
       "      <td>0.878115</td>\n",
       "      <td>0.887301</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.045731</td>\n",
       "      <td>-0.013242</td>\n",
       "      <td>-0.003927</td>\n",
       "      <td>0.002166</td>\n",
       "      <td>0.013408</td>\n",
       "      <td>0.024412</td>\n",
       "      <td>0.026133</td>\n",
       "      <td>-0.021612</td>\n",
       "      <td>-0.037275</td>\n",
       "      <td>-0.004287</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.721813</td>\n",
       "      <td>0.790341</td>\n",
       "      <td>0.778690</td>\n",
       "      <td>0.785007</td>\n",
       "      <td>0.795453</td>\n",
       "      <td>0.804934</td>\n",
       "      <td>0.831996</td>\n",
       "      <td>0.848054</td>\n",
       "      <td>0.879172</td>\n",
       "      <td>0.890917</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.024629</td>\n",
       "      <td>-0.034241</td>\n",
       "      <td>-0.019743</td>\n",
       "      <td>-0.013708</td>\n",
       "      <td>0.001953</td>\n",
       "      <td>0.022814</td>\n",
       "      <td>-0.082541</td>\n",
       "      <td>-0.025631</td>\n",
       "      <td>-0.049618</td>\n",
       "      <td>0.010504</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.714187</td>\n",
       "      <td>0.799934</td>\n",
       "      <td>0.785896</td>\n",
       "      <td>0.788972</td>\n",
       "      <td>0.799467</td>\n",
       "      <td>0.801704</td>\n",
       "      <td>0.826851</td>\n",
       "      <td>0.842497</td>\n",
       "      <td>0.865963</td>\n",
       "      <td>0.877197</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.048506</td>\n",
       "      <td>-0.049251</td>\n",
       "      <td>-0.038292</td>\n",
       "      <td>-0.020060</td>\n",
       "      <td>-0.000687</td>\n",
       "      <td>-0.084857</td>\n",
       "      <td>-0.085209</td>\n",
       "      <td>-0.042470</td>\n",
       "      <td>-0.034387</td>\n",
       "      <td>0.012258</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 49 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Normalized Wind  Prediction1  Prediction2  Prediction3  Prediction4  \\\n",
       "0         0.644724     0.793821     0.778579     0.782684     0.784334   \n",
       "1         0.658617     0.798684     0.780725     0.787723     0.791635   \n",
       "2         0.683924     0.792277     0.779091     0.787298     0.792744   \n",
       "3         0.721813     0.790341     0.778690     0.785007     0.795453   \n",
       "4         0.714187     0.799934     0.785896     0.788972     0.799467   \n",
       "\n",
       "   Prediction5  Prediction6  Prediction7  Prediction8  Prediction9  ...  \\\n",
       "0     0.817920     0.830460     0.840056     0.855320     0.861071  ...   \n",
       "1     0.821870     0.838346     0.849698     0.871606     0.880321  ...   \n",
       "2     0.814910     0.836805     0.848949     0.878115     0.887301  ...   \n",
       "3     0.804934     0.831996     0.848054     0.879172     0.890917  ...   \n",
       "4     0.801704     0.826851     0.842497     0.865963     0.877197  ...   \n",
       "\n",
       "    Error15   Error16   Error17   Error18   Error19   Error20   Error21  \\\n",
       "0 -0.046370 -0.059384 -0.030708  0.002553  0.006360  0.010906 -0.006251   \n",
       "1 -0.053492 -0.039978  0.016226  0.008415  0.026793  0.027830  0.019322   \n",
       "2 -0.045731 -0.013242 -0.003927  0.002166  0.013408  0.024412  0.026133   \n",
       "3 -0.024629 -0.034241 -0.019743 -0.013708  0.001953  0.022814 -0.082541   \n",
       "4 -0.048506 -0.049251 -0.038292 -0.020060 -0.000687 -0.084857 -0.085209   \n",
       "\n",
       "    Error22   Error23   Error24  \n",
       "0  0.033813  0.013871 -0.062462  \n",
       "1  0.070088 -0.056586 -0.021784  \n",
       "2 -0.021612 -0.037275 -0.004287  \n",
       "3 -0.025631 -0.049618  0.010504  \n",
       "4 -0.042470 -0.034387  0.012258  \n",
       "\n",
       "[5 rows x 49 columns]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "norm_df2 = pd.concat([norm_df2, pr_df, er_df],axis=1)\n",
    "norm_df2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "d145ac44",
   "metadata": {},
   "outputs": [],
   "source": [
    "norm_df22 = pd.DataFrame(norm_df).iloc[prediction.shape[0]+timesteps:, :]\n",
    "norm_df22.columns = ['Normalized Wind']\n",
    "npnorm22 = np.array(norm_df22)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "5df93075",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>14</th>\n",
       "      <th>15</th>\n",
       "      <th>16</th>\n",
       "      <th>17</th>\n",
       "      <th>18</th>\n",
       "      <th>19</th>\n",
       "      <th>20</th>\n",
       "      <th>21</th>\n",
       "      <th>22</th>\n",
       "      <th>23</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.366604</td>\n",
       "      <td>0.363255</td>\n",
       "      <td>0.383789</td>\n",
       "      <td>0.416133</td>\n",
       "      <td>0.454973</td>\n",
       "      <td>0.501120</td>\n",
       "      <td>0.553408</td>\n",
       "      <td>0.604316</td>\n",
       "      <td>0.630957</td>\n",
       "      <td>0.634712</td>\n",
       "      <td>...</td>\n",
       "      <td>0.521855</td>\n",
       "      <td>0.513263</td>\n",
       "      <td>0.499454</td>\n",
       "      <td>0.492219</td>\n",
       "      <td>0.509631</td>\n",
       "      <td>0.503469</td>\n",
       "      <td>0.482624</td>\n",
       "      <td>0.449463</td>\n",
       "      <td>0.422944</td>\n",
       "      <td>0.403711</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.407227</td>\n",
       "      <td>0.410880</td>\n",
       "      <td>0.429766</td>\n",
       "      <td>0.459847</td>\n",
       "      <td>0.498899</td>\n",
       "      <td>0.533039</td>\n",
       "      <td>0.569344</td>\n",
       "      <td>0.605926</td>\n",
       "      <td>0.614621</td>\n",
       "      <td>0.614851</td>\n",
       "      <td>...</td>\n",
       "      <td>0.517393</td>\n",
       "      <td>0.507290</td>\n",
       "      <td>0.491653</td>\n",
       "      <td>0.483424</td>\n",
       "      <td>0.484618</td>\n",
       "      <td>0.469760</td>\n",
       "      <td>0.450299</td>\n",
       "      <td>0.423325</td>\n",
       "      <td>0.404079</td>\n",
       "      <td>0.401087</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.415020</td>\n",
       "      <td>0.437605</td>\n",
       "      <td>0.462234</td>\n",
       "      <td>0.494799</td>\n",
       "      <td>0.535859</td>\n",
       "      <td>0.555248</td>\n",
       "      <td>0.576234</td>\n",
       "      <td>0.596957</td>\n",
       "      <td>0.587375</td>\n",
       "      <td>0.580976</td>\n",
       "      <td>...</td>\n",
       "      <td>0.507199</td>\n",
       "      <td>0.492210</td>\n",
       "      <td>0.474021</td>\n",
       "      <td>0.455473</td>\n",
       "      <td>0.447700</td>\n",
       "      <td>0.430675</td>\n",
       "      <td>0.415744</td>\n",
       "      <td>0.401272</td>\n",
       "      <td>0.396440</td>\n",
       "      <td>0.415182</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.434707</td>\n",
       "      <td>0.477320</td>\n",
       "      <td>0.507120</td>\n",
       "      <td>0.542314</td>\n",
       "      <td>0.572283</td>\n",
       "      <td>0.575589</td>\n",
       "      <td>0.578353</td>\n",
       "      <td>0.581659</td>\n",
       "      <td>0.559292</td>\n",
       "      <td>0.545834</td>\n",
       "      <td>...</td>\n",
       "      <td>0.505845</td>\n",
       "      <td>0.485677</td>\n",
       "      <td>0.461266</td>\n",
       "      <td>0.434064</td>\n",
       "      <td>0.420259</td>\n",
       "      <td>0.406833</td>\n",
       "      <td>0.400879</td>\n",
       "      <td>0.397648</td>\n",
       "      <td>0.413193</td>\n",
       "      <td>0.448063</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.456726</td>\n",
       "      <td>0.512386</td>\n",
       "      <td>0.544937</td>\n",
       "      <td>0.582148</td>\n",
       "      <td>0.594345</td>\n",
       "      <td>0.587986</td>\n",
       "      <td>0.579672</td>\n",
       "      <td>0.572500</td>\n",
       "      <td>0.551354</td>\n",
       "      <td>0.536991</td>\n",
       "      <td>...</td>\n",
       "      <td>0.490462</td>\n",
       "      <td>0.458543</td>\n",
       "      <td>0.428629</td>\n",
       "      <td>0.397014</td>\n",
       "      <td>0.388698</td>\n",
       "      <td>0.389387</td>\n",
       "      <td>0.402213</td>\n",
       "      <td>0.415548</td>\n",
       "      <td>0.457367</td>\n",
       "      <td>0.503473</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3482</th>\n",
       "      <td>0.505518</td>\n",
       "      <td>0.511389</td>\n",
       "      <td>0.535697</td>\n",
       "      <td>0.560016</td>\n",
       "      <td>0.559640</td>\n",
       "      <td>0.555156</td>\n",
       "      <td>0.535591</td>\n",
       "      <td>0.524072</td>\n",
       "      <td>0.500966</td>\n",
       "      <td>0.502748</td>\n",
       "      <td>...</td>\n",
       "      <td>0.557973</td>\n",
       "      <td>0.572103</td>\n",
       "      <td>0.609413</td>\n",
       "      <td>0.647190</td>\n",
       "      <td>0.695680</td>\n",
       "      <td>0.699091</td>\n",
       "      <td>0.697887</td>\n",
       "      <td>0.706611</td>\n",
       "      <td>0.659113</td>\n",
       "      <td>0.617930</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3483</th>\n",
       "      <td>0.454871</td>\n",
       "      <td>0.463373</td>\n",
       "      <td>0.491093</td>\n",
       "      <td>0.510518</td>\n",
       "      <td>0.514327</td>\n",
       "      <td>0.511964</td>\n",
       "      <td>0.496149</td>\n",
       "      <td>0.478999</td>\n",
       "      <td>0.457198</td>\n",
       "      <td>0.462982</td>\n",
       "      <td>...</td>\n",
       "      <td>0.548045</td>\n",
       "      <td>0.570672</td>\n",
       "      <td>0.612745</td>\n",
       "      <td>0.648706</td>\n",
       "      <td>0.688007</td>\n",
       "      <td>0.686968</td>\n",
       "      <td>0.668244</td>\n",
       "      <td>0.663814</td>\n",
       "      <td>0.609067</td>\n",
       "      <td>0.560218</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3484</th>\n",
       "      <td>0.405269</td>\n",
       "      <td>0.412940</td>\n",
       "      <td>0.442730</td>\n",
       "      <td>0.455712</td>\n",
       "      <td>0.457993</td>\n",
       "      <td>0.458180</td>\n",
       "      <td>0.443185</td>\n",
       "      <td>0.422063</td>\n",
       "      <td>0.408318</td>\n",
       "      <td>0.419716</td>\n",
       "      <td>...</td>\n",
       "      <td>0.533366</td>\n",
       "      <td>0.561215</td>\n",
       "      <td>0.604059</td>\n",
       "      <td>0.639459</td>\n",
       "      <td>0.669406</td>\n",
       "      <td>0.662631</td>\n",
       "      <td>0.637145</td>\n",
       "      <td>0.626954</td>\n",
       "      <td>0.573104</td>\n",
       "      <td>0.521878</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3485</th>\n",
       "      <td>0.358663</td>\n",
       "      <td>0.361600</td>\n",
       "      <td>0.389319</td>\n",
       "      <td>0.400986</td>\n",
       "      <td>0.398099</td>\n",
       "      <td>0.398993</td>\n",
       "      <td>0.391860</td>\n",
       "      <td>0.372683</td>\n",
       "      <td>0.374009</td>\n",
       "      <td>0.391127</td>\n",
       "      <td>...</td>\n",
       "      <td>0.526897</td>\n",
       "      <td>0.558757</td>\n",
       "      <td>0.601317</td>\n",
       "      <td>0.628597</td>\n",
       "      <td>0.650035</td>\n",
       "      <td>0.632412</td>\n",
       "      <td>0.603890</td>\n",
       "      <td>0.588857</td>\n",
       "      <td>0.535932</td>\n",
       "      <td>0.489460</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3486</th>\n",
       "      <td>0.325543</td>\n",
       "      <td>0.326547</td>\n",
       "      <td>0.347569</td>\n",
       "      <td>0.364105</td>\n",
       "      <td>0.359253</td>\n",
       "      <td>0.363228</td>\n",
       "      <td>0.361110</td>\n",
       "      <td>0.349931</td>\n",
       "      <td>0.367099</td>\n",
       "      <td>0.391200</td>\n",
       "      <td>...</td>\n",
       "      <td>0.533869</td>\n",
       "      <td>0.562954</td>\n",
       "      <td>0.597889</td>\n",
       "      <td>0.613130</td>\n",
       "      <td>0.625346</td>\n",
       "      <td>0.598881</td>\n",
       "      <td>0.564455</td>\n",
       "      <td>0.551250</td>\n",
       "      <td>0.495312</td>\n",
       "      <td>0.455772</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3487 rows × 24 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            0         1         2         3         4         5         6   \\\n",
       "0     0.366604  0.363255  0.383789  0.416133  0.454973  0.501120  0.553408   \n",
       "1     0.407227  0.410880  0.429766  0.459847  0.498899  0.533039  0.569344   \n",
       "2     0.415020  0.437605  0.462234  0.494799  0.535859  0.555248  0.576234   \n",
       "3     0.434707  0.477320  0.507120  0.542314  0.572283  0.575589  0.578353   \n",
       "4     0.456726  0.512386  0.544937  0.582148  0.594345  0.587986  0.579672   \n",
       "...        ...       ...       ...       ...       ...       ...       ...   \n",
       "3482  0.505518  0.511389  0.535697  0.560016  0.559640  0.555156  0.535591   \n",
       "3483  0.454871  0.463373  0.491093  0.510518  0.514327  0.511964  0.496149   \n",
       "3484  0.405269  0.412940  0.442730  0.455712  0.457993  0.458180  0.443185   \n",
       "3485  0.358663  0.361600  0.389319  0.400986  0.398099  0.398993  0.391860   \n",
       "3486  0.325543  0.326547  0.347569  0.364105  0.359253  0.363228  0.361110   \n",
       "\n",
       "            7         8         9   ...        14        15        16  \\\n",
       "0     0.604316  0.630957  0.634712  ...  0.521855  0.513263  0.499454   \n",
       "1     0.605926  0.614621  0.614851  ...  0.517393  0.507290  0.491653   \n",
       "2     0.596957  0.587375  0.580976  ...  0.507199  0.492210  0.474021   \n",
       "3     0.581659  0.559292  0.545834  ...  0.505845  0.485677  0.461266   \n",
       "4     0.572500  0.551354  0.536991  ...  0.490462  0.458543  0.428629   \n",
       "...        ...       ...       ...  ...       ...       ...       ...   \n",
       "3482  0.524072  0.500966  0.502748  ...  0.557973  0.572103  0.609413   \n",
       "3483  0.478999  0.457198  0.462982  ...  0.548045  0.570672  0.612745   \n",
       "3484  0.422063  0.408318  0.419716  ...  0.533366  0.561215  0.604059   \n",
       "3485  0.372683  0.374009  0.391127  ...  0.526897  0.558757  0.601317   \n",
       "3486  0.349931  0.367099  0.391200  ...  0.533869  0.562954  0.597889   \n",
       "\n",
       "            17        18        19        20        21        22        23  \n",
       "0     0.492219  0.509631  0.503469  0.482624  0.449463  0.422944  0.403711  \n",
       "1     0.483424  0.484618  0.469760  0.450299  0.423325  0.404079  0.401087  \n",
       "2     0.455473  0.447700  0.430675  0.415744  0.401272  0.396440  0.415182  \n",
       "3     0.434064  0.420259  0.406833  0.400879  0.397648  0.413193  0.448063  \n",
       "4     0.397014  0.388698  0.389387  0.402213  0.415548  0.457367  0.503473  \n",
       "...        ...       ...       ...       ...       ...       ...       ...  \n",
       "3482  0.647190  0.695680  0.699091  0.697887  0.706611  0.659113  0.617930  \n",
       "3483  0.648706  0.688007  0.686968  0.668244  0.663814  0.609067  0.560218  \n",
       "3484  0.639459  0.669406  0.662631  0.637145  0.626954  0.573104  0.521878  \n",
       "3485  0.628597  0.650035  0.632412  0.603890  0.588857  0.535932  0.489460  \n",
       "3486  0.613130  0.625346  0.598881  0.564455  0.551250  0.495312  0.455772  \n",
       "\n",
       "[3487 rows x 24 columns]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pr_df = pd.DataFrame(tePredict.reshape(-1,24))\n",
    "pr_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "f852a1bb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Error1</th>\n",
       "      <th>Error2</th>\n",
       "      <th>Error3</th>\n",
       "      <th>Error4</th>\n",
       "      <th>Error5</th>\n",
       "      <th>Error6</th>\n",
       "      <th>Error7</th>\n",
       "      <th>Error8</th>\n",
       "      <th>Error9</th>\n",
       "      <th>Error10</th>\n",
       "      <th>...</th>\n",
       "      <th>Error15</th>\n",
       "      <th>Error16</th>\n",
       "      <th>Error17</th>\n",
       "      <th>Error18</th>\n",
       "      <th>Error19</th>\n",
       "      <th>Error20</th>\n",
       "      <th>Error21</th>\n",
       "      <th>Error22</th>\n",
       "      <th>Error23</th>\n",
       "      <th>Error24</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.093841</td>\n",
       "      <td>0.040082</td>\n",
       "      <td>0.001489</td>\n",
       "      <td>-0.029825</td>\n",
       "      <td>-0.059594</td>\n",
       "      <td>-0.087530</td>\n",
       "      <td>-0.075159</td>\n",
       "      <td>-0.010062</td>\n",
       "      <td>0.091568</td>\n",
       "      <td>0.191054</td>\n",
       "      <td>...</td>\n",
       "      <td>0.029286</td>\n",
       "      <td>0.004483</td>\n",
       "      <td>0.023549</td>\n",
       "      <td>0.027470</td>\n",
       "      <td>0.114537</td>\n",
       "      <td>0.188070</td>\n",
       "      <td>0.224329</td>\n",
       "      <td>0.223485</td>\n",
       "      <td>0.183544</td>\n",
       "      <td>0.151064</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.084053</td>\n",
       "      <td>0.028580</td>\n",
       "      <td>-0.016192</td>\n",
       "      <td>-0.054720</td>\n",
       "      <td>-0.089750</td>\n",
       "      <td>-0.095528</td>\n",
       "      <td>-0.045034</td>\n",
       "      <td>0.066537</td>\n",
       "      <td>0.170964</td>\n",
       "      <td>0.204975</td>\n",
       "      <td>...</td>\n",
       "      <td>0.008613</td>\n",
       "      <td>0.031385</td>\n",
       "      <td>0.026904</td>\n",
       "      <td>0.088330</td>\n",
       "      <td>0.169218</td>\n",
       "      <td>0.211465</td>\n",
       "      <td>0.224321</td>\n",
       "      <td>0.183926</td>\n",
       "      <td>0.151432</td>\n",
       "      <td>0.124350</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.032720</td>\n",
       "      <td>-0.008354</td>\n",
       "      <td>-0.052333</td>\n",
       "      <td>-0.093850</td>\n",
       "      <td>-0.092708</td>\n",
       "      <td>-0.059130</td>\n",
       "      <td>0.036845</td>\n",
       "      <td>0.153300</td>\n",
       "      <td>0.177499</td>\n",
       "      <td>0.086036</td>\n",
       "      <td>...</td>\n",
       "      <td>0.031294</td>\n",
       "      <td>0.027461</td>\n",
       "      <td>0.078926</td>\n",
       "      <td>0.140074</td>\n",
       "      <td>0.189405</td>\n",
       "      <td>0.204697</td>\n",
       "      <td>0.176344</td>\n",
       "      <td>0.148625</td>\n",
       "      <td>0.119703</td>\n",
       "      <td>0.077855</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.011251</td>\n",
       "      <td>-0.037247</td>\n",
       "      <td>-0.081530</td>\n",
       "      <td>-0.086253</td>\n",
       "      <td>-0.042095</td>\n",
       "      <td>0.036200</td>\n",
       "      <td>0.134695</td>\n",
       "      <td>0.171783</td>\n",
       "      <td>0.064352</td>\n",
       "      <td>0.018716</td>\n",
       "      <td>...</td>\n",
       "      <td>0.041096</td>\n",
       "      <td>0.090583</td>\n",
       "      <td>0.145867</td>\n",
       "      <td>0.175769</td>\n",
       "      <td>0.194282</td>\n",
       "      <td>0.167433</td>\n",
       "      <td>0.148232</td>\n",
       "      <td>0.120911</td>\n",
       "      <td>0.075866</td>\n",
       "      <td>0.063916</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.057842</td>\n",
       "      <td>-0.076264</td>\n",
       "      <td>-0.083630</td>\n",
       "      <td>-0.032230</td>\n",
       "      <td>0.054955</td>\n",
       "      <td>0.144328</td>\n",
       "      <td>0.169796</td>\n",
       "      <td>0.077560</td>\n",
       "      <td>0.024236</td>\n",
       "      <td>0.039472</td>\n",
       "      <td>...</td>\n",
       "      <td>0.095368</td>\n",
       "      <td>0.143144</td>\n",
       "      <td>0.170334</td>\n",
       "      <td>0.171037</td>\n",
       "      <td>0.149299</td>\n",
       "      <td>0.136740</td>\n",
       "      <td>0.125476</td>\n",
       "      <td>0.078220</td>\n",
       "      <td>0.073219</td>\n",
       "      <td>0.088577</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3482</th>\n",
       "      <td>0.275095</td>\n",
       "      <td>0.135479</td>\n",
       "      <td>0.007227</td>\n",
       "      <td>-0.092148</td>\n",
       "      <td>-0.191737</td>\n",
       "      <td>-0.245046</td>\n",
       "      <td>-0.286779</td>\n",
       "      <td>-0.280992</td>\n",
       "      <td>-0.270403</td>\n",
       "      <td>-0.228773</td>\n",
       "      <td>...</td>\n",
       "      <td>0.086317</td>\n",
       "      <td>0.139072</td>\n",
       "      <td>0.306229</td>\n",
       "      <td>0.368147</td>\n",
       "      <td>0.380698</td>\n",
       "      <td>0.401143</td>\n",
       "      <td>0.416192</td>\n",
       "      <td>0.413016</td>\n",
       "      <td>0.347939</td>\n",
       "      <td>0.276904</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3483</th>\n",
       "      <td>0.078960</td>\n",
       "      <td>-0.065098</td>\n",
       "      <td>-0.161071</td>\n",
       "      <td>-0.240860</td>\n",
       "      <td>-0.285875</td>\n",
       "      <td>-0.310406</td>\n",
       "      <td>-0.308915</td>\n",
       "      <td>-0.292370</td>\n",
       "      <td>-0.274323</td>\n",
       "      <td>-0.236205</td>\n",
       "      <td>...</td>\n",
       "      <td>0.115014</td>\n",
       "      <td>0.267489</td>\n",
       "      <td>0.333702</td>\n",
       "      <td>0.333724</td>\n",
       "      <td>0.390060</td>\n",
       "      <td>0.405273</td>\n",
       "      <td>0.374649</td>\n",
       "      <td>0.352641</td>\n",
       "      <td>0.268042</td>\n",
       "      <td>0.189475</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3484</th>\n",
       "      <td>-0.123201</td>\n",
       "      <td>-0.239224</td>\n",
       "      <td>-0.308647</td>\n",
       "      <td>-0.344489</td>\n",
       "      <td>-0.364377</td>\n",
       "      <td>-0.346884</td>\n",
       "      <td>-0.328185</td>\n",
       "      <td>-0.309458</td>\n",
       "      <td>-0.290868</td>\n",
       "      <td>-0.232312</td>\n",
       "      <td>...</td>\n",
       "      <td>0.230182</td>\n",
       "      <td>0.282172</td>\n",
       "      <td>0.289077</td>\n",
       "      <td>0.341512</td>\n",
       "      <td>0.387711</td>\n",
       "      <td>0.369036</td>\n",
       "      <td>0.325972</td>\n",
       "      <td>0.285929</td>\n",
       "      <td>0.202362</td>\n",
       "      <td>0.036895</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3485</th>\n",
       "      <td>-0.293501</td>\n",
       "      <td>-0.389777</td>\n",
       "      <td>-0.410883</td>\n",
       "      <td>-0.421384</td>\n",
       "      <td>-0.406965</td>\n",
       "      <td>-0.372376</td>\n",
       "      <td>-0.339661</td>\n",
       "      <td>-0.326503</td>\n",
       "      <td>-0.278019</td>\n",
       "      <td>-0.215000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.247854</td>\n",
       "      <td>0.243775</td>\n",
       "      <td>0.303369</td>\n",
       "      <td>0.346902</td>\n",
       "      <td>0.356439</td>\n",
       "      <td>0.321238</td>\n",
       "      <td>0.262865</td>\n",
       "      <td>0.218115</td>\n",
       "      <td>0.050948</td>\n",
       "      <td>-0.092697</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3486</th>\n",
       "      <td>-0.425834</td>\n",
       "      <td>-0.473655</td>\n",
       "      <td>-0.474801</td>\n",
       "      <td>-0.440959</td>\n",
       "      <td>-0.412116</td>\n",
       "      <td>-0.368293</td>\n",
       "      <td>-0.338076</td>\n",
       "      <td>-0.302097</td>\n",
       "      <td>-0.239028</td>\n",
       "      <td>-0.149000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.218887</td>\n",
       "      <td>0.265006</td>\n",
       "      <td>0.316194</td>\n",
       "      <td>0.319535</td>\n",
       "      <td>0.314173</td>\n",
       "      <td>0.257855</td>\n",
       "      <td>0.193713</td>\n",
       "      <td>0.066266</td>\n",
       "      <td>-0.086845</td>\n",
       "      <td>-0.165146</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3487 rows × 24 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        Error1    Error2    Error3    Error4    Error5    Error6    Error7  \\\n",
       "0     0.093841  0.040082  0.001489 -0.029825 -0.059594 -0.087530 -0.075159   \n",
       "1     0.084053  0.028580 -0.016192 -0.054720 -0.089750 -0.095528 -0.045034   \n",
       "2     0.032720 -0.008354 -0.052333 -0.093850 -0.092708 -0.059130  0.036845   \n",
       "3    -0.011251 -0.037247 -0.081530 -0.086253 -0.042095  0.036200  0.134695   \n",
       "4    -0.057842 -0.076264 -0.083630 -0.032230  0.054955  0.144328  0.169796   \n",
       "...        ...       ...       ...       ...       ...       ...       ...   \n",
       "3482  0.275095  0.135479  0.007227 -0.092148 -0.191737 -0.245046 -0.286779   \n",
       "3483  0.078960 -0.065098 -0.161071 -0.240860 -0.285875 -0.310406 -0.308915   \n",
       "3484 -0.123201 -0.239224 -0.308647 -0.344489 -0.364377 -0.346884 -0.328185   \n",
       "3485 -0.293501 -0.389777 -0.410883 -0.421384 -0.406965 -0.372376 -0.339661   \n",
       "3486 -0.425834 -0.473655 -0.474801 -0.440959 -0.412116 -0.368293 -0.338076   \n",
       "\n",
       "        Error8    Error9   Error10  ...   Error15   Error16   Error17  \\\n",
       "0    -0.010062  0.091568  0.191054  ...  0.029286  0.004483  0.023549   \n",
       "1     0.066537  0.170964  0.204975  ...  0.008613  0.031385  0.026904   \n",
       "2     0.153300  0.177499  0.086036  ...  0.031294  0.027461  0.078926   \n",
       "3     0.171783  0.064352  0.018716  ...  0.041096  0.090583  0.145867   \n",
       "4     0.077560  0.024236  0.039472  ...  0.095368  0.143144  0.170334   \n",
       "...        ...       ...       ...  ...       ...       ...       ...   \n",
       "3482 -0.280992 -0.270403 -0.228773  ...  0.086317  0.139072  0.306229   \n",
       "3483 -0.292370 -0.274323 -0.236205  ...  0.115014  0.267489  0.333702   \n",
       "3484 -0.309458 -0.290868 -0.232312  ...  0.230182  0.282172  0.289077   \n",
       "3485 -0.326503 -0.278019 -0.215000  ...  0.247854  0.243775  0.303369   \n",
       "3486 -0.302097 -0.239028 -0.149000  ...  0.218887  0.265006  0.316194   \n",
       "\n",
       "       Error18   Error19   Error20   Error21   Error22   Error23   Error24  \n",
       "0     0.027470  0.114537  0.188070  0.224329  0.223485  0.183544  0.151064  \n",
       "1     0.088330  0.169218  0.211465  0.224321  0.183926  0.151432  0.124350  \n",
       "2     0.140074  0.189405  0.204697  0.176344  0.148625  0.119703  0.077855  \n",
       "3     0.175769  0.194282  0.167433  0.148232  0.120911  0.075866  0.063916  \n",
       "4     0.171037  0.149299  0.136740  0.125476  0.078220  0.073219  0.088577  \n",
       "...        ...       ...       ...       ...       ...       ...       ...  \n",
       "3482  0.368147  0.380698  0.401143  0.416192  0.413016  0.347939  0.276904  \n",
       "3483  0.333724  0.390060  0.405273  0.374649  0.352641  0.268042  0.189475  \n",
       "3484  0.341512  0.387711  0.369036  0.325972  0.285929  0.202362  0.036895  \n",
       "3485  0.346902  0.356439  0.321238  0.262865  0.218115  0.050948 -0.092697  \n",
       "3486  0.319535  0.314173  0.257855  0.193713  0.066266 -0.086845 -0.165146  \n",
       "\n",
       "[3487 rows x 24 columns]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "teY = testY.reshape(-1,24)\n",
    "e_te = testPredict-teY\n",
    "er_df = pd.DataFrame(e_te, columns=Erindex)\n",
    "er_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "c8eaf8ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3487, 24)\n"
     ]
    }
   ],
   "source": [
    "prnorm = np.array(pr_df)\n",
    "ernorm =np.array(er_df)\n",
    "print(ernorm.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "2e31b5c7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.42280987,  0.53644359,  0.54216892,  0.54850924,  0.55209386,\n",
       "         0.56390512,  0.58332431,  0.5939905 ,  0.59479421,  0.57548243,\n",
       "         0.55478811,  0.53404862,  0.49751511,  0.4666267 ,  0.42323729,\n",
       "         0.41423202,  0.40622148,  0.42890528,  0.43662828,  0.4490203 ,\n",
       "         0.46494353,  0.46911514,  0.47943437,  0.47538221,  0.48752052,\n",
       "         0.02832576, -0.01817259, -0.04868168, -0.00552839,  0.05484601,\n",
       "         0.10905774,  0.157166  ,  0.19426133,  0.21713289,  0.23621642,\n",
       "         0.2523612 ,  0.26132295,  0.26425094,  0.25049445,  0.26432396,\n",
       "         0.29762521,  0.29461552,  0.31126326,  0.36475788,  0.40491039,\n",
       "         0.42002875,  0.42581589,  0.408028  ,  0.3869077 ],\n",
       "       [ 0.38840081,  0.54576796,  0.55794966,  0.57587641,  0.58255947,\n",
       "         0.59050834,  0.59850931,  0.59594315,  0.57830125,  0.55003726,\n",
       "         0.52905214,  0.51087469,  0.48619255,  0.47374505,  0.43826002,\n",
       "         0.43945926,  0.42957014,  0.44469169,  0.4358823 ,  0.44352654,\n",
       "         0.45598024,  0.45611078,  0.47692651,  0.47799253,  0.50330788,\n",
       "        -0.01457354, -0.03924126,  0.01825416,  0.07350035,  0.11624177,\n",
       "         0.16168481,  0.19541027,  0.21995171,  0.23146557,  0.24736472,\n",
       "         0.27468252,  0.28381679,  0.30100221,  0.28835196,  0.33086299,\n",
       "         0.29528038,  0.31932667,  0.35161989,  0.3834934 ,  0.40689386,\n",
       "         0.40249229,  0.40957229,  0.37737972,  0.35217964]])"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "etedat = np.concatenate((npnorm22[:prnorm.shape[0],:], prnorm, ernorm), axis=1)\n",
    "etedat[169:171,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "daaef381",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3317, 1, 49)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_timesteps = 1\n",
    "eteX, eteY = create_dataset(etedat, timesteps, output_timesteps, 0)\n",
    "eteY.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "21299039",
   "metadata": {},
   "outputs": [],
   "source": [
    "eteY = eteY[:,:,-24:].reshape(-1,24)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "f9dd460c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(31207, 1, 49)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "norm_df2 = np.array(norm_df2)\n",
    "output_timesteps = 1\n",
    "Xe, Ye = create_dataset(norm_df2, timesteps, output_timesteps, 0)\n",
    "Ye.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "59bd7a6e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(31207, 168, 49)\n",
      "(31207, 24)\n"
     ]
    }
   ],
   "source": [
    "Ye = Ye[:,:,-24:].reshape(-1,24)\n",
    "print(Xe.shape)\n",
    "print(Ye.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "381085c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "trXe, vaXe, trYe, vaYe = train_test_split(Xe, Ye, test_size=0.3, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "41e9b480",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8372"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "dd4cbb87",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mse_mae(y_true, y_pred):\n",
    "    return K.mean(K.square(y_pred - y_true))*10+K.mean(K.abs(y_pred - y_true))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "79386f1f",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_2\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_2 (InputLayer)            [(None, 168, 49)]    0                                            \n",
      "__________________________________________________________________________________________________\n",
      "permute_1 (Permute)             (None, 49, 168)      0           input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_3 (Dense)                 (None, 49, 168)      28392       permute_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_4 (Dense)                 (None, 49, 168)      28392       permute_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "multiply_24 (Multiply)          (None, 49, 168)      0           dense_3[0][0]                    \n",
      "                                                                 dense_4[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "attention_vec (Permute)         (None, 168, 49)      0           multiply_24[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "multiply_25 (Multiply)          (None, 168, 49)      0           input_2[0][0]                    \n",
      "                                                                 attention_vec[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_24 (Conv1D)              (None, 168, 256)     12800       multiply_25[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "activation_44 (Activation)      (None, 168, 256)     0           conv1d_24[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_45 (Activation)      (None, 168, 256)     0           conv1d_24[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "multiply_26 (Multiply)          (None, 168, 256)     0           activation_44[0][0]              \n",
      "                                                                 activation_45[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_25 (Conv1D)              (None, 168, 49)      25137       multiply_26[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "activation_46 (Activation)      (None, 168, 49)      0           conv1d_25[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_47 (Activation)      (None, 168, 49)      0           conv1d_25[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "multiply_27 (Multiply)          (None, 168, 49)      0           activation_46[0][0]              \n",
      "                                                                 activation_47[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "add_6 (Add)                     (None, 168, 49)      0           input_2[0][0]                    \n",
      "                                                                 multiply_27[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "subtract_6 (Subtract)           (None, 168, 49)      0           input_2[0][0]                    \n",
      "                                                                 multiply_27[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_26 (Conv1D)              (None, 168, 256)     12800       add_6[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_28 (Conv1D)              (None, 168, 256)     12800       subtract_6[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_48 (Activation)      (None, 168, 256)     0           conv1d_26[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_49 (Activation)      (None, 168, 256)     0           conv1d_26[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_52 (Activation)      (None, 168, 256)     0           conv1d_28[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_53 (Activation)      (None, 168, 256)     0           conv1d_28[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "multiply_28 (Multiply)          (None, 168, 256)     0           activation_48[0][0]              \n",
      "                                                                 activation_49[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "multiply_30 (Multiply)          (None, 168, 256)     0           activation_52[0][0]              \n",
      "                                                                 activation_53[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_27 (Conv1D)              (None, 168, 49)      25137       multiply_28[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_29 (Conv1D)              (None, 168, 49)      25137       multiply_30[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "activation_50 (Activation)      (None, 168, 49)      0           conv1d_27[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_51 (Activation)      (None, 168, 49)      0           conv1d_27[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_54 (Activation)      (None, 168, 49)      0           conv1d_29[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_55 (Activation)      (None, 168, 49)      0           conv1d_29[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "multiply_29 (Multiply)          (None, 168, 49)      0           activation_50[0][0]              \n",
      "                                                                 activation_51[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "multiply_31 (Multiply)          (None, 168, 49)      0           activation_54[0][0]              \n",
      "                                                                 activation_55[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "add_7 (Add)                     (None, 168, 49)      0           add_6[0][0]                      \n",
      "                                                                 multiply_29[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "subtract_7 (Subtract)           (None, 168, 49)      0           subtract_6[0][0]                 \n",
      "                                                                 multiply_31[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_6 (Concatenate)     (None, 168, 196)     0           add_7[0][0]                      \n",
      "                                                                 subtract_7[0][0]                 \n",
      "                                                                 add_6[0][0]                      \n",
      "                                                                 subtract_6[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_30 (Conv1D)              (None, 168, 256)     50432       concatenate_6[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_32 (Conv1D)              (None, 168, 256)     50432       concatenate_6[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_56 (Activation)      (None, 168, 256)     0           conv1d_30[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_57 (Activation)      (None, 168, 256)     0           conv1d_30[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_60 (Activation)      (None, 168, 256)     0           conv1d_32[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_61 (Activation)      (None, 168, 256)     0           conv1d_32[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "multiply_32 (Multiply)          (None, 168, 256)     0           activation_56[0][0]              \n",
      "                                                                 activation_57[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "multiply_34 (Multiply)          (None, 168, 256)     0           activation_60[0][0]              \n",
      "                                                                 activation_61[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_31 (Conv1D)              (None, 168, 49)      25137       multiply_32[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_33 (Conv1D)              (None, 168, 49)      25137       multiply_34[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "activation_58 (Activation)      (None, 168, 49)      0           conv1d_31[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_59 (Activation)      (None, 168, 49)      0           conv1d_31[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_62 (Activation)      (None, 168, 49)      0           conv1d_33[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_63 (Activation)      (None, 168, 49)      0           conv1d_33[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "multiply_33 (Multiply)          (None, 168, 49)      0           activation_58[0][0]              \n",
      "                                                                 activation_59[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "multiply_35 (Multiply)          (None, 168, 49)      0           activation_62[0][0]              \n",
      "                                                                 activation_63[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "add_8 (Add)                     (None, 168, 49)      0           add_7[0][0]                      \n",
      "                                                                 multiply_33[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "subtract_8 (Subtract)           (None, 168, 49)      0           subtract_7[0][0]                 \n",
      "                                                                 multiply_35[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_7 (Concatenate)     (None, 168, 294)     0           add_8[0][0]                      \n",
      "                                                                 subtract_8[0][0]                 \n",
      "                                                                 concatenate_6[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_34 (Conv1D)              (None, 168, 256)     75520       concatenate_7[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_36 (Conv1D)              (None, 168, 256)     75520       concatenate_7[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_64 (Activation)      (None, 168, 256)     0           conv1d_34[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_65 (Activation)      (None, 168, 256)     0           conv1d_34[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_68 (Activation)      (None, 168, 256)     0           conv1d_36[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_69 (Activation)      (None, 168, 256)     0           conv1d_36[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "multiply_36 (Multiply)          (None, 168, 256)     0           activation_64[0][0]              \n",
      "                                                                 activation_65[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "multiply_38 (Multiply)          (None, 168, 256)     0           activation_68[0][0]              \n",
      "                                                                 activation_69[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_35 (Conv1D)              (None, 168, 49)      25137       multiply_36[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_37 (Conv1D)              (None, 168, 49)      25137       multiply_38[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "activation_66 (Activation)      (None, 168, 49)      0           conv1d_35[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_67 (Activation)      (None, 168, 49)      0           conv1d_35[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_70 (Activation)      (None, 168, 49)      0           conv1d_37[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_71 (Activation)      (None, 168, 49)      0           conv1d_37[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "multiply_37 (Multiply)          (None, 168, 49)      0           activation_66[0][0]              \n",
      "                                                                 activation_67[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "multiply_39 (Multiply)          (None, 168, 49)      0           activation_70[0][0]              \n",
      "                                                                 activation_71[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "add_9 (Add)                     (None, 168, 49)      0           add_8[0][0]                      \n",
      "                                                                 multiply_37[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "subtract_9 (Subtract)           (None, 168, 49)      0           subtract_7[0][0]                 \n",
      "                                                                 multiply_39[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_8 (Concatenate)     (None, 168, 392)     0           add_9[0][0]                      \n",
      "                                                                 subtract_9[0][0]                 \n",
      "                                                                 concatenate_7[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_38 (Conv1D)              (None, 168, 256)     100608      concatenate_8[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_40 (Conv1D)              (None, 168, 256)     100608      concatenate_8[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_72 (Activation)      (None, 168, 256)     0           conv1d_38[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_73 (Activation)      (None, 168, 256)     0           conv1d_38[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_76 (Activation)      (None, 168, 256)     0           conv1d_40[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_77 (Activation)      (None, 168, 256)     0           conv1d_40[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "multiply_40 (Multiply)          (None, 168, 256)     0           activation_72[0][0]              \n",
      "                                                                 activation_73[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "multiply_42 (Multiply)          (None, 168, 256)     0           activation_76[0][0]              \n",
      "                                                                 activation_77[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_39 (Conv1D)              (None, 168, 49)      25137       multiply_40[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_41 (Conv1D)              (None, 168, 49)      25137       multiply_42[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "activation_74 (Activation)      (None, 168, 49)      0           conv1d_39[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_75 (Activation)      (None, 168, 49)      0           conv1d_39[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_78 (Activation)      (None, 168, 49)      0           conv1d_41[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_79 (Activation)      (None, 168, 49)      0           conv1d_41[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "multiply_41 (Multiply)          (None, 168, 49)      0           activation_74[0][0]              \n",
      "                                                                 activation_75[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "multiply_43 (Multiply)          (None, 168, 49)      0           activation_78[0][0]              \n",
      "                                                                 activation_79[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "add_10 (Add)                    (None, 168, 49)      0           add_9[0][0]                      \n",
      "                                                                 multiply_41[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "subtract_10 (Subtract)          (None, 168, 49)      0           subtract_9[0][0]                 \n",
      "                                                                 multiply_43[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_9 (Concatenate)     (None, 168, 490)     0           add_10[0][0]                     \n",
      "                                                                 subtract_10[0][0]                \n",
      "                                                                 concatenate_8[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_10 (Concatenate)    (None, 168, 98)      0           add_10[0][0]                     \n",
      "                                                                 subtract_10[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_11 (Concatenate)    (None, 168, 1470)    0           concatenate_6[0][0]              \n",
      "                                                                 concatenate_7[0][0]              \n",
      "                                                                 concatenate_8[0][0]              \n",
      "                                                                 concatenate_9[0][0]              \n",
      "                                                                 concatenate_10[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_46 (Conv1D)              (None, 168, 720)     1180080     concatenate_11[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout_2 (Dropout)             (None, 168, 720)     0           conv1d_46[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_47 (Conv1D)              (None, 168, 360)     320040      dropout_2[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_3 (Dropout)             (None, 168, 360)     0           conv1d_47[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling1d_1 (Glo (None, 360)          0           dropout_3[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_5 (Dense)                 (None, 24)           8664        global_average_pooling1d_1[0][0] \n",
      "==================================================================================================\n",
      "Total params: 2,283,321\n",
      "Trainable params: 2,283,321\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "num_features = Xe.shape[2]\n",
    "\n",
    "with tf.device('/gpu:0'):\n",
    "    alpha=1.0\n",
    "    gamma=1.2\n",
    "    beta = 1\n",
    "    hfilters = 256\n",
    "    hkernel_size1 = 1\n",
    "    hkernel_size2 = 2\n",
    "    visible1e = Input(shape=(timesteps, num_features))\n",
    "   \n",
    "    per1e = Permute((2,1))(visible1e)\n",
    "    den1ae = Dense(timesteps, activation='tanh')(per1e)\n",
    "    den1be = Dense(timesteps, activation='sigmoid')(per1e)\n",
    "    den1e = Multiply()([den1ae, den1be])\n",
    "    per2e = Permute((2,1), name='attention_vec')(den1e)\n",
    "    mul1e = Multiply()([visible1e, per2e])\n",
    "    \n",
    "    d1e = Conv1D(filters=round(hfilters*alpha), kernel_size=round(hkernel_size1*beta), padding='causal', dilation_rate=1)(mul1e)\n",
    "    d1ae = Activation(activations.tanh)(d1e)\n",
    "    d1be = Activation(activations.sigmoid)(d1e)\n",
    "    d1e = Multiply()([d1ae, d1be])\n",
    "    \n",
    "    d1e = Conv1D(filters=num_features, kernel_size=round(hkernel_size2*beta), padding='causal', dilation_rate=2)(d1e)\n",
    "    d1ae = Activation(activations.tanh)(d1e)\n",
    "    d1be = Activation(activations.sigmoid)(d1e)\n",
    "    d1e = Multiply()([d1ae, d1be])\n",
    "    \n",
    "    res01ae = Add()([visible1e, d1e])   # (100, 25) (100, 25)\n",
    "    res01be = Subtract()([visible1e, d1e])\n",
    "\n",
    "    d1e = Conv1D(filters=round(hfilters*alpha), kernel_size=round(hkernel_size1*beta), padding='causal', dilation_rate=2)(res01ae)\n",
    "    d1ae = Activation(activations.tanh)(d1e)\n",
    "    d1be = Activation(activations.sigmoid)(d1e)\n",
    "    d1e = Multiply()([d1ae, d1be])\n",
    "    \n",
    "    d1e = Conv1D(filters=num_features, kernel_size=round(hkernel_size2*beta), padding='causal', dilation_rate=4)(d1e)    \n",
    "    d1ae = Activation(activations.tanh)(d1e)\n",
    "    d1be = Activation(activations.sigmoid)(d1e)\n",
    "    \n",
    "    d1e = Multiply()([d1ae, d1be])\n",
    "    res02ae = Add()([res01ae, d1e])   # (100, 25) (100, 25)\n",
    "    \n",
    "    d2e = Conv1D(filters=round(hfilters*alpha), kernel_size=round(hkernel_size1*beta), padding='causal', dilation_rate=2)(res01be) \n",
    "    d2ae = Activation(activations.tanh)(d2e)\n",
    "    d2be = Activation(activations.sigmoid)(d2e)\n",
    "    d2e = Multiply()([d2ae, d2be])\n",
    "    \n",
    "    d2e = Conv1D(filters=num_features, kernel_size=round(hkernel_size2*beta), padding='causal', dilation_rate=4)(d2e) \n",
    "    d2ae = Activation(activations.tanh)(d2e)\n",
    "    d2be = Activation(activations.sigmoid)(d2e)\n",
    "    d2e = Multiply()([d2ae, d2be])\n",
    "    \n",
    "    res02be = Subtract()([res01be, d2e])   # (100, 25) (100, 25) \n",
    "    res02e = Concatenate()([res02ae, res02be, res01ae, res01be])\n",
    "    \n",
    "    d1e = Conv1D(filters=round(hfilters*alpha), kernel_size=round(hkernel_size1*beta), padding='causal', dilation_rate=4)(res02e)\n",
    "    d1ae = Activation(activations.tanh)(d1e)\n",
    "    d1be = Activation(activations.sigmoid)(d1e)\n",
    "    d1e = Multiply()([d1ae, d1be])\n",
    "    \n",
    "    d1e = Conv1D(filters=num_features, kernel_size=round(hkernel_size2*beta), padding='causal', dilation_rate=8)(d1e)    \n",
    "    d1ae = Activation(activations.tanh)(d1e)\n",
    "    d1be = Activation(activations.sigmoid)(d1e)\n",
    "    d1e = Multiply()([d1ae, d1be])\n",
    "    \n",
    "    res03ae = Add()([res02ae, d1e])   # (100, 25) (100, 25)\n",
    "    \n",
    "    d2e = Conv1D(filters=round(hfilters*alpha), kernel_size=round(hkernel_size1*beta), padding='causal', dilation_rate=4)(res02e) \n",
    "    d2ae = Activation(activations.tanh)(d2e)\n",
    "    d2be = Activation(activations.sigmoid)(d2e)\n",
    "    d2e = Multiply()([d2ae, d2be])\n",
    "    \n",
    "    d2e = Conv1D(filters=num_features, kernel_size=round(hkernel_size2*beta), padding='causal', dilation_rate=8)(d2e) \n",
    "    d2ae = Activation(activations.tanh)(d2e)\n",
    "    d2be = Activation(activations.sigmoid)(d2e)\n",
    "    d2e = Multiply()([d2ae, d2be])\n",
    "    \n",
    "    res03be = Subtract()([res02be, d2e])   # (100, 25) (100, 25)\n",
    "    res03e = Concatenate()([res03ae, res03be, res02e])\n",
    "    \n",
    "    d1e = Conv1D(filters=round(hfilters*alpha), kernel_size=round(hkernel_size1*beta), padding='causal', dilation_rate=8)(res03e)\n",
    "    d1ae = Activation(activations.tanh)(d1e)\n",
    "    d1be = Activation(activations.sigmoid)(d1e)\n",
    "    d1e = Multiply()([d1ae, d1be])\n",
    "    d1e = Conv1D(filters=num_features, kernel_size=round(hkernel_size2*beta), padding='causal', dilation_rate=4)(d1e)    \n",
    "    d1ae = Activation(activations.tanh)(d1e)\n",
    "    d1be = Activation(activations.sigmoid)(d1e)\n",
    "    d1e = Multiply()([d1ae, d1be])\n",
    "    res04ae = Add()([res03ae, d1e])   # (100, 25) (100, 25)\n",
    "    \n",
    "    d2e = Conv1D(filters=round(hfilters*alpha), kernel_size=round(hkernel_size1*beta), padding='causal', dilation_rate=8)(res03e) \n",
    "    d2ae = Activation(activations.tanh)(d2e)\n",
    "    d2be = Activation(activations.sigmoid)(d2e)\n",
    "    d2e = Multiply()([d2ae, d2be])\n",
    "    \n",
    "    d2e = Conv1D(filters=num_features, kernel_size=round(hkernel_size2*beta), padding='causal', dilation_rate=4)(d2e) \n",
    "    d2ae = Activation(activations.tanh)(d2e)\n",
    "    d2be = Activation(activations.sigmoid)(d2e)\n",
    "    d2e = Multiply()([d2ae, d2be])\n",
    "    \n",
    "    res04be = Subtract()([res02be, d2e])   # (100, 25) (100, 25)\n",
    "    res04e = Concatenate()([res04ae, res04be, res03e])\n",
    "    \n",
    "    d1e = Conv1D(filters=round(hfilters*alpha), kernel_size=round(hkernel_size1*beta), padding='causal', dilation_rate=4)(res04e)\n",
    "    d1ae = Activation(activations.tanh)(d1e)\n",
    "    d1be = Activation(activations.sigmoid)(d1e)\n",
    "    d1e = Multiply()([d1ae, d1be])\n",
    "    \n",
    "    d1e = Conv1D(filters=num_features, kernel_size=round(hkernel_size2*beta), padding='causal', dilation_rate=2)(d1e)    \n",
    "    d1ae = Activation(activations.tanh)(d1e)\n",
    "    d1be = Activation(activations.sigmoid)(d1e)\n",
    "    d1e = Multiply()([d1ae, d1be])\n",
    "    \n",
    "    res05ae = Add()([res04ae, d1e])   # (100, 25) (100, 25)\n",
    "    \n",
    "    d2e = Conv1D(filters=round(hfilters*alpha), kernel_size=round(hkernel_size1*beta), padding='causal', dilation_rate=4)(res04e) \n",
    "    d2ae = Activation(activations.tanh)(d2e)\n",
    "    d2be = Activation(activations.sigmoid)(d2e)\n",
    "    d2e = Multiply()([d2ae, d2be])\n",
    "    \n",
    "    d2e = Conv1D(filters=num_features, kernel_size=round(hkernel_size2*beta), padding='causal', dilation_rate=2)(d2e) \n",
    "    d2ae = Activation(activations.tanh)(d2e)\n",
    "    d2be = Activation(activations.sigmoid)(d2e)\n",
    "    d2e = Multiply()([d2ae, d2be])\n",
    "    \n",
    "    res05be = Subtract()([res04be, d2e])   # (100, 25) (100, 25)\n",
    "    res05e = Concatenate()([res05ae, res05be, res04e])\n",
    "    \n",
    "    d1e = Conv1D(filters=round(hfilters*alpha), kernel_size=round(hkernel_size1*beta), padding='causal', dilation_rate=2)(res05e)\n",
    "    d1ae = Activation(activations.tanh)(d1e)\n",
    "    d1be = Activation(activations.sigmoid)(d1e)\n",
    "    d1e = Multiply()([d1ae, d1be])\n",
    "    \n",
    "    d1e = Conv1D(filters=num_features, kernel_size=round(hkernel_size2*beta), padding='causal', dilation_rate=1)(d1e)    \n",
    "    d1ae = Activation(activations.tanh)(d1e)\n",
    "    d1be = Activation(activations.sigmoid)(d1e)\n",
    "    d1e = Multiply()([d1ae, d1be])\n",
    "\n",
    "    res06ae = Add()([res05ae, d1e])   # (100, 25) (100, 25)\n",
    "    \n",
    "    d2e = Conv1D(filters=round(hfilters*alpha), kernel_size=round(hkernel_size1*beta), padding='causal', dilation_rate=2)(res05e) \n",
    "    d2ae = Activation(activations.tanh)(d2e)\n",
    "    d2be = Activation(activations.sigmoid)(d2e)\n",
    "    d2e = Multiply()([d2ae, d2be])\n",
    "    d2e = Conv1D(filters=num_features, kernel_size=round(hkernel_size2*beta), padding='causal', dilation_rate=1)(d2e) \n",
    "    d2ae = Activation(activations.tanh)(d2e)\n",
    "    d2be = Activation(activations.sigmoid)(d2e)\n",
    "    d2e = Multiply()([d2ae, d2be])\n",
    "\n",
    "    res06be = Subtract()([res05be, d2e])   # (100, 25) (100, 25)\n",
    "    res06e = Concatenate()([res05ae, res05be])\n",
    "    \n",
    "    res10e = Concatenate()([res02e, res03e, res04e, res05e, res06e])   # \n",
    "    \n",
    "    #print('res10 :', res10.shape)  # (None, 24, 11) \n",
    "    \n",
    "    oute = Conv1D(720, 1, padding='same', activation=PReLU())(res10e)   # 256, 11X10=110\n",
    "    oute = Dropout(0.2)(oute)   #SpatialDropout1D\n",
    "    \n",
    "    oute = Conv1D(360, 1, padding='same', activation=PReLU())(oute) # 512,  110X5=550\n",
    "    oute = Dropout(0.2)(oute)\n",
    "    \n",
    "    oute = GlobalAveragePooling1D()(oute) # pool_size=2, strides=1\n",
    "    \n",
    "    oute = Dense(24)(oute) \n",
    "    modele = Model(inputs=[visible1e], outputs=[oute])\n",
    "    \n",
    "    print(modele.summary())\n",
    "    \n",
    "    modele.compile(loss=mse_mae, optimizer='adam', metrics=['mse','mae','mape'])\n",
    "    early_stopping =EarlyStopping(monitor='val_loss', patience=10)\n",
    "    batch_size = 168\n",
    "    epochs = 1000\n",
    "\n",
    "    history_e = LossHistory()\n",
    "    history_e.init()\n",
    "    \n",
    "    #hist = model.fit(trX, trY, epochs=epochs, batch_size=batch_size, shuffle=False, validation_data=(vaX, vaY), callbacks=[history, early_stopping])  # , checkpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "1a0c6e74",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2538"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "3b7b2e78",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "  6/131 [>.............................] - ETA: 16s - loss: 1.9027 - mse: 0.1618 - mae: 0.2843 - mape: 2912.1843WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0582s vs `on_train_batch_end` time: 0.0605s). Check your callbacks.\n",
      "131/131 [==============================] - 25s 161ms/step - loss: 0.2465 - mse: 0.0166 - mae: 0.0807 - mape: 748.2305 - val_loss: 0.1307 - val_mse: 0.0069 - val_mae: 0.0614 - val_mape: 745.5959\n",
      "Epoch 2/1000\n",
      "131/131 [==============================] - 20s 151ms/step - loss: 0.1032 - mse: 0.0051 - mae: 0.0523 - mape: 640.6229 - val_loss: 0.0744 - val_mse: 0.0032 - val_mae: 0.0427 - val_mape: 458.5798\n",
      "Epoch 3/1000\n",
      "131/131 [==============================] - 20s 151ms/step - loss: 0.0658 - mse: 0.0027 - mae: 0.0389 - mape: 464.0234 - val_loss: 0.0486 - val_mse: 0.0017 - val_mae: 0.0316 - val_mape: 364.2837\n",
      "Epoch 4/1000\n",
      "131/131 [==============================] - 20s 150ms/step - loss: 0.0506 - mse: 0.0018 - mae: 0.0324 - mape: 351.7893 - val_loss: 0.0377 - val_mse: 0.0012 - val_mae: 0.0261 - val_mape: 343.8278\n",
      "Epoch 5/1000\n",
      "131/131 [==============================] - 20s 150ms/step - loss: 0.0421 - mse: 0.0014 - mae: 0.0283 - mape: 346.7825 - val_loss: 0.0324 - val_mse: 9.0959e-04 - val_mae: 0.0233 - val_mape: 327.8005\n",
      "Epoch 6/1000\n",
      "131/131 [==============================] - 20s 150ms/step - loss: 0.0369 - mse: 0.0011 - mae: 0.0256 - mape: 348.3895 - val_loss: 0.0287 - val_mse: 7.5512e-04 - val_mae: 0.0211 - val_mape: 267.8975\n",
      "Epoch 7/1000\n",
      "131/131 [==============================] - 20s 150ms/step - loss: 0.0338 - mse: 9.8878e-04 - mae: 0.0240 - mape: 335.3055 - val_loss: 0.0258 - val_mse: 6.3961e-04 - val_mae: 0.0194 - val_mape: 278.0437\n",
      "Epoch 8/1000\n",
      "131/131 [==============================] - 20s 150ms/step - loss: 0.0314 - mse: 8.8256e-04 - mae: 0.0226 - mape: 324.1492 - val_loss: 0.0244 - val_mse: 5.8431e-04 - val_mae: 0.0186 - val_mape: 265.0821\n",
      "Epoch 9/1000\n",
      "131/131 [==============================] - 20s 150ms/step - loss: 0.0299 - mse: 8.1909e-04 - mae: 0.0218 - mape: 326.0748 - val_loss: 0.0237 - val_mse: 5.5902e-04 - val_mae: 0.0181 - val_mape: 281.0172\n",
      "Epoch 10/1000\n",
      "131/131 [==============================] - 20s 150ms/step - loss: 0.0284 - mse: 7.5835e-04 - mae: 0.0209 - mape: 296.5141 - val_loss: 0.0218 - val_mse: 4.8754e-04 - val_mae: 0.0169 - val_mape: 257.7165\n",
      "Epoch 11/1000\n",
      "131/131 [==============================] - 20s 152ms/step - loss: 0.0274 - mse: 7.1572e-04 - mae: 0.0203 - mape: 269.9726 - val_loss: 0.0220 - val_mse: 4.9791e-04 - val_mae: 0.0171 - val_mape: 289.5665\n",
      "Epoch 12/1000\n",
      "131/131 [==============================] - 115s 885ms/step - loss: 0.0261 - mse: 6.6378e-04 - mae: 0.0194 - mape: 301.2475 - val_loss: 0.0204 - val_mse: 4.4144e-04 - val_mae: 0.0160 - val_mape: 238.3639\n",
      "Epoch 13/1000\n",
      "131/131 [==============================] - 154s 1s/step - loss: 0.0256 - mse: 6.4415e-04 - mae: 0.0191 - mape: 288.8956 - val_loss: 0.0202 - val_mse: 4.3408e-04 - val_mae: 0.0159 - val_mape: 234.3824\n",
      "Epoch 14/1000\n",
      "131/131 [==============================] - 155s 1s/step - loss: 0.0249 - mse: 6.1811e-04 - mae: 0.0187 - mape: 243.7903 - val_loss: 0.0192 - val_mse: 4.0094e-04 - val_mae: 0.0152 - val_mape: 235.3088\n",
      "Epoch 15/1000\n",
      "131/131 [==============================] - 115s 881ms/step - loss: 0.0242 - mse: 5.9272e-04 - mae: 0.0183 - mape: 278.2880 - val_loss: 0.0185 - val_mse: 3.7719e-04 - val_mae: 0.0147 - val_mape: 234.7298\n",
      "Epoch 16/1000\n",
      "131/131 [==============================] - 101s 773ms/step - loss: 0.0236 - mse: 5.6913e-04 - mae: 0.0179 - mape: 249.0323 - val_loss: 0.0184 - val_mse: 3.7143e-04 - val_mae: 0.0147 - val_mape: 239.3148\n",
      "Epoch 17/1000\n",
      "131/131 [==============================] - 145s 1s/step - loss: 0.0233 - mse: 5.5535e-04 - mae: 0.0177 - mape: 252.8368 - val_loss: 0.0179 - val_mse: 3.5710e-04 - val_mae: 0.0144 - val_mape: 250.9498\n",
      "Epoch 18/1000\n",
      "131/131 [==============================] - 154s 1s/step - loss: 0.0229 - mse: 5.4072e-04 - mae: 0.0175 - mape: 279.1750 - val_loss: 0.0200 - val_mse: 4.2426e-04 - val_mae: 0.0158 - val_mape: 290.7344\n",
      "Epoch 19/1000\n",
      "131/131 [==============================] - 154s 1s/step - loss: 0.0231 - mse: 5.4745e-04 - mae: 0.0176 - mape: 258.8405 - val_loss: 0.0172 - val_mse: 3.3217e-04 - val_mae: 0.0138 - val_mape: 229.6767\n",
      "Epoch 20/1000\n",
      "131/131 [==============================] - 154s 1s/step - loss: 0.0222 - mse: 5.1499e-04 - mae: 0.0170 - mape: 213.2516 - val_loss: 0.0177 - val_mse: 3.4756e-04 - val_mae: 0.0142 - val_mape: 238.7893\n",
      "Epoch 21/1000\n",
      "131/131 [==============================] - 154s 1s/step - loss: 0.0219 - mse: 5.0376e-04 - mae: 0.0168 - mape: 239.4040 - val_loss: 0.0169 - val_mse: 3.2337e-04 - val_mae: 0.0136 - val_mape: 219.2561\n",
      "Epoch 22/1000\n",
      "131/131 [==============================] - 153s 1s/step - loss: 0.0210 - mse: 4.7219e-04 - mae: 0.0162 - mape: 205.5059 - val_loss: 0.0172 - val_mse: 3.3431e-04 - val_mae: 0.0139 - val_mape: 245.4090\n",
      "Epoch 23/1000\n",
      "131/131 [==============================] - 150s 1s/step - loss: 0.0211 - mse: 4.7661e-04 - mae: 0.0163 - mape: 210.7681 - val_loss: 0.0187 - val_mse: 3.8342e-04 - val_mae: 0.0149 - val_mape: 249.4159\n",
      "Epoch 24/1000\n",
      "131/131 [==============================] - 139s 1s/step - loss: 0.0211 - mse: 4.7611e-04 - mae: 0.0163 - mape: 215.9087 - val_loss: 0.0168 - val_mse: 3.2429e-04 - val_mae: 0.0136 - val_mape: 235.4896\n",
      "Epoch 25/1000\n",
      "131/131 [==============================] - 100s 766ms/step - loss: 0.0208 - mse: 4.6762e-04 - mae: 0.0161 - mape: 269.3899 - val_loss: 0.0172 - val_mse: 3.3296e-04 - val_mae: 0.0139 - val_mape: 251.7082\n",
      "Epoch 26/1000\n",
      "131/131 [==============================] - 116s 886ms/step - loss: 0.0207 - mse: 4.6459e-04 - mae: 0.0161 - mape: 213.3005 - val_loss: 0.0198 - val_mse: 4.1460e-04 - val_mae: 0.0157 - val_mape: 251.9741\n",
      "Epoch 27/1000\n",
      "131/131 [==============================] - 154s 1s/step - loss: 0.0206 - mse: 4.5990e-04 - mae: 0.0160 - mape: 251.9492 - val_loss: 0.0167 - val_mse: 3.2151e-04 - val_mae: 0.0135 - val_mape: 230.0652\n",
      "Epoch 28/1000\n",
      "131/131 [==============================] - 155s 1s/step - loss: 0.0205 - mse: 4.5734e-04 - mae: 0.0159 - mape: 269.5232 - val_loss: 0.0166 - val_mse: 3.1488e-04 - val_mae: 0.0134 - val_mape: 233.8748\n",
      "Epoch 29/1000\n",
      "131/131 [==============================] - 152s 1s/step - loss: 0.0199 - mse: 4.3554e-04 - mae: 0.0155 - mape: 229.4406 - val_loss: 0.0164 - val_mse: 3.0934e-04 - val_mae: 0.0133 - val_mape: 219.1847\n",
      "Epoch 30/1000\n",
      "131/131 [==============================] - 138s 1s/step - loss: 0.0197 - mse: 4.3012e-04 - mae: 0.0154 - mape: 210.8543 - val_loss: 0.0155 - val_mse: 2.8234e-04 - val_mae: 0.0126 - val_mape: 205.0232\n",
      "Epoch 31/1000\n",
      "131/131 [==============================] - 163s 1s/step - loss: 0.0196 - mse: 4.2631e-04 - mae: 0.0154 - mape: 236.1035 - val_loss: 0.0163 - val_mse: 3.0473e-04 - val_mae: 0.0132 - val_mape: 216.7746\n",
      "Epoch 32/1000\n",
      "131/131 [==============================] - 20s 151ms/step - loss: 0.0199 - mse: 4.3405e-04 - mae: 0.0155 - mape: 223.7977 - val_loss: 0.0161 - val_mse: 3.0256e-04 - val_mae: 0.0130 - val_mape: 225.7587\n",
      "Epoch 33/1000\n",
      "131/131 [==============================] - 20s 151ms/step - loss: 0.0193 - mse: 4.1538e-04 - mae: 0.0151 - mape: 213.5811 - val_loss: 0.0155 - val_mse: 2.8395e-04 - val_mae: 0.0127 - val_mape: 219.7520\n",
      "Epoch 34/1000\n",
      "131/131 [==============================] - 20s 150ms/step - loss: 0.0190 - mse: 4.0673e-04 - mae: 0.0150 - mape: 230.0466 - val_loss: 0.0175 - val_mse: 3.4606e-04 - val_mae: 0.0140 - val_mape: 234.6007\n",
      "Epoch 35/1000\n",
      "131/131 [==============================] - 20s 150ms/step - loss: 0.0193 - mse: 4.1558e-04 - mae: 0.0151 - mape: 233.5442 - val_loss: 0.0155 - val_mse: 2.8524e-04 - val_mae: 0.0127 - val_mape: 225.9106\n",
      "Epoch 36/1000\n",
      "131/131 [==============================] - 20s 151ms/step - loss: 0.0189 - mse: 4.0215e-04 - mae: 0.0149 - mape: 197.4207 - val_loss: 0.0166 - val_mse: 3.1712e-04 - val_mae: 0.0135 - val_mape: 234.1951\n",
      "Epoch 37/1000\n",
      "131/131 [==============================] - 20s 150ms/step - loss: 0.0184 - mse: 3.8781e-04 - mae: 0.0146 - mape: 207.1337 - val_loss: 0.0164 - val_mse: 3.1290e-04 - val_mae: 0.0133 - val_mape: 221.7384\n",
      "Epoch 38/1000\n",
      "131/131 [==============================] - 20s 150ms/step - loss: 0.0185 - mse: 3.8943e-04 - mae: 0.0146 - mape: 218.2634 - val_loss: 0.0148 - val_mse: 2.6183e-04 - val_mae: 0.0122 - val_mape: 197.8251\n",
      "Epoch 39/1000\n",
      "131/131 [==============================] - 20s 151ms/step - loss: 0.0188 - mse: 3.9885e-04 - mae: 0.0148 - mape: 215.4587 - val_loss: 0.0167 - val_mse: 3.1689e-04 - val_mae: 0.0135 - val_mape: 236.0350\n",
      "Epoch 40/1000\n",
      "131/131 [==============================] - 20s 150ms/step - loss: 0.0184 - mse: 3.8484e-04 - mae: 0.0145 - mape: 199.6145 - val_loss: 0.0167 - val_mse: 3.2616e-04 - val_mae: 0.0135 - val_mape: 229.0635\n",
      "Epoch 41/1000\n",
      "131/131 [==============================] - 20s 150ms/step - loss: 0.0183 - mse: 3.8364e-04 - mae: 0.0145 - mape: 206.8881 - val_loss: 0.0189 - val_mse: 3.8760e-04 - val_mae: 0.0150 - val_mape: 232.2219\n",
      "Epoch 42/1000\n",
      "131/131 [==============================] - 20s 150ms/step - loss: 0.0190 - mse: 4.0588e-04 - mae: 0.0149 - mape: 210.8774 - val_loss: 0.0171 - val_mse: 3.2971e-04 - val_mae: 0.0138 - val_mape: 199.5219\n",
      "Epoch 43/1000\n",
      "131/131 [==============================] - 20s 150ms/step - loss: 0.0191 - mse: 4.1044e-04 - mae: 0.0150 - mape: 202.1454 - val_loss: 0.0172 - val_mse: 3.3657e-04 - val_mae: 0.0138 - val_mape: 202.2570\n",
      "Epoch 44/1000\n",
      "131/131 [==============================] - 20s 149ms/step - loss: 0.0183 - mse: 3.8365e-04 - mae: 0.0145 - mape: 212.3561 - val_loss: 0.0154 - val_mse: 2.7968e-04 - val_mae: 0.0126 - val_mape: 198.3837\n",
      "Epoch 45/1000\n",
      "131/131 [==============================] - 20s 150ms/step - loss: 0.0181 - mse: 3.7416e-04 - mae: 0.0143 - mape: 193.7767 - val_loss: 0.0164 - val_mse: 3.1450e-04 - val_mae: 0.0133 - val_mape: 230.6876\n",
      "Epoch 46/1000\n",
      "131/131 [==============================] - 20s 150ms/step - loss: 0.0181 - mse: 3.7734e-04 - mae: 0.0143 - mape: 189.1815 - val_loss: 0.0163 - val_mse: 3.0628e-04 - val_mae: 0.0132 - val_mape: 221.4713\n",
      "Epoch 47/1000\n",
      "131/131 [==============================] - 20s 149ms/step - loss: 0.0182 - mse: 3.8198e-04 - mae: 0.0144 - mape: 186.6941 - val_loss: 0.0157 - val_mse: 2.8901e-04 - val_mae: 0.0128 - val_mape: 225.7099\n",
      "Epoch 48/1000\n",
      "131/131 [==============================] - 20s 149ms/step - loss: 0.0178 - mse: 3.6454e-04 - mae: 0.0141 - mape: 204.6577 - val_loss: 0.0154 - val_mse: 2.8616e-04 - val_mae: 0.0126 - val_mape: 215.6014\n"
     ]
    }
   ],
   "source": [
    "# %%time\n",
    "    histe = modele.fit(trXe, trYe, epochs=epochs, batch_size=b_size, shuffle=False, validation_data=(vaXe, vaYe), callbacks=[history_e, early_stopping])  # , checkpoint"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6430841",
   "metadata": {},
   "source": [
    "### Saving FFEL Model Training Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "a228fe54",
   "metadata": {},
   "outputs": [],
   "source": [
    "eloss_history = histe.history['loss']\n",
    "valeloss_history = histe.history['val_loss']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "bd053b2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.savetxt('elosshistory_lead.txt',(eloss_history, valeloss_history))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "67e77afe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4606"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "f353850e",
   "metadata": {},
   "outputs": [],
   "source": [
    "modele.save('Error Learning Model_lead.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8df4c1ec",
   "metadata": {},
   "source": [
    "## FFEL Model Test Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "9a1261dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 168\n",
    "trainePredict = modele.predict(Xe, batch_size=batch_size)\n",
    "etePredict = modele.predict(eteX, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "7b2aa0ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error Training Score > MSE ==  0.00030718369811157337  MAE ==  0.01283941602927101  RMSE ==  0.01752665678649449\n"
     ]
    }
   ],
   "source": [
    "trePredict = trainePredict.reshape([-1])\n",
    "trainYe = Ye.reshape([-1])\n",
    "\n",
    "print('Error Training Score > MSE == ', (np.mean(np.square(trainYe-trePredict))), ' MAE == ', mean_absolute_error(trainYe,trePredict), ' RMSE == ', np.sqrt(np.mean(np.square(trainYe-trePredict))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "4cf4f098",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error Training Score > MSE ==  0.001076969294617801  MAE ==  0.024615836318902986  RMSE ==  0.032817210341797805\n"
     ]
    }
   ],
   "source": [
    "etestPredict = etePredict.reshape([-1])\n",
    "testYe = eteY.reshape([-1])\n",
    "\n",
    "print('Error Training Score > MSE == ', (np.mean(np.square(testYe-etestPredict))), ' MAE == ', mean_absolute_error(testYe,etestPredict), ' RMSE == ', np.sqrt(np.mean(np.square(testYe-etestPredict))))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3a3a594",
   "metadata": {},
   "source": [
    "## Final Prediction Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "d19b306e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3317, 24)\n"
     ]
    }
   ],
   "source": [
    "testPredict = tePredict.reshape(-1,24)\n",
    "addtestPredict = -etePredict + testPredict[timesteps:-2,:]\n",
    "print(addtestPredict.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "79dee903",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error Test Score > MSE ==  0.03357277990633022  MAE ==  0.14762110707082812 MAPE ==  88.33739268989889\n",
      "Error Test Score > MSE ==  0.0010769692992615974  MAE ==  0.024615836419590646 MAPE ==  10.877117884450543\n"
     ]
    }
   ],
   "source": [
    "print('Error Test Score > MSE == ', (np.mean(np.square(teY[timesteps:-2,:]-testPredict[timesteps:-2,:]))), ' MAE == ', mean_absolute_error(teY[timesteps:-2,:], testPredict[timesteps:-2,:]), 'MAPE == ', mean_absolute_percentage_error(teY[timesteps:-2,:], testPredict[timesteps:-2,:]))\n",
    "print('Error Test Score > MSE == ', (np.mean(np.square(teY[timesteps:-2,:]-addtestPredict))), ' MAE == ', mean_absolute_error(teY[timesteps:-2,:], addtestPredict), 'MAPE == ', mean_absolute_percentage_error(teY[timesteps:-2,:], addtestPredict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f7aa07e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
