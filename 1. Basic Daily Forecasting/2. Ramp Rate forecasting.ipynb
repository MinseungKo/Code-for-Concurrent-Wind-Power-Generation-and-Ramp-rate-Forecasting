{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7d369ddd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "import pandas as pd\n",
    "import codecs\n",
    "import numpy as np\n",
    "import math\n",
    "import csv\n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.metrics import recall_score, precision_score # New\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn import preprocessing\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow.keras.preprocessing\n",
    "#from tensorflow.keras.callbacks import ModelCheckpoint, CSVLogger, EarlyStopping, LearningRateScheduler, ReduceLROnPlateau\n",
    "from tensorflow.keras.models import Sequential, Model\n",
    "from tensorflow.keras.layers import Dense, Input, Flatten, Add, Multiply, Subtract\n",
    "from tensorflow.keras import backend as K\n",
    "from tensorflow.keras.layers import Activation, BatchNormalization\n",
    "# regularizers\n",
    "from tensorflow.keras.layers import Conv1D, Conv2D\n",
    "from tensorflow.keras.layers import MaxPooling1D\n",
    "from tensorflow.keras.layers import concatenate\n",
    "from tensorflow.keras.layers import LSTM, Bidirectional\n",
    "from tensorflow.keras.utils import plot_model\n",
    "from tensorflow.keras.layers import Dropout, SpatialDropout1D\n",
    "from scipy import signal\n",
    "import openpyxl\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "from matplotlib import pylab as plt\n",
    "import matplotlib.dates as mdates\n",
    "import seaborn as sns\n",
    "import sklearn\n",
    "from sklearn.model_selection import train_test_split\n",
    "from numpy.linalg import svd\n",
    "import gc\n",
    "from keijzer import *\n",
    "from tensorflow import keras\n",
    "from keras.models import Model\n",
    "from keras.layers import *\n",
    "from tensorflow.keras.optimizers import Adam,SGD\n",
    "from keras.layers import Dense, Input, Flatten, Add, concatenate, Dropout, Activation, Multiply, Embedding, Layer, Reshape\n",
    "from keras.layers import LSTM, Bidirectional, GlobalMaxPooling1D, GlobalAveragePooling1D  \n",
    "from keras.layers import Conv1D, AveragePooling1D, MaxPooling1D\n",
    "#from keras.ops import convert_to_tensor, convert_to_numpy\n",
    "#from keras.utils import plot_model\n",
    "from keras import activations\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from keras.callbacks import ModelCheckpoint, CSVLogger, EarlyStopping, LearningRateScheduler, ReduceLROnPlateau\n",
    "import math\n",
    "\n",
    "class LossHistory(tensorflow.keras.callbacks.Callback):  # history = LossHistory()\n",
    "    def init(self):  # history.init()\n",
    "        self.losses = []\n",
    "        # self.accs = []\n",
    "        self.val_losses = []\n",
    "        # self.val_accs = []\n",
    "        self.rmses = []\n",
    "        self.mses = []\n",
    "        self.maes = []\n",
    "        self.mapes = []\n",
    "        self.val_rmses = []\n",
    "        self.val_mses = []\n",
    "        self.val_maes = []\n",
    "        self.val_mapes = []\n",
    "\n",
    "    def on_epoch_end(self, batch, logs={}):\n",
    "        self.losses.append(logs.get('loss'))\n",
    "        # self.accs.append(logs.get('acc'))\n",
    "        self.val_losses.append(logs.get('val_loss'))\n",
    "        # self.val_accs.append(logs.get('val_accuracy\n",
    "        self.rmses.append(logs.get('root_mean_squared_error'))\n",
    "        self.mses.append(logs.get('mean_squared_error'))\n",
    "        self.maes.append(logs.get('mean_absolute_error'))\n",
    "        self.mapes.append(logs.get('mean_absolute_percentage_error'))\n",
    "        self.val_rmses.append(logs.get('val_root_mean_squared_error'))\n",
    "        self.val_mses.append(logs.get('val_mean_squared_error'))\n",
    "        self.val_maes.append(logs.get('val_mean_absolute_error'))\n",
    "        self.val_mapes.append(logs.get('val_mean_absolute_percentage_error'))\n",
    "\n",
    "\n",
    "\n",
    "def root_squared_mean_error(y_true, y_pred):\n",
    "    return K.mean((K.abs(y_pred - y_true))*K.square(y_true-K.mean(y_true)))*100\n",
    "\n",
    "def mse_mae(y_true, y_pred):\n",
    "    return K.mean(K.square(y_pred - y_true))+K.mean(K.abs(y_pred - y_true))\n",
    "\n",
    "from keras.layers.advanced_activations import PReLU\n",
    "\n",
    "def mean_absolute_percentage_error(y_true, y_pred):\n",
    "    y_true, y_pred = np.array(y_true), np.array(y_pred)\n",
    "    return np.mean(np.abs((y_true - y_pred) / y_true)) * 100\n",
    "\n",
    "def root_mean_squared_error(y_true, y_pred):\n",
    "        return K.sqrt(K.mean(K.square(y_pred - y_true))) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "db7bffce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = '0' # 여러개 사용시 '0,1,2' 식으로 하나의 문자열에 입력\n",
    "gpus = tf.config.experimental.list_physical_devices('GPU') # 호스트 러나임에 표시되는 GPU 장치 목록 반환\n",
    "\n",
    "if gpus: # 반환된 GPU 장치 목록이 있다면\n",
    "    try: # 해당 장치에 대한 메모리 증가 활성화 여부 설정\n",
    "        tf.config.experimental.set_memory_growth(gpus[0], True)\n",
    "    except RuntimeError as e: # try문 실패시에 에러문구 출력\n",
    "        print(e)\n",
    "\n",
    "print(tf.config.list_physical_devices('GPU'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6067773",
   "metadata": {},
   "source": [
    "## Import Data & Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f7533ce0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Time-Date stamp</th>\n",
       "      <th>Date</th>\n",
       "      <th>ERCOT Load</th>\n",
       "      <th>Total Wind Output</th>\n",
       "      <th>Total Wind Installed</th>\n",
       "      <th>Wind Output, % of Load</th>\n",
       "      <th>Wind Output, % of Installed</th>\n",
       "      <th>1-hr MW change</th>\n",
       "      <th>1-hr % change</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>01-01-2020 00:00:00</td>\n",
       "      <td>Jan-01</td>\n",
       "      <td>36823</td>\n",
       "      <td>12335</td>\n",
       "      <td>27040</td>\n",
       "      <td>33.5</td>\n",
       "      <td>45.617</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>01-01-2020 01:00:00</td>\n",
       "      <td>Jan-01</td>\n",
       "      <td>36511</td>\n",
       "      <td>13300</td>\n",
       "      <td>27040</td>\n",
       "      <td>36.4</td>\n",
       "      <td>49.187</td>\n",
       "      <td>965.4</td>\n",
       "      <td>7.826</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>01-01-2020 02:00:00</td>\n",
       "      <td>Jan-01</td>\n",
       "      <td>36022</td>\n",
       "      <td>13586</td>\n",
       "      <td>27040</td>\n",
       "      <td>37.7</td>\n",
       "      <td>50.245</td>\n",
       "      <td>286.2</td>\n",
       "      <td>2.152</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>01-01-2020 03:00:00</td>\n",
       "      <td>Jan-01</td>\n",
       "      <td>35790</td>\n",
       "      <td>14107</td>\n",
       "      <td>27040</td>\n",
       "      <td>39.4</td>\n",
       "      <td>52.171</td>\n",
       "      <td>520.9</td>\n",
       "      <td>3.834</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>01-01-2020 04:00:00</td>\n",
       "      <td>Jan-01</td>\n",
       "      <td>35642</td>\n",
       "      <td>14887</td>\n",
       "      <td>27040</td>\n",
       "      <td>41.8</td>\n",
       "      <td>55.055</td>\n",
       "      <td>779.6</td>\n",
       "      <td>5.527</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35060</th>\n",
       "      <td>12-31-2023 20:00:00</td>\n",
       "      <td>Dec-31</td>\n",
       "      <td>44887</td>\n",
       "      <td>17161</td>\n",
       "      <td>38631</td>\n",
       "      <td>38.23</td>\n",
       "      <td>44.42</td>\n",
       "      <td>2858</td>\n",
       "      <td>19.99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35061</th>\n",
       "      <td>12-31-2023 21:00:00</td>\n",
       "      <td>Dec-31</td>\n",
       "      <td>44013</td>\n",
       "      <td>18301</td>\n",
       "      <td>38631</td>\n",
       "      <td>41.58</td>\n",
       "      <td>47.37</td>\n",
       "      <td>1139</td>\n",
       "      <td>6.64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35062</th>\n",
       "      <td>12-31-2023 22:00:00</td>\n",
       "      <td>Dec-31</td>\n",
       "      <td>43280</td>\n",
       "      <td>18607</td>\n",
       "      <td>38631</td>\n",
       "      <td>42.99</td>\n",
       "      <td>48.17</td>\n",
       "      <td>307</td>\n",
       "      <td>1.67</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35063</th>\n",
       "      <td>12-31-2023 23:00:00</td>\n",
       "      <td>Dec-31</td>\n",
       "      <td>42319</td>\n",
       "      <td>17866</td>\n",
       "      <td>38631</td>\n",
       "      <td>42.22</td>\n",
       "      <td>46.25</td>\n",
       "      <td>-741</td>\n",
       "      <td>-3.98</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35064</th>\n",
       "      <td>01-01-2024 00:00:00</td>\n",
       "      <td>Jan-01</td>\n",
       "      <td>41682</td>\n",
       "      <td>15869</td>\n",
       "      <td>38631</td>\n",
       "      <td>38.07</td>\n",
       "      <td>41.08</td>\n",
       "      <td>-1996</td>\n",
       "      <td>-11.17</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>35065 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           Time-Date stamp    Date ERCOT Load Total Wind Output  \\\n",
       "0      01-01-2020 00:00:00  Jan-01      36823             12335   \n",
       "1      01-01-2020 01:00:00  Jan-01      36511             13300   \n",
       "2      01-01-2020 02:00:00  Jan-01      36022             13586   \n",
       "3      01-01-2020 03:00:00  Jan-01      35790             14107   \n",
       "4      01-01-2020 04:00:00  Jan-01      35642             14887   \n",
       "...                    ...     ...        ...               ...   \n",
       "35060  12-31-2023 20:00:00  Dec-31      44887             17161   \n",
       "35061  12-31-2023 21:00:00  Dec-31      44013             18301   \n",
       "35062  12-31-2023 22:00:00  Dec-31      43280             18607   \n",
       "35063  12-31-2023 23:00:00  Dec-31      42319             17866   \n",
       "35064  01-01-2024 00:00:00  Jan-01      41682             15869   \n",
       "\n",
       "      Total Wind Installed Wind Output, % of Load Wind Output, % of Installed  \\\n",
       "0                    27040                   33.5                      45.617   \n",
       "1                    27040                   36.4                      49.187   \n",
       "2                    27040                   37.7                      50.245   \n",
       "3                    27040                   39.4                      52.171   \n",
       "4                    27040                   41.8                      55.055   \n",
       "...                    ...                    ...                         ...   \n",
       "35060                38631                  38.23                       44.42   \n",
       "35061                38631                  41.58                       47.37   \n",
       "35062                38631                  42.99                       48.17   \n",
       "35063                38631                  42.22                       46.25   \n",
       "35064                38631                  38.07                       41.08   \n",
       "\n",
       "      1-hr MW change 1-hr % change  \n",
       "0                NaN           NaN  \n",
       "1              965.4         7.826  \n",
       "2              286.2         2.152  \n",
       "3              520.9         3.834  \n",
       "4              779.6         5.527  \n",
       "...              ...           ...  \n",
       "35060           2858         19.99  \n",
       "35061           1139          6.64  \n",
       "35062            307          1.67  \n",
       "35063           -741         -3.98  \n",
       "35064          -1996        -11.17  \n",
       "\n",
       "[35065 rows x 9 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_path = 'C:/Users/smartgrid_AI/Desktop/windpower_ramprate/ercot_2020.csv'\n",
    "data_source1 = pd.read_csv(data_path)\n",
    "dat_source1 = pd.DataFrame(data_source1)\n",
    "#dat_source1 = dat_source1.iloc[:-3,:]\n",
    "\n",
    "data_path = 'C:/Users/smartgrid_AI/Desktop/windpower_ramprate/ercot_2021.csv'\n",
    "data_source2 = pd.read_csv(data_path)\n",
    "dat_source2 = pd.DataFrame(data_source2)\n",
    "dat_source2 = dat_source2.iloc[:8761,:9]\n",
    "\n",
    "data_path = 'C:/Users/smartgrid_AI/Desktop/windpower_ramprate/ercot_2022.csv'\n",
    "data_source3 = pd.read_csv(data_path)\n",
    "dat_source3 = pd.DataFrame(data_source3)\n",
    "dat_source3 = dat_source3.iloc[:8760,:9]\n",
    "\n",
    "data_path = 'C:/Users/smartgrid_AI/Desktop/windpower_ramprate/ercot_2023.csv'\n",
    "data_source4 = pd.read_csv(data_path)\n",
    "dat_source4 = pd.DataFrame(data_source4)\n",
    "dat_source4 = dat_source4.iloc[:8760,:9]\n",
    "\n",
    "dat_arr1 = np.array(dat_source1)\n",
    "dat_arr2 = np.array(dat_source2)\n",
    "dat_arr3 = np.array(dat_source3)\n",
    "dat_arr4 = np.array(dat_source4)\n",
    "\n",
    "dat_arr = np.concatenate([dat_arr1, dat_arr2, dat_arr3, dat_arr4],axis=0)\n",
    "dat_arr.shape # 8784, 8761, 8760, 8760\n",
    "\n",
    "dat_source = pd.DataFrame(dat_arr, columns=['Time-Date stamp','Date','ERCOT Load','Total Wind Output','Total Wind Installed','Wind Output, % of Load','Wind Output, % of Installed','1-hr MW change','1-hr % change'])\n",
    "dat_source"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "affdf1dd",
   "metadata": {},
   "source": [
    "### Dividing by Installed Capacity & Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "03917179",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MW % change</th>\n",
       "      <th>Total Wind Output</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3.56879</td>\n",
       "      <td>0.491864</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.05769</td>\n",
       "      <td>0.502441</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.92678</td>\n",
       "      <td>0.521709</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2.88462</td>\n",
       "      <td>0.550555</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.580621</td>\n",
       "      <td>0.544749</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35059</th>\n",
       "      <td>7.3982</td>\n",
       "      <td>0.444229</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35060</th>\n",
       "      <td>2.951</td>\n",
       "      <td>0.473739</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35061</th>\n",
       "      <td>0.79211</td>\n",
       "      <td>0.48166</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35062</th>\n",
       "      <td>-1.91815</td>\n",
       "      <td>0.462478</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35063</th>\n",
       "      <td>-5.16942</td>\n",
       "      <td>0.410784</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>35064 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      MW % change Total Wind Output\n",
       "0         3.56879          0.491864\n",
       "1         1.05769          0.502441\n",
       "2         1.92678          0.521709\n",
       "3         2.88462          0.550555\n",
       "4       -0.580621          0.544749\n",
       "...           ...               ...\n",
       "35059      7.3982          0.444229\n",
       "35060       2.951          0.473739\n",
       "35061     0.79211           0.48166\n",
       "35062    -1.91815          0.462478\n",
       "35063    -5.16942          0.410784\n",
       "\n",
       "[35064 rows x 2 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dat = pd.DataFrame()\n",
    "dat['MW % change'] = np.array(dat_source.iloc[1:,3], dtype=float)-np.array(dat_source.iloc[0:-1,3], dtype=float)\n",
    "dat['MW % change'] = np.divide(np.array(dat['MW % change']),np.array(dat_source.iloc[1:,4]))*100\n",
    "dat['Total Wind Output'] = np.divide(np.array(dat_source.iloc[1:,3]), np.array(dat_source.iloc[1:,4]))\n",
    "\n",
    "dat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6b1ccc39",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Year</th>\n",
       "      <th>MW % change</th>\n",
       "      <th>Total Wind Output</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2020</td>\n",
       "      <td>3.56879</td>\n",
       "      <td>0.491864</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2020</td>\n",
       "      <td>1.05769</td>\n",
       "      <td>0.502441</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2020</td>\n",
       "      <td>1.92678</td>\n",
       "      <td>0.521709</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2020</td>\n",
       "      <td>2.88462</td>\n",
       "      <td>0.550555</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2020</td>\n",
       "      <td>-0.580621</td>\n",
       "      <td>0.544749</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35059</th>\n",
       "      <td>2023</td>\n",
       "      <td>7.3982</td>\n",
       "      <td>0.444229</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35060</th>\n",
       "      <td>2023</td>\n",
       "      <td>2.951</td>\n",
       "      <td>0.473739</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35061</th>\n",
       "      <td>2023</td>\n",
       "      <td>0.79211</td>\n",
       "      <td>0.48166</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35062</th>\n",
       "      <td>2023</td>\n",
       "      <td>-1.91815</td>\n",
       "      <td>0.462478</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35063</th>\n",
       "      <td>2023</td>\n",
       "      <td>-5.16942</td>\n",
       "      <td>0.410784</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>35064 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Year MW % change Total Wind Output\n",
       "0      2020     3.56879          0.491864\n",
       "1      2020     1.05769          0.502441\n",
       "2      2020     1.92678          0.521709\n",
       "3      2020     2.88462          0.550555\n",
       "4      2020   -0.580621          0.544749\n",
       "...     ...         ...               ...\n",
       "35059  2023      7.3982          0.444229\n",
       "35060  2023       2.951          0.473739\n",
       "35061  2023     0.79211           0.48166\n",
       "35062  2023    -1.91815          0.462478\n",
       "35063  2023    -5.16942          0.410784\n",
       "\n",
       "[35064 rows x 3 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ramp_ratio = 20\n",
    "load_ratio = 10\n",
    "year_arr = np.concatenate([np.ones(8784)*2020, np.ones(8760)*2021, np.ones(8760)*2022, np.ones(8760)*2023])\n",
    "year_df = pd.DataFrame(year_arr, columns=['Year'], dtype=int)\n",
    "wind_df = pd.concat([year_df, dat], axis=1)\n",
    "wind_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b1616158",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Year</th>\n",
       "      <th>MW % change</th>\n",
       "      <th>Total Wind Output</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2020</td>\n",
       "      <td>0.620197</td>\n",
       "      <td>0.644724</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2020</td>\n",
       "      <td>0.544580</td>\n",
       "      <td>0.658617</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2020</td>\n",
       "      <td>0.570751</td>\n",
       "      <td>0.683924</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2020</td>\n",
       "      <td>0.599594</td>\n",
       "      <td>0.721813</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2020</td>\n",
       "      <td>0.495246</td>\n",
       "      <td>0.714187</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35058</th>\n",
       "      <td>2023</td>\n",
       "      <td>0.774643</td>\n",
       "      <td>0.484984</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35059</th>\n",
       "      <td>2023</td>\n",
       "      <td>0.735512</td>\n",
       "      <td>0.582157</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35060</th>\n",
       "      <td>2023</td>\n",
       "      <td>0.601593</td>\n",
       "      <td>0.620917</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35061</th>\n",
       "      <td>2023</td>\n",
       "      <td>0.536583</td>\n",
       "      <td>0.631322</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35062</th>\n",
       "      <td>2023</td>\n",
       "      <td>0.454969</td>\n",
       "      <td>0.606127</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>35063 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Year  MW % change  Total Wind Output\n",
       "0      2020     0.620197           0.644724\n",
       "1      2020     0.544580           0.658617\n",
       "2      2020     0.570751           0.683924\n",
       "3      2020     0.599594           0.721813\n",
       "4      2020     0.495246           0.714187\n",
       "...     ...          ...                ...\n",
       "35058  2023     0.774643           0.484984\n",
       "35059  2023     0.735512           0.582157\n",
       "35060  2023     0.601593           0.620917\n",
       "35061  2023     0.536583           0.631322\n",
       "35062  2023     0.454969           0.606127\n",
       "\n",
       "[35063 rows x 3 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wind_df = wind_df.reset_index(drop=True)\n",
    "std_scaler = sklearn.preprocessing.MinMaxScaler()\n",
    "std_scaler_load = sklearn.preprocessing.MinMaxScaler()\n",
    "std_scaler_ramp = sklearn.preprocessing.MinMaxScaler()\n",
    "\n",
    "wind_df[['Total Wind Output']] = std_scaler.fit_transform(wind_df[['Total Wind Output']])\n",
    "wind_df[['MW % change']] = std_scaler_ramp.fit_transform(wind_df[['MW % change']])\n",
    "#wind_df[['Wind Change, % of Load', 'Wind Change']] = std_scaler_ramp.fit_transform(wind_df[['Wind Change, % of Load', 'Wind Change']])\n",
    "wind_df = wind_df.iloc[:-1,:]\n",
    "wind_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c254738f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Year</th>\n",
       "      <th>Wind Change</th>\n",
       "      <th>Wind Output</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2020</td>\n",
       "      <td>0.620197</td>\n",
       "      <td>0.644724</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2020</td>\n",
       "      <td>0.544580</td>\n",
       "      <td>0.658617</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2020</td>\n",
       "      <td>0.570751</td>\n",
       "      <td>0.683924</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2020</td>\n",
       "      <td>0.599594</td>\n",
       "      <td>0.721813</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2020</td>\n",
       "      <td>0.495246</td>\n",
       "      <td>0.714187</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35058</th>\n",
       "      <td>2023</td>\n",
       "      <td>0.774643</td>\n",
       "      <td>0.484984</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35059</th>\n",
       "      <td>2023</td>\n",
       "      <td>0.735512</td>\n",
       "      <td>0.582157</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35060</th>\n",
       "      <td>2023</td>\n",
       "      <td>0.601593</td>\n",
       "      <td>0.620917</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35061</th>\n",
       "      <td>2023</td>\n",
       "      <td>0.536583</td>\n",
       "      <td>0.631322</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35062</th>\n",
       "      <td>2023</td>\n",
       "      <td>0.454969</td>\n",
       "      <td>0.606127</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>35063 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Year  Wind Change  Wind Output\n",
       "0      2020     0.620197     0.644724\n",
       "1      2020     0.544580     0.658617\n",
       "2      2020     0.570751     0.683924\n",
       "3      2020     0.599594     0.721813\n",
       "4      2020     0.495246     0.714187\n",
       "...     ...          ...          ...\n",
       "35058  2023     0.774643     0.484984\n",
       "35059  2023     0.735512     0.582157\n",
       "35060  2023     0.601593     0.620917\n",
       "35061  2023     0.536583     0.631322\n",
       "35062  2023     0.454969     0.606127\n",
       "\n",
       "[35063 rows x 3 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ramp_df = pd.DataFrame(wind_df)\n",
    "ramp_df.columns=['Year', 'Wind Change', 'Wind Output']\n",
    "ramp_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9ff1ec0",
   "metadata": {},
   "source": [
    "## Wind Ramp Rate Forecasting"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70e9b878",
   "metadata": {},
   "source": [
    "### SVD-based Feature Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fce61dc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from numpy.linalg import svd\n",
    "import gc\n",
    "\n",
    "def create_dataset(dataset, timesteps, output_timesteps, leadtime):\n",
    "    dataX, dataY = [], []\n",
    "    for i in range(len(dataset) - timesteps -output_timesteps - leadtime - 1):\n",
    "        a = dataset[i:(i + timesteps), :]\n",
    "        dataX.append(a)\n",
    "        dataY.append(dataset[(i + timesteps + leadtime):(i+timesteps+output_timesteps+leadtime), :])\n",
    "    return np.array(dataX), np.array(dataY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4b31be66",
   "metadata": {},
   "outputs": [],
   "source": [
    "norm_df = np.array(wind_df['Wind Change']).reshape(-1,1)\n",
    "timesteps = 24*7\n",
    "output_timesteps = 24\n",
    "num_features = 1\n",
    "leadtime = 6\n",
    "X, Y = create_dataset(norm_df, timesteps, output_timesteps, leadtime)\n",
    "b_size = timesteps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "32fda9f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "dec_num = timesteps\n",
    "high_ind = 35\n",
    "\n",
    "addX = np.zeros((X.shape[0], dec_num, high_ind+1))\n",
    "\n",
    "def svdadd(X, start, end, b_size):\n",
    "    dec_x = X[start:end, :, :]\n",
    "    U, S, Vh = svd(dec_x.reshape(b_size, -1))\n",
    "\n",
    "    high_sig = np.matmul(np.matmul(U[:,:high_ind], np.diag(S[0:high_ind])), Vh[:high_ind,:])\n",
    "    low_sig = X[:dec_num, :, :].reshape(b_size,-1)-high_sig\n",
    "\n",
    "    rec_x = np.zeros((b_size, b_size, high_ind))\n",
    "    #print(sum(S[0:high_ind])/sum(S))\n",
    "    for i in range(high_ind):\n",
    "        rec_x[:,:,i] = np.matmul((U[:,i]*S[i]).reshape(-1,1), Vh[i,:].reshape(1,-1))    \n",
    "    return rec_x, low_sig\n",
    "\n",
    "for k in range(X.shape[0]//dec_num):\n",
    "    rec_x, low_sig = svdadd(X, k*dec_num, (k+1)*dec_num, b_size)\n",
    "    addX[k*dec_num:k*dec_num+dec_num,:, :-1] = rec_x\n",
    "    addX[k*dec_num:k*dec_num+dec_num,:, -1] = low_sig\n",
    "    \n",
    "rec_x, low_sig = svdadd(X, X.shape[0]-dec_num, X.shape[0], b_size)\n",
    "addX[X.shape[0]-dec_num:X.shape[0], :, :-1] = rec_x\n",
    "addX[X.shape[0]-dec_num:X.shape[0],:, -1] = low_sig\n",
    "\n",
    "addX_det = addX[:, :, :-1]\n",
    "addX_det = np.sum(addX_det, axis=2)\n",
    "X = np.concatenate([X, addX], axis=2)\n",
    "num_features = X.shape[2]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef0e5550",
   "metadata": {},
   "source": [
    "### Training/Test Set Division & Shuffled Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b036542a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((31377, 168, 37), (31377, 24), (3487, 168, 37), (3487, 24))"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trvaX, teX, trvaY, teY = train_test_split(X, Y, test_size=0.1, shuffle=False)\n",
    "\n",
    "idx = np.arange(trvaX.shape[0])\n",
    "np.random.shuffle(idx)\n",
    "strvaX = trvaX[idx]\n",
    "strvaY = trvaY[idx]\n",
    "strvaY = strvaY.reshape(-1, output_timesteps)\n",
    "\n",
    "trvaY = trvaY.reshape(-1, output_timesteps)\n",
    "teY = teY.reshape(-1, output_timesteps)\n",
    "\n",
    "strX, svaX, strY, svaY = train_test_split(strvaX, strvaY, test_size=0.3, shuffle=False)\n",
    "trX, vaX, trY, vaY = train_test_split(trvaX, trvaY, test_size=0.3, shuffle=False)\n",
    "\n",
    "trvaX.shape, trvaY.shape, teX.shape, teY.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f063a1b8",
   "metadata": {},
   "source": [
    "## Wind Ramp Rate Forecasting Basic Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ca706a83",
   "metadata": {},
   "outputs": [],
   "source": [
    "def MAEMD(y_true, y_pred):\n",
    "    return K.mean((K.abs(y_pred - y_true))*K.square(y_true-K.mean(y_true)))*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "77a7cbd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers.advanced_activations import PReLU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "b7e63520",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(None, 168, 296)\n",
      "Model: \"model_9\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_9 (InputLayer)            [(None, 168, 37)]    0                                            \n",
      "__________________________________________________________________________________________________\n",
      "permute_16 (Permute)            (None, 37, 168)      0           input_9[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_41 (Dense)                (None, 168, 37)      1406        input_9[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_42 (Dense)                (None, 168, 37)      1406        input_9[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_39 (Dense)                (None, 37, 168)      28392       permute_16[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dense_40 (Dense)                (None, 37, 168)      28392       permute_16[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "multiply_212 (Multiply)         (None, 168, 37)      0           dense_41[0][0]                   \n",
      "                                                                 dense_42[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "multiply_210 (Multiply)         (None, 37, 168)      0           dense_39[0][0]                   \n",
      "                                                                 dense_40[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "permute_17 (Permute)            (None, 37, 168)      0           input_9[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "attention_vec2 (Permute)        (None, 37, 168)      0           multiply_212[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "attention_vec (Permute)         (None, 168, 37)      0           multiply_210[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "multiply_213 (Multiply)         (None, 37, 168)      0           permute_17[0][0]                 \n",
      "                                                                 attention_vec2[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "multiply_211 (Multiply)         (None, 168, 37)      0           input_9[0][0]                    \n",
      "                                                                 attention_vec[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_213 (Conv1D)             (None, 37, 168)      28392       multiply_213[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_199 (Conv1D)             (None, 168, 168)     6384        multiply_211[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "activation_384 (Activation)     (None, 37, 168)      0           conv1d_213[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_385 (Activation)     (None, 37, 168)      0           conv1d_213[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_356 (Activation)     (None, 168, 168)     0           conv1d_199[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_357 (Activation)     (None, 168, 168)     0           conv1d_199[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "multiply_228 (Multiply)         (None, 37, 168)      0           activation_384[0][0]             \n",
      "                                                                 activation_385[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "multiply_214 (Multiply)         (None, 168, 168)     0           activation_356[0][0]             \n",
      "                                                                 activation_357[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_214 (Conv1D)             (None, 37, 168)      56616       multiply_228[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_200 (Conv1D)             (None, 168, 37)      12469       multiply_214[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "activation_386 (Activation)     (None, 37, 168)      0           conv1d_214[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_387 (Activation)     (None, 37, 168)      0           conv1d_214[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_358 (Activation)     (None, 168, 37)      0           conv1d_200[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_359 (Activation)     (None, 168, 37)      0           conv1d_200[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "multiply_229 (Multiply)         (None, 37, 168)      0           activation_386[0][0]             \n",
      "                                                                 activation_387[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "multiply_215 (Multiply)         (None, 168, 37)      0           activation_358[0][0]             \n",
      "                                                                 activation_359[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_57 (Add)                    (None, 37, 168)      0           multiply_213[0][0]               \n",
      "                                                                 multiply_229[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "subtract_56 (Subtract)          (None, 37, 168)      0           multiply_213[0][0]               \n",
      "                                                                 multiply_229[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "add_53 (Add)                    (None, 168, 37)      0           multiply_211[0][0]               \n",
      "                                                                 multiply_215[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "subtract_52 (Subtract)          (None, 168, 37)      0           multiply_211[0][0]               \n",
      "                                                                 multiply_215[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_215 (Conv1D)             (None, 37, 168)      28392       add_57[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_217 (Conv1D)             (None, 37, 168)      28392       subtract_56[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_201 (Conv1D)             (None, 168, 168)     6384        add_53[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_203 (Conv1D)             (None, 168, 168)     6384        subtract_52[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "activation_388 (Activation)     (None, 37, 168)      0           conv1d_215[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_389 (Activation)     (None, 37, 168)      0           conv1d_215[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_392 (Activation)     (None, 37, 168)      0           conv1d_217[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_393 (Activation)     (None, 37, 168)      0           conv1d_217[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_360 (Activation)     (None, 168, 168)     0           conv1d_201[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_361 (Activation)     (None, 168, 168)     0           conv1d_201[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_364 (Activation)     (None, 168, 168)     0           conv1d_203[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_365 (Activation)     (None, 168, 168)     0           conv1d_203[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "multiply_230 (Multiply)         (None, 37, 168)      0           activation_388[0][0]             \n",
      "                                                                 activation_389[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "multiply_232 (Multiply)         (None, 37, 168)      0           activation_392[0][0]             \n",
      "                                                                 activation_393[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "multiply_216 (Multiply)         (None, 168, 168)     0           activation_360[0][0]             \n",
      "                                                                 activation_361[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "multiply_218 (Multiply)         (None, 168, 168)     0           activation_364[0][0]             \n",
      "                                                                 activation_365[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_216 (Conv1D)             (None, 37, 168)      56616       multiply_230[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_218 (Conv1D)             (None, 37, 168)      56616       multiply_232[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_202 (Conv1D)             (None, 168, 37)      12469       multiply_216[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_204 (Conv1D)             (None, 168, 37)      12469       multiply_218[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "activation_390 (Activation)     (None, 37, 168)      0           conv1d_216[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_391 (Activation)     (None, 37, 168)      0           conv1d_216[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_394 (Activation)     (None, 37, 168)      0           conv1d_218[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_395 (Activation)     (None, 37, 168)      0           conv1d_218[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_362 (Activation)     (None, 168, 37)      0           conv1d_202[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_363 (Activation)     (None, 168, 37)      0           conv1d_202[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_366 (Activation)     (None, 168, 37)      0           conv1d_204[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_367 (Activation)     (None, 168, 37)      0           conv1d_204[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "multiply_231 (Multiply)         (None, 37, 168)      0           activation_390[0][0]             \n",
      "                                                                 activation_391[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "multiply_233 (Multiply)         (None, 37, 168)      0           activation_394[0][0]             \n",
      "                                                                 activation_395[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "multiply_217 (Multiply)         (None, 168, 37)      0           activation_362[0][0]             \n",
      "                                                                 activation_363[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "multiply_219 (Multiply)         (None, 168, 37)      0           activation_366[0][0]             \n",
      "                                                                 activation_367[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_58 (Add)                    (None, 37, 168)      0           add_57[0][0]                     \n",
      "                                                                 multiply_231[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "subtract_57 (Subtract)          (None, 37, 168)      0           subtract_56[0][0]                \n",
      "                                                                 multiply_233[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "add_54 (Add)                    (None, 168, 37)      0           add_53[0][0]                     \n",
      "                                                                 multiply_217[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "subtract_53 (Subtract)          (None, 168, 37)      0           subtract_52[0][0]                \n",
      "                                                                 multiply_219[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_58 (Concatenate)    (None, 37, 672)      0           add_58[0][0]                     \n",
      "                                                                 subtract_57[0][0]                \n",
      "                                                                 add_57[0][0]                     \n",
      "                                                                 subtract_56[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_55 (Concatenate)    (None, 168, 148)     0           add_54[0][0]                     \n",
      "                                                                 subtract_53[0][0]                \n",
      "                                                                 add_53[0][0]                     \n",
      "                                                                 subtract_52[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_219 (Conv1D)             (None, 37, 168)      113064      concatenate_58[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_221 (Conv1D)             (None, 37, 168)      113064      concatenate_58[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_205 (Conv1D)             (None, 168, 168)     25032       concatenate_55[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_207 (Conv1D)             (None, 168, 168)     25032       concatenate_55[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_396 (Activation)     (None, 37, 168)      0           conv1d_219[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_397 (Activation)     (None, 37, 168)      0           conv1d_219[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_400 (Activation)     (None, 37, 168)      0           conv1d_221[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_401 (Activation)     (None, 37, 168)      0           conv1d_221[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_368 (Activation)     (None, 168, 168)     0           conv1d_205[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_369 (Activation)     (None, 168, 168)     0           conv1d_205[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_372 (Activation)     (None, 168, 168)     0           conv1d_207[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_373 (Activation)     (None, 168, 168)     0           conv1d_207[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "multiply_234 (Multiply)         (None, 37, 168)      0           activation_396[0][0]             \n",
      "                                                                 activation_397[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "multiply_236 (Multiply)         (None, 37, 168)      0           activation_400[0][0]             \n",
      "                                                                 activation_401[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "multiply_220 (Multiply)         (None, 168, 168)     0           activation_368[0][0]             \n",
      "                                                                 activation_369[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "multiply_222 (Multiply)         (None, 168, 168)     0           activation_372[0][0]             \n",
      "                                                                 activation_373[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_220 (Conv1D)             (None, 37, 168)      56616       multiply_234[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_222 (Conv1D)             (None, 37, 168)      56616       multiply_236[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_206 (Conv1D)             (None, 168, 37)      12469       multiply_220[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_208 (Conv1D)             (None, 168, 37)      12469       multiply_222[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "activation_398 (Activation)     (None, 37, 168)      0           conv1d_220[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_399 (Activation)     (None, 37, 168)      0           conv1d_220[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_402 (Activation)     (None, 37, 168)      0           conv1d_222[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_403 (Activation)     (None, 37, 168)      0           conv1d_222[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_370 (Activation)     (None, 168, 37)      0           conv1d_206[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_371 (Activation)     (None, 168, 37)      0           conv1d_206[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_374 (Activation)     (None, 168, 37)      0           conv1d_208[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_375 (Activation)     (None, 168, 37)      0           conv1d_208[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "multiply_235 (Multiply)         (None, 37, 168)      0           activation_398[0][0]             \n",
      "                                                                 activation_399[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "multiply_237 (Multiply)         (None, 37, 168)      0           activation_402[0][0]             \n",
      "                                                                 activation_403[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "multiply_221 (Multiply)         (None, 168, 37)      0           activation_370[0][0]             \n",
      "                                                                 activation_371[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "multiply_223 (Multiply)         (None, 168, 37)      0           activation_374[0][0]             \n",
      "                                                                 activation_375[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_59 (Add)                    (None, 37, 168)      0           add_58[0][0]                     \n",
      "                                                                 multiply_235[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "subtract_58 (Subtract)          (None, 37, 168)      0           subtract_57[0][0]                \n",
      "                                                                 multiply_237[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "add_55 (Add)                    (None, 168, 37)      0           add_54[0][0]                     \n",
      "                                                                 multiply_221[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "subtract_54 (Subtract)          (None, 168, 37)      0           subtract_53[0][0]                \n",
      "                                                                 multiply_223[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_59 (Concatenate)    (None, 37, 1008)     0           add_59[0][0]                     \n",
      "                                                                 subtract_58[0][0]                \n",
      "                                                                 concatenate_58[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_56 (Concatenate)    (None, 168, 222)     0           add_55[0][0]                     \n",
      "                                                                 subtract_54[0][0]                \n",
      "                                                                 concatenate_55[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_223 (Conv1D)             (None, 37, 168)      169512      concatenate_59[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_225 (Conv1D)             (None, 37, 168)      169512      concatenate_59[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_209 (Conv1D)             (None, 168, 168)     37464       concatenate_56[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_211 (Conv1D)             (None, 168, 168)     37464       concatenate_56[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_404 (Activation)     (None, 37, 168)      0           conv1d_223[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_405 (Activation)     (None, 37, 168)      0           conv1d_223[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_408 (Activation)     (None, 37, 168)      0           conv1d_225[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_409 (Activation)     (None, 37, 168)      0           conv1d_225[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_376 (Activation)     (None, 168, 168)     0           conv1d_209[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_377 (Activation)     (None, 168, 168)     0           conv1d_209[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_380 (Activation)     (None, 168, 168)     0           conv1d_211[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_381 (Activation)     (None, 168, 168)     0           conv1d_211[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "multiply_238 (Multiply)         (None, 37, 168)      0           activation_404[0][0]             \n",
      "                                                                 activation_405[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "multiply_240 (Multiply)         (None, 37, 168)      0           activation_408[0][0]             \n",
      "                                                                 activation_409[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "multiply_224 (Multiply)         (None, 168, 168)     0           activation_376[0][0]             \n",
      "                                                                 activation_377[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "multiply_226 (Multiply)         (None, 168, 168)     0           activation_380[0][0]             \n",
      "                                                                 activation_381[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_224 (Conv1D)             (None, 37, 168)      56616       multiply_238[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_226 (Conv1D)             (None, 37, 168)      56616       multiply_240[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_210 (Conv1D)             (None, 168, 37)      12469       multiply_224[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_212 (Conv1D)             (None, 168, 37)      12469       multiply_226[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "activation_406 (Activation)     (None, 37, 168)      0           conv1d_224[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_407 (Activation)     (None, 37, 168)      0           conv1d_224[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_410 (Activation)     (None, 37, 168)      0           conv1d_226[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_411 (Activation)     (None, 37, 168)      0           conv1d_226[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_378 (Activation)     (None, 168, 37)      0           conv1d_210[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_379 (Activation)     (None, 168, 37)      0           conv1d_210[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_382 (Activation)     (None, 168, 37)      0           conv1d_212[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_383 (Activation)     (None, 168, 37)      0           conv1d_212[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "multiply_239 (Multiply)         (None, 37, 168)      0           activation_406[0][0]             \n",
      "                                                                 activation_407[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "multiply_241 (Multiply)         (None, 37, 168)      0           activation_410[0][0]             \n",
      "                                                                 activation_411[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "multiply_225 (Multiply)         (None, 168, 37)      0           activation_378[0][0]             \n",
      "                                                                 activation_379[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "multiply_227 (Multiply)         (None, 168, 37)      0           activation_382[0][0]             \n",
      "                                                                 activation_383[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_60 (Add)                    (None, 37, 168)      0           add_59[0][0]                     \n",
      "                                                                 multiply_239[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "subtract_59 (Subtract)          (None, 37, 168)      0           subtract_58[0][0]                \n",
      "                                                                 multiply_241[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "add_56 (Add)                    (None, 168, 37)      0           add_55[0][0]                     \n",
      "                                                                 multiply_225[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "subtract_55 (Subtract)          (None, 168, 37)      0           subtract_54[0][0]                \n",
      "                                                                 multiply_227[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_60 (Concatenate)    (None, 37, 1344)     0           add_60[0][0]                     \n",
      "                                                                 subtract_59[0][0]                \n",
      "                                                                 concatenate_59[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_57 (Concatenate)    (None, 168, 296)     0           add_56[0][0]                     \n",
      "                                                                 subtract_55[0][0]                \n",
      "                                                                 concatenate_56[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_227 (Conv1D)             (None, 37, 168)      232176      concatenate_60[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_228 (Conv1D)             (None, 168, 168)     78120       concatenate_57[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout_21 (Dropout)            (None, 37, 168)      0           conv1d_227[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dropout_22 (Dropout)            (None, 168, 168)     0           conv1d_228[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_61 (Concatenate)    (None, 205, 168)     0           dropout_21[0][0]                 \n",
      "                                                                 dropout_22[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_229 (Conv1D)             (None, 205, 168)     62832       concatenate_61[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout_23 (Dropout)            (None, 205, 168)     0           conv1d_229[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling1d_7 (Glo (None, 168)          0           dropout_23[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dense_43 (Dense)                (None, 24)           4056        global_average_pooling1d_7[0][0] \n",
      "==================================================================================================\n",
      "Total params: 1,714,847\n",
      "Trainable params: 1,714,847\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "from keras import regularizers\n",
    "\n",
    "num_features = trvaX.shape[2]\n",
    "output_timesteps = trvaY.shape[1]\n",
    "\n",
    "with tf.device('/gpu:0'):\n",
    "    alpha=1.0\n",
    "    gamma=1\n",
    "    beta = 1\n",
    "    hfilters = 168\n",
    "    hkernel_size1 = 1\n",
    "    hkernel_size2 = 2\n",
    "    visible1 = Input(shape=(timesteps, num_features))\n",
    "   \n",
    "    ## Attention Block\n",
    "    pera = Permute((2,1))(visible1)\n",
    "    den1a = Dense(timesteps, activation='tanh')(pera)\n",
    "    den1b = Dense(timesteps, activation='sigmoid')(pera)\n",
    "    den1 = Multiply()([den1a, den1b])\n",
    "    per2 = Permute((2,1), name='attention_vec')(den1)\n",
    "    mul1 = Multiply()([visible1, per2])   \n",
    "    \n",
    "    ## Permuted Attention Block\n",
    "    per1 = Permute((2,1))(visible1)\n",
    "    den2a = Dense(num_features, activation='tanh')(visible1)\n",
    "    den2b = Dense(num_features, activation='sigmoid')(visible1)\n",
    "    den2 = Multiply()([den2a, den2b])\n",
    "    perb2 = Permute((2,1), name='attention_vec2')(den2)\n",
    "    \n",
    "    mul2 = Multiply()([per1, perb2])     \n",
    "    \n",
    "    ## Parallel DCCNN Blocks 1-1 ~ 3-1\n",
    "    d1 = Conv1D(filters=round(hfilters*alpha), kernel_size=round(hkernel_size1*beta), padding='causal', dilation_rate=1)(mul1)\n",
    "    d1a = Activation(activations.tanh)(d1)\n",
    "    d1b = Activation(activations.sigmoid)(d1)\n",
    "    d1 = Multiply()([d1a, d1b])\n",
    "    \n",
    "    d1 = Conv1D(filters=num_features, kernel_size=round(hkernel_size2*beta), padding='causal', dilation_rate=2)(d1)\n",
    "    d1a = Activation(activations.tanh)(d1)\n",
    "    d1b = Activation(activations.sigmoid)(d1)\n",
    "    d1 = Multiply()([d1a, d1b])\n",
    "    \n",
    "    rres01a = Add()([mul1, d1])   # (100, 25) (100, 25)\n",
    "    rres01b = Subtract()([mul1, d1])\n",
    "    \n",
    "    d1 = Conv1D(filters=round(hfilters*alpha), kernel_size=round(hkernel_size1*beta), padding='causal', dilation_rate=2)(rres01a)\n",
    "    d1a = Activation(activations.tanh)(d1)\n",
    "    d1b = Activation(activations.sigmoid)(d1)\n",
    "    d1 = Multiply()([d1a, d1b])\n",
    "    \n",
    "    d1 = Conv1D(filters=num_features, kernel_size=round(hkernel_size2*beta), padding='causal', dilation_rate=4)(d1)    \n",
    "    d1a = Activation(activations.tanh)(d1)\n",
    "    d1b = Activation(activations.sigmoid)(d1)\n",
    "    \n",
    "    d1 = Multiply()([d1a, d1b])\n",
    "    rres02a = Add()([rres01a, d1])   # (100, 25) (100, 25)\n",
    "    \n",
    "    d2 = Conv1D(filters=round(hfilters*alpha), kernel_size=round(hkernel_size1*beta), padding='causal', dilation_rate=2)(rres01b) \n",
    "    d2a = Activation(activations.tanh)(d2)\n",
    "    d2b = Activation(activations.sigmoid)(d2)\n",
    "    d2 = Multiply()([d2a, d2b])\n",
    "    \n",
    "    d2 = Conv1D(filters=num_features, kernel_size=round(hkernel_size2*beta), padding='causal', dilation_rate=4)(d2) \n",
    "    d2a = Activation(activations.tanh)(d2)\n",
    "    d2b = Activation(activations.sigmoid)(d2)\n",
    "    d2 = Multiply()([d2a, d2b])\n",
    "    \n",
    "    rres02b = Subtract()([rres01b, d2])   # (100, 25) (100, 25) \n",
    "    rres02 = Concatenate()([rres02a, rres02b, rres01a, rres01b])\n",
    "    #rres02 = Dropout(0.2)(rres02)\n",
    "    \n",
    "    d1 = Conv1D(filters=round(hfilters*alpha), kernel_size=round(hkernel_size1*beta), padding='causal', dilation_rate=4)(rres02)\n",
    "    d1a = Activation(activations.tanh)(d1)\n",
    "    d1b = Activation(activations.sigmoid)(d1)\n",
    "    d1 = Multiply()([d1a, d1b])\n",
    "    \n",
    "    d1 = Conv1D(filters=num_features, kernel_size=round(hkernel_size2*beta), padding='causal', dilation_rate=2)(d1)    \n",
    "    d1a = Activation(activations.tanh)(d1)\n",
    "    d1b = Activation(activations.sigmoid)(d1)\n",
    "    d1 = Multiply()([d1a, d1b])\n",
    "    \n",
    "    rres03a = Add()([rres02a, d1])   # (100, 25) (100, 25)\n",
    "    \n",
    "    d2 = Conv1D(filters=round(hfilters*alpha), kernel_size=round(hkernel_size1*beta), padding='causal', dilation_rate=4)(rres02) \n",
    "    d2a = Activation(activations.tanh)(d2)\n",
    "    d2b = Activation(activations.sigmoid)(d2)\n",
    "    d2 = Multiply()([d2a, d2b])\n",
    "    \n",
    "    d2 = Conv1D(filters=num_features, kernel_size=round(hkernel_size2*beta), padding='causal', dilation_rate=2)(d2) \n",
    "    d2a = Activation(activations.tanh)(d2)\n",
    "    d2b = Activation(activations.sigmoid)(d2)\n",
    "    d2 = Multiply()([d2a, d2b])\n",
    "    rres03b = Subtract()([rres02b, d2])\n",
    "    rres03 = Concatenate()([rres03a, rres03b, rres02])\n",
    "    \n",
    "    d1 = Conv1D(filters=round(hfilters*alpha), kernel_size=round(hkernel_size1*beta), padding='causal', dilation_rate=4)(rres03)\n",
    "    d1a = Activation(activations.tanh)(d1)\n",
    "    d1b = Activation(activations.sigmoid)(d1)\n",
    "    d1 = Multiply()([d1a, d1b])\n",
    "    \n",
    "    d1 = Conv1D(filters=num_features, kernel_size=round(hkernel_size2*beta), padding='causal', dilation_rate=2)(d1)    \n",
    "    d1a = Activation(activations.tanh)(d1)\n",
    "    d1b = Activation(activations.sigmoid)(d1)\n",
    "    d1 = Multiply()([d1a, d1b])\n",
    "    \n",
    "    rres04a = Add()([rres03a, d1])   # (100, 25) (100, 25)\n",
    "    \n",
    "    d2 = Conv1D(filters=round(hfilters*alpha), kernel_size=round(hkernel_size1*beta), padding='causal', dilation_rate=4)(rres03) \n",
    "    d2a = Activation(activations.tanh)(d2)\n",
    "    d2b = Activation(activations.sigmoid)(d2)\n",
    "    d2 = Multiply()([d2a, d2b])\n",
    "    \n",
    "    d2 = Conv1D(filters=num_features, kernel_size=round(hkernel_size2*beta), padding='causal', dilation_rate=2)(d2) \n",
    "    d2a = Activation(activations.tanh)(d2)\n",
    "    d2b = Activation(activations.sigmoid)(d2)\n",
    "    d2 = Multiply()([d2a, d2b])\n",
    "    rres04b = Subtract()([rres03b, d2])\n",
    "    rres10 = Concatenate()([rres04a, rres04b, rres03])\n",
    "\n",
    "    ## Right-half DCCNN Blocks 1-2 ~ 3-2\n",
    "    d1 = Conv1D(filters=round(hfilters*alpha), kernel_size=round(hkernel_size1*beta), padding='causal', dilation_rate=1)(mul2)\n",
    "    d1a = Activation(activations.tanh)(d1)\n",
    "    d1b = Activation(activations.sigmoid)(d1)\n",
    "    d1 = Multiply()([d1a, d1b])\n",
    "    \n",
    "    d1 = Conv1D(filters=timesteps, kernel_size=round(hkernel_size2*beta), padding='causal', dilation_rate=2)(d1)\n",
    "    d1a = Activation(activations.tanh)(d1)\n",
    "    d1b = Activation(activations.sigmoid)(d1)\n",
    "    d1 = Multiply()([d1a, d1b])\n",
    "    \n",
    "    res01a = Add()([mul2, d1])   # (100, 25) (100, 25)\n",
    "    res01b = Subtract()([mul2, d1])\n",
    "    \n",
    "    \n",
    "    d1 = Conv1D(filters=round(hfilters*alpha), kernel_size=round(hkernel_size1*beta), padding='causal', dilation_rate=2)(res01a)\n",
    "    d1a = Activation(activations.tanh)(d1)\n",
    "    d1b = Activation(activations.sigmoid)(d1)\n",
    "    d1 = Multiply()([d1a, d1b])\n",
    "    \n",
    "    d1 = Conv1D(filters=timesteps, kernel_size=round(hkernel_size2*beta), padding='causal', dilation_rate=4)(d1)    \n",
    "    d1a = Activation(activations.tanh)(d1)\n",
    "    d1b = Activation(activations.sigmoid)(d1)\n",
    "    \n",
    "    d1 = Multiply()([d1a, d1b])\n",
    "    res02a = Add()([res01a, d1])   # (100, 25) (100, 25)\n",
    "    \n",
    "    d2 = Conv1D(filters=round(hfilters*alpha), kernel_size=round(hkernel_size1*beta), padding='causal', dilation_rate=2)(res01b) \n",
    "    d2a = Activation(activations.tanh)(d2)\n",
    "    d2b = Activation(activations.sigmoid)(d2)\n",
    "    d2 = Multiply()([d2a, d2b])\n",
    "    \n",
    "    d2 = Conv1D(filters=timesteps, kernel_size=round(hkernel_size2*beta), padding='causal', dilation_rate=4)(d2) \n",
    "    d2a = Activation(activations.tanh)(d2)\n",
    "    d2b = Activation(activations.sigmoid)(d2)\n",
    "    d2 = Multiply()([d2a, d2b])\n",
    "    \n",
    "    res02b = Subtract()([res01b, d2])   # (100, 25) (100, 25) \n",
    "    res02 = Concatenate()([res02a, res02b, res01a, res01b])\n",
    "    #res02 = Dropout(0.2)(res02)\n",
    "    \n",
    "    d1 = Conv1D(filters=round(hfilters*alpha), kernel_size=round(hkernel_size1*beta), padding='causal', dilation_rate=4)(res02)\n",
    "    d1a = Activation(activations.tanh)(d1)\n",
    "    d1b = Activation(activations.sigmoid)(d1)\n",
    "    d1 = Multiply()([d1a, d1b])\n",
    "    \n",
    "    d1 = Conv1D(filters=timesteps, kernel_size=round(hkernel_size2*beta), padding='causal', dilation_rate=2)(d1)    \n",
    "    d1a = Activation(activations.tanh)(d1)\n",
    "    d1b = Activation(activations.sigmoid)(d1)\n",
    "    d1 = Multiply()([d1a, d1b])\n",
    "    \n",
    "    res03a = Add()([res02a, d1])   # (100, 25) (100, 25)\n",
    "    \n",
    "    d2 = Conv1D(filters=round(hfilters*alpha), kernel_size=round(hkernel_size1*beta), padding='causal', dilation_rate=4)(res02) \n",
    "    d2a = Activation(activations.tanh)(d2)\n",
    "    d2b = Activation(activations.sigmoid)(d2)\n",
    "    d2 = Multiply()([d2a, d2b])\n",
    "    \n",
    "    d2 = Conv1D(filters=timesteps, kernel_size=round(hkernel_size2*beta), padding='causal', dilation_rate=2)(d2) \n",
    "    d2a = Activation(activations.tanh)(d2)\n",
    "    d2b = Activation(activations.sigmoid)(d2)\n",
    "    d2 = Multiply()([d2a, d2b])\n",
    "    \n",
    "    res03b = Subtract()([res02b, d2])\n",
    "    res03 = Concatenate()([res03a, res03b, res02])\n",
    "    \n",
    "    d1 = Conv1D(filters=round(hfilters*alpha), kernel_size=round(hkernel_size1*beta), padding='causal', dilation_rate=4)(res03)\n",
    "    d1a = Activation(activations.tanh)(d1)\n",
    "    d1b = Activation(activations.sigmoid)(d1)\n",
    "    d1 = Multiply()([d1a, d1b])\n",
    "    \n",
    "    d1 = Conv1D(filters=timesteps, kernel_size=round(hkernel_size2*beta), padding='causal', dilation_rate=2)(d1)    \n",
    "    d1a = Activation(activations.tanh)(d1)\n",
    "    d1b = Activation(activations.sigmoid)(d1)\n",
    "    d1 = Multiply()([d1a, d1b])\n",
    "    \n",
    "    res04a = Add()([res03a, d1])   # (100, 25) (100, 25)\n",
    "    \n",
    "    d2 = Conv1D(filters=round(hfilters*alpha), kernel_size=round(hkernel_size1*beta), padding='causal', dilation_rate=4)(res03) \n",
    "    d2a = Activation(activations.tanh)(d2)\n",
    "    d2b = Activation(activations.sigmoid)(d2)\n",
    "    d2 = Multiply()([d2a, d2b])\n",
    "    \n",
    "    d2 = Conv1D(filters=timesteps, kernel_size=round(hkernel_size2*beta), padding='causal', dilation_rate=2)(d2) \n",
    "    d2a = Activation(activations.tanh)(d2)\n",
    "    d2b = Activation(activations.sigmoid)(d2)\n",
    "    d2 = Multiply()([d2a, d2b])\n",
    "    \n",
    "    res04b = Subtract()([res03b, d2])\n",
    "    res10 = Concatenate()([res04a, res04b, res03])\n",
    "    print(rres10.shape)\n",
    "    \n",
    "    ## Output Blocks\n",
    "    out1 = Conv1D(24*7, 1, padding='same', activation=PReLU())(res10)   # 256, 11X10=110\n",
    "    out1 = Dropout(0.2)(out1)  \n",
    "    \n",
    "    out2 = Conv1D(24*7, 1, padding='same', activation=PReLU())(rres10)   # 256, 11X10=110\n",
    "    out2 = Dropout(0.2)(out2)\n",
    "    \n",
    "    out = Concatenate(axis=1)([out1, out2])\n",
    "    \n",
    "    ## Output Block\n",
    "    out = Conv1D(24*7, 1, padding='same', activation=PReLU())(out) # 512,  110X5=550\n",
    "    out = Dropout(0.2)(out)\n",
    "\n",
    "    #, kernel_regularizer=regularizers.L1L2(l1=1e-5, l2=1e-4)\n",
    "    out = GlobalAveragePooling1D()(out) \n",
    "\n",
    "    out = Dense(output_timesteps)(out) \n",
    "    model = Model(inputs=[visible1], outputs=[out])\n",
    "    \n",
    "    print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "497e3597",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "269558"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "59898a52",
   "metadata": {},
   "outputs": [],
   "source": [
    "    model.compile(loss=MAEMD, optimizer='adam', metrics=['mse','mae', MAEMD])\n",
    "    early_stopping =EarlyStopping(monitor='val_loss', patience=10)\n",
    "    batch_size = 168\n",
    "    epochs = 1000\n",
    "    #root_squared_mean_error\n",
    "    history = LossHistory()\n",
    "    history.init()\n",
    "    \n",
    "    #hist = model.fit(trX, trY, epochs=epochs, batch_size=batch_size, shuffle=False, validation_data=(vaX, vaY), callbacks=[history, early_stopping])  # , checkpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "434eb005",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "131/131 [==============================] - 52s 338ms/step - loss: 0.2134 - mse: 0.0277 - mae: 0.1178 - MAEMD: 0.2134 - val_loss: 0.1963 - val_mse: 0.0119 - val_mae: 0.0832 - val_MAEMD: 0.1944\n",
      "Epoch 2/1000\n",
      "131/131 [==============================] - 37s 287ms/step - loss: 0.1772 - mse: 0.0149 - mae: 0.0954 - MAEMD: 0.1772 - val_loss: 0.1454 - val_mse: 0.0164 - val_mae: 0.1021 - val_MAEMD: 0.1442\n",
      "Epoch 3/1000\n",
      "131/131 [==============================] - 37s 285ms/step - loss: 0.1376 - mse: 0.0182 - mae: 0.1085 - MAEMD: 0.1376 - val_loss: 0.1355 - val_mse: 0.0170 - val_mae: 0.1052 - val_MAEMD: 0.1344\n",
      "Epoch 4/1000\n",
      "131/131 [==============================] - 36s 276ms/step - loss: 0.1331 - mse: 0.0183 - mae: 0.1089 - MAEMD: 0.1331 - val_loss: 0.1341 - val_mse: 0.0178 - val_mae: 0.1082 - val_MAEMD: 0.1330\n",
      "Epoch 5/1000\n",
      "131/131 [==============================] - 38s 287ms/step - loss: 0.1307 - mse: 0.0182 - mae: 0.1087 - MAEMD: 0.1307 - val_loss: 0.1316 - val_mse: 0.0177 - val_mae: 0.1077 - val_MAEMD: 0.1305\n",
      "Epoch 6/1000\n",
      "131/131 [==============================] - 36s 277ms/step - loss: 0.1288 - mse: 0.0180 - mae: 0.1080 - MAEMD: 0.1289 - val_loss: 0.1297 - val_mse: 0.0180 - val_mae: 0.1088 - val_MAEMD: 0.1287\n",
      "Epoch 7/1000\n",
      "131/131 [==============================] - 37s 287ms/step - loss: 0.1276 - mse: 0.0179 - mae: 0.1076 - MAEMD: 0.1276 - val_loss: 0.1284 - val_mse: 0.0175 - val_mae: 0.1066 - val_MAEMD: 0.1274\n",
      "Epoch 8/1000\n",
      "131/131 [==============================] - 37s 285ms/step - loss: 0.1265 - mse: 0.0177 - mae: 0.1068 - MAEMD: 0.1266 - val_loss: 0.1279 - val_mse: 0.0173 - val_mae: 0.1060 - val_MAEMD: 0.1269\n",
      "Epoch 9/1000\n",
      "131/131 [==============================] - 36s 270ms/step - loss: 0.1256 - mse: 0.0176 - mae: 0.1065 - MAEMD: 0.1256 - val_loss: 0.1271 - val_mse: 0.0173 - val_mae: 0.1053 - val_MAEMD: 0.1261\n",
      "Epoch 10/1000\n",
      "131/131 [==============================] - 36s 277ms/step - loss: 0.1244 - mse: 0.0174 - mae: 0.1057 - MAEMD: 0.1244 - val_loss: 0.1260 - val_mse: 0.0168 - val_mae: 0.1041 - val_MAEMD: 0.1250\n",
      "Epoch 11/1000\n",
      "131/131 [==============================] - 37s 283ms/step - loss: 0.1233 - mse: 0.0173 - mae: 0.1051 - MAEMD: 0.1233 - val_loss: 0.1259 - val_mse: 0.0170 - val_mae: 0.1044 - val_MAEMD: 0.1249\n",
      "Epoch 12/1000\n",
      "131/131 [==============================] - 37s 279ms/step - loss: 0.1221 - mse: 0.0171 - mae: 0.1043 - MAEMD: 0.1221 - val_loss: 0.1257 - val_mse: 0.0170 - val_mae: 0.1041 - val_MAEMD: 0.1247\n",
      "Epoch 13/1000\n",
      "131/131 [==============================] - 36s 278ms/step - loss: 0.1205 - mse: 0.0167 - mae: 0.1031 - MAEMD: 0.1205 - val_loss: 0.1256 - val_mse: 0.0165 - val_mae: 0.1021 - val_MAEMD: 0.1246\n",
      "Epoch 14/1000\n",
      "131/131 [==============================] - 36s 279ms/step - loss: 0.1186 - mse: 0.0163 - mae: 0.1014 - MAEMD: 0.1186 - val_loss: 0.1252 - val_mse: 0.0158 - val_mae: 0.1000 - val_MAEMD: 0.1242\n",
      "Epoch 15/1000\n",
      "131/131 [==============================] - 36s 275ms/step - loss: 0.1164 - mse: 0.0158 - mae: 0.0998 - MAEMD: 0.1164 - val_loss: 0.1247 - val_mse: 0.0159 - val_mae: 0.1001 - val_MAEMD: 0.1236\n",
      "Epoch 16/1000\n",
      "131/131 [==============================] - 35s 270ms/step - loss: 0.1147 - mse: 0.0155 - mae: 0.0985 - MAEMD: 0.1146 - val_loss: 0.1246 - val_mse: 0.0159 - val_mae: 0.1000 - val_MAEMD: 0.1236\n",
      "Epoch 17/1000\n",
      "131/131 [==============================] - 37s 287ms/step - loss: 0.1129 - mse: 0.0152 - mae: 0.0976 - MAEMD: 0.1129 - val_loss: 0.1274 - val_mse: 0.0161 - val_mae: 0.1008 - val_MAEMD: 0.1261\n",
      "Epoch 18/1000\n",
      "131/131 [==============================] - 34s 262ms/step - loss: 0.1112 - mse: 0.0150 - mae: 0.0969 - MAEMD: 0.1112 - val_loss: 0.1254 - val_mse: 0.0156 - val_mae: 0.0988 - val_MAEMD: 0.1243\n",
      "Epoch 19/1000\n",
      "131/131 [==============================] - 37s 279ms/step - loss: 0.1099 - mse: 0.0149 - mae: 0.0966 - MAEMD: 0.1099 - val_loss: 0.1262 - val_mse: 0.0159 - val_mae: 0.0995 - val_MAEMD: 0.1251\n",
      "Epoch 20/1000\n",
      "131/131 [==============================] - 37s 282ms/step - loss: 0.1091 - mse: 0.0148 - mae: 0.0961 - MAEMD: 0.1090 - val_loss: 0.1262 - val_mse: 0.0153 - val_mae: 0.0978 - val_MAEMD: 0.1250\n",
      "Epoch 21/1000\n",
      "131/131 [==============================] - 39s 295ms/step - loss: 0.1076 - mse: 0.0147 - mae: 0.0957 - MAEMD: 0.1075 - val_loss: 0.1253 - val_mse: 0.0156 - val_mae: 0.0986 - val_MAEMD: 0.1241\n",
      "Epoch 22/1000\n",
      "131/131 [==============================] - 36s 279ms/step - loss: 0.1064 - mse: 0.0145 - mae: 0.0951 - MAEMD: 0.1064 - val_loss: 0.1261 - val_mse: 0.0159 - val_mae: 0.0999 - val_MAEMD: 0.1250\n",
      "Epoch 23/1000\n",
      "131/131 [==============================] - 37s 283ms/step - loss: 0.1049 - mse: 0.0145 - mae: 0.0948 - MAEMD: 0.1049 - val_loss: 0.1275 - val_mse: 0.0158 - val_mae: 0.0995 - val_MAEMD: 0.1263\n",
      "Epoch 24/1000\n",
      "131/131 [==============================] - 38s 290ms/step - loss: 0.1039 - mse: 0.0143 - mae: 0.0943 - MAEMD: 0.1039 - val_loss: 0.1279 - val_mse: 0.0160 - val_mae: 0.1000 - val_MAEMD: 0.1266\n",
      "Epoch 25/1000\n",
      " 10/131 [=>............................] - ETA: 27s - loss: 0.1029 - mse: 0.0141 - mae: 0.0937 - MAEMD: 0.1029"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<timed exec>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\navy\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1187\u001b[0m               \u001b[0mlogs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtmp_logs\u001b[0m  \u001b[1;31m# No error, now safe to assign to logs.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1188\u001b[0m               \u001b[0mend_step\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mstep\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstep_increment\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1189\u001b[1;33m               \u001b[0mcallbacks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mon_train_batch_end\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mend_step\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1190\u001b[0m               \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstop_training\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1191\u001b[0m                 \u001b[1;32mbreak\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\navy\\lib\\site-packages\\keras\\callbacks.py\u001b[0m in \u001b[0;36mon_train_batch_end\u001b[1;34m(self, batch, logs)\u001b[0m\n\u001b[0;32m    433\u001b[0m     \"\"\"\n\u001b[0;32m    434\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_should_call_train_batch_hooks\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 435\u001b[1;33m       \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call_batch_hook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mModeKeys\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTRAIN\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'end'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mlogs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    436\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    437\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0mon_test_batch_begin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\navy\\lib\\site-packages\\keras\\callbacks.py\u001b[0m in \u001b[0;36m_call_batch_hook\u001b[1;34m(self, mode, hook, batch, logs)\u001b[0m\n\u001b[0;32m    293\u001b[0m       \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call_batch_begin_hook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmode\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    294\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0mhook\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'end'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 295\u001b[1;33m       \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call_batch_end_hook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmode\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    296\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    297\u001b[0m       \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Unrecognized hook: {}'\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhook\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\navy\\lib\\site-packages\\keras\\callbacks.py\u001b[0m in \u001b[0;36m_call_batch_end_hook\u001b[1;34m(self, mode, batch, logs)\u001b[0m\n\u001b[0;32m    313\u001b[0m       \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_batch_times\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch_time\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    314\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 315\u001b[1;33m     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call_batch_hook_helper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhook_name\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    316\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    317\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_batch_times\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m>=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_num_batches_for_timing_check\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\navy\\lib\\site-packages\\keras\\callbacks.py\u001b[0m in \u001b[0;36m_call_batch_hook_helper\u001b[1;34m(self, hook_name, batch, logs)\u001b[0m\n\u001b[0;32m    351\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mcallback\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    352\u001b[0m       \u001b[0mhook\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcallback\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhook_name\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 353\u001b[1;33m       \u001b[0mhook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    354\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    355\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_check_timing\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\navy\\lib\\site-packages\\keras\\callbacks.py\u001b[0m in \u001b[0;36mon_train_batch_end\u001b[1;34m(self, batch, logs)\u001b[0m\n\u001b[0;32m   1026\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1027\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0mon_train_batch_end\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1028\u001b[1;33m     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_batch_update_progbar\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1029\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1030\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0mon_test_batch_end\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\navy\\lib\\site-packages\\keras\\callbacks.py\u001b[0m in \u001b[0;36m_batch_update_progbar\u001b[1;34m(self, batch, logs)\u001b[0m\n\u001b[0;32m   1098\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mverbose\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1099\u001b[0m       \u001b[1;31m# Only block async when verbose = 1.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1100\u001b[1;33m       \u001b[0mlogs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_utils\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msync_to_numpy_or_python_type\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlogs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1101\u001b[0m       \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mprogbar\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mseen\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlogs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfinalize\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1102\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\navy\\lib\\site-packages\\keras\\utils\\tf_utils.py\u001b[0m in \u001b[0;36msync_to_numpy_or_python_type\u001b[1;34m(tensors)\u001b[0m\n\u001b[0;32m    514\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mt\u001b[0m  \u001b[1;31m# Don't turn ragged or sparse tensors to NumPy.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    515\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 516\u001b[1;33m   \u001b[1;32mreturn\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnest\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmap_structure\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_to_single_numpy_or_python_type\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtensors\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    517\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    518\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\navy\\lib\\site-packages\\tensorflow\\python\\util\\nest.py\u001b[0m in \u001b[0;36mmap_structure\u001b[1;34m(func, *structure, **kwargs)\u001b[0m\n\u001b[0;32m    867\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    868\u001b[0m   return pack_sequence_as(\n\u001b[1;32m--> 869\u001b[1;33m       \u001b[0mstructure\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mentries\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    870\u001b[0m       expand_composites=expand_composites)\n\u001b[0;32m    871\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\navy\\lib\\site-packages\\tensorflow\\python\\util\\nest.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    867\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    868\u001b[0m   return pack_sequence_as(\n\u001b[1;32m--> 869\u001b[1;33m       \u001b[0mstructure\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mentries\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    870\u001b[0m       expand_composites=expand_composites)\n\u001b[0;32m    871\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\navy\\lib\\site-packages\\keras\\utils\\tf_utils.py\u001b[0m in \u001b[0;36m_to_single_numpy_or_python_type\u001b[1;34m(t)\u001b[0m\n\u001b[0;32m    510\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_to_single_numpy_or_python_type\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mt\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    511\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mt\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 512\u001b[1;33m       \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    513\u001b[0m       \u001b[1;32mreturn\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mndim\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m0\u001b[0m \u001b[1;32melse\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    514\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mt\u001b[0m  \u001b[1;31m# Don't turn ragged or sparse tensors to NumPy.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\navy\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\u001b[0m in \u001b[0;36mnumpy\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1092\u001b[0m     \"\"\"\n\u001b[0;32m   1093\u001b[0m     \u001b[1;31m# TODO(slebedev): Consider avoiding a copy for non-CPU or remote tensors.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1094\u001b[1;33m     \u001b[0mmaybe_arr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_numpy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1095\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mmaybe_arr\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmaybe_arr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32melse\u001b[0m \u001b[0mmaybe_arr\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1096\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\navy\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\u001b[0m in \u001b[0;36m_numpy\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1058\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_numpy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1059\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1060\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_numpy_internal\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1061\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1062\u001b[0m       \u001b[0msix\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mraise_from\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_status_to_exception\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcode\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "    %%time\n",
    "    b_size = 168\n",
    "    #hist = model.fit(strvaX, strvaY, epochs=epochs, batch_size=b_size, shuffle=False, validation_data=(teX, teY), callbacks=[history, early_stopping])  # , checkpoint\n",
    "    hist = model.fit(strX, strY, epochs=epochs, batch_size=b_size, shuffle=False, validation_data=(svaX, svaY), callbacks=[history, early_stopping])  # , checkpoint"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53c5af2b",
   "metadata": {},
   "source": [
    "### Saving Basic Model Training Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "2ae08389",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('Basic Ramp Model Final_lead.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "0c2dbccf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "234423"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "d35572cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_history = hist.history['loss']\n",
    "valloss_history = hist.history['val_loss']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "794320f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.device('/gpu:0'):\n",
    "    model = keras.models.load_model('Basic Ramp Model Final_lead.h5', custom_objects={'MAEMD': MAEMD})\n",
    "    gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "2b2a761c",
   "metadata": {},
   "outputs": [],
   "source": [
    "layer_name = 'attention_vec'\n",
    "intermediate_layer_model = Model(inputs=model.input,\n",
    "                                 outputs=model.get_layer(layer_name).output)\n",
    "intermediate_output = intermediate_layer_model.predict(strvaX)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "d5ad0504",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(168, 37)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "avg_int_output = np.mean(intermediate_output, axis=0)\n",
    "avg_int_output.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "78943d95",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x432 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.set_theme(style=\"white\")\n",
    "f, ax = plt.subplots(figsize=(12, 6))\n",
    "\n",
    "# Generate a custom diverging colormap\n",
    "cmap = sns.diverging_palette(230, 20, as_cmap=True)\n",
    "\n",
    "# Draw the heatmap with the mask and correct aspect ratio\n",
    "sns.heatmap(np.transpose(abs(avg_int_output)), cmap=\"rocket\")\n",
    "lx = ax.set_xticklabels([])\n",
    "ly = ax.set_yticklabels([])\n",
    "cax = ax.figure.axes[-1]\n",
    "cax.tick_params(labelsize=14)\n",
    "\n",
    "f.savefig('ramp_attention_output.png', dpi=1000, bbox_inches=\"tight\")\n",
    "#f.savefig('ramp_attention_output.eps', dpi=1000, bbox_inches=\"tight\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "82148fad",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.cla()   # clear the current axes\n",
    "plt.clf()   # clear the current figure\n",
    "plt.close() #"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "76d7d03a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(37, 168)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "layer_name = 'attention_vec2'\n",
    "intermediate_layer_model = Model(inputs=model.input,\n",
    "                                 outputs=model.get_layer(layer_name).output)\n",
    "intermediate_output = intermediate_layer_model.predict(strvaX)\n",
    "avg_int_output = np.mean(intermediate_output, axis=0)\n",
    "avg_int_output.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "2649f14d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x432 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.set_theme(style=\"white\")\n",
    "f, ax = plt.subplots(figsize=(12, 6))\n",
    "\n",
    "# Generate a custom diverging colormap\n",
    "cmap = sns.diverging_palette(230, 20, as_cmap=True)\n",
    "\n",
    "# Draw the heatmap with the mask and correct aspect ratio\n",
    "#sns.heatmap(np.transpose(abs(avg_int_output)), cmap=\"rocket\")\n",
    "sns.heatmap((abs(avg_int_output)), cmap=\"rocket\")\n",
    "lx = ax.set_xticklabels([])\n",
    "ly = ax.set_yticklabels([])\n",
    "cax = ax.figure.axes[-1]\n",
    "cax.tick_params(labelsize=14)\n",
    "\n",
    "f.savefig('ramp_attention_output2.png', dpi=1000, bbox_inches=\"tight\")\n",
    "#f.savefig('ramp_attention_output.eps', dpi=1000, bbox_inches=\"tight\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "abc66fc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.cla()   # clear the current axes\n",
    "plt.clf()   # clear the current figure\n",
    "plt.close() #"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0396b0c",
   "metadata": {},
   "source": [
    "## Basic Model Test Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9b97fcd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 168\n",
    "\n",
    "testPredict = model.predict(teX, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "68909a9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def npMAEMS(y_true, y_pred):\n",
    "    return np.mean((abs(y_pred - y_true))*np.square(y_true))*100\n",
    "def npMAEMD(y_true, y_pred):\n",
    "    return np.mean((abs(y_pred - y_true))*np.square(y_true-np.mean(y_true)))*100\n",
    "def npMSE(y_true, y_pred):\n",
    "    return np.mean(np.square(-y_true+y_pred))\n",
    "def npMAE(y_true, y_pred):\n",
    "    return np.mean(abs(-y_true+y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "4ac9f71d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error Test Score > MSE ==  0.013735277815234795  MAE ==  0.09257788197673515  MAEMD ==  0.10327403141510459\n"
     ]
    }
   ],
   "source": [
    "tePredict = testPredict.reshape(-1)\n",
    "testY = teY.reshape(-1)\n",
    "print('Error Test Score > MSE == ', npMSE(testY, tePredict), ' MAE == ', npMAE(testY, tePredict), ' MAEMD == ', npMAEMD(testY, tePredict))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c0a1f32",
   "metadata": {},
   "source": [
    "## Wind Ramp Rate FFEL Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "51d34f34",
   "metadata": {},
   "outputs": [],
   "source": [
    "trX, vaX, trY, vaY = train_test_split(trvaX, trvaY, test_size=1/6, shuffle=False)\n",
    "trY = trY.reshape(-1,output_timesteps)\n",
    "vaY = vaY.reshape(-1,output_timesteps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "323ce4fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainPredict = model.predict(trX, batch_size=batch_size)\n",
    "validPredict = model.predict(vaX, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "ec423354",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(31377, 24)\n",
      "(31377, 24)\n"
     ]
    }
   ],
   "source": [
    "e_tr = trainPredict - trY\n",
    "e_va = validPredict - vaY\n",
    "errors = np.vstack([e_tr, e_va])\n",
    "prediction = np.vstack([trainPredict, validPredict])\n",
    "print(errors.shape)\n",
    "print(prediction.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "1685d008",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Normalized Ramp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.620197</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.544580</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.570751</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.599594</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.495246</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Normalized Ramp\n",
       "0         0.620197\n",
       "1         0.544580\n",
       "2         0.570751\n",
       "3         0.599594\n",
       "4         0.495246"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "norm_df2 = pd.DataFrame(norm_df).iloc[:prediction.shape[0], :]\n",
    "norm_df2.columns = ['Normalized Ramp']\n",
    "norm_df2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "8d782a17",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Prediction1</th>\n",
       "      <th>Prediction2</th>\n",
       "      <th>Prediction3</th>\n",
       "      <th>Prediction4</th>\n",
       "      <th>Prediction5</th>\n",
       "      <th>Prediction6</th>\n",
       "      <th>Prediction7</th>\n",
       "      <th>Prediction8</th>\n",
       "      <th>Prediction9</th>\n",
       "      <th>Prediction10</th>\n",
       "      <th>...</th>\n",
       "      <th>Prediction15</th>\n",
       "      <th>Prediction16</th>\n",
       "      <th>Prediction17</th>\n",
       "      <th>Prediction18</th>\n",
       "      <th>Prediction19</th>\n",
       "      <th>Prediction20</th>\n",
       "      <th>Prediction21</th>\n",
       "      <th>Prediction22</th>\n",
       "      <th>Prediction23</th>\n",
       "      <th>Prediction24</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.444676</td>\n",
       "      <td>0.436860</td>\n",
       "      <td>0.302638</td>\n",
       "      <td>0.297785</td>\n",
       "      <td>0.421782</td>\n",
       "      <td>0.451090</td>\n",
       "      <td>0.508404</td>\n",
       "      <td>0.556098</td>\n",
       "      <td>0.610513</td>\n",
       "      <td>0.662830</td>\n",
       "      <td>...</td>\n",
       "      <td>0.684189</td>\n",
       "      <td>0.526042</td>\n",
       "      <td>0.527760</td>\n",
       "      <td>0.481013</td>\n",
       "      <td>0.430079</td>\n",
       "      <td>0.408124</td>\n",
       "      <td>0.432230</td>\n",
       "      <td>0.469366</td>\n",
       "      <td>0.433775</td>\n",
       "      <td>0.384112</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.393561</td>\n",
       "      <td>0.369372</td>\n",
       "      <td>0.341190</td>\n",
       "      <td>0.454414</td>\n",
       "      <td>0.465517</td>\n",
       "      <td>0.417204</td>\n",
       "      <td>0.480796</td>\n",
       "      <td>0.600435</td>\n",
       "      <td>0.554215</td>\n",
       "      <td>0.490364</td>\n",
       "      <td>...</td>\n",
       "      <td>0.581016</td>\n",
       "      <td>0.507182</td>\n",
       "      <td>0.464872</td>\n",
       "      <td>0.451960</td>\n",
       "      <td>0.443003</td>\n",
       "      <td>0.481689</td>\n",
       "      <td>0.423889</td>\n",
       "      <td>0.405364</td>\n",
       "      <td>0.397222</td>\n",
       "      <td>0.416176</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.281735</td>\n",
       "      <td>0.346389</td>\n",
       "      <td>0.429335</td>\n",
       "      <td>0.435216</td>\n",
       "      <td>0.366630</td>\n",
       "      <td>0.436345</td>\n",
       "      <td>0.543661</td>\n",
       "      <td>0.533085</td>\n",
       "      <td>0.459744</td>\n",
       "      <td>0.470875</td>\n",
       "      <td>...</td>\n",
       "      <td>0.567222</td>\n",
       "      <td>0.423415</td>\n",
       "      <td>0.388701</td>\n",
       "      <td>0.456166</td>\n",
       "      <td>0.445300</td>\n",
       "      <td>0.433350</td>\n",
       "      <td>0.371297</td>\n",
       "      <td>0.371676</td>\n",
       "      <td>0.375083</td>\n",
       "      <td>0.343617</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.273427</td>\n",
       "      <td>0.444346</td>\n",
       "      <td>0.433546</td>\n",
       "      <td>0.422055</td>\n",
       "      <td>0.460161</td>\n",
       "      <td>0.555514</td>\n",
       "      <td>0.524731</td>\n",
       "      <td>0.452719</td>\n",
       "      <td>0.558419</td>\n",
       "      <td>0.729217</td>\n",
       "      <td>...</td>\n",
       "      <td>0.508064</td>\n",
       "      <td>0.361275</td>\n",
       "      <td>0.333902</td>\n",
       "      <td>0.435677</td>\n",
       "      <td>0.491621</td>\n",
       "      <td>0.446159</td>\n",
       "      <td>0.403773</td>\n",
       "      <td>0.422831</td>\n",
       "      <td>0.386955</td>\n",
       "      <td>0.269077</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.319735</td>\n",
       "      <td>0.396001</td>\n",
       "      <td>0.406660</td>\n",
       "      <td>0.442480</td>\n",
       "      <td>0.450827</td>\n",
       "      <td>0.488388</td>\n",
       "      <td>0.501562</td>\n",
       "      <td>0.536546</td>\n",
       "      <td>0.686988</td>\n",
       "      <td>0.684791</td>\n",
       "      <td>...</td>\n",
       "      <td>0.371363</td>\n",
       "      <td>0.347615</td>\n",
       "      <td>0.369525</td>\n",
       "      <td>0.380759</td>\n",
       "      <td>0.330504</td>\n",
       "      <td>0.357211</td>\n",
       "      <td>0.368331</td>\n",
       "      <td>0.359699</td>\n",
       "      <td>0.245907</td>\n",
       "      <td>0.257066</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31372</th>\n",
       "      <td>0.179432</td>\n",
       "      <td>0.186400</td>\n",
       "      <td>0.283756</td>\n",
       "      <td>0.466718</td>\n",
       "      <td>0.550215</td>\n",
       "      <td>0.626457</td>\n",
       "      <td>0.742539</td>\n",
       "      <td>0.753185</td>\n",
       "      <td>0.771121</td>\n",
       "      <td>0.811836</td>\n",
       "      <td>...</td>\n",
       "      <td>0.426471</td>\n",
       "      <td>0.393733</td>\n",
       "      <td>0.363955</td>\n",
       "      <td>0.341164</td>\n",
       "      <td>0.313086</td>\n",
       "      <td>0.315988</td>\n",
       "      <td>0.188803</td>\n",
       "      <td>0.198456</td>\n",
       "      <td>0.349545</td>\n",
       "      <td>0.403387</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31373</th>\n",
       "      <td>0.248527</td>\n",
       "      <td>0.388267</td>\n",
       "      <td>0.484408</td>\n",
       "      <td>0.582086</td>\n",
       "      <td>0.607232</td>\n",
       "      <td>0.743621</td>\n",
       "      <td>0.720474</td>\n",
       "      <td>0.596254</td>\n",
       "      <td>0.684116</td>\n",
       "      <td>0.819395</td>\n",
       "      <td>...</td>\n",
       "      <td>0.399665</td>\n",
       "      <td>0.336597</td>\n",
       "      <td>0.368596</td>\n",
       "      <td>0.407575</td>\n",
       "      <td>0.346324</td>\n",
       "      <td>0.270225</td>\n",
       "      <td>0.236950</td>\n",
       "      <td>0.354727</td>\n",
       "      <td>0.326925</td>\n",
       "      <td>0.250012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31374</th>\n",
       "      <td>0.382436</td>\n",
       "      <td>0.548531</td>\n",
       "      <td>0.568935</td>\n",
       "      <td>0.627955</td>\n",
       "      <td>0.673686</td>\n",
       "      <td>0.744356</td>\n",
       "      <td>0.625724</td>\n",
       "      <td>0.633339</td>\n",
       "      <td>0.764129</td>\n",
       "      <td>0.785478</td>\n",
       "      <td>...</td>\n",
       "      <td>0.474984</td>\n",
       "      <td>0.375184</td>\n",
       "      <td>0.370839</td>\n",
       "      <td>0.316162</td>\n",
       "      <td>0.293981</td>\n",
       "      <td>0.240323</td>\n",
       "      <td>0.357223</td>\n",
       "      <td>0.376408</td>\n",
       "      <td>0.325814</td>\n",
       "      <td>0.253837</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31375</th>\n",
       "      <td>0.479252</td>\n",
       "      <td>0.603519</td>\n",
       "      <td>0.582363</td>\n",
       "      <td>0.605877</td>\n",
       "      <td>0.628811</td>\n",
       "      <td>0.653491</td>\n",
       "      <td>0.664704</td>\n",
       "      <td>0.711577</td>\n",
       "      <td>0.780092</td>\n",
       "      <td>0.687738</td>\n",
       "      <td>...</td>\n",
       "      <td>0.380617</td>\n",
       "      <td>0.402319</td>\n",
       "      <td>0.347452</td>\n",
       "      <td>0.265388</td>\n",
       "      <td>0.290139</td>\n",
       "      <td>0.437950</td>\n",
       "      <td>0.357874</td>\n",
       "      <td>0.310164</td>\n",
       "      <td>0.267198</td>\n",
       "      <td>0.362260</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31376</th>\n",
       "      <td>0.606521</td>\n",
       "      <td>0.616107</td>\n",
       "      <td>0.612900</td>\n",
       "      <td>0.604315</td>\n",
       "      <td>0.599260</td>\n",
       "      <td>0.619668</td>\n",
       "      <td>0.656708</td>\n",
       "      <td>0.701701</td>\n",
       "      <td>0.643148</td>\n",
       "      <td>0.561141</td>\n",
       "      <td>...</td>\n",
       "      <td>0.411087</td>\n",
       "      <td>0.452819</td>\n",
       "      <td>0.387088</td>\n",
       "      <td>0.347387</td>\n",
       "      <td>0.400589</td>\n",
       "      <td>0.380267</td>\n",
       "      <td>0.290362</td>\n",
       "      <td>0.303698</td>\n",
       "      <td>0.412212</td>\n",
       "      <td>0.490589</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>31377 rows × 24 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Prediction1  Prediction2  Prediction3  Prediction4  Prediction5  \\\n",
       "0         0.444676     0.436860     0.302638     0.297785     0.421782   \n",
       "1         0.393561     0.369372     0.341190     0.454414     0.465517   \n",
       "2         0.281735     0.346389     0.429335     0.435216     0.366630   \n",
       "3         0.273427     0.444346     0.433546     0.422055     0.460161   \n",
       "4         0.319735     0.396001     0.406660     0.442480     0.450827   \n",
       "...            ...          ...          ...          ...          ...   \n",
       "31372     0.179432     0.186400     0.283756     0.466718     0.550215   \n",
       "31373     0.248527     0.388267     0.484408     0.582086     0.607232   \n",
       "31374     0.382436     0.548531     0.568935     0.627955     0.673686   \n",
       "31375     0.479252     0.603519     0.582363     0.605877     0.628811   \n",
       "31376     0.606521     0.616107     0.612900     0.604315     0.599260   \n",
       "\n",
       "       Prediction6  Prediction7  Prediction8  Prediction9  Prediction10  ...  \\\n",
       "0         0.451090     0.508404     0.556098     0.610513      0.662830  ...   \n",
       "1         0.417204     0.480796     0.600435     0.554215      0.490364  ...   \n",
       "2         0.436345     0.543661     0.533085     0.459744      0.470875  ...   \n",
       "3         0.555514     0.524731     0.452719     0.558419      0.729217  ...   \n",
       "4         0.488388     0.501562     0.536546     0.686988      0.684791  ...   \n",
       "...            ...          ...          ...          ...           ...  ...   \n",
       "31372     0.626457     0.742539     0.753185     0.771121      0.811836  ...   \n",
       "31373     0.743621     0.720474     0.596254     0.684116      0.819395  ...   \n",
       "31374     0.744356     0.625724     0.633339     0.764129      0.785478  ...   \n",
       "31375     0.653491     0.664704     0.711577     0.780092      0.687738  ...   \n",
       "31376     0.619668     0.656708     0.701701     0.643148      0.561141  ...   \n",
       "\n",
       "       Prediction15  Prediction16  Prediction17  Prediction18  Prediction19  \\\n",
       "0          0.684189      0.526042      0.527760      0.481013      0.430079   \n",
       "1          0.581016      0.507182      0.464872      0.451960      0.443003   \n",
       "2          0.567222      0.423415      0.388701      0.456166      0.445300   \n",
       "3          0.508064      0.361275      0.333902      0.435677      0.491621   \n",
       "4          0.371363      0.347615      0.369525      0.380759      0.330504   \n",
       "...             ...           ...           ...           ...           ...   \n",
       "31372      0.426471      0.393733      0.363955      0.341164      0.313086   \n",
       "31373      0.399665      0.336597      0.368596      0.407575      0.346324   \n",
       "31374      0.474984      0.375184      0.370839      0.316162      0.293981   \n",
       "31375      0.380617      0.402319      0.347452      0.265388      0.290139   \n",
       "31376      0.411087      0.452819      0.387088      0.347387      0.400589   \n",
       "\n",
       "       Prediction20  Prediction21  Prediction22  Prediction23  Prediction24  \n",
       "0          0.408124      0.432230      0.469366      0.433775      0.384112  \n",
       "1          0.481689      0.423889      0.405364      0.397222      0.416176  \n",
       "2          0.433350      0.371297      0.371676      0.375083      0.343617  \n",
       "3          0.446159      0.403773      0.422831      0.386955      0.269077  \n",
       "4          0.357211      0.368331      0.359699      0.245907      0.257066  \n",
       "...             ...           ...           ...           ...           ...  \n",
       "31372      0.315988      0.188803      0.198456      0.349545      0.403387  \n",
       "31373      0.270225      0.236950      0.354727      0.326925      0.250012  \n",
       "31374      0.240323      0.357223      0.376408      0.325814      0.253837  \n",
       "31375      0.437950      0.357874      0.310164      0.267198      0.362260  \n",
       "31376      0.380267      0.290362      0.303698      0.412212      0.490589  \n",
       "\n",
       "[31377 rows x 24 columns]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Prindex = ['Prediction1', 'Prediction2','Prediction3','Prediction4','Prediction5','Prediction6','Prediction7','Prediction8','Prediction9','Prediction10','Prediction11','Prediction12','Prediction13', 'Prediction14','Prediction15','Prediction16','Prediction17','Prediction18','Prediction19','Prediction20','Prediction21','Prediction22','Prediction23','Prediction24']\n",
    "Erindex = ['Error1', 'Error2','Error3','Error4','Error5','Error6','Error7','Error8','Error9','Error10','Error11','Error12','Error13', 'Error14','Error15','Error16','Error17','Error18','Error19','Error20','Error21','Error22','Error23','Error24']\n",
    "\n",
    "pr_df = pd.DataFrame(prediction, columns=Prindex)\n",
    "pr_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "dde30e73",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Error1</th>\n",
       "      <th>Error2</th>\n",
       "      <th>Error3</th>\n",
       "      <th>Error4</th>\n",
       "      <th>Error5</th>\n",
       "      <th>Error6</th>\n",
       "      <th>Error7</th>\n",
       "      <th>Error8</th>\n",
       "      <th>Error9</th>\n",
       "      <th>Error10</th>\n",
       "      <th>...</th>\n",
       "      <th>Error15</th>\n",
       "      <th>Error16</th>\n",
       "      <th>Error17</th>\n",
       "      <th>Error18</th>\n",
       "      <th>Error19</th>\n",
       "      <th>Error20</th>\n",
       "      <th>Error21</th>\n",
       "      <th>Error22</th>\n",
       "      <th>Error23</th>\n",
       "      <th>Error24</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.204030</td>\n",
       "      <td>-0.126875</td>\n",
       "      <td>-0.087480</td>\n",
       "      <td>-0.235325</td>\n",
       "      <td>-0.280824</td>\n",
       "      <td>-0.044936</td>\n",
       "      <td>-0.002878</td>\n",
       "      <td>0.027443</td>\n",
       "      <td>0.082637</td>\n",
       "      <td>0.115800</td>\n",
       "      <td>...</td>\n",
       "      <td>0.131257</td>\n",
       "      <td>-0.015420</td>\n",
       "      <td>0.080290</td>\n",
       "      <td>0.090539</td>\n",
       "      <td>-0.044515</td>\n",
       "      <td>-0.054864</td>\n",
       "      <td>-0.051649</td>\n",
       "      <td>-0.003791</td>\n",
       "      <td>-0.024128</td>\n",
       "      <td>-0.300063</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.170174</td>\n",
       "      <td>-0.020746</td>\n",
       "      <td>-0.191920</td>\n",
       "      <td>-0.248192</td>\n",
       "      <td>-0.030508</td>\n",
       "      <td>-0.094078</td>\n",
       "      <td>-0.047859</td>\n",
       "      <td>0.072560</td>\n",
       "      <td>0.007185</td>\n",
       "      <td>-0.031052</td>\n",
       "      <td>...</td>\n",
       "      <td>0.039554</td>\n",
       "      <td>0.059712</td>\n",
       "      <td>0.074398</td>\n",
       "      <td>-0.022634</td>\n",
       "      <td>-0.019984</td>\n",
       "      <td>-0.002190</td>\n",
       "      <td>-0.049268</td>\n",
       "      <td>-0.052539</td>\n",
       "      <td>-0.286953</td>\n",
       "      <td>0.001715</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.108383</td>\n",
       "      <td>-0.186720</td>\n",
       "      <td>-0.273272</td>\n",
       "      <td>-0.060809</td>\n",
       "      <td>-0.144652</td>\n",
       "      <td>-0.092310</td>\n",
       "      <td>0.015785</td>\n",
       "      <td>-0.013946</td>\n",
       "      <td>-0.061673</td>\n",
       "      <td>-0.070142</td>\n",
       "      <td>...</td>\n",
       "      <td>0.119752</td>\n",
       "      <td>0.032941</td>\n",
       "      <td>-0.085894</td>\n",
       "      <td>-0.006822</td>\n",
       "      <td>-0.038579</td>\n",
       "      <td>-0.039807</td>\n",
       "      <td>-0.086606</td>\n",
       "      <td>-0.312500</td>\n",
       "      <td>-0.039378</td>\n",
       "      <td>-0.060564</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.259683</td>\n",
       "      <td>-0.258260</td>\n",
       "      <td>-0.062479</td>\n",
       "      <td>-0.089227</td>\n",
       "      <td>-0.068494</td>\n",
       "      <td>0.027638</td>\n",
       "      <td>-0.022300</td>\n",
       "      <td>-0.068697</td>\n",
       "      <td>0.017402</td>\n",
       "      <td>0.151561</td>\n",
       "      <td>...</td>\n",
       "      <td>0.117590</td>\n",
       "      <td>-0.113319</td>\n",
       "      <td>-0.129085</td>\n",
       "      <td>-0.048202</td>\n",
       "      <td>0.018464</td>\n",
       "      <td>-0.011743</td>\n",
       "      <td>-0.280403</td>\n",
       "      <td>0.008370</td>\n",
       "      <td>-0.017226</td>\n",
       "      <td>-0.042915</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.382871</td>\n",
       "      <td>-0.100024</td>\n",
       "      <td>-0.104622</td>\n",
       "      <td>-0.086175</td>\n",
       "      <td>-0.077048</td>\n",
       "      <td>-0.058643</td>\n",
       "      <td>-0.019854</td>\n",
       "      <td>-0.004471</td>\n",
       "      <td>0.109333</td>\n",
       "      <td>0.162929</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.103231</td>\n",
       "      <td>-0.115373</td>\n",
       "      <td>-0.114354</td>\n",
       "      <td>-0.092398</td>\n",
       "      <td>-0.127399</td>\n",
       "      <td>-0.326964</td>\n",
       "      <td>-0.046130</td>\n",
       "      <td>-0.044482</td>\n",
       "      <td>-0.066084</td>\n",
       "      <td>-0.059237</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31372</th>\n",
       "      <td>-0.127168</td>\n",
       "      <td>-0.198049</td>\n",
       "      <td>-0.109804</td>\n",
       "      <td>-0.008127</td>\n",
       "      <td>0.022299</td>\n",
       "      <td>0.069368</td>\n",
       "      <td>0.114236</td>\n",
       "      <td>0.104901</td>\n",
       "      <td>0.112446</td>\n",
       "      <td>0.141812</td>\n",
       "      <td>...</td>\n",
       "      <td>0.133218</td>\n",
       "      <td>-0.041549</td>\n",
       "      <td>-0.343795</td>\n",
       "      <td>-0.245338</td>\n",
       "      <td>-0.131787</td>\n",
       "      <td>-0.185393</td>\n",
       "      <td>-0.361092</td>\n",
       "      <td>-0.238903</td>\n",
       "      <td>-0.137608</td>\n",
       "      <td>0.050349</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31373</th>\n",
       "      <td>-0.135921</td>\n",
       "      <td>-0.005294</td>\n",
       "      <td>0.009563</td>\n",
       "      <td>0.054170</td>\n",
       "      <td>0.050143</td>\n",
       "      <td>0.115318</td>\n",
       "      <td>0.072189</td>\n",
       "      <td>-0.062421</td>\n",
       "      <td>0.014091</td>\n",
       "      <td>0.136823</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.035617</td>\n",
       "      <td>-0.371152</td>\n",
       "      <td>-0.217905</td>\n",
       "      <td>-0.037298</td>\n",
       "      <td>-0.155057</td>\n",
       "      <td>-0.279670</td>\n",
       "      <td>-0.200410</td>\n",
       "      <td>-0.132426</td>\n",
       "      <td>-0.026113</td>\n",
       "      <td>-0.080007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31374</th>\n",
       "      <td>-0.011124</td>\n",
       "      <td>0.073686</td>\n",
       "      <td>0.041019</td>\n",
       "      <td>0.070866</td>\n",
       "      <td>0.045382</td>\n",
       "      <td>0.096072</td>\n",
       "      <td>-0.032951</td>\n",
       "      <td>-0.036685</td>\n",
       "      <td>0.081556</td>\n",
       "      <td>0.181232</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.232766</td>\n",
       "      <td>-0.211318</td>\n",
       "      <td>-0.074034</td>\n",
       "      <td>-0.185219</td>\n",
       "      <td>-0.255915</td>\n",
       "      <td>-0.197037</td>\n",
       "      <td>-0.129930</td>\n",
       "      <td>0.023370</td>\n",
       "      <td>-0.004205</td>\n",
       "      <td>-0.127974</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31375</th>\n",
       "      <td>0.004407</td>\n",
       "      <td>0.075603</td>\n",
       "      <td>0.025274</td>\n",
       "      <td>-0.022426</td>\n",
       "      <td>-0.019474</td>\n",
       "      <td>-0.005184</td>\n",
       "      <td>-0.005320</td>\n",
       "      <td>0.029005</td>\n",
       "      <td>0.175846</td>\n",
       "      <td>0.207538</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.205885</td>\n",
       "      <td>-0.042554</td>\n",
       "      <td>-0.153929</td>\n",
       "      <td>-0.284508</td>\n",
       "      <td>-0.147221</td>\n",
       "      <td>-0.049204</td>\n",
       "      <td>0.004837</td>\n",
       "      <td>-0.019855</td>\n",
       "      <td>-0.114613</td>\n",
       "      <td>-0.076378</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31376</th>\n",
       "      <td>0.078605</td>\n",
       "      <td>0.059018</td>\n",
       "      <td>-0.015403</td>\n",
       "      <td>-0.043970</td>\n",
       "      <td>-0.059415</td>\n",
       "      <td>-0.050356</td>\n",
       "      <td>-0.025865</td>\n",
       "      <td>0.097456</td>\n",
       "      <td>0.162948</td>\n",
       "      <td>0.220332</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.033786</td>\n",
       "      <td>-0.048562</td>\n",
       "      <td>-0.162808</td>\n",
       "      <td>-0.089972</td>\n",
       "      <td>-0.086565</td>\n",
       "      <td>0.027229</td>\n",
       "      <td>-0.039657</td>\n",
       "      <td>-0.078113</td>\n",
       "      <td>-0.026427</td>\n",
       "      <td>-0.052913</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>31377 rows × 24 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         Error1    Error2    Error3    Error4    Error5    Error6    Error7  \\\n",
       "0     -0.204030 -0.126875 -0.087480 -0.235325 -0.280824 -0.044936 -0.002878   \n",
       "1     -0.170174 -0.020746 -0.191920 -0.248192 -0.030508 -0.094078 -0.047859   \n",
       "2     -0.108383 -0.186720 -0.273272 -0.060809 -0.144652 -0.092310  0.015785   \n",
       "3     -0.259683 -0.258260 -0.062479 -0.089227 -0.068494  0.027638 -0.022300   \n",
       "4     -0.382871 -0.100024 -0.104622 -0.086175 -0.077048 -0.058643 -0.019854   \n",
       "...         ...       ...       ...       ...       ...       ...       ...   \n",
       "31372 -0.127168 -0.198049 -0.109804 -0.008127  0.022299  0.069368  0.114236   \n",
       "31373 -0.135921 -0.005294  0.009563  0.054170  0.050143  0.115318  0.072189   \n",
       "31374 -0.011124  0.073686  0.041019  0.070866  0.045382  0.096072 -0.032951   \n",
       "31375  0.004407  0.075603  0.025274 -0.022426 -0.019474 -0.005184 -0.005320   \n",
       "31376  0.078605  0.059018 -0.015403 -0.043970 -0.059415 -0.050356 -0.025865   \n",
       "\n",
       "         Error8    Error9   Error10  ...   Error15   Error16   Error17  \\\n",
       "0      0.027443  0.082637  0.115800  ...  0.131257 -0.015420  0.080290   \n",
       "1      0.072560  0.007185 -0.031052  ...  0.039554  0.059712  0.074398   \n",
       "2     -0.013946 -0.061673 -0.070142  ...  0.119752  0.032941 -0.085894   \n",
       "3     -0.068697  0.017402  0.151561  ...  0.117590 -0.113319 -0.129085   \n",
       "4     -0.004471  0.109333  0.162929  ... -0.103231 -0.115373 -0.114354   \n",
       "...         ...       ...       ...  ...       ...       ...       ...   \n",
       "31372  0.104901  0.112446  0.141812  ...  0.133218 -0.041549 -0.343795   \n",
       "31373 -0.062421  0.014091  0.136823  ... -0.035617 -0.371152 -0.217905   \n",
       "31374 -0.036685  0.081556  0.181232  ... -0.232766 -0.211318 -0.074034   \n",
       "31375  0.029005  0.175846  0.207538  ... -0.205885 -0.042554 -0.153929   \n",
       "31376  0.097456  0.162948  0.220332  ... -0.033786 -0.048562 -0.162808   \n",
       "\n",
       "        Error18   Error19   Error20   Error21   Error22   Error23   Error24  \n",
       "0      0.090539 -0.044515 -0.054864 -0.051649 -0.003791 -0.024128 -0.300063  \n",
       "1     -0.022634 -0.019984 -0.002190 -0.049268 -0.052539 -0.286953  0.001715  \n",
       "2     -0.006822 -0.038579 -0.039807 -0.086606 -0.312500 -0.039378 -0.060564  \n",
       "3     -0.048202  0.018464 -0.011743 -0.280403  0.008370 -0.017226 -0.042915  \n",
       "4     -0.092398 -0.127399 -0.326964 -0.046130 -0.044482 -0.066084 -0.059237  \n",
       "...         ...       ...       ...       ...       ...       ...       ...  \n",
       "31372 -0.245338 -0.131787 -0.185393 -0.361092 -0.238903 -0.137608  0.050349  \n",
       "31373 -0.037298 -0.155057 -0.279670 -0.200410 -0.132426 -0.026113 -0.080007  \n",
       "31374 -0.185219 -0.255915 -0.197037 -0.129930  0.023370 -0.004205 -0.127974  \n",
       "31375 -0.284508 -0.147221 -0.049204  0.004837 -0.019855 -0.114613 -0.076378  \n",
       "31376 -0.089972 -0.086565  0.027229 -0.039657 -0.078113 -0.026427 -0.052913  \n",
       "\n",
       "[31377 rows x 24 columns]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "er_df = pd.DataFrame(errors, columns=Erindex)\n",
    "er_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "2b2d55b4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Normalized Ramp</th>\n",
       "      <th>Prediction1</th>\n",
       "      <th>Prediction2</th>\n",
       "      <th>Prediction3</th>\n",
       "      <th>Prediction4</th>\n",
       "      <th>Prediction5</th>\n",
       "      <th>Prediction6</th>\n",
       "      <th>Prediction7</th>\n",
       "      <th>Prediction8</th>\n",
       "      <th>Prediction9</th>\n",
       "      <th>...</th>\n",
       "      <th>Error15</th>\n",
       "      <th>Error16</th>\n",
       "      <th>Error17</th>\n",
       "      <th>Error18</th>\n",
       "      <th>Error19</th>\n",
       "      <th>Error20</th>\n",
       "      <th>Error21</th>\n",
       "      <th>Error22</th>\n",
       "      <th>Error23</th>\n",
       "      <th>Error24</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.620197</td>\n",
       "      <td>0.444676</td>\n",
       "      <td>0.436860</td>\n",
       "      <td>0.302638</td>\n",
       "      <td>0.297785</td>\n",
       "      <td>0.421782</td>\n",
       "      <td>0.451090</td>\n",
       "      <td>0.508404</td>\n",
       "      <td>0.556098</td>\n",
       "      <td>0.610513</td>\n",
       "      <td>...</td>\n",
       "      <td>0.131257</td>\n",
       "      <td>-0.015420</td>\n",
       "      <td>0.080290</td>\n",
       "      <td>0.090539</td>\n",
       "      <td>-0.044515</td>\n",
       "      <td>-0.054864</td>\n",
       "      <td>-0.051649</td>\n",
       "      <td>-0.003791</td>\n",
       "      <td>-0.024128</td>\n",
       "      <td>-0.300063</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.544580</td>\n",
       "      <td>0.393561</td>\n",
       "      <td>0.369372</td>\n",
       "      <td>0.341190</td>\n",
       "      <td>0.454414</td>\n",
       "      <td>0.465517</td>\n",
       "      <td>0.417204</td>\n",
       "      <td>0.480796</td>\n",
       "      <td>0.600435</td>\n",
       "      <td>0.554215</td>\n",
       "      <td>...</td>\n",
       "      <td>0.039554</td>\n",
       "      <td>0.059712</td>\n",
       "      <td>0.074398</td>\n",
       "      <td>-0.022634</td>\n",
       "      <td>-0.019984</td>\n",
       "      <td>-0.002190</td>\n",
       "      <td>-0.049268</td>\n",
       "      <td>-0.052539</td>\n",
       "      <td>-0.286953</td>\n",
       "      <td>0.001715</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.570751</td>\n",
       "      <td>0.281735</td>\n",
       "      <td>0.346389</td>\n",
       "      <td>0.429335</td>\n",
       "      <td>0.435216</td>\n",
       "      <td>0.366630</td>\n",
       "      <td>0.436345</td>\n",
       "      <td>0.543661</td>\n",
       "      <td>0.533085</td>\n",
       "      <td>0.459744</td>\n",
       "      <td>...</td>\n",
       "      <td>0.119752</td>\n",
       "      <td>0.032941</td>\n",
       "      <td>-0.085894</td>\n",
       "      <td>-0.006822</td>\n",
       "      <td>-0.038579</td>\n",
       "      <td>-0.039807</td>\n",
       "      <td>-0.086606</td>\n",
       "      <td>-0.312500</td>\n",
       "      <td>-0.039378</td>\n",
       "      <td>-0.060564</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.599594</td>\n",
       "      <td>0.273427</td>\n",
       "      <td>0.444346</td>\n",
       "      <td>0.433546</td>\n",
       "      <td>0.422055</td>\n",
       "      <td>0.460161</td>\n",
       "      <td>0.555514</td>\n",
       "      <td>0.524731</td>\n",
       "      <td>0.452719</td>\n",
       "      <td>0.558419</td>\n",
       "      <td>...</td>\n",
       "      <td>0.117590</td>\n",
       "      <td>-0.113319</td>\n",
       "      <td>-0.129085</td>\n",
       "      <td>-0.048202</td>\n",
       "      <td>0.018464</td>\n",
       "      <td>-0.011743</td>\n",
       "      <td>-0.280403</td>\n",
       "      <td>0.008370</td>\n",
       "      <td>-0.017226</td>\n",
       "      <td>-0.042915</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.495246</td>\n",
       "      <td>0.319735</td>\n",
       "      <td>0.396001</td>\n",
       "      <td>0.406660</td>\n",
       "      <td>0.442480</td>\n",
       "      <td>0.450827</td>\n",
       "      <td>0.488388</td>\n",
       "      <td>0.501562</td>\n",
       "      <td>0.536546</td>\n",
       "      <td>0.686988</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.103231</td>\n",
       "      <td>-0.115373</td>\n",
       "      <td>-0.114354</td>\n",
       "      <td>-0.092398</td>\n",
       "      <td>-0.127399</td>\n",
       "      <td>-0.326964</td>\n",
       "      <td>-0.046130</td>\n",
       "      <td>-0.044482</td>\n",
       "      <td>-0.066084</td>\n",
       "      <td>-0.059237</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 49 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Normalized Ramp  Prediction1  Prediction2  Prediction3  Prediction4  \\\n",
       "0         0.620197     0.444676     0.436860     0.302638     0.297785   \n",
       "1         0.544580     0.393561     0.369372     0.341190     0.454414   \n",
       "2         0.570751     0.281735     0.346389     0.429335     0.435216   \n",
       "3         0.599594     0.273427     0.444346     0.433546     0.422055   \n",
       "4         0.495246     0.319735     0.396001     0.406660     0.442480   \n",
       "\n",
       "   Prediction5  Prediction6  Prediction7  Prediction8  Prediction9  ...  \\\n",
       "0     0.421782     0.451090     0.508404     0.556098     0.610513  ...   \n",
       "1     0.465517     0.417204     0.480796     0.600435     0.554215  ...   \n",
       "2     0.366630     0.436345     0.543661     0.533085     0.459744  ...   \n",
       "3     0.460161     0.555514     0.524731     0.452719     0.558419  ...   \n",
       "4     0.450827     0.488388     0.501562     0.536546     0.686988  ...   \n",
       "\n",
       "    Error15   Error16   Error17   Error18   Error19   Error20   Error21  \\\n",
       "0  0.131257 -0.015420  0.080290  0.090539 -0.044515 -0.054864 -0.051649   \n",
       "1  0.039554  0.059712  0.074398 -0.022634 -0.019984 -0.002190 -0.049268   \n",
       "2  0.119752  0.032941 -0.085894 -0.006822 -0.038579 -0.039807 -0.086606   \n",
       "3  0.117590 -0.113319 -0.129085 -0.048202  0.018464 -0.011743 -0.280403   \n",
       "4 -0.103231 -0.115373 -0.114354 -0.092398 -0.127399 -0.326964 -0.046130   \n",
       "\n",
       "    Error22   Error23   Error24  \n",
       "0 -0.003791 -0.024128 -0.300063  \n",
       "1 -0.052539 -0.286953  0.001715  \n",
       "2 -0.312500 -0.039378 -0.060564  \n",
       "3  0.008370 -0.017226 -0.042915  \n",
       "4 -0.044482 -0.066084 -0.059237  \n",
       "\n",
       "[5 rows x 49 columns]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "norm_df2 = pd.concat([norm_df2, pr_df, er_df],axis=1)\n",
    "norm_df2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "02c47415",
   "metadata": {},
   "outputs": [],
   "source": [
    "norm_df22 = pd.DataFrame(norm_df).iloc[prediction.shape[0]+timesteps:, :]\n",
    "norm_df22.columns = ['Normalized Wind']\n",
    "npnorm22 = np.array(norm_df22)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "8f89916e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>14</th>\n",
       "      <th>15</th>\n",
       "      <th>16</th>\n",
       "      <th>17</th>\n",
       "      <th>18</th>\n",
       "      <th>19</th>\n",
       "      <th>20</th>\n",
       "      <th>21</th>\n",
       "      <th>22</th>\n",
       "      <th>23</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.543832</td>\n",
       "      <td>0.654460</td>\n",
       "      <td>0.661829</td>\n",
       "      <td>0.563464</td>\n",
       "      <td>0.599267</td>\n",
       "      <td>0.699634</td>\n",
       "      <td>0.721294</td>\n",
       "      <td>0.555084</td>\n",
       "      <td>0.459930</td>\n",
       "      <td>0.413151</td>\n",
       "      <td>...</td>\n",
       "      <td>0.383349</td>\n",
       "      <td>0.378832</td>\n",
       "      <td>0.416335</td>\n",
       "      <td>0.502154</td>\n",
       "      <td>0.421978</td>\n",
       "      <td>0.295683</td>\n",
       "      <td>0.288353</td>\n",
       "      <td>0.526186</td>\n",
       "      <td>0.635084</td>\n",
       "      <td>0.611497</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.630573</td>\n",
       "      <td>0.672083</td>\n",
       "      <td>0.612464</td>\n",
       "      <td>0.601688</td>\n",
       "      <td>0.777240</td>\n",
       "      <td>0.809328</td>\n",
       "      <td>0.738840</td>\n",
       "      <td>0.605367</td>\n",
       "      <td>0.463053</td>\n",
       "      <td>0.389225</td>\n",
       "      <td>...</td>\n",
       "      <td>0.356993</td>\n",
       "      <td>0.294499</td>\n",
       "      <td>0.445579</td>\n",
       "      <td>0.447441</td>\n",
       "      <td>0.337021</td>\n",
       "      <td>0.303622</td>\n",
       "      <td>0.396032</td>\n",
       "      <td>0.643599</td>\n",
       "      <td>0.670800</td>\n",
       "      <td>0.686093</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.640508</td>\n",
       "      <td>0.585354</td>\n",
       "      <td>0.583009</td>\n",
       "      <td>0.666596</td>\n",
       "      <td>0.664024</td>\n",
       "      <td>0.573583</td>\n",
       "      <td>0.461036</td>\n",
       "      <td>0.441605</td>\n",
       "      <td>0.395695</td>\n",
       "      <td>0.328200</td>\n",
       "      <td>...</td>\n",
       "      <td>0.375800</td>\n",
       "      <td>0.405021</td>\n",
       "      <td>0.418488</td>\n",
       "      <td>0.361929</td>\n",
       "      <td>0.330251</td>\n",
       "      <td>0.482720</td>\n",
       "      <td>0.586071</td>\n",
       "      <td>0.635742</td>\n",
       "      <td>0.625080</td>\n",
       "      <td>0.678007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.591370</td>\n",
       "      <td>0.674265</td>\n",
       "      <td>0.745430</td>\n",
       "      <td>0.724724</td>\n",
       "      <td>0.604814</td>\n",
       "      <td>0.500152</td>\n",
       "      <td>0.434369</td>\n",
       "      <td>0.341298</td>\n",
       "      <td>0.316183</td>\n",
       "      <td>0.293644</td>\n",
       "      <td>...</td>\n",
       "      <td>0.404902</td>\n",
       "      <td>0.393448</td>\n",
       "      <td>0.282479</td>\n",
       "      <td>0.282697</td>\n",
       "      <td>0.390511</td>\n",
       "      <td>0.558223</td>\n",
       "      <td>0.624812</td>\n",
       "      <td>0.681554</td>\n",
       "      <td>0.686911</td>\n",
       "      <td>0.628185</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.595108</td>\n",
       "      <td>0.688872</td>\n",
       "      <td>0.715966</td>\n",
       "      <td>0.548925</td>\n",
       "      <td>0.410343</td>\n",
       "      <td>0.399815</td>\n",
       "      <td>0.391418</td>\n",
       "      <td>0.331532</td>\n",
       "      <td>0.318394</td>\n",
       "      <td>0.353330</td>\n",
       "      <td>...</td>\n",
       "      <td>0.529118</td>\n",
       "      <td>0.322337</td>\n",
       "      <td>0.281502</td>\n",
       "      <td>0.436176</td>\n",
       "      <td>0.605363</td>\n",
       "      <td>0.580775</td>\n",
       "      <td>0.560694</td>\n",
       "      <td>0.602099</td>\n",
       "      <td>0.660337</td>\n",
       "      <td>0.573784</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3482</th>\n",
       "      <td>0.414186</td>\n",
       "      <td>0.476000</td>\n",
       "      <td>0.489328</td>\n",
       "      <td>0.438869</td>\n",
       "      <td>0.397788</td>\n",
       "      <td>0.387884</td>\n",
       "      <td>0.359688</td>\n",
       "      <td>0.301307</td>\n",
       "      <td>0.313337</td>\n",
       "      <td>0.343947</td>\n",
       "      <td>...</td>\n",
       "      <td>0.510686</td>\n",
       "      <td>0.476882</td>\n",
       "      <td>0.599392</td>\n",
       "      <td>0.656811</td>\n",
       "      <td>0.658377</td>\n",
       "      <td>0.661628</td>\n",
       "      <td>0.581761</td>\n",
       "      <td>0.552943</td>\n",
       "      <td>0.446615</td>\n",
       "      <td>0.388538</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3483</th>\n",
       "      <td>0.508140</td>\n",
       "      <td>0.565769</td>\n",
       "      <td>0.503267</td>\n",
       "      <td>0.429874</td>\n",
       "      <td>0.419059</td>\n",
       "      <td>0.406631</td>\n",
       "      <td>0.322405</td>\n",
       "      <td>0.224723</td>\n",
       "      <td>0.307368</td>\n",
       "      <td>0.408572</td>\n",
       "      <td>...</td>\n",
       "      <td>0.608613</td>\n",
       "      <td>0.580088</td>\n",
       "      <td>0.729738</td>\n",
       "      <td>0.743280</td>\n",
       "      <td>0.734202</td>\n",
       "      <td>0.688269</td>\n",
       "      <td>0.650296</td>\n",
       "      <td>0.610259</td>\n",
       "      <td>0.502680</td>\n",
       "      <td>0.398985</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3484</th>\n",
       "      <td>0.571365</td>\n",
       "      <td>0.594385</td>\n",
       "      <td>0.533655</td>\n",
       "      <td>0.447615</td>\n",
       "      <td>0.336455</td>\n",
       "      <td>0.310910</td>\n",
       "      <td>0.312988</td>\n",
       "      <td>0.408423</td>\n",
       "      <td>0.480554</td>\n",
       "      <td>0.471709</td>\n",
       "      <td>...</td>\n",
       "      <td>0.503992</td>\n",
       "      <td>0.626963</td>\n",
       "      <td>0.766269</td>\n",
       "      <td>0.680384</td>\n",
       "      <td>0.610868</td>\n",
       "      <td>0.560537</td>\n",
       "      <td>0.500876</td>\n",
       "      <td>0.383980</td>\n",
       "      <td>0.336071</td>\n",
       "      <td>0.385004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3485</th>\n",
       "      <td>0.503822</td>\n",
       "      <td>0.450070</td>\n",
       "      <td>0.395983</td>\n",
       "      <td>0.336282</td>\n",
       "      <td>0.289279</td>\n",
       "      <td>0.318499</td>\n",
       "      <td>0.399246</td>\n",
       "      <td>0.489296</td>\n",
       "      <td>0.530354</td>\n",
       "      <td>0.551319</td>\n",
       "      <td>...</td>\n",
       "      <td>0.573304</td>\n",
       "      <td>0.705280</td>\n",
       "      <td>0.809377</td>\n",
       "      <td>0.687193</td>\n",
       "      <td>0.548680</td>\n",
       "      <td>0.429719</td>\n",
       "      <td>0.332872</td>\n",
       "      <td>0.316301</td>\n",
       "      <td>0.372328</td>\n",
       "      <td>0.450443</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3486</th>\n",
       "      <td>0.444628</td>\n",
       "      <td>0.392050</td>\n",
       "      <td>0.332240</td>\n",
       "      <td>0.327784</td>\n",
       "      <td>0.304862</td>\n",
       "      <td>0.401722</td>\n",
       "      <td>0.466723</td>\n",
       "      <td>0.526824</td>\n",
       "      <td>0.565640</td>\n",
       "      <td>0.589547</td>\n",
       "      <td>...</td>\n",
       "      <td>0.745123</td>\n",
       "      <td>0.734829</td>\n",
       "      <td>0.747867</td>\n",
       "      <td>0.625623</td>\n",
       "      <td>0.457817</td>\n",
       "      <td>0.337824</td>\n",
       "      <td>0.292884</td>\n",
       "      <td>0.362799</td>\n",
       "      <td>0.434886</td>\n",
       "      <td>0.399427</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3487 rows × 24 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            0         1         2         3         4         5         6   \\\n",
       "0     0.543832  0.654460  0.661829  0.563464  0.599267  0.699634  0.721294   \n",
       "1     0.630573  0.672083  0.612464  0.601688  0.777240  0.809328  0.738840   \n",
       "2     0.640508  0.585354  0.583009  0.666596  0.664024  0.573583  0.461036   \n",
       "3     0.591370  0.674265  0.745430  0.724724  0.604814  0.500152  0.434369   \n",
       "4     0.595108  0.688872  0.715966  0.548925  0.410343  0.399815  0.391418   \n",
       "...        ...       ...       ...       ...       ...       ...       ...   \n",
       "3482  0.414186  0.476000  0.489328  0.438869  0.397788  0.387884  0.359688   \n",
       "3483  0.508140  0.565769  0.503267  0.429874  0.419059  0.406631  0.322405   \n",
       "3484  0.571365  0.594385  0.533655  0.447615  0.336455  0.310910  0.312988   \n",
       "3485  0.503822  0.450070  0.395983  0.336282  0.289279  0.318499  0.399246   \n",
       "3486  0.444628  0.392050  0.332240  0.327784  0.304862  0.401722  0.466723   \n",
       "\n",
       "            7         8         9   ...        14        15        16  \\\n",
       "0     0.555084  0.459930  0.413151  ...  0.383349  0.378832  0.416335   \n",
       "1     0.605367  0.463053  0.389225  ...  0.356993  0.294499  0.445579   \n",
       "2     0.441605  0.395695  0.328200  ...  0.375800  0.405021  0.418488   \n",
       "3     0.341298  0.316183  0.293644  ...  0.404902  0.393448  0.282479   \n",
       "4     0.331532  0.318394  0.353330  ...  0.529118  0.322337  0.281502   \n",
       "...        ...       ...       ...  ...       ...       ...       ...   \n",
       "3482  0.301307  0.313337  0.343947  ...  0.510686  0.476882  0.599392   \n",
       "3483  0.224723  0.307368  0.408572  ...  0.608613  0.580088  0.729738   \n",
       "3484  0.408423  0.480554  0.471709  ...  0.503992  0.626963  0.766269   \n",
       "3485  0.489296  0.530354  0.551319  ...  0.573304  0.705280  0.809377   \n",
       "3486  0.526824  0.565640  0.589547  ...  0.745123  0.734829  0.747867   \n",
       "\n",
       "            17        18        19        20        21        22        23  \n",
       "0     0.502154  0.421978  0.295683  0.288353  0.526186  0.635084  0.611497  \n",
       "1     0.447441  0.337021  0.303622  0.396032  0.643599  0.670800  0.686093  \n",
       "2     0.361929  0.330251  0.482720  0.586071  0.635742  0.625080  0.678007  \n",
       "3     0.282697  0.390511  0.558223  0.624812  0.681554  0.686911  0.628185  \n",
       "4     0.436176  0.605363  0.580775  0.560694  0.602099  0.660337  0.573784  \n",
       "...        ...       ...       ...       ...       ...       ...       ...  \n",
       "3482  0.656811  0.658377  0.661628  0.581761  0.552943  0.446615  0.388538  \n",
       "3483  0.743280  0.734202  0.688269  0.650296  0.610259  0.502680  0.398985  \n",
       "3484  0.680384  0.610868  0.560537  0.500876  0.383980  0.336071  0.385004  \n",
       "3485  0.687193  0.548680  0.429719  0.332872  0.316301  0.372328  0.450443  \n",
       "3486  0.625623  0.457817  0.337824  0.292884  0.362799  0.434886  0.399427  \n",
       "\n",
       "[3487 rows x 24 columns]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pr_df = pd.DataFrame(tePredict.reshape(-1,24))\n",
    "pr_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "b56aa610",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Error1</th>\n",
       "      <th>Error2</th>\n",
       "      <th>Error3</th>\n",
       "      <th>Error4</th>\n",
       "      <th>Error5</th>\n",
       "      <th>Error6</th>\n",
       "      <th>Error7</th>\n",
       "      <th>Error8</th>\n",
       "      <th>Error9</th>\n",
       "      <th>Error10</th>\n",
       "      <th>...</th>\n",
       "      <th>Error15</th>\n",
       "      <th>Error16</th>\n",
       "      <th>Error17</th>\n",
       "      <th>Error18</th>\n",
       "      <th>Error19</th>\n",
       "      <th>Error20</th>\n",
       "      <th>Error21</th>\n",
       "      <th>Error22</th>\n",
       "      <th>Error23</th>\n",
       "      <th>Error24</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.013257</td>\n",
       "      <td>0.026157</td>\n",
       "      <td>0.013545</td>\n",
       "      <td>-0.095211</td>\n",
       "      <td>-0.070758</td>\n",
       "      <td>0.017061</td>\n",
       "      <td>0.117048</td>\n",
       "      <td>0.074884</td>\n",
       "      <td>0.119121</td>\n",
       "      <td>0.119898</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.118032</td>\n",
       "      <td>-0.171063</td>\n",
       "      <td>-0.021024</td>\n",
       "      <td>0.015000</td>\n",
       "      <td>0.068940</td>\n",
       "      <td>-0.034336</td>\n",
       "      <td>-0.093458</td>\n",
       "      <td>0.087547</td>\n",
       "      <td>0.091583</td>\n",
       "      <td>0.068395</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.002270</td>\n",
       "      <td>0.023798</td>\n",
       "      <td>-0.046211</td>\n",
       "      <td>-0.068336</td>\n",
       "      <td>0.094668</td>\n",
       "      <td>0.205083</td>\n",
       "      <td>0.258640</td>\n",
       "      <td>0.264558</td>\n",
       "      <td>0.169800</td>\n",
       "      <td>-0.046056</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.192903</td>\n",
       "      <td>-0.142861</td>\n",
       "      <td>-0.041575</td>\n",
       "      <td>0.094404</td>\n",
       "      <td>0.007002</td>\n",
       "      <td>-0.078189</td>\n",
       "      <td>-0.042606</td>\n",
       "      <td>0.100098</td>\n",
       "      <td>0.127698</td>\n",
       "      <td>0.118134</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.007777</td>\n",
       "      <td>-0.073321</td>\n",
       "      <td>-0.087016</td>\n",
       "      <td>-0.015977</td>\n",
       "      <td>0.059778</td>\n",
       "      <td>0.093383</td>\n",
       "      <td>0.120227</td>\n",
       "      <td>0.148352</td>\n",
       "      <td>-0.039587</td>\n",
       "      <td>-0.379550</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.061560</td>\n",
       "      <td>-0.082133</td>\n",
       "      <td>0.065451</td>\n",
       "      <td>0.031910</td>\n",
       "      <td>-0.051560</td>\n",
       "      <td>0.044082</td>\n",
       "      <td>0.042570</td>\n",
       "      <td>0.092640</td>\n",
       "      <td>0.057122</td>\n",
       "      <td>0.026365</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.067305</td>\n",
       "      <td>0.004240</td>\n",
       "      <td>0.062857</td>\n",
       "      <td>0.120478</td>\n",
       "      <td>0.124614</td>\n",
       "      <td>0.159342</td>\n",
       "      <td>0.141116</td>\n",
       "      <td>-0.093983</td>\n",
       "      <td>-0.391566</td>\n",
       "      <td>-0.292858</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.082252</td>\n",
       "      <td>0.040411</td>\n",
       "      <td>-0.047540</td>\n",
       "      <td>-0.099114</td>\n",
       "      <td>-0.048127</td>\n",
       "      <td>0.014721</td>\n",
       "      <td>0.081710</td>\n",
       "      <td>0.113595</td>\n",
       "      <td>0.035269</td>\n",
       "      <td>0.008115</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.074916</td>\n",
       "      <td>0.006299</td>\n",
       "      <td>0.111720</td>\n",
       "      <td>0.068725</td>\n",
       "      <td>0.069534</td>\n",
       "      <td>0.106562</td>\n",
       "      <td>-0.043863</td>\n",
       "      <td>-0.376217</td>\n",
       "      <td>-0.268107</td>\n",
       "      <td>-0.091543</td>\n",
       "      <td>...</td>\n",
       "      <td>0.176080</td>\n",
       "      <td>-0.007682</td>\n",
       "      <td>-0.100309</td>\n",
       "      <td>-0.002462</td>\n",
       "      <td>0.061861</td>\n",
       "      <td>0.037673</td>\n",
       "      <td>-0.007265</td>\n",
       "      <td>-0.049542</td>\n",
       "      <td>0.040266</td>\n",
       "      <td>-0.009441</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3482</th>\n",
       "      <td>-0.196138</td>\n",
       "      <td>-0.370279</td>\n",
       "      <td>-0.373165</td>\n",
       "      <td>-0.357444</td>\n",
       "      <td>-0.342400</td>\n",
       "      <td>-0.236783</td>\n",
       "      <td>-0.203865</td>\n",
       "      <td>-0.171746</td>\n",
       "      <td>-0.122145</td>\n",
       "      <td>-0.077425</td>\n",
       "      <td>...</td>\n",
       "      <td>0.155104</td>\n",
       "      <td>0.052703</td>\n",
       "      <td>0.384354</td>\n",
       "      <td>0.199425</td>\n",
       "      <td>0.063254</td>\n",
       "      <td>0.187951</td>\n",
       "      <td>0.106291</td>\n",
       "      <td>0.012931</td>\n",
       "      <td>-0.106415</td>\n",
       "      <td>-0.192633</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3483</th>\n",
       "      <td>-0.338139</td>\n",
       "      <td>-0.296724</td>\n",
       "      <td>-0.293046</td>\n",
       "      <td>-0.310314</td>\n",
       "      <td>-0.205607</td>\n",
       "      <td>-0.156922</td>\n",
       "      <td>-0.150648</td>\n",
       "      <td>-0.210758</td>\n",
       "      <td>-0.114004</td>\n",
       "      <td>-0.030027</td>\n",
       "      <td>...</td>\n",
       "      <td>0.184434</td>\n",
       "      <td>0.365050</td>\n",
       "      <td>0.272352</td>\n",
       "      <td>0.148157</td>\n",
       "      <td>0.260525</td>\n",
       "      <td>0.212799</td>\n",
       "      <td>0.110283</td>\n",
       "      <td>0.057229</td>\n",
       "      <td>-0.078491</td>\n",
       "      <td>-0.181873</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3484</th>\n",
       "      <td>-0.291127</td>\n",
       "      <td>-0.201928</td>\n",
       "      <td>-0.206534</td>\n",
       "      <td>-0.177051</td>\n",
       "      <td>-0.227098</td>\n",
       "      <td>-0.162144</td>\n",
       "      <td>-0.122494</td>\n",
       "      <td>-0.012949</td>\n",
       "      <td>0.041954</td>\n",
       "      <td>0.067096</td>\n",
       "      <td>...</td>\n",
       "      <td>0.288954</td>\n",
       "      <td>0.169578</td>\n",
       "      <td>0.171145</td>\n",
       "      <td>0.206707</td>\n",
       "      <td>0.135398</td>\n",
       "      <td>0.020525</td>\n",
       "      <td>-0.052154</td>\n",
       "      <td>-0.197190</td>\n",
       "      <td>-0.244787</td>\n",
       "      <td>-0.389639</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3485</th>\n",
       "      <td>-0.292490</td>\n",
       "      <td>-0.290119</td>\n",
       "      <td>-0.228683</td>\n",
       "      <td>-0.227271</td>\n",
       "      <td>-0.183775</td>\n",
       "      <td>-0.116983</td>\n",
       "      <td>-0.022126</td>\n",
       "      <td>0.050696</td>\n",
       "      <td>0.125740</td>\n",
       "      <td>0.143822</td>\n",
       "      <td>...</td>\n",
       "      <td>0.115919</td>\n",
       "      <td>0.110157</td>\n",
       "      <td>0.335700</td>\n",
       "      <td>0.211723</td>\n",
       "      <td>0.008668</td>\n",
       "      <td>-0.123311</td>\n",
       "      <td>-0.248298</td>\n",
       "      <td>-0.264558</td>\n",
       "      <td>-0.402315</td>\n",
       "      <td>-0.285069</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3486</th>\n",
       "      <td>-0.295561</td>\n",
       "      <td>-0.232617</td>\n",
       "      <td>-0.231313</td>\n",
       "      <td>-0.145270</td>\n",
       "      <td>-0.130619</td>\n",
       "      <td>-0.019650</td>\n",
       "      <td>0.028124</td>\n",
       "      <td>0.122211</td>\n",
       "      <td>0.158143</td>\n",
       "      <td>0.227963</td>\n",
       "      <td>...</td>\n",
       "      <td>0.149999</td>\n",
       "      <td>0.261152</td>\n",
       "      <td>0.272397</td>\n",
       "      <td>0.085610</td>\n",
       "      <td>-0.095214</td>\n",
       "      <td>-0.243346</td>\n",
       "      <td>-0.287975</td>\n",
       "      <td>-0.411843</td>\n",
       "      <td>-0.300626</td>\n",
       "      <td>-0.202166</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3487 rows × 24 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        Error1    Error2    Error3    Error4    Error5    Error6    Error7  \\\n",
       "0    -0.013257  0.026157  0.013545 -0.095211 -0.070758  0.017061  0.117048   \n",
       "1     0.002270  0.023798 -0.046211 -0.068336  0.094668  0.205083  0.258640   \n",
       "2    -0.007777 -0.073321 -0.087016 -0.015977  0.059778  0.093383  0.120227   \n",
       "3    -0.067305  0.004240  0.062857  0.120478  0.124614  0.159342  0.141116   \n",
       "4    -0.074916  0.006299  0.111720  0.068725  0.069534  0.106562 -0.043863   \n",
       "...        ...       ...       ...       ...       ...       ...       ...   \n",
       "3482 -0.196138 -0.370279 -0.373165 -0.357444 -0.342400 -0.236783 -0.203865   \n",
       "3483 -0.338139 -0.296724 -0.293046 -0.310314 -0.205607 -0.156922 -0.150648   \n",
       "3484 -0.291127 -0.201928 -0.206534 -0.177051 -0.227098 -0.162144 -0.122494   \n",
       "3485 -0.292490 -0.290119 -0.228683 -0.227271 -0.183775 -0.116983 -0.022126   \n",
       "3486 -0.295561 -0.232617 -0.231313 -0.145270 -0.130619 -0.019650  0.028124   \n",
       "\n",
       "        Error8    Error9   Error10  ...   Error15   Error16   Error17  \\\n",
       "0     0.074884  0.119121  0.119898  ... -0.118032 -0.171063 -0.021024   \n",
       "1     0.264558  0.169800 -0.046056  ... -0.192903 -0.142861 -0.041575   \n",
       "2     0.148352 -0.039587 -0.379550  ... -0.061560 -0.082133  0.065451   \n",
       "3    -0.093983 -0.391566 -0.292858  ... -0.082252  0.040411 -0.047540   \n",
       "4    -0.376217 -0.268107 -0.091543  ...  0.176080 -0.007682 -0.100309   \n",
       "...        ...       ...       ...  ...       ...       ...       ...   \n",
       "3482 -0.171746 -0.122145 -0.077425  ...  0.155104  0.052703  0.384354   \n",
       "3483 -0.210758 -0.114004 -0.030027  ...  0.184434  0.365050  0.272352   \n",
       "3484 -0.012949  0.041954  0.067096  ...  0.288954  0.169578  0.171145   \n",
       "3485  0.050696  0.125740  0.143822  ...  0.115919  0.110157  0.335700   \n",
       "3486  0.122211  0.158143  0.227963  ...  0.149999  0.261152  0.272397   \n",
       "\n",
       "       Error18   Error19   Error20   Error21   Error22   Error23   Error24  \n",
       "0     0.015000  0.068940 -0.034336 -0.093458  0.087547  0.091583  0.068395  \n",
       "1     0.094404  0.007002 -0.078189 -0.042606  0.100098  0.127698  0.118134  \n",
       "2     0.031910 -0.051560  0.044082  0.042570  0.092640  0.057122  0.026365  \n",
       "3    -0.099114 -0.048127  0.014721  0.081710  0.113595  0.035269  0.008115  \n",
       "4    -0.002462  0.061861  0.037673 -0.007265 -0.049542  0.040266 -0.009441  \n",
       "...        ...       ...       ...       ...       ...       ...       ...  \n",
       "3482  0.199425  0.063254  0.187951  0.106291  0.012931 -0.106415 -0.192633  \n",
       "3483  0.148157  0.260525  0.212799  0.110283  0.057229 -0.078491 -0.181873  \n",
       "3484  0.206707  0.135398  0.020525 -0.052154 -0.197190 -0.244787 -0.389639  \n",
       "3485  0.211723  0.008668 -0.123311 -0.248298 -0.264558 -0.402315 -0.285069  \n",
       "3486  0.085610 -0.095214 -0.243346 -0.287975 -0.411843 -0.300626 -0.202166  \n",
       "\n",
       "[3487 rows x 24 columns]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "teY = testY.reshape(-1,24)\n",
    "e_te = testPredict-teY\n",
    "er_df = pd.DataFrame(e_te, columns=Erindex)\n",
    "er_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "b0dddae5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3487, 24)\n"
     ]
    }
   ],
   "source": [
    "prnorm = np.array(pr_df)\n",
    "ernorm =np.array(er_df)\n",
    "print(ernorm.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "a93ad192",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.37973304,  0.58168519,  0.60544753,  0.54663783,  0.53608632,\n",
       "         0.62316757,  0.60378921,  0.52027524,  0.38854301,  0.34092382,\n",
       "         0.45156395,  0.51253438,  0.56806505,  0.50199193,  0.43575025,\n",
       "         0.37629715,  0.34810576,  0.51436853,  0.53225011,  0.47493756,\n",
       "         0.39577472,  0.4452551 ,  0.50394899,  0.49134061,  0.51242119,\n",
       "        -0.03702677, -0.02701171, -0.05057401,  0.1140724 ,  0.22177458,\n",
       "         0.17082542,  0.09338582, -0.04098396, -0.07509565,  0.03002959,\n",
       "         0.08436615,  0.15963856,  0.06679021, -0.0090426 , -0.08408128,\n",
       "        -0.06991186, -0.05726697,  0.03998118,  0.05644038, -0.06140667,\n",
       "        -0.04237812, -0.0191714 , -0.05288026, -0.07655827],\n",
       "       [ 0.43384298,  0.54045868,  0.54403424,  0.58192766,  0.59073418,\n",
       "         0.53344572,  0.47046873,  0.37595931,  0.33545759,  0.39590016,\n",
       "         0.42598021,  0.43417209,  0.46262547,  0.43737057,  0.36278373,\n",
       "         0.36330411,  0.35731068,  0.39242804,  0.40086144,  0.37761885,\n",
       "         0.44862545,  0.54107577,  0.575185  ,  0.57757986,  0.55383784,\n",
       "        -0.09200056, -0.0531776 ,  0.15991374,  0.18934119,  0.10048192,\n",
       "         0.04357932, -0.05356766, -0.08056187, -0.0256342 , -0.00218802,\n",
       "         0.0257456 ,  0.02742375, -0.00742228, -0.0975947 , -0.05471351,\n",
       "        -0.21432482, -0.09984089, -0.01763573, -0.07956254, -0.03900777,\n",
       "         0.01795538,  0.03096413, -0.0113996 , -0.07470502]])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "etedat = np.concatenate((npnorm22[:prnorm.shape[0],:], prnorm, ernorm), axis=1)\n",
    "etedat[169:171,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "706966a2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3317, 1, 49)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_timesteps = 1\n",
    "eteX, eteY = create_dataset(etedat, timesteps, output_timesteps, 0)\n",
    "eteY.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "2f809680",
   "metadata": {},
   "outputs": [],
   "source": [
    "eteY = eteY[:,:,-24:].reshape(-1,24)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "ab35790e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(31207, 1, 49)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "norm_df2 = np.array(norm_df2)\n",
    "output_timesteps = 1\n",
    "Xe, Ye = create_dataset(norm_df2, timesteps, output_timesteps, 0)\n",
    "Ye.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "847766bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(31207, 168, 49)\n",
      "(31207, 24)\n"
     ]
    }
   ],
   "source": [
    "Ye = Ye[:,:,-24:].reshape(-1,24)\n",
    "print(Xe.shape)\n",
    "print(Ye.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "26aad0ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "trXe, vaXe, trYe, vaYe = train_test_split(Xe, Ye, test_size=0.3, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "47341bca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6271"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "01a3bb13",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((3317, 168, 49), (3317, 24), (31207, 168, 49), (31207, 24))"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eteX.shape, eteY.shape, Xe.shape, Ye.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "c00b8a5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mse_mae(y_true, y_pred):\n",
    "    return K.mean(K.square(y_pred - y_true))*10+K.mean(K.abs(y_pred - y_true))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "8d00c245",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            [(None, 168, 49)]    0                                            \n",
      "__________________________________________________________________________________________________\n",
      "permute (Permute)               (None, 49, 168)      0           input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, 49, 168)      28392       permute[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 49, 168)      28392       permute[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "multiply (Multiply)             (None, 49, 168)      0           dense[0][0]                      \n",
      "                                                                 dense_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "attention_vec (Permute)         (None, 168, 49)      0           multiply[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "multiply_1 (Multiply)           (None, 168, 49)      0           input_1[0][0]                    \n",
      "                                                                 attention_vec[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv1d (Conv1D)                 (None, 168, 256)     12800       multiply_1[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation (Activation)         (None, 168, 256)     0           conv1d[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "activation_1 (Activation)       (None, 168, 256)     0           conv1d[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "multiply_2 (Multiply)           (None, 168, 256)     0           activation[0][0]                 \n",
      "                                                                 activation_1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_1 (Conv1D)               (None, 168, 49)      25137       multiply_2[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_2 (Activation)       (None, 168, 49)      0           conv1d_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_3 (Activation)       (None, 168, 49)      0           conv1d_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "multiply_3 (Multiply)           (None, 168, 49)      0           activation_2[0][0]               \n",
      "                                                                 activation_3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "add (Add)                       (None, 168, 49)      0           input_1[0][0]                    \n",
      "                                                                 multiply_3[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "subtract (Subtract)             (None, 168, 49)      0           input_1[0][0]                    \n",
      "                                                                 multiply_3[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_2 (Conv1D)               (None, 168, 256)     12800       add[0][0]                        \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_4 (Conv1D)               (None, 168, 256)     12800       subtract[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_4 (Activation)       (None, 168, 256)     0           conv1d_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_5 (Activation)       (None, 168, 256)     0           conv1d_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_8 (Activation)       (None, 168, 256)     0           conv1d_4[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_9 (Activation)       (None, 168, 256)     0           conv1d_4[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "multiply_4 (Multiply)           (None, 168, 256)     0           activation_4[0][0]               \n",
      "                                                                 activation_5[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "multiply_6 (Multiply)           (None, 168, 256)     0           activation_8[0][0]               \n",
      "                                                                 activation_9[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_3 (Conv1D)               (None, 168, 49)      25137       multiply_4[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_5 (Conv1D)               (None, 168, 49)      25137       multiply_6[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_6 (Activation)       (None, 168, 49)      0           conv1d_3[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_7 (Activation)       (None, 168, 49)      0           conv1d_3[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_10 (Activation)      (None, 168, 49)      0           conv1d_5[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_11 (Activation)      (None, 168, 49)      0           conv1d_5[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "multiply_5 (Multiply)           (None, 168, 49)      0           activation_6[0][0]               \n",
      "                                                                 activation_7[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "multiply_7 (Multiply)           (None, 168, 49)      0           activation_10[0][0]              \n",
      "                                                                 activation_11[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "add_1 (Add)                     (None, 168, 49)      0           add[0][0]                        \n",
      "                                                                 multiply_5[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "subtract_1 (Subtract)           (None, 168, 49)      0           subtract[0][0]                   \n",
      "                                                                 multiply_7[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "concatenate (Concatenate)       (None, 168, 196)     0           add_1[0][0]                      \n",
      "                                                                 subtract_1[0][0]                 \n",
      "                                                                 add[0][0]                        \n",
      "                                                                 subtract[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_6 (Conv1D)               (None, 168, 256)     50432       concatenate[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_8 (Conv1D)               (None, 168, 256)     50432       concatenate[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "activation_12 (Activation)      (None, 168, 256)     0           conv1d_6[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_13 (Activation)      (None, 168, 256)     0           conv1d_6[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_16 (Activation)      (None, 168, 256)     0           conv1d_8[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_17 (Activation)      (None, 168, 256)     0           conv1d_8[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "multiply_8 (Multiply)           (None, 168, 256)     0           activation_12[0][0]              \n",
      "                                                                 activation_13[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "multiply_10 (Multiply)          (None, 168, 256)     0           activation_16[0][0]              \n",
      "                                                                 activation_17[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_7 (Conv1D)               (None, 168, 49)      25137       multiply_8[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_9 (Conv1D)               (None, 168, 49)      25137       multiply_10[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "activation_14 (Activation)      (None, 168, 49)      0           conv1d_7[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_15 (Activation)      (None, 168, 49)      0           conv1d_7[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_18 (Activation)      (None, 168, 49)      0           conv1d_9[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_19 (Activation)      (None, 168, 49)      0           conv1d_9[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "multiply_9 (Multiply)           (None, 168, 49)      0           activation_14[0][0]              \n",
      "                                                                 activation_15[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "multiply_11 (Multiply)          (None, 168, 49)      0           activation_18[0][0]              \n",
      "                                                                 activation_19[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "add_2 (Add)                     (None, 168, 49)      0           add_1[0][0]                      \n",
      "                                                                 multiply_9[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "subtract_2 (Subtract)           (None, 168, 49)      0           subtract_1[0][0]                 \n",
      "                                                                 multiply_11[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, 168, 294)     0           add_2[0][0]                      \n",
      "                                                                 subtract_2[0][0]                 \n",
      "                                                                 concatenate[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_10 (Conv1D)              (None, 168, 256)     75520       concatenate_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_12 (Conv1D)              (None, 168, 256)     75520       concatenate_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_20 (Activation)      (None, 168, 256)     0           conv1d_10[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_21 (Activation)      (None, 168, 256)     0           conv1d_10[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_24 (Activation)      (None, 168, 256)     0           conv1d_12[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_25 (Activation)      (None, 168, 256)     0           conv1d_12[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "multiply_12 (Multiply)          (None, 168, 256)     0           activation_20[0][0]              \n",
      "                                                                 activation_21[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "multiply_14 (Multiply)          (None, 168, 256)     0           activation_24[0][0]              \n",
      "                                                                 activation_25[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_11 (Conv1D)              (None, 168, 49)      25137       multiply_12[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_13 (Conv1D)              (None, 168, 49)      25137       multiply_14[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "activation_22 (Activation)      (None, 168, 49)      0           conv1d_11[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_23 (Activation)      (None, 168, 49)      0           conv1d_11[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_26 (Activation)      (None, 168, 49)      0           conv1d_13[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_27 (Activation)      (None, 168, 49)      0           conv1d_13[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "multiply_13 (Multiply)          (None, 168, 49)      0           activation_22[0][0]              \n",
      "                                                                 activation_23[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "multiply_15 (Multiply)          (None, 168, 49)      0           activation_26[0][0]              \n",
      "                                                                 activation_27[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "add_3 (Add)                     (None, 168, 49)      0           add_2[0][0]                      \n",
      "                                                                 multiply_13[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "subtract_3 (Subtract)           (None, 168, 49)      0           subtract_1[0][0]                 \n",
      "                                                                 multiply_15[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_2 (Concatenate)     (None, 168, 392)     0           add_3[0][0]                      \n",
      "                                                                 subtract_3[0][0]                 \n",
      "                                                                 concatenate_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_14 (Conv1D)              (None, 168, 256)     100608      concatenate_2[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_16 (Conv1D)              (None, 168, 256)     100608      concatenate_2[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_28 (Activation)      (None, 168, 256)     0           conv1d_14[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_29 (Activation)      (None, 168, 256)     0           conv1d_14[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_32 (Activation)      (None, 168, 256)     0           conv1d_16[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_33 (Activation)      (None, 168, 256)     0           conv1d_16[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "multiply_16 (Multiply)          (None, 168, 256)     0           activation_28[0][0]              \n",
      "                                                                 activation_29[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "multiply_18 (Multiply)          (None, 168, 256)     0           activation_32[0][0]              \n",
      "                                                                 activation_33[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_15 (Conv1D)              (None, 168, 49)      25137       multiply_16[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_17 (Conv1D)              (None, 168, 49)      25137       multiply_18[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "activation_30 (Activation)      (None, 168, 49)      0           conv1d_15[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_31 (Activation)      (None, 168, 49)      0           conv1d_15[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_34 (Activation)      (None, 168, 49)      0           conv1d_17[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_35 (Activation)      (None, 168, 49)      0           conv1d_17[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "multiply_17 (Multiply)          (None, 168, 49)      0           activation_30[0][0]              \n",
      "                                                                 activation_31[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "multiply_19 (Multiply)          (None, 168, 49)      0           activation_34[0][0]              \n",
      "                                                                 activation_35[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "add_4 (Add)                     (None, 168, 49)      0           add_3[0][0]                      \n",
      "                                                                 multiply_17[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "subtract_4 (Subtract)           (None, 168, 49)      0           subtract_3[0][0]                 \n",
      "                                                                 multiply_19[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_3 (Concatenate)     (None, 168, 490)     0           add_4[0][0]                      \n",
      "                                                                 subtract_4[0][0]                 \n",
      "                                                                 concatenate_2[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_4 (Concatenate)     (None, 168, 98)      0           add_4[0][0]                      \n",
      "                                                                 subtract_4[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_5 (Concatenate)     (None, 168, 1470)    0           concatenate[0][0]                \n",
      "                                                                 concatenate_1[0][0]              \n",
      "                                                                 concatenate_2[0][0]              \n",
      "                                                                 concatenate_3[0][0]              \n",
      "                                                                 concatenate_4[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_22 (Conv1D)              (None, 168, 720)     1180080     concatenate_5[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout (Dropout)               (None, 168, 720)     0           conv1d_22[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_23 (Conv1D)              (None, 168, 360)     320040      dropout[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)             (None, 168, 360)     0           conv1d_23[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling1d (Globa (None, 360)          0           dropout_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_2 (Dense)                 (None, 24)           8664        global_average_pooling1d[0][0]   \n",
      "==================================================================================================\n",
      "Total params: 2,283,321\n",
      "Trainable params: 2,283,321\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "num_features = Xe.shape[2]\n",
    "\n",
    "with tf.device('/gpu:0'):\n",
    "    alpha=1.0\n",
    "    gamma=1.2\n",
    "    beta = 1\n",
    "    hfilters = 256\n",
    "    hkernel_size1 = 1\n",
    "    hkernel_size2 = 2\n",
    "    visible1e = Input(shape=(timesteps, num_features))\n",
    "   \n",
    "    per1e = Permute((2,1))(visible1e)\n",
    "    den1ae = Dense(timesteps, activation='tanh')(per1e)\n",
    "    den1be = Dense(timesteps, activation='sigmoid')(per1e)\n",
    "    den1e = Multiply()([den1ae, den1be])\n",
    "    per2e = Permute((2,1), name='attention_vec')(den1e)\n",
    "    mul1e = Multiply()([visible1e, per2e])\n",
    "    \n",
    "    d1e = Conv1D(filters=round(hfilters*alpha), kernel_size=round(hkernel_size1*beta), padding='causal', dilation_rate=1)(mul1e)\n",
    "    d1ae = Activation(activations.tanh)(d1e)\n",
    "    d1be = Activation(activations.sigmoid)(d1e)\n",
    "    d1e = Multiply()([d1ae, d1be])\n",
    "    \n",
    "    d1e = Conv1D(filters=num_features, kernel_size=round(hkernel_size2*beta), padding='causal', dilation_rate=2)(d1e)\n",
    "    d1ae = Activation(activations.tanh)(d1e)\n",
    "    d1be = Activation(activations.sigmoid)(d1e)\n",
    "    d1e = Multiply()([d1ae, d1be])\n",
    "    \n",
    "    res01ae = Add()([visible1e, d1e])   # (100, 25) (100, 25)\n",
    "    res01be = Subtract()([visible1e, d1e])\n",
    "\n",
    "    d1e = Conv1D(filters=round(hfilters*alpha), kernel_size=round(hkernel_size1*beta), padding='causal', dilation_rate=2)(res01ae)\n",
    "    d1ae = Activation(activations.tanh)(d1e)\n",
    "    d1be = Activation(activations.sigmoid)(d1e)\n",
    "    d1e = Multiply()([d1ae, d1be])\n",
    "    \n",
    "    d1e = Conv1D(filters=num_features, kernel_size=round(hkernel_size2*beta), padding='causal', dilation_rate=4)(d1e)    \n",
    "    d1ae = Activation(activations.tanh)(d1e)\n",
    "    d1be = Activation(activations.sigmoid)(d1e)\n",
    "    \n",
    "    d1e = Multiply()([d1ae, d1be])\n",
    "    res02ae = Add()([res01ae, d1e])   # (100, 25) (100, 25)\n",
    "    \n",
    "    d2e = Conv1D(filters=round(hfilters*alpha), kernel_size=round(hkernel_size1*beta), padding='causal', dilation_rate=2)(res01be) \n",
    "    d2ae = Activation(activations.tanh)(d2e)\n",
    "    d2be = Activation(activations.sigmoid)(d2e)\n",
    "    d2e = Multiply()([d2ae, d2be])\n",
    "    \n",
    "    d2e = Conv1D(filters=num_features, kernel_size=round(hkernel_size2*beta), padding='causal', dilation_rate=4)(d2e) \n",
    "    d2ae = Activation(activations.tanh)(d2e)\n",
    "    d2be = Activation(activations.sigmoid)(d2e)\n",
    "    d2e = Multiply()([d2ae, d2be])\n",
    "    \n",
    "    res02be = Subtract()([res01be, d2e])   # (100, 25) (100, 25) \n",
    "    res02e = Concatenate()([res02ae, res02be, res01ae, res01be])\n",
    "    \n",
    "    d1e = Conv1D(filters=round(hfilters*alpha), kernel_size=round(hkernel_size1*beta), padding='causal', dilation_rate=4)(res02e)\n",
    "    d1ae = Activation(activations.tanh)(d1e)\n",
    "    d1be = Activation(activations.sigmoid)(d1e)\n",
    "    d1e = Multiply()([d1ae, d1be])\n",
    "    \n",
    "    d1e = Conv1D(filters=num_features, kernel_size=round(hkernel_size2*beta), padding='causal', dilation_rate=8)(d1e)    \n",
    "    d1ae = Activation(activations.tanh)(d1e)\n",
    "    d1be = Activation(activations.sigmoid)(d1e)\n",
    "    d1e = Multiply()([d1ae, d1be])\n",
    "    \n",
    "    res03ae = Add()([res02ae, d1e])   # (100, 25) (100, 25)\n",
    "    \n",
    "    d2e = Conv1D(filters=round(hfilters*alpha), kernel_size=round(hkernel_size1*beta), padding='causal', dilation_rate=4)(res02e) \n",
    "    d2ae = Activation(activations.tanh)(d2e)\n",
    "    d2be = Activation(activations.sigmoid)(d2e)\n",
    "    d2e = Multiply()([d2ae, d2be])\n",
    "    \n",
    "    d2e = Conv1D(filters=num_features, kernel_size=round(hkernel_size2*beta), padding='causal', dilation_rate=8)(d2e) \n",
    "    d2ae = Activation(activations.tanh)(d2e)\n",
    "    d2be = Activation(activations.sigmoid)(d2e)\n",
    "    d2e = Multiply()([d2ae, d2be])\n",
    "    \n",
    "    res03be = Subtract()([res02be, d2e])   # (100, 25) (100, 25)\n",
    "    res03e = Concatenate()([res03ae, res03be, res02e])\n",
    "    \n",
    "    d1e = Conv1D(filters=round(hfilters*alpha), kernel_size=round(hkernel_size1*beta), padding='causal', dilation_rate=8)(res03e)\n",
    "    d1ae = Activation(activations.tanh)(d1e)\n",
    "    d1be = Activation(activations.sigmoid)(d1e)\n",
    "    d1e = Multiply()([d1ae, d1be])\n",
    "    d1e = Conv1D(filters=num_features, kernel_size=round(hkernel_size2*beta), padding='causal', dilation_rate=4)(d1e)    \n",
    "    d1ae = Activation(activations.tanh)(d1e)\n",
    "    d1be = Activation(activations.sigmoid)(d1e)\n",
    "    d1e = Multiply()([d1ae, d1be])\n",
    "    res04ae = Add()([res03ae, d1e])   # (100, 25) (100, 25)\n",
    "    \n",
    "    d2e = Conv1D(filters=round(hfilters*alpha), kernel_size=round(hkernel_size1*beta), padding='causal', dilation_rate=8)(res03e) \n",
    "    d2ae = Activation(activations.tanh)(d2e)\n",
    "    d2be = Activation(activations.sigmoid)(d2e)\n",
    "    d2e = Multiply()([d2ae, d2be])\n",
    "    \n",
    "    d2e = Conv1D(filters=num_features, kernel_size=round(hkernel_size2*beta), padding='causal', dilation_rate=4)(d2e) \n",
    "    d2ae = Activation(activations.tanh)(d2e)\n",
    "    d2be = Activation(activations.sigmoid)(d2e)\n",
    "    d2e = Multiply()([d2ae, d2be])\n",
    "    \n",
    "    res04be = Subtract()([res02be, d2e])   # (100, 25) (100, 25)\n",
    "    res04e = Concatenate()([res04ae, res04be, res03e])\n",
    "    \n",
    "    d1e = Conv1D(filters=round(hfilters*alpha), kernel_size=round(hkernel_size1*beta), padding='causal', dilation_rate=4)(res04e)\n",
    "    d1ae = Activation(activations.tanh)(d1e)\n",
    "    d1be = Activation(activations.sigmoid)(d1e)\n",
    "    d1e = Multiply()([d1ae, d1be])\n",
    "    \n",
    "    d1e = Conv1D(filters=num_features, kernel_size=round(hkernel_size2*beta), padding='causal', dilation_rate=2)(d1e)    \n",
    "    d1ae = Activation(activations.tanh)(d1e)\n",
    "    d1be = Activation(activations.sigmoid)(d1e)\n",
    "    d1e = Multiply()([d1ae, d1be])\n",
    "    \n",
    "    res05ae = Add()([res04ae, d1e])   # (100, 25) (100, 25)\n",
    "    \n",
    "    d2e = Conv1D(filters=round(hfilters*alpha), kernel_size=round(hkernel_size1*beta), padding='causal', dilation_rate=4)(res04e) \n",
    "    d2ae = Activation(activations.tanh)(d2e)\n",
    "    d2be = Activation(activations.sigmoid)(d2e)\n",
    "    d2e = Multiply()([d2ae, d2be])\n",
    "    \n",
    "    d2e = Conv1D(filters=num_features, kernel_size=round(hkernel_size2*beta), padding='causal', dilation_rate=2)(d2e) \n",
    "    d2ae = Activation(activations.tanh)(d2e)\n",
    "    d2be = Activation(activations.sigmoid)(d2e)\n",
    "    d2e = Multiply()([d2ae, d2be])\n",
    "    \n",
    "    res05be = Subtract()([res04be, d2e])   # (100, 25) (100, 25)\n",
    "    res05e = Concatenate()([res05ae, res05be, res04e])\n",
    "    \n",
    "    d1e = Conv1D(filters=round(hfilters*alpha), kernel_size=round(hkernel_size1*beta), padding='causal', dilation_rate=2)(res05e)\n",
    "    d1ae = Activation(activations.tanh)(d1e)\n",
    "    d1be = Activation(activations.sigmoid)(d1e)\n",
    "    d1e = Multiply()([d1ae, d1be])\n",
    "    \n",
    "    d1e = Conv1D(filters=num_features, kernel_size=round(hkernel_size2*beta), padding='causal', dilation_rate=1)(d1e)    \n",
    "    d1ae = Activation(activations.tanh)(d1e)\n",
    "    d1be = Activation(activations.sigmoid)(d1e)\n",
    "    d1e = Multiply()([d1ae, d1be])\n",
    "\n",
    "    res06ae = Add()([res05ae, d1e])   # (100, 25) (100, 25)\n",
    "    \n",
    "    d2e = Conv1D(filters=round(hfilters*alpha), kernel_size=round(hkernel_size1*beta), padding='causal', dilation_rate=2)(res05e) \n",
    "    d2ae = Activation(activations.tanh)(d2e)\n",
    "    d2be = Activation(activations.sigmoid)(d2e)\n",
    "    d2e = Multiply()([d2ae, d2be])\n",
    "    d2e = Conv1D(filters=num_features, kernel_size=round(hkernel_size2*beta), padding='causal', dilation_rate=1)(d2e) \n",
    "    d2ae = Activation(activations.tanh)(d2e)\n",
    "    d2be = Activation(activations.sigmoid)(d2e)\n",
    "    d2e = Multiply()([d2ae, d2be])\n",
    "\n",
    "    res06be = Subtract()([res05be, d2e])   # (100, 25) (100, 25)\n",
    "    res06e = Concatenate()([res05ae, res05be])\n",
    "    \n",
    "    res10e = Concatenate()([res02e, res03e, res04e, res05e, res06e])   # \n",
    "    \n",
    "    #print('res10 :', res10.shape)  # (None, 24, 11) \n",
    "    \n",
    "    oute = Conv1D(720, 1, padding='same', activation=PReLU())(res10e)   # 256, 11X10=110\n",
    "    oute = Dropout(0.2)(oute)   #SpatialDropout1D\n",
    "    \n",
    "    oute = Conv1D(360, 1, padding='same', activation=PReLU())(oute) # 512,  110X5=550\n",
    "    oute = Dropout(0.2)(oute)\n",
    "    \n",
    "    oute = GlobalAveragePooling1D()(oute) # pool_size=2, strides=1\n",
    "    \n",
    "    oute = Dense(24)(oute) \n",
    "    modele = Model(inputs=[visible1e], outputs=[oute])\n",
    "    \n",
    "    print(modele.summary())\n",
    "    \n",
    "    modele.compile(loss=mse_mae, optimizer='adam', metrics=['mse','mae','mape'])\n",
    "    early_stopping =EarlyStopping(monitor='val_loss', patience=10)\n",
    "    batch_size = 168\n",
    "    epochs = 1000\n",
    "\n",
    "    history_e = LossHistory()\n",
    "    history_e.init()\n",
    "    \n",
    "    #hist = model.fit(trX, trY, epochs=epochs, batch_size=batch_size, shuffle=False, validation_data=(vaX, vaY), callbacks=[history, early_stopping])  # , checkpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "b3d3cea6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2538"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "8d536660",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "131/131 [==============================] - 27s 176ms/step - loss: 0.2851 - mse: 0.0191 - mae: 0.0938 - mape: 484.2299 - val_loss: 0.1640 - val_mse: 0.0090 - val_mae: 0.0744 - val_mape: 426.6877\n",
      "Epoch 2/1000\n",
      "131/131 [==============================] - 21s 159ms/step - loss: 0.1772 - mse: 0.0099 - mae: 0.0781 - mape: 442.5740 - val_loss: 0.1392 - val_mse: 0.0073 - val_mae: 0.0667 - val_mape: 373.2038\n",
      "Epoch 3/1000\n",
      "131/131 [==============================] - 21s 161ms/step - loss: 0.1475 - mse: 0.0078 - mae: 0.0690 - mape: 415.0349 - val_loss: 0.1158 - val_mse: 0.0057 - val_mae: 0.0591 - val_mape: 427.9271\n",
      "Epoch 4/1000\n",
      "131/131 [==============================] - 21s 158ms/step - loss: 0.1279 - mse: 0.0065 - mae: 0.0629 - mape: 401.6848 - val_loss: 0.1039 - val_mse: 0.0049 - val_mae: 0.0549 - val_mape: 412.4030\n",
      "Epoch 5/1000\n",
      "131/131 [==============================] - 20s 151ms/step - loss: 0.1194 - mse: 0.0059 - mae: 0.0601 - mape: 411.6657 - val_loss: 0.0965 - val_mse: 0.0044 - val_mae: 0.0522 - val_mape: 381.5177\n",
      "Epoch 6/1000\n",
      "131/131 [==============================] - 20s 152ms/step - loss: 0.1111 - mse: 0.0054 - mae: 0.0573 - mape: 392.1133 - val_loss: 0.0881 - val_mse: 0.0039 - val_mae: 0.0490 - val_mape: 365.0099\n",
      "Epoch 7/1000\n",
      "131/131 [==============================] - 20s 152ms/step - loss: 0.1033 - mse: 0.0049 - mae: 0.0545 - mape: 375.7900 - val_loss: 0.0829 - val_mse: 0.0036 - val_mae: 0.0470 - val_mape: 365.3174\n",
      "Epoch 8/1000\n",
      "131/131 [==============================] - 20s 153ms/step - loss: 0.0967 - mse: 0.0044 - mae: 0.0522 - mape: 404.9582 - val_loss: 0.0772 - val_mse: 0.0032 - val_mae: 0.0447 - val_mape: 350.3123\n",
      "Epoch 9/1000\n",
      "131/131 [==============================] - 20s 152ms/step - loss: 0.0919 - mse: 0.0041 - mae: 0.0504 - mape: 416.7791 - val_loss: 0.0755 - val_mse: 0.0031 - val_mae: 0.0441 - val_mape: 333.5597\n",
      "Epoch 10/1000\n",
      "131/131 [==============================] - 20s 153ms/step - loss: 0.0882 - mse: 0.0039 - mae: 0.0491 - mape: 386.9801 - val_loss: 0.0722 - val_mse: 0.0029 - val_mae: 0.0427 - val_mape: 323.2903\n",
      "Epoch 11/1000\n",
      "131/131 [==============================] - 20s 152ms/step - loss: 0.0849 - mse: 0.0037 - mae: 0.0478 - mape: 390.9906 - val_loss: 0.0706 - val_mse: 0.0029 - val_mae: 0.0420 - val_mape: 312.8424\n",
      "Epoch 12/1000\n",
      "131/131 [==============================] - 20s 152ms/step - loss: 0.0821 - mse: 0.0035 - mae: 0.0466 - mape: 364.7795 - val_loss: 0.0699 - val_mse: 0.0028 - val_mae: 0.0417 - val_mape: 317.0328\n",
      "Epoch 13/1000\n",
      "131/131 [==============================] - 20s 152ms/step - loss: 0.0796 - mse: 0.0034 - mae: 0.0456 - mape: 370.5096 - val_loss: 0.0682 - val_mse: 0.0027 - val_mae: 0.0410 - val_mape: 308.8811\n",
      "Epoch 14/1000\n",
      "131/131 [==============================] - 20s 152ms/step - loss: 0.0778 - mse: 0.0033 - mae: 0.0449 - mape: 381.0298 - val_loss: 0.0683 - val_mse: 0.0027 - val_mae: 0.0410 - val_mape: 320.7114\n",
      "Epoch 15/1000\n",
      "131/131 [==============================] - 20s 152ms/step - loss: 0.0765 - mse: 0.0032 - mae: 0.0444 - mape: 419.0916 - val_loss: 0.0669 - val_mse: 0.0027 - val_mae: 0.0404 - val_mape: 298.5114\n",
      "Epoch 16/1000\n",
      "131/131 [==============================] - 20s 152ms/step - loss: 0.0759 - mse: 0.0032 - mae: 0.0441 - mape: 371.3715 - val_loss: 0.0686 - val_mse: 0.0027 - val_mae: 0.0412 - val_mape: 320.7383\n",
      "Epoch 17/1000\n",
      "131/131 [==============================] - 20s 151ms/step - loss: 0.0755 - mse: 0.0032 - mae: 0.0439 - mape: 394.1775 - val_loss: 0.0676 - val_mse: 0.0027 - val_mae: 0.0407 - val_mape: 298.4185\n",
      "Epoch 18/1000\n",
      "131/131 [==============================] - 20s 151ms/step - loss: 0.0747 - mse: 0.0031 - mae: 0.0436 - mape: 367.4511 - val_loss: 0.0691 - val_mse: 0.0028 - val_mae: 0.0415 - val_mape: 319.0777\n",
      "Epoch 19/1000\n",
      "131/131 [==============================] - 20s 152ms/step - loss: 0.0740 - mse: 0.0031 - mae: 0.0433 - mape: 389.0114 - val_loss: 0.0669 - val_mse: 0.0026 - val_mae: 0.0404 - val_mape: 306.0923\n",
      "Epoch 20/1000\n",
      "131/131 [==============================] - 20s 151ms/step - loss: 0.0737 - mse: 0.0030 - mae: 0.0432 - mape: 377.6488 - val_loss: 0.0668 - val_mse: 0.0026 - val_mae: 0.0404 - val_mape: 302.6958\n",
      "Epoch 21/1000\n",
      "131/131 [==============================] - 20s 152ms/step - loss: 0.0735 - mse: 0.0030 - mae: 0.0431 - mape: 369.2015 - val_loss: 0.0659 - val_mse: 0.0026 - val_mae: 0.0400 - val_mape: 294.5726\n",
      "Epoch 22/1000\n",
      "131/131 [==============================] - 20s 152ms/step - loss: 0.0729 - mse: 0.0030 - mae: 0.0429 - mape: 348.9707 - val_loss: 0.0663 - val_mse: 0.0026 - val_mae: 0.0402 - val_mape: 295.7594\n",
      "Epoch 23/1000\n",
      "131/131 [==============================] - 20s 152ms/step - loss: 0.0727 - mse: 0.0030 - mae: 0.0428 - mape: 385.6933 - val_loss: 0.0661 - val_mse: 0.0026 - val_mae: 0.0400 - val_mape: 294.6389\n",
      "Epoch 24/1000\n",
      "131/131 [==============================] - 20s 152ms/step - loss: 0.0725 - mse: 0.0030 - mae: 0.0427 - mape: 349.7944 - val_loss: 0.0677 - val_mse: 0.0027 - val_mae: 0.0408 - val_mape: 322.5251\n",
      "Epoch 25/1000\n",
      "131/131 [==============================] - 20s 152ms/step - loss: 0.0711 - mse: 0.0029 - mae: 0.0421 - mape: 335.6453 - val_loss: 0.0687 - val_mse: 0.0027 - val_mae: 0.0412 - val_mape: 325.5930\n",
      "Epoch 26/1000\n",
      "131/131 [==============================] - 20s 152ms/step - loss: 0.0707 - mse: 0.0029 - mae: 0.0419 - mape: 371.7038 - val_loss: 0.0684 - val_mse: 0.0027 - val_mae: 0.0411 - val_mape: 332.7079\n",
      "Epoch 27/1000\n",
      "131/131 [==============================] - 20s 152ms/step - loss: 0.0705 - mse: 0.0029 - mae: 0.0419 - mape: 335.0448 - val_loss: 0.0674 - val_mse: 0.0027 - val_mae: 0.0407 - val_mape: 312.2782\n",
      "Epoch 28/1000\n",
      "131/131 [==============================] - 20s 152ms/step - loss: 0.0708 - mse: 0.0029 - mae: 0.0420 - mape: 333.8010 - val_loss: 0.0653 - val_mse: 0.0026 - val_mae: 0.0397 - val_mape: 302.4599\n",
      "Epoch 29/1000\n",
      "131/131 [==============================] - 20s 152ms/step - loss: 0.0705 - mse: 0.0029 - mae: 0.0418 - mape: 342.4004 - val_loss: 0.0666 - val_mse: 0.0026 - val_mae: 0.0403 - val_mape: 302.9957\n",
      "Epoch 30/1000\n",
      "131/131 [==============================] - 20s 151ms/step - loss: 0.0705 - mse: 0.0029 - mae: 0.0419 - mape: 315.9245 - val_loss: 0.0659 - val_mse: 0.0026 - val_mae: 0.0399 - val_mape: 337.4234\n",
      "Epoch 31/1000\n",
      "131/131 [==============================] - 20s 152ms/step - loss: 0.0696 - mse: 0.0028 - mae: 0.0415 - mape: 328.8761 - val_loss: 0.0658 - val_mse: 0.0026 - val_mae: 0.0399 - val_mape: 308.9893\n",
      "Epoch 32/1000\n",
      "131/131 [==============================] - 20s 151ms/step - loss: 0.0692 - mse: 0.0028 - mae: 0.0413 - mape: 381.1266 - val_loss: 0.0677 - val_mse: 0.0027 - val_mae: 0.0408 - val_mape: 323.7728\n",
      "Epoch 33/1000\n",
      "131/131 [==============================] - 20s 151ms/step - loss: 0.0690 - mse: 0.0028 - mae: 0.0412 - mape: 390.3159 - val_loss: 0.0667 - val_mse: 0.0026 - val_mae: 0.0403 - val_mape: 306.1354\n",
      "Epoch 34/1000\n",
      "131/131 [==============================] - 20s 152ms/step - loss: 0.0684 - mse: 0.0027 - mae: 0.0409 - mape: 363.7295 - val_loss: 0.0677 - val_mse: 0.0027 - val_mae: 0.0408 - val_mape: 305.9721\n",
      "Epoch 35/1000\n",
      "131/131 [==============================] - 20s 151ms/step - loss: 0.0678 - mse: 0.0027 - mae: 0.0407 - mape: 386.4495 - val_loss: 0.0726 - val_mse: 0.0030 - val_mae: 0.0430 - val_mape: 332.3703\n",
      "Epoch 36/1000\n",
      "131/131 [==============================] - 20s 151ms/step - loss: 0.0684 - mse: 0.0027 - mae: 0.0409 - mape: 355.2827 - val_loss: 0.0683 - val_mse: 0.0027 - val_mae: 0.0411 - val_mape: 307.9594\n",
      "Epoch 37/1000\n",
      "131/131 [==============================] - 20s 152ms/step - loss: 0.0684 - mse: 0.0027 - mae: 0.0409 - mape: 319.9655 - val_loss: 0.0696 - val_mse: 0.0028 - val_mae: 0.0416 - val_mape: 312.0046\n",
      "Epoch 38/1000\n",
      "131/131 [==============================] - 20s 152ms/step - loss: 0.0676 - mse: 0.0027 - mae: 0.0406 - mape: 343.5739 - val_loss: 0.0704 - val_mse: 0.0028 - val_mae: 0.0419 - val_mape: 306.5027\n"
     ]
    }
   ],
   "source": [
    "# %%time\n",
    "    histe = modele.fit(trXe, trYe, epochs=epochs, batch_size=b_size, shuffle=False, validation_data=(vaXe, vaYe), callbacks=[history_e, early_stopping])  # , checkpoint"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e00afbe7",
   "metadata": {},
   "source": [
    "### Saving FFEL Model Training Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "51031da5",
   "metadata": {},
   "outputs": [],
   "source": [
    "eloss_history = histe.history['loss']\n",
    "valeloss_history = histe.history['val_loss']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "f5777c3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#np.savetxt('ramp_elosshistory.txt',(eloss_history, valeloss_history))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "4c398aad",
   "metadata": {},
   "outputs": [],
   "source": [
    "modele.save('Error Learning Ramp Model_lead.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "aaae6d1e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4574"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c60c6785",
   "metadata": {},
   "source": [
    "## FFEL Model Test Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "a15310fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 168\n",
    "trainePredict = modele.predict(Xe, batch_size=batch_size)\n",
    "etePredict = modele.predict(eteX, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "604aa912",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error Training Score > MSE ==  0.0028353837893406726  MAE ==  0.04166487740595779  RMSE ==  0.05324832193919986\n"
     ]
    }
   ],
   "source": [
    "trePredict = trainePredict.reshape([-1])\n",
    "trainYe = Ye.reshape([-1])\n",
    "\n",
    "print('Error Training Score > MSE == ', (np.mean(np.square(trainYe-trePredict))), ' MAE == ', mean_absolute_error(trainYe,trePredict), ' RMSE == ', np.sqrt(np.mean(np.square(trainYe-trePredict))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "2bda4f4a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error Training Score > MSE ==  0.002951717014448956  MAE ==  0.04264055046100602  RMSE ==  0.05432970655588852\n"
     ]
    }
   ],
   "source": [
    "etestPredict = etePredict.reshape([-1])\n",
    "testYe = eteY.reshape([-1])\n",
    "\n",
    "print('Error Training Score > MSE == ', (np.mean(np.square(testYe-etestPredict))), ' MAE == ', mean_absolute_error(testYe,etestPredict), ' RMSE == ', np.sqrt(np.mean(np.square(testYe-etestPredict))))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "907ec801",
   "metadata": {},
   "source": [
    "## Final Prediction Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "c1dd9def",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3317, 24)\n"
     ]
    }
   ],
   "source": [
    "testPredict = tePredict.reshape(-1,24)\n",
    "addtestPredict = -etePredict + testPredict[timesteps:-2,:]\n",
    "print(addtestPredict.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "ab5a84a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error Test Score > MSE ==  0.013663134495961227  MAE ==  0.0923658812924052 MAPE ==  18.61691932968386\n",
      "Error Test Score > MSE ==  0.002951717023037153  MAE ==  0.04264055052190879 MAPE ==  8.65737314233121\n"
     ]
    }
   ],
   "source": [
    "print('Error Test Score > MSE == ', (np.mean(np.square(teY[timesteps:-2,:]-testPredict[timesteps:-2,:]))), ' MAE == ', mean_absolute_error(teY[timesteps:-2,:], testPredict[timesteps:-2,:]), 'MAPE == ', mean_absolute_percentage_error(teY[timesteps:-2,:], testPredict[timesteps:-2,:]))\n",
    "print('Error Test Score > MSE == ', (np.mean(np.square(teY[timesteps:-2,:]-addtestPredict))), ' MAE == ', mean_absolute_error(teY[timesteps:-2,:], addtestPredict), 'MAPE == ', mean_absolute_percentage_error(teY[timesteps:-2,:], addtestPredict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "580aeb71",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
